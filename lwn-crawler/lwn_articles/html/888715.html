        <!DOCTYPE html>
        <html lang="en">
        <head><title>Readahead: the documentation I wanted to read [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/888715/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/890578/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/888715/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Readahead: the documentation I wanted to read</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>LWN.net needs you!</b>
<p>
Without subscribers, LWN would simply not exist.  Please consider
       <a href="/Promo/nst-nag2/subscribe">signing up for a subscription</a> and helping
       to keep LWN publishing.
</blockquote>
<div class="GAByline">
           <p>April 8, 2022</p>
           <p>This article was contributed by Neil&nbsp;Brown</p>
           </div>
<p>The readahead code in the Linux kernel is nominally responsible for
reading data that has not yet been explicitly requested from storage,
with the idea that it might be needed soon.  The code is stable, functional, widely
used, and uncontroversial, so it is reasonable to expect the code to be of
high quality, and largely this is true.  Recently, I found the need to
document this code, which naturally shone a rather different light on
it.  This work revealed minor problems with functionality and significant
problems with naming.


<p>My particular reason for wanting documentation probably colors my view
of the code so I'll start there.  Once upon a time, Linux had a strong
concept of "congestion" as it applied to I/O paths.  If the queue of
requests to some device grew too large, the backing device would be
marked as "congested" and certain optional I/O requests would be skipped
or delayed, particularly writeback and readahead.  As time has passed,
<a href="/Articles/873672/">so too (apparently) has the need for congestion management</a>.  Maybe this
is because many I/O devices are now faster than our CPUs but, whatever
the reason, the block layer no longer tracks congestion and only a few
virtual "backing devices" continue this outdated practice.

<p>In Linux 5.16, the only backing device that gets marked as "read
congested" is the virtual device
used for FUSE filesystems.  As part of a project to remove all remnants
of congestion tracking, I proposed that there was really nothing special about
FUSE, and it should just accept all readahead requests just like
everyone else.  Miklos Szeredi, the maintainer of FUSE, <a href="/ml/linux-kernel/CAJfpegt-igF8HqsDUcMzfU0jYv8WpofLy0Uv0YnXLzsfx=tkGg@mail.gmail.com/">found my
reasoning to be unsatisfactory</a> — and who could blame him?  If
FUSE doesn't want readahead requests, it shouldn't have to accept them.
Trying to understand how FUSE could safely say "no" to readahead,
without having to maintain the congestion-tracking functionality in
common code, started me on the path to understanding readahead — once it
was <a
href="/ml/linux-kernel/YfiUaJ59A3px+DqP@casper.infradead.org/">explained to
me</a> that it wasn't as simple as just changing the 
"readahead" callback in FUSE to return zero.

<p>The main part of the API exported by <tt>mm/readahead.c</tt> is two functions:
<a
href="https://elixir.bootlin.com/linux/v5.17/source/mm/readahead.c#L553"><tt>page_cache_sync_ra()</tt></a>
and <a
href="https://elixir.bootlin.com/linux/v5.17/source/mm/readahead.c#L583"><tt>page_cache_async_ra()</tt></a>.
This functionality is also available with a slightly simpler interface as
<a
href="https://elixir.bootlin.com/linux/v5.17/source/include/linux/pagemap.h#L1037"><tt>page_cache_sync_readahead()</tt></a>
and  <a
href="https://elixir.bootlin.com/linux/v5.17/source/include/linux/pagemap.h#L1058"><tt>page_cache_async_readahead()</tt></a>,
which
are nicely documented in <a
href="https://www.kernel.org/doc/html/v5.18-rc1/core-api/mm-api.html?highlight=page_cache_async_readahead#c.page_cache_sync_readahead">the
kernel documentation</a>.

<p>
<h4>Sync and async</h4>

<p>Unfortunately, that documentation is not explicit on how the "sync" or
"async" in the names are relevant.  Clarifying this was among my
first tasks so, to help with that clarification, I'll refer you to a
selection from <a
href="https://www.kernel.org/doc/html/v5.18-rc1/core-api/mm-api.html#readahead">my
new documentation</a>, which was <a 
href="https://git.kernel.org/linus/84dacdbd5352">merged for the 5.18
release</a>.  It starts:

<blockquote class="bq">
<p>Readahead is used to read content into the page cache before it is
explicitly requested by the application.  Readahead only ever attempts
to read pages that are not yet in the page cache.  If a page is present
but not up-to-date, readahead will not try to read it.  In that case a
simple -&gt;readpage() will be requested.

<p>Readahead is triggered when an application read request (whether a
system call or a page fault) finds that the requested page is not in the
page cache, or that it is in the page cache and has the <tt>PG_readahead</tt>
flag set.  This flag indicates that the page was loaded as part of a
previous readahead request and now that it has been accessed, it is
time for the next read-ahead.

<p>Each readahead request is partly synchronous read, and partly async
readahead.

</blockquote>
<p>We stop here, in mid-paragraph, to focus on those two terms: sync and async.
Readahead is, by its nature, asynchronous — nothing is waiting for it.
An explicitly requested read, instead, will ultimately be synchronous, as the
operation cannot complete until the data arrives.  These two modes are
clearly related and handling them both in the same code makes sense.
Describing them both as being "readahead" — a choice that was
effectively forced on me by the code — is not so defensible.

<p>Anyone who has been around computers long enough to know that a
"kilobyte" isn't (necessarily) 1000 bytes will also know that we
technologists often follow the practice of Lewis Carroll's "Humpty Dumpty" in
<a href="https://www.gutenberg.org/files/12/12-h/12-h.htm"><i>Through the
Looking Glass</i></a>:

<blockquote class="bq">
<p>"When I use a word," Humpty Dumpty said in rather a scornful tone, "it
means just what I choose it to mean — neither more nor less."

</blockquote>
<p>We seem to make that mistake rather more than is good for us, and the
readahead code is certainly not innocent.
<p>
Each filesystem can provide
an <a
href="https://elixir.bootlin.com/linux/v5.17/source/include/linux/fs.h#L363"><tt>address_space_operations</tt></a>
method, named <tt>readahead()</tt>, to initiate a read; it is on this
basis that the term "readahead request"
is used in the documentation.  There is also an address-space operation
called <tt>readpages()</tt>, though it was <a
href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=8151b4c8bee43cea7a28cb0300123df90880e60c">marked
as deprecated</a> in
the middle of 2020 and will be <a
href="https://git.kernel.org/linus/704528d895dd">removed for 5.18</a>.  These two functions
have much the same functionality (they both issue read requests for a
collection of pages).  The newer <tt>readahead()</tt> has a much better interface
(the details are beyond the scope of this article), but <tt>readpages()</tt> has
undoubtedly the better name — because that is what they both do. They don't
just "read ahead" but also issue reads that have explicitly been
requested.

<p>Once one realizes that the functionality of <tt>readahead()</tt> is just to
submit read requests, some of which the caller will wait for ("sync")
and some of which the caller won't wait for ("async"), the intention of
the code starts to become a lot clearer.  Names matter.
<p>
<h4>When readahead can be skipped</h4>

<p>Returning to the original problem of giving FUSE the opportunity to skip
readahead, a way forward now appears.  The <tt>readahead()</tt> function that
FUSE supplies must read all the pages that will be waited for, but
it doesn't need to read the remainder.  One of the improvements to the
interface that came with the introduction of the <tt>readahead()</tt> operation
is that more information is available to the filesystem.  This
information includes a <tt>struct
file_ra_state</tt>, which contains 
a field called <tt>async_size</tt>.  Aha!  This must be the size of the readahead
section.
<p>
Or is it?  Can we trust the name?  This structure is,
fortunately, <a
href="https://www.kernel.org/doc/html/v5.18-rc1/filesystems/api-summary.html?highlight=file_ra_state#c.file_ra_state">documented</a>;
the description for this <tt>async_size</tt> field 
reads: "<q>Start next readahead when this many pages are left</q>".  What does
that mean, and what does it have to do with being "async"?  Possibly
reading some more of the new documentation will help.

<blockquote class="bq">
<p>Each readahead request is partly synchronous read, and partly async
readahead.  This is reflected in the struct file_ra_state which
contains -&gt;size being to total number of pages, and -&gt;async_size which
is the number of pages in the async section.  The first page in this
async section will have PG_readahead set as a trigger for a subsequent
readahead.  Once a series of sequential reads has been established,
there should be no need for a synchronous component and all readahead
requests will be fully asynchronous.

</blockquote>
<p>The second sentence, which presents the meaning of <tt>async_size</tt>, is
something I made up — it was not previously present in any documentation
and is not completely consistent with the code, though it matches the
field name perfectly.  The third sentence, about the <tt>PG_readahead</tt> flag,
matches the code and pre-existing documentation.

<p>A core idea in readahead is to take a risk and read more than was
requested.  If that risk brings rewards and the extra data is
accessed, then that justifies a further risk of reading even more data
that hasn't been requested.  When performing a single sequential read
through a file, the details of past behavior can easily be stored in
the <tt>struct file_ra_state</tt>.  However if an application reads from two,
three, or more, sections of the file and interleaves these sequential
reads, then <tt>file_ra_state</tt> cannot keep track of all that state.
Instead we rely on the content already in the page cache.  Specifically
we have a flag, <tt>PG_readahead</tt>, which can be set on a page.  That name
should be read in the past tense: the page was read ahead.  A risk was
taken when reading that page so, if it pays off and the page is accessed,
then that is justification for taking another risk and reading some
more.

<p>Which page should this flag be set on?  Another core premise of
readahead is that reads are often sequential, and it is only on this
basis that we take a risk and read the following pages.  So if the first
of the ahead-read pages is accessed, then a sequential read can be
assumed.  If some later page is read, less can be concluded.  It seems
clear to me that <tt>PG_readahead</tt> must be set on the first of the pages
that were opportunistically requested.  This is consistent with the
documented behavior of setting it based on the value of <tt>async_size</tt>,
and is consistent with <em>most</em> of the code, though there are a couple of
places where some different value is used with no clear
justification.

<p>This, then, is enough to allow FUSE to choose when to skip pages in its
<tt>readahead()</tt> handler — it looks at the <tt>async_size</tt> value —
but it isn't
quite enough for completely correct behavior.  When <tt>readahead()</tt> is
called, the pages of memory have already been added to the page cache,
though they have not yet been marked
up-to-date.  Leaving them there without initiating a read can result in
later attempts to read them being less efficient.  This can <a href="https://www.spinics.net/lists/mm-commits/msg163315.html">easily be
fixed</a> by having the caller drop pages from the page cache if
the <tt>readahead()</tt> function chose to ignore them and indicated this by
<em>not</em> updating some (private) fields in <a
href="https://elixir.bootlin.com/linux/v5.17/source/include/linux/pagemap.h#L993"><tt>struct
readahead_control</tt></a>.

<p>
<h4>Oddities</h4>

<p>There is a bit more to the documentation, and there are more oddities
that only came to light because of the need to document.  So, picking up
where we left off:

<blockquote class="bq">
<p>When either of the triggers causes a readahead, three numbers need to
be determined: the start of the region, the size of the region, and the
size of the async tail.

<p>The start of the region is simply the first page address at or after
the accessed address, which is not currently populated in the page
cache.  This is found with a simple search in the page cache.

<p>The size of the async tail is determined by subtracting the size that
was explicitly requested from the determined request size, unless this
would be less than zero — then zero is used.  NOTE THIS CALCULATION IS
WRONG WHEN THE START OF THE REGION IS NOT THE ACCESSED PAGE.

</blockquote>
<p>Often I have used the act of documentation as a means for finding and
fixing bugs — if accurate documentation starts to look contorted, it can
be easier to fix the code first so as to allow the documentation to be
more coherent.  In this case I chose to leave the document clumsy, in
part because naming was again a problem, and as we know, finding good
names is hard.

<p>As mentioned, the readahead code has two API functions with
unfortunate names: <tt>page_cache_sync_ra()</tt> and <tt>page_cache_async_ra()</tt>.
These are called in response to the two triggers — when trying to access
a page that is not cached, or when accessing a page that was flagged as
<tt>PG_readahead</tt>.  Both might issue reads that will soon be waited on (sync)
as well as reads that might not be (async).

<p>Each of these functions has a final argument called <tt>req_count</tt>, which
is the count of pages in the initial request.  The implication is that
we need at least that many pages, but it is OK to request more if that
seems appropriate.  It is the meaning and use of <tt>req_count</tt> that
resulted in that loud NOTE ending that above section of documentation.

<p>Interpreting <tt>req_count</tt> as "size of the initial request" matches
the name, but it isn't always obvious that this is the number being
passed in.  As we have seen, the logic in the readahead code is mostly
about guessing how much data might be needed in the future.  Some
callers of these functions already <em>know</em> that a sequential read is
happening, for example because the <a href="https://man7.org/linux/man-pages/man2/madvise.2.html"><tt>madvise()</tt> system call</a> has
been used to declare the application's intentions.  In these cases,
<tt>req_count</tt> is set to a suitably large number.
This isn't exactly the number of pages that are needed now, but it is
  the number of pages that are <em>known</em> to be wanted, so these are
  pages that the filesystem should not skip just because it is
  inconvenient to read them just now.

<p>With the caveat that the request may include explicitly requested
future pages, it is fairly clear what <tt>req_count</tt> means, but how is it
used?  Before diving in to explore this, it will help to read a bit more
of the new documentation to understand how the size of a readahead
request is calculated.

<blockquote class="bq">
<p>The size of the region is normally determined from the size of the
previous readahead which loaded the preceding pages.  This may be
discovered from the struct file_ra_state for simple sequential reads,
or from examining the state of the page cache when multiple
sequential reads are interleaved.  Specifically: where the readahead
was triggered by the <tt>PG_readahead</tt> flag, the size of the previous
readahead is assumed to be the number of pages from the triggering
page to the start of the new readahead.  In these cases, the size of
the previous readahead is scaled, often doubled, for the new
readahead, though see get_next_ra_size() for details.

</blockquote>
<p>For the <tt>page_cache_sync_ra()</tt> case, called when a wanted page is
missing, one would expect <tt>req_count</tt> to be at least one, and that is in
fact the case.  Some number of pages will be allocated, depending how
big a hole there is in the page cache, how big the request is, and how
much readahead seems justified.  These pages are added to the page cache
and the filesystem's <tt>readahead()</tt> function is called to load them.

<p>When <tt>page_cache_async_ra()</tt> is called because a <tt>PG_readahead</tt> flagged
page was found, the situation is different.  The set of pages that will
be read will <em>not</em> include the page that was just found (it has already been
read) and probably not some number of subsequent pages.  The code will
search through the page cache for the first missing page, and consider
reading from there.  How many of these pages will be among those needed
for the initial request?  Maybe some, certainly not <tt>req_count</tt> of them.

<p>That last claim of the relationship between <tt>req_count</tt> and the pages
actually read is based on assumptions which, as I have occasionally
suggested, are not always completely consistent with the code.  To be
sure, we need to go back to the code and see how <tt>req_count</tt> is actually
used in the <tt>page_cache_async_ra()</tt> case.
Fortunately we have many years of development history in Git, and the
documentation found for individual patches is often better than
documentation found in the code.
<p>
<h4><tt>req_count</tt> through the ages</h4>

<p>Prior to Linux 2.6.31, <tt>req_count</tt> (then called <tt>req_size</tt>) wasn't used
for the reads triggered by <tt>PG_readahead</tt> at all.  The <a
href="https://git.kernel.org/linus/160334a0cfa8">change</a> in that
release caused it to be used to increase the size of ahead reads.
Previously, this was calculated as the size of the previous ahead read,
scaled up by a factor of two or four.  Since then, it is the size of the
previous ahead read <em>plus <tt>req_count</tt></em>, and then scaled up.  The
justification for this change was:

<blockquote class="bq">
<p>Make sure interleaved readahead size is larger than request size.  This
also makes the readahead window grow up more quickly.

</blockquote>
<p>Unfortunately, there is no indication of the sort of workload that would
benefit from this change.  To me, it has the appearance of <tt>req_count</tt>
being used not because it was the right number based on some theoretical
analysis, but because it was an easily available number that was about
the right size.  So this doesn't provide much insight into what
<tt>req_count</tt> is supposed to <em>mean</em>.

<p>Then, in Linux 4.10, <tt>req_count</tt> found a new use.  <a
href="https://git.kernel.org/linus/9491ae4aade6">That patch</a> allowed
the number of pages requested in the readahead process to be at least
the size of the original request, even if that is larger that maximum
readahead size that is configured (as long as it wasn't bigger than the
device was configured to accept).  This is a clear acknowledgment that
part of the "readahead" is really a synchronous read, not to be
constrained by readahead limits.  It also emphasizes that <tt>req_count</tt> isn't
simply a size (maybe to be used for scaling), but it identifies a
specific set of pages — from the starting point of the request.  So when
the starting point for readahead is moved forward over any pages that
are already in the page cache, the <tt>req_count</tt> really should be reduced
by the number of pages skipped over.  Only then will it still signify
the number of pages that are part of the original request, which still
need to be read and which can justify exceeding the maximum readahead
size.

<p>From a purely behavioral perspective, this lack of clarity over the
meaning of this parameter may not be all that important.  Readahead
size calculations are heuristics.  There is no right answer and, if a
couple of extra fudge factors slip in by mistake, it is just a different
heuristic.  But from the perspective of wanting to understand the code,
and particularly of wanting to change the code without breaking
anything, this sort of detail can be quite important.

<p>As mentioned, I want the filesystem to know how many pages were
explicitly requested, and how many were heuristically suggested.  This
requires a clear understanding of what <tt>req_count</tt> means.  Getting
slightly incorrect data may not hurt a lot, but it certainly doesn't
help.

<p>
<h4>The rest of the story</h4>

<p>And now we can read the remainder of the documentation, which hopefully
will integrate some of the ideas already explored.  As it is aimed at
people who are already generally familiar with the Linux page cache, it
contains some concepts such as page locking that are best just skipped
over by the casual reader.

<blockquote class="bq">
<p>If the size of the previous read cannot be determined, the number of
preceding pages in the page cache is used to estimate the size of
a previous read.  This estimate could easily be misled by random
reads being coincidentally adjacent, so it is ignored unless it is
larger than the current request, and it is not scaled up, unless it
is at the start of file.

<p>In general, readahead is accelerated at the start of the file, as
reads from there are often sequential.  There are other minor
adjustments to the readahead size in various special cases and these
are best discovered by reading the code.

<p>The above calculation, based on the previous readahead size, determines
the size of the readahead operation, to which any requested 
read size may be added.

<p>Readahead requests are sent to the filesystem using the -&gt;readahead()
address space operation, for which mpage_readahead() is a canonical
implementation.  -&gt;readahead() should normally initiate reads on all
pages, but may fail to read any or all pages without causing an I/O
error.  The page cache reading code will issue a -&gt;readpage() request
for any page which -&gt;readahead() does not provide, and only an error
from this will be final.

<p>-&gt;readahead() will generally call readahead_page() repeatedly to get
each page from those prepared for readahead.  It may fail to read a
page by:

<ul>

<li> 
<p>not calling readahead_page() sufficiently many times, effectively
ignoring some pages, as might be appropriate if the path to
storage is congested.

</li>

<li> 
<p>failing to actually submit a read request for a given page,
possibly due to insufficient resources, or

</li>

<li> 
<p>getting an error during subsequent processing of a request.

</li>
</ul>
<p>In the last two cases, the page should be unlocked to indicate that
the read attempt has failed.  In the first case the page will be
unlocked by the caller.

<p>Those pages not in the final <tt>async_size</tt> of the request should be
considered to be important and -&gt;readahead() should not fail them due
to congestion or temporary resource unavailability, but should wait
for necessary resources (e.g.  memory or indexing information) to
become available.  Pages in the final <tt>async_size</tt> may be
considered less urgent and failure to read them is more acceptable.
In this case it is best to use delete_from_page_cache() to remove the
pages from the page cache as is automatically done for pages that
were not fetched with readahead_page().  This will allow a
subsequent synchronous readahead request to try them again.  If they
are left in the page cache, then they will be read individually using
-&gt;readpage().

</blockquote>
<p>The purpose of writing the documentation was to ensure that I understood the
code and ensure that others would be able to understand my motivation
for changes to that code.  It has, I think, achieved that.  However it
has also opened up opportunities for making the code, and the names used
in the code, more transparent.  While I would like such improvements to
happen, I'm not sure when I'll find time — through I would make time to
help if someone else wanted to drive the effort.

<p>The purpose of this meta-narrative about the writing of the
documentation is different.  I wanted to highlight the difficulty of
maintaining a coherent "intent" or "meaning" of various details of the
code, as it is modified by various people at various times.  Meanings
can drift, inconsistencies can accumulate, misnomers can become
entrenched.

As a community we have found that the best way to maximize correctness
and consistency is to have tools that alert us to problems.  Until we
have tools that can read documentation (including the implicit
documentation of variable names) and highlight inconsistencies, that is
one part of the process that we will have to continue doing ourselves.

<p>So please:  when you change code, also change the documentation.  And if
there isn't any documentation yet — write some!<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Documentation">Memory management/Documentation</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Readahead">Memory management/Readahead</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Readahead">Readahead</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Brown_Neil">Brown, Neil</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/888715/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor890836"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Readahead: the documentation I wanted to read</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 10, 2022 2:10 UTC (Sun)
                               by <b>jreiser</b> (subscriber, #11027)
                              [<a href="/Articles/890836/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I applaud this and other efforts to enhance maintainability.  Almost every study has concluded that maintenance costs are at least 60% of the life cycle cost of software.  When the writing and initial testing have been completed, then more than half of the total work remains to be done (over time). Making maintenance easier through better documentation (thorough and accurate) creates higher-quality and less-expensive software.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/890836/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor890846"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Readahead: the documentation I wanted to read</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 10, 2022 11:29 UTC (Sun)
                               by <b>donald.buczek</b> (subscriber, #112892)
                              [<a href="/Articles/890846/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thanks for the article and the docs!<br>
<p>
A year or so ago I dug my way through the code without the help of your new documentation, because I was looking for a way to fix something, which I think is sub-optimal behavior of mm: We&#x27;ve noticed that a single sequential read of a single big file (bigger than the memory available for the page cache) triggers the shrinkers and makes you lose all your valuable caches for the never-again needed data from the big file.<br>
<p>
As the readahead code is in a position to detect sequential access patterns and has access to the information of the backing file (is it &quot;big&quot;?) , I wonder, if that was the right place to detect the scenario and maybe drop specific pages from that file before more valuable pages and other caches are affected.<br>
<p>
I made some experiments with the detection part, which in our use-case is complicated by the fact, that accesses come over NFS, so they are out of order occasionally. Additional NFS drawbacks: fadvice() data not available, alternative mitigations based on cgroups not available...<br>
<p>
I could more or less identify this pattern and do a printk to show, that an opportunity was detected, but I didn&#x27;t get to the other parts, which would be<br>
<p>
- Decide, which pages of the sequential file to scarify. LRU might not be optimal here, because if the file is read a second time, it will be from the beginning again.<br>
<p>
- How to drop specific pages from the cache. I guess, there are a lot things which can be done wrongly.<br>
<p>
Probably i won&#x27;t get very far. Maybe other work ( multi-generational LRU? ) will help in that problem area.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/890846/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor890851"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Readahead: the documentation I wanted to read</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 10, 2022 18:06 UTC (Sun)
                               by <b>willy</b> (subscriber, #9762)
                              [<a href="/Articles/890851/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thanks for bringing this up! It&#x27;s a problem I&#x27;m aware of and want to fix, but don&#x27;t have a plan for how to fix yet.<br>
<p>
I am a bit confused that it evicts useful data. The way it *should* work is that the use-once pages go on the inactive list, then the inactive list gets pruned, and the pages on the active list stay there.<br>
<p>
Do you see a difference if the files are accessed locally versus over NFS? If so, it may be a bug in NFSd (that it&#x27;s adding pages to the active list instead of the inactive list, perhaps)<br>
<p>
I&#x27;m not sure that LWN comments are the best place to help you debug this; would you mind taking this to linux-mm, and/or linux-fsdevel?<br>
<p>
I don&#x27;t think that readahead is the right place to fix this, but it may be the right place to fix a related problem (which might end up fixing your problem). That is, on an SMP (indeed, NUMA system), a sequential read much larger than memory will end up triggering reclaim, as it should. The problem is that each CPU tries to take pages from the end of the LRU list and then remove it from the page cache. But all the pages belong to the same file, so they all fight over the same i_pages lock, and do not make useful progress.<br>
<p>
Since readahead is already using the i_pages lock to add the new pages to the page cache, I think it&#x27;s the right place to remove unwanted pages from the page cache, but as you note, we need to find the right pages to toss (or not ... there&#x27;s an argument that throwing away the wrong pages is cheaper than finding the right ones ...)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/890851/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor890881"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Readahead: the documentation I wanted to read</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 11, 2022 8:19 UTC (Mon)
                               by <b>donald.buczek</b> (subscriber, #112892)
                              [<a href="/Articles/890881/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; I am a bit confused that it evicts useful data.</font><br>
<p>
Sorry, I was unclear with the term &quot;valuable&quot;. I&#x27;m not talking about hot pages, which are accessed by the system. These can probably avoid eviction by returning to the active list fast enough. The (possibly) useful data lost, I&#x27;ve talked about, are other inactive pages and data from other caches (namely dcache). The original user complaint was, &quot; `ls` take ages in the morning&quot;. So only when the user took a break, his data was replaced. That by itself is not wrong and the basic strategy of LRU. How should the system now, that the user is going to return the next morning? On the other hand, the system *could* notice, that a big file, which is never going to fit into the cache,  is being read sequentially from the beginning. So keeping the already processed head of the file when memory is needed, is even more likely to be useless, because it will be evicted anyway if the observed pattern continues.<br>
<p>
<font class="QuotedText">&gt; Do you see a difference if the files are accessed locally versus over NFS</font><br>
<p>
No, the same is true for access from the local system. NFS is just a complication in the regards I mentioned  (sometimes out of order, no fadvice, no cgroups). In the thread referenced below, I&#x27;ve posted a reproducer script for a local file access.<br>
<p>
<font class="QuotedText">&gt; would you mind taking this to linux-mm, and/or linux-fsdevel</font><br>
<p>
A colleague of mine did so in August 2021 [1]<br>
<p>
Best<br>
  Donald<br>
<p>
[1]: <a href="https://lore.kernel.org/all/878157e2-b065-aaee-f26b-5c87e9ddc2d6@molgen.mpg.de/T/#m933e86097e9e02430ca6d09554648e6b3ba1c87d">https://lore.kernel.org/all/878157e2-b065-aaee-f26b-5c87e...</a><br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/890881/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor890941"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Readahead: the documentation I wanted to read</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 11, 2022 13:39 UTC (Mon)
                               by <b>willy</b> (subscriber, #9762)
                              [<a href="/Articles/890941/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Ah, I see that in my inbox now ... I read the third email in the chain (the first two went only to xfs?), but didn&#x27;t read the fourth and fifth. The usual too-much-email problem.<br>
<p>
Anyway, I think recognising this special case probably isn&#x27;t the right solution. Backup is always tricky, and your proposal would fix one-large-file but do nothing for many-small-files.<br>
<p>
I suspect the right way to go is to recognise that the page cache is large and has many easily-reclaimable pages, and shrink only the page cache. ie the problem is that backup is exerting general memory pressure when we&#x27;d really like it to only exert pressure only on the page cache. Or rather, we&#x27;d like the page cache to initially exert pressure only on the page cache. The dcache should initially exert pressure only on the dcache. Etc. If a cache can&#x27;t reclaim enough memory easily, then it should pressure other caches to shrink.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/890941/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor891090"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Readahead: the documentation I wanted to read</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 12, 2022 19:08 UTC (Tue)
                               by <b>donald.buczek</b> (subscriber, #112892)
                              [<a href="/Articles/891090/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt;  Backup is always tricky, and your proposal would fix one-large-file but do nothing for many-small-files.</font><br>
<p>
To be exact, its not backup. Our maintenance jobs run locally and are tamed via cgroups. Its (other) users.  Our scientific users often process rather big files. <br>
<p>
<font class="QuotedText">&gt; Or rather, we&#x27;d like the page cache to initially exert pressure only on the page cache. The dcache should initially exert pressure only on the dcache. Etc. If a cache can&#x27;t reclaim enough memory easily, then it should pressure other caches to shrink.</font><br>
<p>
This would probably help a lot in the problem area I described and also in some others. It good to know, that this is on your mind. The negative dentries discussion mentioned in the later lwn article seems to get into the same field.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/891090/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor890956"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Readahead: the documentation I wanted to read</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 11, 2022 14:17 UTC (Mon)
                               by <b>bfields</b> (subscriber, #19510)
                              [<a href="/Articles/890956/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>Additional NFS drawbacks: fadvice() data not available</blockquote>

<p>There is actually an IO_ADVISE operation, that Linux doesn't implement: https://www.rfc-editor.org/rfc/rfc7862.html#section-1.4.2

<p>Maybe there's a good reason it hasn't been implemented yet, but, anyway, it might be another thing worth looking into here.



      
          <div class="CommentReplyButton">
            <form action="/Articles/890956/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor890958"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">SAM / DAM files</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 11, 2022 14:18 UTC (Mon)
                               by <b>Wol</b> (subscriber, #4433)
                              [<a href="/Articles/890958/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
An OS I used in the past (Pr1mos, what else :-) flagged all files as either SAM or DAM. From the coder&#x27;s POV there was no real difference between the two - the same primitives worked the same way on all files. But the S and D stood for Sequential and Direct, and the documentation was very clear that sequential files were meant to be read from the beginning, while Direct files were quite happy reading random blocks.<br>
<p>
Is there any way this sort of information could be fed through to these routines, because there&#x27;s clearly no point reading-ahead a dam file, while there is no point caching a sam file once that bit of data has been synchronously read ...<br>
<p>
Cheers,<br>
Wol<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/890958/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor890972"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">SAM / DAM files</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 11, 2022 18:28 UTC (Mon)
                               by <b>joib</b> (subscriber, #8541)
                              [<a href="/Articles/890972/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; An OS I used in the past (Pr1mos, what else :-) flagged all files as either SAM or DAM. From the coder&#x27;s POV there was no real difference between the two - the same primitives worked the same way on all files. But the S and D stood for Sequential and Direct, and the documentation was very clear that sequential files were meant to be read from the beginning, while Direct files were quite happy reading random blocks.</font><br>
<p>
Sounds like an OS designed for Fortran, which has sequential access and direct access I/O. Or well, nowadays Fortran additionally has stream access as well, which is more like the stream of bytes model Unix and Windows provide. Fortran sequential files allow stepping forwards or backwards one record at a time (or going all the way to the beginning or end), but going forwards or backwards N records is an O(N) operation. Direct access, conceptually, is a bunch of fixed size records allowing access in any order.<br>
<p>
Needless to say, on a modern day OS which provides only the stream-of-bytes model, it&#x27;s the task of the Fortran runtime library to implement direct and sequential access on top of the stream-of-bytes model that the OS provides.<br>
<p>
<font class="QuotedText">&gt;  Is there any way this sort of information could be fed through to these routines, because there&#x27;s clearly no point reading-ahead a dam file, while there is no point caching a sam file once that bit of data has been synchronously read ...</font><br>
<p>
At least from the perspective of the typical Fortran applications I&#x27;ve seen, this would be a very simplistic and bad caching strategy. For instance, reading direct access files sequentially (as in, first read record #1, then record #2, etc) is actually very common, as is rereading files (maybe by rerunning the applications with partially different input parameters etc.).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/890972/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor891002"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">SAM / DAM files</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 12, 2022 2:46 UTC (Tue)
                               by <b>Fowl</b> (subscriber, #65667)
                              [<a href="/Articles/891002/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Windows has FILE_FLAG_SEQUENTIAL_SCAN and FILE_FLAG_RANDOM_ACCESS &quot;hints&quot; that can be passed when opening files, indeed.<br>
<p>
<a href="https://devblogs.microsoft.com/oldnewthing/20120120-00/?p=8493">https://devblogs.microsoft.com/oldnewthing/20120120-00/?p...</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/891002/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor891016"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">SAM / DAM files</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 12, 2022 9:44 UTC (Tue)
                               by <b>farnz</b> (subscriber, #17727)
                              [<a href="/Articles/891016/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>And on the POSIX side, there's <a href="https://pubs.opengroup.org/onlinepubs/000095399/functions/posix_fadvise.html"><tt>posix_fadvise</tt></a>, which has those two options, plus 3 more for telling the kernel what you're planning to do in the near future.


      
          <div class="CommentReplyButton">
            <form action="/Articles/891016/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2022, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
