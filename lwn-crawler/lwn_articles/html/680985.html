        <!DOCTYPE html>
        <html lang="en">
        <head><title>An introduction to last branch records [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/680985/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/680617/">Return to the Development page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/680985/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>An introduction to last branch records</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Please consider subscribing to LWN</b>
<p>
Subscriptions are the lifeblood of LWN.net.  If you appreciate this
content and would like to see more of it, your subscription will
help to ensure that LWN continues to thrive.  Please visit
<a href="/Promo/nst-nag1/subscribe">this page</a> to join up and keep LWN on
the net.
</blockquote>
<div class="GAByline">
           <p>March 23, 2016</p>
           <p>This article was contributed by Andi Kleen</p>
           </div>
Let's say we have have a large program that runs too slowly; its performance
needs to be improved.  
The program is big and complicated and not completely understood.  The code
may or may not be a <a href="http://www.laputan.org/mud/">big ball of
mud</a>.  To improve performance we now need to find which parts
are the performance bottlenecks.  
A standard profiler, like Linux perf, will help identify them, but often
just knowing the bottlenecks is not good enough.  
It may be not obvious why they are are slow, or what causes them to be executed.

<p>
So, often it is not enough to look at a single location in the program, but
we need to see how larger parts of the program behave together. For that, we
need to look at the control flow of frequently executed "traces" of the
program. A facility in Intel processors, last branch records (LBRs),
provide a way to look at this control flow.  These CPUs can log branch
information to special registers in realtime.

<h4>Branches</h4>

<p>
At the most basic software level, a program consists of computation and
control structures (branches). Looking at the branches is a good start, since
branches can be mapped back to source lines and the control structures of
the programming language. 
Of course it is nice to see the values of variables too, but those values change
frequently, which generates lots of information.  Control flow and branches
are much easier to analyze and are quite useful to understand how the
program behaves. 
So it's useful to have a way to record and analyze branches.

<p>
Let's look at a simple example:

<pre>
    for (i = 0; i &lt; 10; i++) 
	    if (i % 2 != 0)
		    foo(i);
</pre>

translates to the following pseudocode:

<pre>
	    i = 0
    loop:
	    tmp = i % 2
	    if tmp == 0 goto l2		# jump 1 
		    call foo(i)		# jump 2
	    l2:
	    if i++ &lt; 10 goto loop	# jump 4

    function foo(i):
	    ...
	    return			# jump 3
</pre>

which then can be mapped to assembler instructions.

<p> 
If we can trace the jumps, we can understand what the program does and, more
importantly, how to make 
it faster. For example, the <tt>foo()</tt> function may be slow and we want
to understand what exactly 
causes it to be called and if the number of calls can be reduced.

<p>
If we look at the execution of the above example we get:

<pre>
    jump 1	# if tmp == 0 goto l2  (branch not taken, but still traced)
    jump 2	# call foo(i)
    jump 3	# return
    jump 4	# if i++ &lt; 10 goto loop (branch taken)
    jump 1	# if tmp == 0 goto l2  (branch taken, since i % 2 != 0)
    jump 4 	# if i++ &lt; 10 goto loop (branch taken)
    ... repeat 8 more times ...
</pre>

This execution pattern can then be analyzed.  For example we can see that
<tt>foo()</tt> is only called for half of the loop iterations. Such information
can then be used for performance tuning.

<p>
Not all program control flow results in branches. In some cases the
compiler can generate branch-less code (for example, using conditional move
instructions), which will not show up as individual branches. But most
interesting code usually has real branches. 

<p>
Of course, for such a trivial example it's relatively straightforward to understand what is happening even without such a trace.
But for complex programs, we often need all the help the tools can provide.

<h4>Logging branches</h4>

<p>
A compiler or binary analyzer can do static control-flow analysis over a program to determine branches. But without running the program — only being able to guess — it doesn't know which branches are hot and which are cold. When doing performance analysis, we only care about hot code (tuning cold code won't help anyone), so knowing what is hot is important.

<p>
Also, static control-flow graphs are incomplete; for example, they cannot
follow indirect function calls where the target is only known at run time
and typically do not know the loop iteration counts. To really understand
these things, 
branches need to be collected at run time. 

<p>
A modern CPU is likely running at multiple GHz and can execute many instructions
in parallel. For typical code, there is a branch every five to ten
instructions. This gives a large number of branches: if we log the 64-bit
target address of every branch each ten instructions on a 3GHz CPU (about
one branch every  3ns) we would generate 2.2GB of data each second per
processor thread. For most purposes, this is far too much data and, in fact, may be beyond what the memory subsystem or the disk can store.

<p>
There is a way to record every branch using <a
href="/Articles/648154/">Processor Trace</a> (PT) on newer
Intel CPUs. PT addresses this problem by heavily compressing branches and
avoiding redundant information. But it can still generate an overwhelming
amount of information.

<h4>Sampling</h4>

<p>
For performance tuning, we can often use sampling instead. We are only
interested in the most common (hot) code paths, which will eventually
show up in sampling (at least most of the time, short of <a
href="https://www.usenix.org/system/files/conference/atc15/atc15-paper-nowak.pdf">systematic
shadow [PDF]</a> effects). So by sampling branches, we can build up a histogram of interesting control-flow patterns.

<p>
The overhead of sampling can be adjusted by lowering the sampling rate, at a tradeoff to accuracy. Sampling generates far less data than full tracing, which makes any analysis later much easier.

<p>
The CPU has performance counters that can be programmed to count branches
and raise an interrupt on every Nth branch. Linux perf can be configured to
sample branches using performance counters. However, N cannot be too small
because interrupts are expensive and doing them frequently would slow down
the workload too much. Usually, we are interested in short sequences of
branches (for example the loop body of a hot loop) where it is useful to
see multiple consecutive branches.  

<h4>Last branch records to the rescue</h4>

<p>
Intel CPUs have a feature called last branch records (LBR) where the CPU
can continuously log branches to a set of model-specific registers
(MSRs). The CPU 
hardware can do this in parallel while executing the program without
causing any slowdown. There is some performance penalty for reading these
registers, however. 

<p>
The LBRs log the "from" and "to" address of each branch along with some
additional 
metadata. The registers act like a ring buffer that is continuously
overwritten and provides only the most recent entries. There is also a TOS (top
of stack) register to provide a pointer to the most recent branch. With
LBRs we can sample branches, but during each sample look at the previous
8-32 branches that were executed. This gives reasonable coverage of the control flow in the hot code paths, but does not overwhelm us with too much information, as only a smaller number of the total branches are examined.

<p>
The number of branch entries in the LBRs varies depending on the Intel CPU
generation:
<blockquote>
<table cellspacing=3>
<tr><th>CPU generation</th><th>Branches in LBR</th></tr>
<tr class="Even"><td>Netburst to Merom</td><td>4</td></tr>
<tr class="Odd"><td>Nehalem to Haswell</td><td>16</td></tr>
<tr class="Even"><td>Skylake</td><td>32</td></tr>
<tr class="Odd"><td>Atom</td><td>8</td></tr>
</table>
</blockquote>

Once we are able to sample LBRs it is possible to set up sampling of branch events at a frequency that does not slow down the workload unduly, and still create an useful histogram of hot branches.

<p>
It is important to keep in mind that this is still sampling, so not every
executed branch can be examined. CPUs generally execute too fast for that
to be feasible. That is one reason why it's not a good idea to try to use
LBRs to detect specific patterns of security exploits, for
example. Security checks require examining everything, but sampling cannot
do that. 

<h4>Basic block frequencies</h4>

<p>
Linux perf is a profiler integrated with Linux. <a href="http://linux.die.net/man/1/perf-record"><tt>perf&nbsp;record</tt></a> supports <a href="https://perf.wiki.kernel.org/index.php/Tutorial#Sampling_with_perf_record">sampling</a> the LBRs using the -b option.

<pre>
    % perf record -b workload
</pre>

<p>
That gives us a list of hot branches, but what can we do with the data?
One simple use is to show the frequency of basic blocks
using a histogram.  This gives us the frequency of every program block or,
more importantly, how often every branch to a given 
target is executed.

<p>
This is supported in perf by <a
href="http://linux.die.net/man/1/perf-report"><tt>perf&nbsp;report</tt></a>,
which generates a histogram from the sampling data collected
earlier by <tt>perf&nbsp;record</tt>.
Note that <tt>div</tt> is the test program in the listing below.

<pre>
    % perf record -b -e cycles:u ./div
    % perf report --sort symbol_from,symbol_to --stdio
    ...
    # Samples: 632K of event 'cycles'
    # Event count (approx.): 632064
    #
    # Overhead  Source Symbol                            Target Symbol                          
    # ........  .......................................  ................
    #
	32.71%  [.] main                                 [.] main
	22.90%  [.] main                                 [.] compute_flag
	22.41%  [.] compute_flag                         [.] main
	21.60%  [.] compute_flag                         [.] compute_flag
</pre>

<p>
This gives us a histogram of all the branches. We know 33% of branches
are inside main, and 23% of branches are from main to compute flag,
and another 23% back.

<p>
Currently perf can only report functions, not source lines, in this mode, which limits the usefulness somewhat, as 
functions often contain a large number of branches and it may not be clear
which are the hot and cold ones. 

<h4>Compiler profile feedback</h4>

<p>
One way to use this information is for profile feedback for compilers, like
GCC or LLVM. Modern compilers 
support many optimizations, but normally they operate with one hand tied behind their back by not knowing which code
is hot and which is cold.  They can use the basic block frequencies and
branch target information to guide their optimizations,  
such as function inlining, and to do de-virtualization (inlining hot
indirect method calls).  Often important 
optimizations, such as function splitting to optimize instruction cache
use, are only available with profile feedback. 

<p>
Traditionally such profiling information was collected with specially
instrumented binaries, typically with 
counters for each basic block and other hooks to collect the targets of
indirect jumps. Adding this instrumentation 
slows down the programs quite a bit, and it requires separate binaries,
which can be hard to manage 
in a production environment.

<p>
Getting profile feedback directly out of a profiler using a hardware
profiling mechanism is  
better because it can be done directly on the production binary, with only
the impact for collecting the data.
This allows continuous optimization by regularly feeding back dynamic
profiling data to 
a rebuild.

<p>
Since the compiler primarily needs basic block frequencies, sampling LBRs is the best way to collect this
information, as that gives good coverage of the branches with reasonable
overhead. 
Google implemented such a scheme for GCC and LLVM with the <a
href="https://gcc.gnu.org/wiki/AutoFDO">Automatic Feedback Directed
Optimizer</a> (AutoFDO) project. AutoFDO has been available in GCC since
version 5.0 (or in a slightly improved form in the 4.9 Google branch), or
in LLVM since 3.5. 

<p>
We sample the branches in a workload with LBRs enabled:

<pre>
    % gcc -O2 -o program ...
    % ocperf.py record -b -e BR_INST_RETIRED.ALL_BRANCHES:p program
    % create_gcov --binary=program --profile=perf.data -gcov_version=1
    % gcc -fauto-profile -O2 ... 
</pre> 

<p>
(<tt>ocperf.py</tt> is a perf wrapper available in <a
href="https://github.com/andikleen/pmu-tools">pmu-tools</a> that allows 
resolving named performance monitoring unit events such as <tt>BR_INST_RETIRED.ALL_BRANCHES</tt>. Without it, using something
like <tt>-e&nbsp;cpu/event=0xc4,umask=0x0/</tt> would be needed.)

<p>
AutoFDO has some capability to tolerate stale profiles — profile
data that has been  
collected using an older version of the binary. The more out of date it
gets, the less 
useful it is, but this often avoids reprofiling for smaller changes.
The AutoFDO toolchain can also generate similar feedback profile data for LLVM/Clang with the <tt>create_llvm_prof</tt>
tool. This is supported in LLVM since 3.6.

<p>
The performance increase using AutoFDO can be substantial.
For example, when building GNU <tt>awk</tt> with profile feedback for a simple
<a href="https://github.com/Tensibai/benchmark-awk-vs">benchmark</a>, we
see about 18% shorter run times 
for the feedback-optimized binary, with no significant slowdown occurring during
the profiling phase.  Of course,  the results will vary depending on the
workload; in particular, the gains may be less if the training workload is 
significantly different from 
the actual  workload.

<h4>Hot-path analysis</h4>

<p>
Newer versions of perf can also use LBRs for profiling "super blocks", which
are  a combination 
of multiple basic blocks that frequently get executed in order. This allows
finding the hot 
execution paths in the executable to examine them directly for optimization opportunities.
In perf this is implemented by extending the call-stack display mechanism
and adding the last basic blocks 
into the call stack, which is normally used to display the most common
hierarchy of function calls. 

<p>
One interesting case here is when something cheap (such as setting a flag)
causes something 
expensive later. This is usually difficult to profile because the cheap
operation will 
not show up in the profiler, and it may not be obvious from the expensive code what caused it.
Let's look at an example:

<pre>
      1 /* div.c */
      2 volatile int count;
      3 
      4 __attribute__((noinline))
      5 int compute_flag(int i)
      6 {
      7         if (i % 10 &lt; 4)          /* ... in 40% of the iterations */
      8                 return i + 1;
      9         return 0;
     10 }
     11 
     12 int main(void)
     13 {
     14         int i;
     15         int flag;
     16         volatile double x = 1212121212, y = 121212; /* Avoid compiler optimizing away */
     17 
     18         for (i = 0; i &lt; 2000000000; i++) {
     19                 flag = compute_flag(i);
     20         
     21                 /* Some other code */
     22                 count++;
     23 
     24                 if (flag)
     25                         x += x / y + y / x;     /* Execute expensive division if flag is set */
     26         }
     27         return 0;
     28 }
</pre>

<p>
Division can be expensive. In this example division is only executed in 40% of
the loop iterations, but it is so expensive that it clearly shows up as the most
expensive operation.

<p>
We want to focus on the path through the program that causes the division.
This can be done by using the call graph (<tt>-g</tt>) and LBR
(<tt>-b</tt>) options in <tt>perf&nbsp;record</tt> and the
<tt>--branch-history</tt> option in <tt>perf&nbsp;report</tt>, which 
adds the last branch information to the call graph. Essentially it gives
8-32 branches 
extra context of why something happened:

<p>

<pre>
    % gcc -O2 -g -o div div.c
    % perf record -e cycles:pp -c 1000000 -g -b ./div
    % perf report --branch-history --stdio --no-children
    ...
    # Overhead  Source:Line                            Symbol                  Shared Object   
    # ........  .....................................  ......................  ................
    #
    ...
	31.81%  div.c:25                               [.] main                div             
		|
		---main div.c:19
		   compute_flag div.c:10
		   compute_flag div.c:10
		   compute_flag div.c:8               <b>&lt;================== FLAG SETTING</b>
		   compute_flag div.c:6
		   main div.c:19
		   main div.c:19
		   main div.c:18
		   |          
		   |--17.50%--main div.c:19
		   |          compute_flag div.c:10
		   |          compute_flag div.c:10
		   |          compute_flag div.c:8

</pre>

<p>
We can examine the path through the source code through the line
numbers. <tt>div.c:25</tt> is the  
division. The path through the program is printed reversed (last on the
top). When looking at
what runs before the division we see it is always <tt>div.c:8</tt>, which is
the flag 
setting 
that causes the division later.
If we want to avoid the division, we would need to optimize how flag is set.

<p>
The <tt>--branch-history</tt> option was added to perf&nbsp;3.18.
Right now,  using this facility requires matching line numbers manually,
which can be tedious. 
In future versions of perf, this will hopefully be improved.

<h4>Conclusion</h4>

<p>
Last branch records are a powerful facility, which can enable advanced
performance-analysis techniques. 
They also can be used to generate better code from compilers. Linux perf has
support  
for using LBRs to help improve performance. While some details
could be improved 
in perf, the support is working well enough to be a useful tool in
day-to-day performance tuning.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Tracing-Last_branch_records">Tracing/Last branch records</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Kleen_Andi">Kleen, Andi</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/680985/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor717800"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Good explanation. I have a question though.</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 22, 2017 18:30 UTC (Wed)
                               by <b>tritron</b> (guest, #114732)
                              [<a href="/Articles/717800/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This is a good explanation about LBRs. One question, the LBRs are stored in MSRs so, how can one guaranty that all the LBRs that are in the ring buffer before belongs to a particular thread. Is there any way to identify this? Are all LBRs from different threads mixed?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/717800/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2016, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
