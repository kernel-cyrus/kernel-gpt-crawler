        <!DOCTYPE html>
        <html lang="en">
        <head><title>Large pages, large blocks, and large problems [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/250335/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/249526/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/250335/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Large pages, large blocks, and large problems</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>This article brought to you by LWN subscribers</b>
<p>
Subscribers to LWN.net made this article &mdash; and everything that
       surrounds it &mdash; possible.  If you appreciate our content, please
       <a href="/Promo/nst-nag3/subscribe">buy a subscription</a> and make the next
       set of articles possible.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>September 19, 2007</br>
           </div>
Most of the core virtual memory subsystem developers met for a mini-summit
just before the 2007 Kernel Summit in Cambridge.  They came away feeling
that they had resolved a number of VM scalability problems.  Subsequent
discussions have made it clear that, perhaps, this conclusion was a bit
premature.  They may well have resolved things, but it is not clear that
everybody came to the same resolution.
<p>

All of the issues at hand relate to scalability in one way or another.
While the virtual memory subsystem has been through a great many changes
aimed at making it work well on contemporary systems, one key aspect of how
it works has remained essentially unchanged since the beginning: the
4096-byte (on most architectures) page size.  Over that time, the amount of
memory installed on a typical system has grown by about three orders of
magnitude - that's 1000 times more pages that the kernel must manage and
1000 times more page faults which must be handled.
Since it does not appear that this trend will stop soon, there is a clear
scalability problem which must be managed.
<p>

This problem is complicated by the way that Linux tends to fragment its
memory.  Almost all memory allocations are done in units of a single page,
with the result that system RAM tends to get scattered into large numbers
of single-page chunks.  The kernel's memory allocator tries to keep larger
groups of pages together, but there are limits to how successful it can be.
The file 
<tt>/proc/buddyinfo</tt> can be illustrative here; on a system which has
been running and busy for a while, the number of higher-order (larger)
pages, as shown in the rightmost columns, will be very small.
<p>

The main response to memory fragmentation has been to avoid higher-order
allocations at almost any cost.  There are very few places in the kernel
where allocations of multiple contiguous pages are done.  This approach has
worked for some time, but avoiding larger allocations does not always make
the need for such allocations go away.  In fact, there are many things
which could benefit from larger contiguous memory areas, including:
<p>
<ul>
<li> Applications which use large amounts of memory will be working with 
     large numbers of pages.  The translation lookaside buffer (TLB) in the
     CPU, which speeds virtual address lookups, is generally relatively
     small, to the point that large applications run up a lot of
     time-consuming TLB misses.  Larger pages require fewer TLB entries,
     and will thus result in faster execution.  The hugetlbfs extension was
     created for just this purpose, but it is a specialized mechanism used
     by few applications, and it does not do anything special to make large
     contiguous memory regions easier for the kernel to find.
<p>
<li> I/O operations can work better with larger contiguous chunks of data
     to work with.  Users trying to use "jumbo frames" (extra-large
     packets) on high-performance network adapters have been experiencing
     problems for a while.  Many devices are limited in the number of
     scatter/gather entries they support for a single operation, so small
     buffers limit the overall I/O operation size.  Disk devices are
     pushing toward larger sector sizes which would best be supported by
     larger contiguous buffers within the kernel.
<p>

<li> Filesystems are feeling pressure to use larger block sizes for a
     number of performance reasons.  <a href="/Articles/250466/">This
     message from David Chinner</a> provides an excellent explanation of
     why filesystems benefit from larger blocks.
     But it is hard (on Linux) for a filesystem to work
     with block sizes larger than the page size; XFS does it, but the
     resulting code is seen as non-optimal and is not as fast as it could
     be.  Most other filesystems do not even try; as a result, an ext3
     filesystem created on a system with 8192-byte pages cannot be mounted
     on a system with smaller pages.

</ul>
<p>
None of these issues are a surprise; developers have seen them coming for
some time.  So there are a number of potential solutions waiting on the
wings.  What is lacking is a consensus on which solution is the best way to
go.
<p>

One piece of the puzzle may be Mel Gorman's <a
href="http://lwn.net/Articles/224829/">fragmentation avoidance work</a>,
which has been discussed here more than once.  Mel's patches seek to
separate allocations which can be moved in physical memory from those which
cannot.  When movable allocations are grouped together, the kernel can,
when necessary, create higher-order groups of pages by relocating
allocations which are in the way.  Some of Mel's work is in 2.6.23; more
may be merged for 2.6.24.  The <a
href="http://lwn.net/Articles/211505/">lumpy reclaim</a> patches, also in
2.6.23, encourage the creation of large blocks by targeting adjacent pages
when memory is being reclaimed.
<p>

The immediate cause for the current discussion is a new version of
Christoph Lameter's <a href="http://lwn.net/Articles/232757/">large block
size</a> patches.  Christoph has filled in the largest remaining gap in
that patch set by implementing <tt>mmap()</tt> support.  This code enables
the page cache to manage chunks of file data larger than a single page
which, in turn, addresses many of the I/O and filesystem issues.  Christoph
has given <a href="http://lwn.net/Articles/249169/">a long list of
reasons</a> why this patch should be merged, but agreement is not
universal.
<p>

At the top of the list of objections would appear to be the fact that the
large block size patches require the availability of higher-order pages to
work; there is no fallback if memory becomes sufficiently fragmented that
those allocations are not available.  So a system which has filesystems
using larger block sizes will fall apart in the absence of large,
contiguous blocks of memory - and, as we have seen, that is not an uncommon
situation on Linux systems.  The fragmentation avoidance patches can
improve the situation quite a bit, but there is no guarantee that

<span class="PullQuote">
<span class="invisible">[PULL QUOTE: </span>
If this patch set is merged, some developers want
it to include a loud warning to discourage users from
actually expecting it to work.
<span class="invisible"> END QUOTE]</span>
</span>


fragmentation will not occur, either as a result of the wrong workload or a
deliberate attack.  So, if this patch set is merged, some developers want
it to include a loud warning to discourage users (and distributors) from
actually expecting it to work.  
<p>

An alternative is Nick Piggin's <a
href="http://lwn.net/Articles/239621/">fsblock</a> work.  People like to
complain about the buffer head layer in current kernels, but that layer has
a purpose: it tracks the mapping between page cache blocks and the
associated physical disk sectors.  The fsblock patch replaces the buffer
head code with a new implementation with the goals of better performance
and cleaner abstractions.
<p>

One of the things fsblock can do is support large blocks for filesystems.
The current patch does not use higher-order allocations to implement this
support; instead, large blocks are made virtually contiguous in the
<tt>vmalloc()</tt> space through a call to <tt>vmap()</tt> - a technique
used by XFS now.  The advantage of using <tt>vmap()</tt> is that the
filesystem code can see large, contiguous blocks without the need for
physical adjacency, so fragmentation is not an issue.  
<p>

On the other hand, using <tt>vmap()</tt> is quite slow, the address space
available for <tt>vmap()</tt> on 32-bit systems is small enough to cause
problems, and using <tt>vmap()</tt> does nothing to help at the I/O level.
So Nick plans to extend fsblock to implement large blocks with contiguous
allocations, but with a fallback to <tt>vmap()</tt> when large allocations
are not available.  In theory, this approach should be be best of both
worlds, giving the benefits of large blocks without unseemly explosions in
the presence of fragmentation.  <a href="/Articles/250371/">Says Nick</a>:
<p>
<div class="BigQuote">
	However fsblock can do everything that higher order pagecache can
	do in terms of avoiding vmap and giving contiguous memory to block
	devices by opportunistically allocating higher orders of pages, and
	falling back to vmap if they cannot be satisfied.
</div>
<p>

From the conversation, it seems that a number of developers see fsblock as
the future.  But it is not something for the near future.  The patch is
big, intrusive, and scary, which will slow its progress (and memory
management patches have a tendency to merge at a glacial pace to begin
with).  It lacks the opportunistic large block feature.  Only the Minix
filesystem has been updated to use fsblock, and that patch was rather
large.  Everybody (including Nick) anticipates that more complex
filesystems - those with features like journaling - will present surprises
and require changes of unknown size.  Fsblock is not a near-term solution.
<p>

One <a href="http://lwn.net/Articles/250460/">recently-posted patch</a>
from Christoph could help fill in some of the gaps.  His "virtual compound
page" patch allows kernel code to request a large, contiguous allocation;
that request will be satisfied with physically contiguous memory if
possible.  If that memory is not available, virtually contiguous memory
will be returned instead.  Beyond providing opportunistic large block
allocation for fsblock, this feature could conceivably be used in a
number of places where <tt>vmalloc()</tt> is called now, resulting in
better performance when memory is not overly fragmented.
<p>


Meanwhile, Andrea Arcangeli has been relatively quiet for some time, but one should
not forget that he is the author of much of the VM code in the kernel now.
He <a href="/Articles/250368/">advocates a different approach entirely</a>:
<p>
<div class="BigQuote">
	From my part I am really convinced the only sane way to approach
	the VM scalability and larger-physically contiguous pages problem
	is the CONFIG_PAGE_SHIFT patch (aka large PAGE_SIZE from Hugh for
	2.4).
</div>
<p>
The <a href="http://lwn.net/Articles/240914/">CONFIG_PAGE_SHIFT patch</a>
is a rework of an old idea: separate the size of a page as seen by the
operating system from the hardware's notion of the page size.  Hardware
pages can be clustered together to create larger software pages which, in
turn, become the basic unit of memory management.  If all pages in the
system were, say, 64KB in length, a 64KB buffer would be a single-page
allocation with no fragmentation issues at all.
<p>

If the system is to go to larger pages, creating them in software is about
the only option.  Most processors support more than one hardware page size,
but the smallest of the larger page sizes tend to be too large for general
use.  For example, i386 processors have no page sizes between 4KB and 2MB.
Clustering pages in software enables the use of more reasonable page sizes
and creates the flexibility needed to optimize the page size for the
expected load on the system.  This approach will make large block support
easy, and it will help with the I/O performance issues as well.  Page
clustering is not helpful for TLB pressure problems, but there is little to
be done there in any sort of general way.
<p>

The biggest problem, perhaps, with page clustering is that it replaces
external fragmentation with internal fragmentation.  A 64KB page will, when
used as the page cache for a 1KB file, waste 63KB of memory.  There are
provisions in Andrea's patch for splitting large pages to handle this
situation; Andrea claims that this splitting will not lead to the same sort
of fragmentation seen on current systems, but he has not, yet, convinced
the others of this fact.
<p>

Conclusions from this discussion are hard to come by; at one point Mel
Gorman <a href="/Articles/250372/">asked</a>: "<q>Are we going to agree
on some sort of plan or are we just going to handwave ourselves to
death?</q>"  Linus has just <a href="/Articles/250373/">called the whole
discussion "idiotic"</a>.  What may happen is that the large block size
patches go in - with warnings - as a way of keeping a small subset of users
happy and providing more information about the problem space.  Memory
management hacking requires a certain amount of black-magic handwaving in
the best of times; there is no reason to believe that the waving of hands
is going to slow down anytime soon this time around.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#fsblock">fsblock</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Huge_pages">Huge pages</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Large_allocations">Memory management/Large allocations</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/250335/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor250481"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 19, 2007 16:22 UTC (Wed)
                               by <b>james</b> (subscriber, #1325)
                              [<a href="/Articles/250481/">Link</a>] (20 responses)
      </p>
      
      </div>
      </summary>
      Some of Linus' thoughts (presumably) can be found <a href="http://realworldtech.com/forums/index.cfm?action=detail&id=82298&threadid=82157&roomid=2">at
Real World Technologies</a> (and associated thread):
<blockquote>
[The performance cost of] Page table handling stays pretty constant - you basically
get TLB misses proportionately to your data size, which
means that the more TLB misses you get, the more data cache
misses you get!
<p>
So realistically, TLB costs are never going to grow in
any unbounded kind of manner - they are always limited by
(and generally <em>much</em> smaller than) the D$ costs!
There are loads that are more TLB-intensive than others
(and loads that are more D$ intensive, of course!), but
in the end, TLB's aren't the problem.
<p>
Unless the CPU micro-architecture is unbalanced, of course.
There have certainly been uarchs that increased the cache
size a lot without increasing the TLB size. Now, <b>of
course</b> they'll be TLB-limited! But that's not really a
fundamental issue, it's just an unbalanced design.
<p>
</blockquote>
and
<blockquote>
You want good cache behavior if you have 256GB of memory,
or your performance will suck. It's that easy. And if you
have good locality in the D$, then the TLB's will work
fine.
</blockquote>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250481/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250485"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 19, 2007 16:51 UTC (Wed)
                               by <b>avik</b> (guest, #704)
                              [<a href="/Articles/250485/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      It's an oversimplification.  Suppose you have a large memory machine and <br>
you're doing completely random access.  With 4KB pages, you'll get a tlb <br>
miss and two cache hits (one for the data and one for the pte).  With <br>
large pages, the page tables can be all cached and you only take a tlb <br>
miss and a single cache miss.<br>
<p>
So for this contrived workload, you get a ~2X speedup by using large <br>
pages.  Obviously real workloads will get less speedup, but it is still <br>
significant.<br>
<p>
Another way of stating this is that large pages don't just increase the <br>
coverage of the tlb, they also increase the pagetable coverage of the <br>
data cache, which can be much more significant.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250485/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250574"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 0:52 UTC (Thu)
                               by <b>sayler</b> (guest, #3164)
                              [<a href="/Articles/250574/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      Yes, *but* you have a commensurate increase in the cost (in silicon area, latency, validation) to support large-page-TLB entries.  IIRC (from the above RWT thread) modern Intel processors support only 2 TLB entries for large pages!<br>
<p>
In other words, you may lose some performance by going to large pages because of resource constraints.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250574/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250613"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 5:51 UTC (Thu)
                               by <b>avik</b> (guest, #704)
                              [<a href="/Articles/250613/">Link</a>] 
      </p>
      
      </div>
      </summary>
      I'm talking about current hardware, not proposing changes to hardware.<br>
<p>
The workload I described will gain a 2X boost from using large pages <br>
regardless of the tlb's allocation of large and small pages.  And while it <br>
is not a real-life workload, others have demonstrated nice performance <br>
improvements with large pages.<br>
<p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250613/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor250979"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 21, 2007 17:17 UTC (Fri)
                               by <b>vonbrand</b> (subscriber, #4458)
                              [<a href="/Articles/250979/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <p>
The cost is the same <em>once the data is in RAM</em>. Loading and storing large pages is costlier. It is not at all that simple.
      
          <div class="CommentReplyButton">
            <form action="/Articles/250979/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor251005"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 21, 2007 19:48 UTC (Fri)
                               by <b>avik</b> (guest, #704)
                              [<a href="/Articles/251005/">Link</a>] 
      </p>
      
      </div>
      </summary>
      My comment (and Linus' remarks) is talking about large pages, not large <br>
blocks.  The assumption is that this is a memory workload, not an I/O <br>
workload.  There's no disk I/O involved.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/251005/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor250487"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The story repeats itself</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 19, 2007 17:00 UTC (Wed)
                               by <b>khim</b> (subscriber, #9252)
                              [<a href="/Articles/250487/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <p>Deja vu: the same thing happened when question about more the 4GB of memory in 32-bit system was raised. <b>Of course</b> it's insane to try to handle 16GiB or 32GiB with 32bit CPU. <b>Of course</b> the proper solution is switch to 64bit CPU. But when <b>the most popular</b> arch is 32-bit and users <b>need</b> huge memory systems - what can you do ?</p>

<p>Here we have the same situation. Most CPUs are balanced (PPC, Athlon64, etc), but there are one vendor which sells two architectures of CPU which are seriously unbalanced. Can we safely ignore this obscure vendor and these crippled CPUs ? Not when vendor is called Intel and CPUs are Pentium 4 and Core 2. They both only have 128-items TLB (enough for 512KiB with 4KiB pages) and 4MiB of cache (at least in some models). That's 8 times difference! Yes, this is insane, yes, this is problem of CPU design. Yet when it's the most popular vendor and the "crippled architecture" is the most popular CPU from said vendor - you can not just ignore the problem and hope that it'll  go away.</p>

<p>There are rumors that Vista SP1 will use 4MB pages to speedup I/O...</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250487/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250493"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The story repeats itself</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 19, 2007 17:23 UTC (Wed)
                               by <b>proski</b> (subscriber, #104)
                              [<a href="/Articles/250493/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      Isn't Core 2 64-bit?  That problem is going away.  And 16 Gb of RAM costs significantly more than a CPU and a motherboard that can support it properly, and it has always been like that.
<p>
The same applies to the cache.  Changing the CPU will cost fraction of the memory it's supposed to support.
      
          <div class="CommentReplyButton">
            <form action="/Articles/250493/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250496"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The story repeats itself</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 19, 2007 17:38 UTC (Wed)
                               by <b>khim</b> (subscriber, #9252)
                              [<a href="/Articles/250496/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <p>Core 2 is 64bit only, but people needed 16GiB of RAM <b>years ago</b> when x86-compatible 64bit CPUs were just a project. Thus PAE support was added to Linux.</p>

<p>The same - with TLB today: may be someday we'll have the truly balanced architecture but today - we don't. Add it's not clear if we'll have balanced architecture tomorrow: TLB must be fast (or else it's useless) but it's hard to create large and fast cache. Of course it's possible to use 2-level TLB (like AMD does today), but it's not some minor modification - it's possible that we'll be forced to wait few years till the new Intel's design. And all these years Linux will be worse then Windows... not a good position...</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250496/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250561"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The story repeats itself</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 19, 2007 22:44 UTC (Wed)
                               by <b>proski</b> (subscriber, #104)
                              [<a href="/Articles/250561/">Link</a>] 
      </p>
      
      </div>
      </summary>
      I don't see any references to Windows in the story.
      
          <div class="CommentReplyButton">
            <form action="/Articles/250561/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor250576"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The story repeats itself</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 0:52 UTC (Thu)
                               by <b>sayler</b> (guest, #3164)
                              [<a href="/Articles/250576/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      "Core 2 is 64bit only"<br>
<p>
No.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250576/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250808"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Oops</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 21:09 UTC (Thu)
                               by <b>khim</b> (subscriber, #9252)
                              [<a href="/Articles/250808/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Perils of editing. Initially I wanted so say that only "Core 2" is 64bit while Pentium 4 (except latest models of Prescott), Pentium 3 and so on are 32bit. Phrase was too cumbersome and I've removed everything but the "only" word was left after editing...<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250808/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor251860"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The story repeats itself</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 27, 2007 13:31 UTC (Thu)
                               by <b>anton</b> (subscriber, #25547)
                              [<a href="/Articles/251860/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>[...] Pentium 4 and Core 2. They both only have 128-items
TLB (enough for 512KiB with 4KiB pages)</blockquote>

Note that this assumes that each page is fully utilized with hot data,
i.e., the best case.  That's rarely the case and that's why cache
lines are smaller than a page.  So, in the worst case, 128 TLB entries
cover only 128 cache lines, i.e., with 64-byte L1 cache lines, 8KB.  I
have no data on typical cases, but if half the page contains hot data,
a 128-entry TLB will cover only 256KB of data in the caches.  You can
then hope that your working set is smaller, or you will see TLB
thrashing.

<p>If page utilization is a problem, larger pages will probably have
limited benefit: the relative utilization (hot data/page size) will
probably go down.  However, as long as the absolute utilization (hot
data/page) goes up, larger pages will still be useful in terms of
reducing TLB misses; they do have other costs, though.

      
          <div class="CommentReplyButton">
            <form action="/Articles/251860/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor250520"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 19, 2007 18:39 UTC (Wed)
                               by <b>eSk</b> (guest, #45221)
                              [<a href="/Articles/250520/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      I've never understood Linus' aversion against general support for superpages.  He always seems to make use of this argument that it does not matter (performance or otherwise).  However, at the OSDI '02 Navarro published a very thorough analysis of how superpage support helped performance by increasing TLB coverage [1].  The page sizes used were 8KB, 64KB, 512KB, and 4MB and the whole thing was implemented in FreeBSD.  He also described the techiques used for promoting and demoting superpages (i.e., automatically converting beween different page sizes as needed).  He didn't even talk about other advantages of using superpages (e.g., for supporting large blocks), but the results he obtained were still impressive.  BTW, another side effect of using superpages is that you tend to get better cache utilization because you automatically get a cache coloring effect by using the larger page sizes.<br>
<p>
<p>
[1] Navarro et al., "Practical, transparent operating system support for superpages", OSDI '02.<br>
<a href="http://www.usenix.org/events/osdi2002/tech/full_papers/navarro/navarro.pdf">http://www.usenix.org/events/osdi2002/tech/full_papers/na...</a><br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250520/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250577"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 0:54 UTC (Thu)
                               by <b>sayler</b> (guest, #3164)
                              [<a href="/Articles/250577/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      "This system is implemented in FreeBSD on the Alpha architecture,"  The Alpha has (had?) good support for higher-order page allocation at the hardware level that is not currently present in current-gen Intel and AMD chips.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250577/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250661"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 11:13 UTC (Thu)
                               by <b>eSk</b> (guest, #45221)
                              [<a href="/Articles/250661/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      Sure.  Running these experiments on any x86-lineage chip would obviously not work (except perhaps in a simulator) because of lacking the wider range of page sizes.  The point I was trying to make is that Linus argues strongly against the usefulness of any page size above 4K/8K, except for some special cases where very large superpages are used explicitly.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250661/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor251864"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 27, 2007 13:43 UTC (Thu)
                               by <b>anton</b> (subscriber, #25547)
                              [<a href="/Articles/251864/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>Running these experiments on any x86-lineage chip would
obviously not work (except perhaps in a simulator) because of lacking
the wider range of page sizes.</blockquote>

On a machine that has plenty of memory for what's running on it, a
variation of the Navarro approach might still be useful even on an
IA32/AMD64 machine.  The OS would rarely feel enough memory pressure
to consider splitting a large page.

<p>Also, since Linux also supports architectures that have
finer-grained page size steps, it should not look just at what
IA32/AMD64 support.  And once a popular OS like Linux supports it, the
hardware designers at Intel and AMD can better justify adding
additional page sizes to their hardware.

      
          <div class="CommentReplyButton">
            <form action="/Articles/251864/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor250695"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 13:42 UTC (Thu)
                               by <b>zlynx</b> (guest, #2285)
                              [<a href="/Articles/250695/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      Intel's Itanium supports page sizes in all powers of 2 from 4K to 256M.  That's a current-gen Intel chip.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250695/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250945"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 21, 2007 14:58 UTC (Fri)
                               by <b>jamesh</b> (guest, #1159)
                              [<a href="/Articles/250945/">Link</a>] 
      </p>
      
      </div>
      </summary>
      It may be present generation, but any software developer who made decisions based on the assumption of increased adoption of Itanium is crazy.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250945/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor250982"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 21, 2007 17:21 UTC (Fri)
                               by <b>vonbrand</b> (subscriber, #4458)
                              [<a href="/Articles/250982/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <p>
Current generation intel chips are clones of AMD64.
      
          <div class="CommentReplyButton">
            <form action="/Articles/250982/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250990"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 21, 2007 18:33 UTC (Fri)
                               by <b>zlynx</b> (guest, #2285)
                              [<a href="/Articles/250990/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Not really, or they would have included more of the good parts like the IOMMU and memory controller.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250990/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor250545"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 19, 2007 20:44 UTC (Wed)
                               by <b>vblum</b> (guest, #1151)
                              [<a href="/Articles/250545/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      How do applications with large allocated arrays for numerics (say) get around the page size / memory fragmentation issue? Wouldn't one expect them to experience some slowdown when the system's memory gets heavily fragmented, if the basic arrays are significantly larger than the cache size? just wondering ...<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250545/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250552"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 19, 2007 22:06 UTC (Wed)
                               by <b>i3839</b> (guest, #31386)
                              [<a href="/Articles/250552/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      Only the kernel accesses memory by physical addresses, userspace processes use virtual memory, so "fragmented memory" can look like one contiguous chunk to them.<br>
<p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250552/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250645"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 9:18 UTC (Thu)
                               by <b>vblum</b> (guest, #1151)
                              [<a href="/Articles/250645/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      Yes, masking fragmentation at a low level will make things look contiguous, but in reality someone somewhere has to do the work to bring the fragments together. Is the adverse impact on performance (wall-clock time for large operations) really negligible? (thanks to clever cache use?)<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250645/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250686"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 12:55 UTC (Thu)
                               by <b>i3839</b> (guest, #31386)
                              [<a href="/Articles/250686/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Not really.<br>
<p>
There is always a mapping made between the virtual addresses and the physical ones, so what's different is which physical pages are chosen. Choosing contiguous physical pages is harder and takes more time, but it doesn't give any advantages. Bringing the fragments together is done by mapping them to a contiguous virtual memory range.<br>
<p>
Mapping to contiguous physical pages might be faster if the hardware supports (really) variable sized pages, but as far as I know none does.<br>
<p>
Fragmentation doesn't slow things down, it only makes it harder to allocate chunks bigger than one pagesize.<br>
<p>
The demand for bigger pagesizes comes from people who think it will reduce overhead for their workload, because everything that's done per page can be done less often. The main thing preventing this from working seamlessly is fragmentation.<br>
<p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250686/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor250566"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 19, 2007 23:42 UTC (Wed)
                               by <b>riddochc</b> (guest, #43)
                              [<a href="/Articles/250566/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      Memory management is not something I know much about - relevant classes I took at the university were limited to pre-386 assembly and digital logic, so I'm not even sure that my understanding of a "page" is accurate.<br>
<p>
Can someone recommend reading materials (preferably free, but don't rule something really good out just on that account) on this stuff?<br>
<p>
And otherwise, I'm curious how the proposed changes would affect the work of people who are trying to get Linux to scale down to smaller devices?<br>
<p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250566/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250572"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 0:49 UTC (Thu)
                               by <b>drag</b> (guest, #31333)
                              [<a href="/Articles/250572/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <font class="QuotedText">&gt; And otherwise, I'm curious how the proposed changes would affect the work of people who are trying to get Linux to scale down to smaller devices?</font><br>
<p>
I donno. All of this stuff is over my head, but I expect it would either have a generally null effect to generally positive effect. <br>
<p>
<p>
I know that a popular task to put Linux to use for is those little embedded 'NAS' controllers. You know, those things running little ARM proccessor or something lightweight like that were you can shove 3 or 4 SATA drives into and they cost around 100-200 bucks or so.<br>
<p>
I know that for Gigabit speed networks, and faster interconnects, one of the major problems you have, in terms of performance, is that they are still using very tiny MTU's originally developed for 10Mbit/s networks. 'Jumbo frames' are were you take the small 1500 bytes and bump the size up to 9500bytes or even higher. This leads to significantly less interrupts being generated by the controller and much less TCP overhead. IF all your hardware and network hardware supports it. You can realy get very significant network performance improvements.  Sometimes 2x the performance at half the cpu usage.<br>
<p>
Then if you take that further and are able to use large packets with large disk blocks, say that if you strip away the ethernet frame and tcp information the datagram of the packet and the size of the disk block is the same size, then I suppose you can reduce overhead and increase performance even more.<br>
<p>
All in all this would allow people to make slower/cheaper proccessors and perform better. Cheaper, faster embedded Linux devices.<br>
<p>
<p>
Of course this is all very idealized. Lots of switches and NICs don't support jumbo packets, most people will still use Widnows with SMB which is just naturally slow, and most people don't have the abilty to configure the network in this way even if they know how. Plus the sorts of CPU they use I don't know if they would even have those large memory page sizes supported. <br>
<p>
<p>
Oh well. <br>
<p>
<font class="QuotedText">&gt; Can someone recommend reading materials (preferably free, but don't rule something really good out just on that account) on this stuff?</font><br>
<p>
Ever checked out <a href="http://kernelnewbies.org/">http://kernelnewbies.org/</a><br>
or <a href="http://www.linux-books.us/linux_general_0014.php">http://www.linux-books.us/linux_general_0014.php</a> ?<br>
<p>
<p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250572/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250583"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 1:58 UTC (Thu)
                               by <b>sayler</b> (guest, #3164)
                              [<a href="/Articles/250583/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      In general, I agree with what you say, but keep in mind that Ethernet frames are inherently variable in size, that is, you can have 1500, 1501, 1502, ... byte frames and the transmission time will increase nearly linearly.  <br>
<p>
We have much coarser choices for page sizes.  Even on Alpha (which apparently did a good job here), page size choices were something like 8k ** 2*N where N ran between 0 and 3..  <br>
<p>
There is some other somewhat interesting data here: <a href="http://lists.freebsd.org/pipermail/freebsd-hackers/2003-October/003604.html">http://lists.freebsd.org/pipermail/freebsd-hackers/2003-O...</a> showing measured {i,d}tlb size for various page sizes on various uArchs.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250583/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor250951"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 21, 2007 15:16 UTC (Fri)
                               by <b>jamesh</b> (guest, #1159)
                              [<a href="/Articles/250951/">Link</a>] 
      </p>
      
      </div>
      </summary>
      It is true that ethernet frames are variable size, but it also states that the maximum payload size is 1500 bytes as the grandparent post says.  You need to have some upper limit in order to make hardware that can reliably store and forward packets (as a switch would need to do when forwarding a packet to a slower network).<br>
<p>
Ethernet frames larger than 1500 bytes are non-standard and commonly known as "jumbo frames".  And as you can guess, they'll only work if all the hardware involved in the link supports the larger frames.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250951/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor250698"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 14:04 UTC (Thu)
                               by <b>lethal</b> (guest, #36121)
                              [<a href="/Articles/250698/">Link</a>] 
      </p>
      
      </div>
      </summary>
      The biggest problem on the small side is transparent usage of large TLBs, the idea being something akin to Andrea's CONFIG_PAGE_SHIFT but relative to the TLB size whilst maintaining normal PAGE_SIZE'ed PTEs. One thing that was tossed about at kernel summit was the idea of having the VM provide base page and range hints for contiguous page frames which could be optimized for in the TLB miss handler for software-loaded TLBs (many embedded systems, where TLBs are very small, for example). Namely, for some extra performance hit in the architecture-specific hot path we have the ability to cut off linear page faults directly, rather than speculatively (this is an important distinction between this approach and the rice superpages as well as the approaches used by HP-UX and IRIX).<br>
<p>
The other issue is that the d-cache does grow, and the TLB doesn't always scale accordingly. For heavy shared library and multi-threading apps, folks love to toss on copious amounts of slower cache, to the point where there's insufficient TLB coverage to make it out of cache, and thus, thrashing ensues when small pages are used. On ia64 the answer to this is always to bump up PAGE_SIZE, where 64kB tends to be a requirement to make it out of cache (and these are _huge_ TLBs!). On embedded where the TLBs are orders of magnitude smaller and consistently under pressure, bumping up the page size is simply not an option. We don't want a large page size, we want a large TLB entry size that can span multiple pages in order to reduce the amount of application time we waste on linear faulting.<br>
<p>
I brought this up at kernel summit, and Linus supported the idea of VM hinting for page ranges, so it will be interesting to see where this work goes. Not only will such things tie in with Christoph's work, it also operates under the assumption that we're not fragmented out of the box, too. Thus, there's also a dependence on Mel's work, especially if one is to consider ways to passively provide hints during page reclaim or so.<br>
<p>
It is worth differentiating between large pages and large TLBs. Large pages on embedded outside of application specific use (ie, hugetlbfs) are generally undesirable. The general embedded case is usually reasonably large memory apertures (relative to TLB and PAGE_SIZE), especially in peripheral space. Then a combination of many small files and some very big ones. The places where we have explicit control over the TLB size (ie, ioremap()) are already handled by the architectures that care, so in terms of transparency, it's simply anonymous and file-backed pages where VM hinting is helpful. Background scanning is mentioned from time to time, but is unrealistic for these applications since the system is usually doing run-time power management, also.<br>
<p>
The picture today is certainly much less bleak than it was even just a year ago, but there is still a lot of work to be done.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250698/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor251113"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 23, 2007 23:23 UTC (Sun)
                               by <b>man_ls</b> (guest, #15091)
                              [<a href="/Articles/251113/">Link</a>] 
      </p>
      
      </div>
      </summary>
      I found Henson's article here on LWN quite good: <a href="http://lwn.net/Articles/188056/">KHB: Transparent support for large pages</a>. The referred paper by Navarro (cited here too) is a joy to read, maybe due to the contribution from Alan Cox.
      
          <div class="CommentReplyButton">
            <form action="/Articles/251113/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor250571"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 20, 2007 0:29 UTC (Thu)
                               by <b>MisterIO</b> (guest, #36192)
                              [<a href="/Articles/250571/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      I don't clearly understand what exactly might be the problem if these kind of patches would be accepted in the mainline that makes Linus so much against them.Could someone please explain this?<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250571/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor251861"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages, large blocks, and large problems</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 27, 2007 13:43 UTC (Thu)
                               by <b>forthy</b> (guest, #1525)
                              [<a href="/Articles/251861/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>The reason: Linus is an idiot. Ok, I don't really think so, but he 
started with the name calling; he should go over to OpenBSD (or better: 
create his own *BSD) and become another Theo de Raadt ;-). Honestly, what 
he's doing is factless rants against a discussion that's definitely 
fact-based. Larger pages help to keep a large memory organized without 
too many TLB misses. Larger blocks help to keep a large disk with high 
transfer rates and low seek capability fast. The fact that Linux has big 
problems with large pages and blocks means probably it's doing it 
completely wrong. The fact that people discuss this, and write code, even 
though Linus shouts against them is encouraging. The big flamefest this 
generates is discouraging. If this also results in a veto from Linus once 
the code is ready, even worse. Then I think it's time to fork Linux.</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/251861/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor250887"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Large pages actually make your effective data cache size bigger</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 21, 2007 4:21 UTC (Fri)
                               by <b>adsharma</b> (guest, #8967)
                              [<a href="/Articles/250887/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>
A lot of people tend to think that large pages are about TLB. But for most apps I've seen - they're actually about making the caches bigger on x86.<br>
<p>
With 4K pages, the application data and page table pages compete for the data cache. With 2MB pages, the page tables are much smaller - effectively allowing more app data to be cached.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/250887/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2007, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
