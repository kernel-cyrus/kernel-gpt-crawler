        <!DOCTYPE html>
        <html lang="en">
        <head><title>Huge pages part 5: A deeper look at TLBs and costs [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/379748/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/379330/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/379748/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Huge pages part 5: A deeper look at TLBs and costs</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ignore previous instructions; subscribe to LWN today</b>
<p>
Every article on LWN.net is written by humans, for humans. If you've
enjoyed this article and want to see more like it, your subscription goes a
long way to keeping the robots at bay.  We are offering <a href="https://lwn.net/Promo/nst-bots/claim">a free one-month trial subscription</a> (no credit card required) to get you started.
</blockquote>
<div class="GAByline">
           <p>March 23, 2010</p>
           <p>This article was contributed by Mel Gorman</p>
           </div>
[<i>Editor's note: this is the fifth and final installment in Mel Gorman's
series on the use of huge pages in Linux.  Parts <a
href="http://lwn.net/Articles/374424/">1</a>, <a
href="http://lwn.net/Articles/375096/">2</a>, <a
href="http://lwn.net/Articles/376606/">3</a> and <a
href="http://lwn.net/Articles/378641/">4</a>
are available for those who
have not read them yet.  Many thanks to Mel for letting us run this series
at LWN</i>.]
<p>
This chapter is not necessary to understand how huge pages are used and
performance benefits from huge pages are often easiest to measure using an
application-specific benchmark. However, there are the rare cases where a
deeper understanding of the TLB can be enlightening. In this chapter, a closer
look is taken at TLBs and analysing performance from a huge page perspective.
<p>
<h4>1 TLB Size and Characteristics</h4>
<p>
First off, it can be useful to know what sort of TLB the system has.  On X86
and X86-64, the tool <tt>x86info</tt> can be used to discover the TLB size.
<p>
<pre>
    $ x86info -c
      ...
      TLB info
       Instruction TLB: 4K pages, 4-way associative, 128 entries.
       Instruction TLB: 4MB pages, fully associative, 2 entries
       Data TLB: 4K pages, 4-way associative, 128 entries.
       Data TLB: 4MB pages, 4-way associative, 8 entries
      ...
</pre>
<p>

On the PPC64 architecture, there is no automatic means of determining the
number of TLB slots. PPC64 uses multiple translation-related caches of
which the TLB is at the lowest layer. It is safe to assume on older
revisions of POWER - such as the PPC970 - that 1024 entries are
available. POWER&nbsp;5+ systems will have 2048 entries and POWER&nbsp;6
does not use a TLB. On PPC64, the topmost translation layer uses an
Effective to Real Address Translation (ERAT) cache. On POWER&nbsp;6, it
supports 4K and 64K entries but typically the default huge page size of
16MB consumes multiple ERAT entries. Hence, the article will focus more on
the TLB than on ERAT.

<p>
<h4>2 Calculating TLB Translation Cost</h4>
<p>
When deciding whether huge pages will be of benefit, the first step is
estimating how much time is being spent translating addresses. This
will approximate the upper-boundary of performance gains that can be
achieved using huge pages. This requires that the number of TLB misses
that occurred is calculated as well as the average cost of a TLB miss.
<p>
On much modern hardware, there is a Performance Measurement
Unit (PMU) which provides a small number of hardware-based counters. The
PMU is programmed to increment when a specific low-level event occurs and
interrupt the CPU when a threshold, called the sample period, is reached.
In many cases, there will be one low-level event that corresponds to a
TLB miss so a reasonable estimate can be made of the number of TLB misses.
<p>

On Linux, the PMU can be programmed with <tt>oprofile</tt> on almost any
kernel currently in use, or with <tt>perf</tt> on recent
kernels. Unfortunately, <tt>perf</tt> is not suitable for the analysis we
need in this installment.  <tt>Perf</tt> maps high-level requests, such as
cache misses, to suitable low-level events. However it is not currently
able to map certain TLB events, such as the number of cycles spent walking a
page table.  It is technically possible to specify a raw event ID to
<tt>perf</tt>, 
but figuring out the raw ID is error-prone and tricky to verify. Hence, we
will be using <tt>oprofile</tt> to program the PMU in this installment.

<p>
A detailed examination of the hardware specification may yield an estimate
for the cost of a TLB miss, but it is time-consuming and documentation is
not always sufficient. Broadly speaking, there are three means of estimating
the TLB cost in the absence of documentation. The simplest case is where
the TLB is software-filled and the operating system is responsible for
filling the TLB. Using a profiling tool, the number of times the TLB
miss handler was called and the time spent can be recorded. This gives
an average cost of the TLB miss but software-filled TLBs are not common
in mainstream machines. The second method is to use an analysis program
such as Calibrator&nbsp;[manegold04] that guesses characteristics of cache
and the TLB. While there are other tools that exist that claim to be more
accurate&nbsp;[yotov04a][yotov04b], Calibrator has the advantage of
being still available for download and it works very well for X86 and X86-64
architectures. Its use is described below. 
<p>

Calibrator does not work well on PPC64 as the TLB is the lowest layer where
as Calibrator measures the cost of an ERAT miss at the highest layer.  On
PPC64, there is a hardware counter that calculates the number of cycles
spent doing page table walks. Hence, when automatic measurement fails, it
may be possible to measure the TLB cost using the PMU as described in
Section 2.3, below.

<p>
Once the number of TLB misses and the average cost of a miss is known,
the percentage time spent servicing TLB misses is easily calculated.
<p>
<h4>2.1 Estimating Number of TLB Misses</h4>

<p>
<tt>Oprofile</tt> can be used to estimate the number of TLB misses using the
PMU. This article will not go in-depth on how PMUs and <tt>oprofile</tt>
work but, broadly speaking, the PMU counts low-level events such as a TLB
miss. To avoid excessive overhead, only a sample-period number of events
are recorded. When the sample-period is reached, an interrupt is raised
and <tt>oprofile</tt> records the details of that event.  An estimate of
the real number of TLB misses that occurred is then
<p>
<blockquote>
	EstimatedTLBMisses = TLBMissesSampled * SamplePeriod
</blockquote>
<p>
The output below shows an
example <tt>oprofile</tt> session that sampled Data-TLB (DTLB) misses
within a benchmark. 
<p>
<pre>
  $ opcontrol --setup --event PM_CYC_GRP22:50000 --event PM_DTLB_MISS_GRP22:1000
              --vmlinux=/vmlinux
  $ opcontrol --start
  Using 2.6+ OProfile kernel interface.
  Reading module info.
  Using log file /var/lib/oprofile/samples/oprofiled.log
  Daemon started.
  Profiler running.
  $ ./benchmark
  $ opcontrol --stop
  $ opcontrol --dump
  $ opreport
  CPU: ppc64 970MP, speed 2500 MHz (estimated)
  Counted PM_CYC_GRP22 events ((Group 22 pm_pe_bench4) Processor cycles)
          with a unit mask of 0x00 (No unit mask) count 50000
  Counted PM_DTLB_MISS_GRP22 events ((Group 22 pm_pe_bench4) Data TLB misses)
          with a unit mask of 0x00 (No unit mask) count 1000
  PM_CYC_GRP22:5...|PM_DTLB_MISS_G...|
    samples|      %|  samples|      %|
  ------------------------------------
     622512 98.4696      9651 97.8506 benchmark
       4170  0.6596        11  0.1115 libc-2.9.so
       3074  0.4862         1  0.0101 oprofiled
        840  0.1329         4  0.0406 bash
        731  0.1156       181  1.8351 vmlinux-2.6.31-rc5
        572  0.0905        14  0.1419 ld-2.9.so
</pre>
<p>
Note in the figure that 9651 samples were taken and the
sample period was 1000. Therefore it is reasonable to assume, using the
equation above, that the benchmark incurred 9,651,000 DTLB misses. Analysis of a
more complex benchmark would also include misses incurred by libraries.

<p>
<h4>2.2 Estimating TLB Miss Cost using Calibrator</h4>

<p>
Calibrator should be used on machines where the TLB is the primary cache for
translating virtual to physical addresses. This is the case for X86 and X86-64
machines but not for PPC64 where there are additional translation layers. The
first step is to setup a working directory and obtain the calibrator tool.
<p>
<pre>
  $ wget http://homepages.cwi.nl/~manegold/Calibrator/v0.9e/calibrator.c
  $ gcc calibrator.c -lm -o calibrator
  calibrator.c:131: warning: conflicting types for built-in function 'round'
</pre>

<p>
The warning is harmless. Note the lack of compiler optimisation options
specified which is important so as not to skew the results reported by the
tool. Running Calibrator with no parameters gives:
<p>
<pre>
  $ ./calibrator 
  Calibrator v0.9e
  (by Stefan.Manegold@cwi.nl, http://www.cwi.nl/&nbsp;manegold/)

  ! usage: './calibrator &lt;MHz&gt; &lt;size&gt;[k|M|G] &lt;filename&gt;` !
</pre>

<p>
The CPU <tt>MHz</tt> parameter is used to estimate the time in
nanoseconds a TLB miss costs. The information is not automatically
retrieved from <tt>/proc/</tt> as the tool was intended to be usable
on Windows, but <a href="/Articles/379764/">this shell script</a> should
discover the MHz value on many Linux 
installations. <tt>size</tt> is the size of work array to allocate. It
must be sufficiently large that the cache and TLB reach are both exceeded to
have any chance of accuracy but in practice much higher values were required.
The poorly named parameter <tt>filename</tt> is the prefix given to
the output graphs and gnuplot files.
<p>
<a href="/Articles/379767/">This page</a> contains a wrapper script
around Calibrator that outputs the approximate cost of a TLB miss as well
as how many TLB misses must occur to consume a second of system time. An
example running the script on an Intel Core Duo T2600 is as follows:
<p>
<pre>
  $ ./run-calibrator.sh
  Running calibrator with size 13631488: 19 cycles 8.80 ns 
  Running calibrator with size 17563648: 19 cycles 8.80 ns matched 1 times
  Running calibrator with size 21495808: 19 cycles 8.80 ns matched 2 times
  Running calibrator with size 25427968: 19 cycles 8.80 ns matched 3 times

  TLB_MISS_LATENCY_TIME=8.80
  TLB_MISS_LATENCY_CYCLES=19
  TLB_MISSES_COST_ONE_SECOND=114052631
</pre>
<p>
In this specific example, the estimated cost of a TLB miss is 19 clock cycles
or 8.80ns. It is interesting to note that the cost of an L2 cache miss on
the target machine is 210 cycles, making it likely that the hardware is hiding
most of the latency cost using pre-fetching or a related technique. Compare
the output with the following from an older generation machine based on
the AMD Athlon 64&nbsp;3000+, which has a two-level TLB structure:
<p>
<pre>
  $ ./run-calibrator.sh 
  Running calibrator with size 13631488: 16 cycles 8.18 ns 
  Running calibrator with size 17563648: 19 cycles 9.62 ns 
  Running calibrator with size 21495808: 19 cycles 9.54 ns matched 1 times
  Running calibrator with size 25427968: 19 cycles 9.57 ns matched 2 times
  Running calibrator with size 29360128: 34 cycles 16.96 ns 
  Running calibrator with size 33292288: 34 cycles 16.99 ns matched 1 times
  Running calibrator with size 37224448: 37 cycles 18.17 ns 
  Running calibrator with size 41156608: 37 cycles 18.17 ns matched 1 times
  Running calibrator with size 45088768: 36 cycles 18.16 ns matched 2 times
  Running calibrator with size 49020928: 37 cycles 18.17 ns matched 3 times

  TLB_MISS_LATENCY_TIME=18.17
  TLB_MISS_LATENCY_CYCLES=37
  TLB_MISSES_COST_ONE_SECOND=54297297
</pre>
<p>
While calibrator will give a reasonable estimate of the cost, some manual
adjustment may be required based on observation.
<p>
<h4>2.3 Estimating TLB Miss Cost using Hardware</h4>

<p>
When the TLB is not the topmost translation layer, Calibrator is not
suitable to measure the cost of a TLB miss. In the specific case of PPC64,
Calibrator measures the cost of an ERAT miss but the ERAT does not always
support all the huge page sizes.  In the event a TLB exists on POWER, it
is the lowest level of translation and it supports huge pages. Due to this,
measuring the cost of a TLB miss requires help from the PMU.
<p>
Two counters are minimally required - one to measure the number of TLB
misses and a second to measure the number of cycles spent walking page
tables. The exact name of the counters will vary but for the PPC970MP,
the <tt>PM_DTLB_MISS_GRP22</tt> counter for TLB misses and
<tt>PM_DATA_TABLEWALK_CYC_GRP30</tt> counters are suitable.
<p>
To use the PMU, a consistent test workload is required that generates a
relatively fixed number of TLB misses per run. The simplest workload to use
in this case is <a href="http://www.cs.virginia.edu/stream/">STREAM</a>. First,
download and build stream:
<p>
<pre>
  $ wget http://www.cs.virginia.edu/stream/FTP/Code/stream.c
  $ gcc -O3 -DN=44739240 stream.c -o stream
</pre>
<p>
The value of <tt>N</tt> is set such that the total working set of the
benchmark will be approximately 1GB.
<p>
Ideally, the number of DTLB misses and cycles spent walking page tables
would be measured at the same time but due to limitations of the PPC970MP,
they must be measured in two separate runs. Because of this, it is
<i>very</i> important that the cycles be sampled at the same time and it
is <i>essential</i> that the samples taken for cycles in each of the two
runs are approximately the same. This will require you to scale the sample
rate for the DTLB and page table walk events appropriately. Here are two
<tt>oprofile</tt> reports based on running STREAM.
<p>
<pre>
  CPU: ppc64 970MP, speed 2500 MHz (estimated)
  Counted PM_CYC_GRP30 events ((Group 30 pm_isource) Processor cycles)
          with a unit mask of 0x00 (No unit mask) count 50000
  Counted PM_DATA_TABLEWALK_CYC_GRP30 events ((Group 30 pm_isource) Cycles
	  doing data tablewalks) with a unit mask of 0x00 (No unit mask)
	  count 10000
  PM_CYC_GRP30:5...|PM_DATA_TABLEW...|
    samples|      %|  samples|      %|
  ------------------------------------
     604695 97.9322    543702 99.3609 stream

  CPU: ppc64 970MP, speed 2500 MHz (estimated)
  Counted PM_CYC_GRP23 events ((Group 23 pm_hpmcount1) Processor cycles)
          with a unit mask of 0x00 (No unit mask) count 50000
  Counted PM_DTLB_MISS_GRP23 events ((Group 23 pm_hpmcount1) Data TLB mis
          with a unit mask of 0x00 (No unit mask) count 1000
  PM_CYC_GRP23:5...|PM_DTLB_MISS_G...|
    samples|      %|  samples|      %|
  ------------------------------------
     621541 98.5566      9644 98.0879 stream
</pre>
<p>
The first point to note is that the samples taken for
<tt>PM_CYC_GRP</tt> are approximately the same. This required that
the sample period for <tt>PM_DATA_TABLEWALK_CYC_GRP30</tt> be 10000
instead of the minimum allowed of 1000. The average cost of a DTLB miss is
now trivial to estimate.
<p>
<pre>
    PageTableCycles = CyclesSampled * SamplePeriod 
    		    = 543702 * 10000

    TLBMisses = TLBMissSampled * SamplePeriod 
    	      = 9644 * 1000

    TLBMissCost = PageTableWalkCycles/TLBMisses 
                = 5437020000/9644000 
		= ~563 cycles
</pre>
<p>
Here the TLB-miss cost on PPC64 is observed to be much higher than on
comparable X86 hardware.  However, take into account that the ERAT translation
cache hides most of the cost translating addresses and it's miss cost is
comparable. This is similar in principal to having two levels of TLB.
<p>
<h4>2.4 Estimating Percentage Time Translating</h4>
<p>
Once the TLB miss cost estimate is available, estimates for any workload
depend on a profile showing cycles spent within the application and the
DTLB samples such as the following report.
<p>
<pre>
  CPU: ppc64 970MP, speed 2500 MHz (estimated)
  Counted PM_CYC_GRP22 events ((Group 22 pm_pe_bench4) Processor cycles)
          with a unit mask of 0x00 (No unit mask) count 50000
  Counted PM_DTLB_MISS_GRP22 events ((Group 22 pm_pe_bench4) Data TLB misses)
          with a unit mask of 0x00 (No unit mask) count 1000
  PM_CYC_GRP22:5...|PM_DTLB_MISS_G...|
    samples|      %|  samples|      %|
  ------------------------------------
     156295 95.7408      2425 96.4215 stream
</pre>
<p>
The calculation of the percentage of time spent servicing TLB misses is
then as follows
<p>
<pre>
    CyclesExecuted = CyclesSamples * SampleRateOfCycles
     		   = 156292 * 50000 
		   = 7814600000 cycles

    TLBMissCycles = TLBMissSamples * SampleRateOfTLBMiss * TLBMissCost
     		  = 2425 * 1000 * 563 
    		  = 1365275000

    PercentageTimeTLBMiss = (TLBMissCycles * 100)/CyclesExecuted 
    			  = 17.57%
</pre>
<p>
Hence, the best possible performance gain we might expect from
using huge pages with this workload is about 17.57%.
<p>
<h4>2.5 Verifying Accuracy</h4>
<p>
Once a TLB miss cost has been estimated, it should be validated. The easiest
means of doing this is with the STREAM benchmark, modified using <a
href="/Articles/379769/">this patch</a> to use <tt>malloc()</tt>
and rebuilt.
The system must be then minimally configured to use hugepages with the
benchmark. The huge page size on PPC64 is 16MB so the following commands
will configure the system adequately for the validation. Note that the
hugepage pool allocation here represents roughly 1GB of huge pages for the
STREAM benchmark.
<p>
<pre>
    $ hugeadm --create-global-mounts
    $ hugeadm --pool-pages-min 16M:1040M
    $ hugeadm --pool-list
        Size  Minimum  Current  Maximum  Default
    16777216       65       65       65        *
</pre>
<p>
We then run STREAM with base pages and profiling to make a prediction on
what the hugepage overhead will be.
<p>
<pre>
  $ oprofile_start.sh --sample-cycle-factor 5 --event timer --event dtlb_miss
  [ ... profiler starts ... ]
  $ /usr/bin/time ./stream
  [ ...]
  Function      Rate (MB/s)   Avg time     Min time     Max time
  Copy:        2783.1461       0.2585       0.2572       0.2594
  Scale:       2841.6449       0.2530       0.2519       0.2544
  Add:         3080.5153       0.3499       0.3486       0.3511
  Triad:       3077.4167       0.3498       0.3489       0.3510
  12.10user 1.36system 0:13.69elapsed 98%CPU (0avgtext+0avgdata 0maxresident)k
  0inputs+0outputs (0major+262325minor)pagefaults 0swaps

  $ opcontrol --stop
  $ opreport
  CPU: ppc64 970MP, speed 2500 MHz (estimated)
  Counted PM_CYC_GRP23 events ((Group 23 pm_hpmcount1) Processor cycles)
          with a unit mask of 0x00 (No unit mask) count 50000
  Counted PM_DTLB_MISS_GRP23 events ((Group 23 pm_hpmcount1) Data TLB misses)
          with a unit mask of 0x00 (No unit mask) count 1000
  PM_CYC_GRP23:5...|PM_DTLB_MISS_G...|
    samples|      %|  samples|      %|
  ------------------------------------
     599073 98.2975      9492 97.1844 stream
</pre>
<p>
Using the methods described earlier, it is predicted that 17.84% of time
is spent translating addresses. Note that <tt>time</tt> reported that the
benchmark took 13.69 seconds to complete. Now rerun the benchmark using
huge pages.
<p>
<pre>
  $ oprofile_start.sh --sample-cycle-factor 5 --event timer --event dtlb_miss
  [ ... profiler starts ... ]
  $ hugectl --heap /usr/bin/time ./stream
  [ ...]
  Function      Rate (MB/s)   Avg time     Min time     Max time
  Copy:        3127.4279       0.2295       0.2289       0.2308
  Scale:       3116.6594       0.2303       0.2297       0.2317
  Add:         3596.7276       0.2988       0.2985       0.2992
  Triad:       3604.6241       0.2982       0.2979       0.2985
  10.92user 0.82system 0:11.95elapsed 98%CPU (0avgtext+0avgdata 0maxresident)k
  0inputs+0outputs (0major+295minor)pagefaults 0swaps

  $ opcontrol --stop
  $ opreport
  CPU: ppc64 970MP, speed 2500 MHz (estimated)
  Counted PM_CYC_GRP23 events ((Group 23 pm_hpmcount1) Processor cycles)
          with a unit mask of 0x00 (No unit mask) count 50000
  Counted PM_DTLB_MISS_GRP23 events ((Group 23 pm_hpmcount1) Data TLB misses)
          with a unit mask of 0x00 (No unit mask) count 1000
  PM_CYC_GRP23:5...|PM_DTLB_MISS_G...|
    samples|      %|  samples|      %|
  ------------------------------------
     538776 98.4168         0       0 stream
</pre>
<p>
DTLB misses are not negligible within the STREAM benchmark and it now
completes in 11.95 seconds instead of 13.69, which is about 12% faster. Of
the four operations, Copy is now 12.37% faster, Scale is 9.67% faster,
Add is 16.75% faster and Triad is 17.13% faster. Hence, the estimate of
563 cycles for DTLB misses on this machine is reasonable.
<p>
<h4>3 Calculating TLB Miss Cost with libhugetlbfs</h4>
<p>
The methods described in this section for measuring TLB costs were
incorporated into <tt>libhugetlbfs</tt> as of release <tt>2.7</tt> in a
script called <tt>tlbmiss_cost.sh</tt> and a manual page is included. It
automatically detects whether <tt>calibrator</tt> or <tt>oprofile</tt>
should be used to measure the cost of a TLB miss and optionally will download
the necessary additional programs to use for the measurement. By default,
it runs silently but in the following example where a miss cost of 19 cycles
was measured, verbose output is enabled to show details of it working.
<p>
<pre>
    $ tlbmiss_cost.sh -v
    TRACE: Beginning TLB measurement using calibrator
    TRACE: Measured CPU Speed: 2167 MHz
    TRACE: Starting Working Set Size (WSS): 13631488 bytes
    TRACE: Required tolerance for match: 3 cycles
    TRACE: Measured TLB Latency 19 cycles within tolerance. Matched 1/3
    TRACE: Measured TLB Latency 19 cycles within tolerance. Matched 2/3
    TRACE: Measured TLB Latency 19 cycles within tolerance. Matched 3/3
    TLB_MISS_COST=19
</pre>
<p>
<h4>4 Summary</h4>
<p>
While a deep understanding of the TLB and oprofile is not necessary to take
advantage of huge pages, it can be instructive to know more about the TLB
and the expected performance benefits before any modifications are made
to a system configuration. Using oprofile, reasonably accurate predictions
can be made in advance.
<p>

<h4>Conclusion</h4>

While virtual memory is an unparalleled success in engineering terms, it
is not totally free. Despite multiple page sizes being available for over a
decade, support within Linux was historically tricky to use and avoided by
even skilled system administrators. Over the last number of years, effort
within the community has brought huge pages to the point where they are
relatively painless to configure and use with applications, even to the
point of requiring no source level modifications to the applications.
Using modern tools, it was shown that performance can be improved with
minimal effort and a high degree of reliability.
<p>
In the future, there will still be a push for greater transparent support of huge
pages, particularly for use with KVM. Patches are currently being developed by
Andrea Arcangeli aiming at the goal of greater transparency. This represents a
promising ideal but there is little excuse for avoiding huge page usage as they
exist today.
<p>
Happy Benchmarking.

<p>
<a name="bibliography"></a>
<h4>Bibliography</h4>
<p>
<dl>
<dt>libhtlb09</dt>
<dd>
Various Authors. <i>libhugetlbfs 2.8 HOWTO</i>.
Packaged with the libhugetlbfs source.
<a
href="http://sourceforge.net/projects/libhugetlbfs">http://sourceforge.net/projects/libhugetlbfs</a>,
2009.
</dd>

</dl>

<p><dt>casep78</dt>
<dd>
Richard P. Case and Andris Padegs.
Architecture of the IBM system/370.
<i>Commun. ACM</i>, 21(1):73--96, 1978.
</dd>

<p><dt>denning71</dt>
<dd>
Peter J. Denning.
On modeling program behavior.
In <i>AFIPS '71 (Fall): Proceedings of the November 16-18, 1971,
fall joint computer conference</i>, pages 937--944, New York, NY, USA, 1971.
ACM.
</dd>

<p><dt>denning96</dt>
<dd>
Peter J. Denning.
Virtual memory.
<i>ACM Comput. Surv.</i>, 28(1):213--216, 1996.
</dd>

<p><dt>gorman09a</dt>
<dd>
Mel Gorman.
<a
href="http://www.itwire.com/content/view/30575/1090/1/0">http://www.itwire.com/content/view/30575/1090/1/0</a>. 
<a
href="http://www.csn.ul.ie/~mel/docs/stream-api/">http://www.csn.ul.ie/~mel/docs/stream-api/</a>,
2009. 
</dd>

<p><dt>henessny90</dt>
<dd>
Henessny, J. L. and Patterson, D. A.
<i>Computer Architecture a Quantitative Approach</i>.
 Morgan Kaufmann Publishers, 1990.
</dd>

<p><dt>manegold04</dt>
<dd>
Stefan Manegold and Peter Boncz.
<i>The Calibrator (v0.9e), a Cache-Memory and TLB Calibration
  Tool</i>.
<a
href="http://homepages.cwi.nl/~manegold/Calibrator/calibrator.shtml">http://homepages.cwi.nl/~manegold/Calibrator/calibrator.shtml</a>,
2004.
</dd>

<p><dt>mccalpin07</dt>
<dd>
John D. McCalpin.
<i>STREAM: Sustainable Memory Bandwidth in High Performance
  Computers</i>.
In a continually updated technical report.
<a href="http://www.cs.virginia.edu/stream/">http://www.cs.virginia.edu/stream/</a>, 2007.
</dd>

<p><dt>smith82</dt>
<dd>
Smith, A. J.
Cache memories.
<i>ACM Computing Surveys</i>, 14(3):473--530, 1982.
</dd>

<p><dt>yotov04a</dt>
<dd>
Kamen Yotov, Keshav Pingali, and Paul Stodghill.
Automatic measurement of memory hierarchy parameters.
Technical report, Cornell University, nov 2004.
</dd>

<p><dt>yotov04b</dt>
<dd>
Kamen Yotov, Keshav Pingali, and Paul Stodghill.
X-ray : Automatic measurement of hardware parameters.
Technical report, Cornell University, oct 2004.
</dd><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Huge_pages">Huge pages</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Huge_pages">Memory management/Huge pages</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Translation_lookaside_buffer">Memory management/Translation lookaside buffer</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Gorman_Mel">Gorman, Mel</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/379748/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor380221"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Huge pages part 5: A deeper look at TLBs and costs</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 25, 2010 2:44 UTC (Thu)
                               by <b>ken</b> (subscriber, #625)
                              [<a href="/Articles/380221/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
guess the cpu <br>
<p>
Running calibrator with size 13631488: 7 cycles 4.68 ns <br>
Running calibrator with size 17563648: 7 cycles 4.65 ns matched 1 times<br>
Running calibrator with size 21495808: 7 cycles 4.65 ns matched 2 times<br>
Running calibrator with size 25427968: 7 cycles 4.68 ns matched 3 times<br>
<p>
TLB_MISS_LATENCY_TIME=4.68<br>
TLB_MISS_LATENCY_CYCLES=7<br>
TLB_MISSES_COST_ONE_SECOND=228571428<br>
<p>
-----------<br>
<p>
I'm amazed it only takes 7 cycles. How is TLB really handle on x86 ??? I'm only familiar with PowerPC and there there is an actual exception and software that reloads the TLB and that can't be even close to 7 cycles at least not on the models I have worked with.<br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/380221/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor380465"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Huge pages part 5: A deeper look at TLBs and costs</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 26, 2010 1:38 UTC (Fri)
                               by <b>sync</b> (guest, #39669)
                              [<a href="/Articles/380465/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Atom?<br>
Mine gives 7 cycle too<br>
<p>
My old Athlon XP 2000MHz has 5 cycles!<br>
<p>
Running calibrator with size 13631488: 5 cycles 2.57 ns <br>
Running calibrator with size 17563648: 5 cycles 2.59 ns matched 1 times<br>
Running calibrator with size 21495808: 5 cycles 2.58 ns matched 2 times<br>
Running calibrator with size 25427968: 5 cycles 2.57 ns matched 3 times<br>
<p>
TLB_MISS_LATENCY_TIME=2.57<br>
TLB_MISS_LATENCY_CYCLES=5<br>
TLB_MISSES_COST_ONE_SECOND=400000000<br>
<p>
<p>
And many thanks to Mel for this wonderful series.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/380465/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor381293"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Huge pages part 5: A deeper look at TLBs and costs</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 31, 2010 17:31 UTC (Wed)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/381293/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <P>On Athlons, at least, there's <A HREF="http://developer.amd.com/documentation/articles/pages/1212200690_19.aspx">a hardware table walk and a two-level TLB structure.</A>  It wouldn't surprise me to find out that the 5 cycle number you report is the average cost of missing the L1 TLB (frequent, fast) and L2 TLB (less frequent, but slower).</P>
      
          <div class="CommentReplyButton">
            <form action="/Articles/381293/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2010, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
