        <!DOCTYPE html>
        <html lang="en">
        <head><title>Debugging the kernel using Ftrace - part 2 [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/366796/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/367025/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/366796/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Debugging the kernel using Ftrace - part 2</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>We're bad at marketing</b>
<p>
We can admit it, marketing is not our strong suit. Our strength is
writing the kind of articles that developers, administrators, and
free-software supporters depend on to know what is going on in the
Linux world. Please <a href="/Promo/nsn-bad/subscribe">subscribe today</a> to help us keep doing that, and so
we donâ€™t have to get good at marketing.
</blockquote>
<div class="GAByline">
           <p>December 22, 2009</p>
           <p>This article was contributed by Steven Rostedt</p>
           </div>
<p>The Ftrace tracing utility has many different features that will assist
in tracking down Linux kernel problems.  The <a href="http://lwn.net/Articles/365835/">previous
article</a> discussed setting up Ftrace, using the function and function graph
tracers, using <tt>trace_printk()</tt>, and a simple way to stop the recording
of a trace from user space.  This installment will touch on how user space
can interact with Ftrace, faster ways of stopping the trace, debugging a
crash, and finding what kernel functions are the biggest stack hogs.</p>

<h4>Trace Markers</h4>

<p>Seeing what happens inside the kernel gives the user a better
understanding of how their system works. But sometimes there needs to be
coordination between what is happening in user space and what is happening
inside the kernel.  The timestamps that are shown in the traces are all
relative to what is happening within the trace, but they do not correspond
well with wall time.</p>

<p>To help synchronize between the actions in user space and kernel space,
the <tt>trace_marker</tt> file was created. It provides a way to write into the
Ftrace ring buffer from user space. This marker will then appear in the trace
to give a location in the trace of where a specific event occurred.</p>

<pre>
    [tracing]# echo hello world &gt; trace_marker
    [tracing]# cat trace
    # tracer: nop
    #
    #           TASK-PID    CPU#    TIMESTAMP  FUNCTION
    #              | |       |          |         |
               &lt;...&gt;-3718  [001]  5546.183420: 0: hello world
</pre>

<p>
The <tt>&lt;...&gt;</tt> indicates that the name of the task that
wrote the marker was not recorded. Future releases may fix this.
</p>

<h4>Starting, Stopping and Recording in a Program</h4>

<p>The <tt>tracing_on</tt> and <tt>trace_marker</tt>
files work very well to trace the activities of an application if the
source of the application is available. If there is a problem within the
application and you need to find out what is happening inside the kernel at
a particular location of the application, these two files come in
handy.</p>

<p>At the start of the application, you can open
these files to have the file descriptors ready:</p>

<pre>
    int trace_fd = -1;
    int marker_fd = -1;

    int main(int argc, char **argv)
    {
	    char *debugfs;
	    char path[256];
	    [...]

	    debugfs = find_debugfs();
	    if (debugfs) {
		    strcpy(path, debugfs);  /* BEWARE buffer overflow */
		    strcat(path,"/tracing/tracing_on");
		    trace_fd = open(path, O_WRONLY);
		    if (trace_fd &gt;= 0)
			    write(trace_fd, "1", 1);

		    strcpy(path, debugfs);
		    strcat(path,"/tracing/trace_marker");
		    marker_fd = open(path, O_WRONLY);
</pre>


<p>Then, at some critical location in the code, markers can be placed
to show where the application currently is: </p>

<pre>
    if (marker_fd &gt;= 0)
	    write(marker_fd, "In critical area\n", 17);

    if (critical_function() < 0) {
	    /* we failed! */
	    if (trace_fd &gt;= 0)
		    write(trace_fd, "0", 1);
    }
</pre>


<p>In looking at the example, first you see a function
called "find_debugfs()". The proper location to mount the debug file system
is at <tt>/sys/kernel/debug</tt> but a robust tool should not depend on the
debug file system being mounted there. An example of
<tt>find_debugfs()</tt> is located <a
href="http://lwn.net/Articles/366800/">here</a>.
The file descriptors are initialized to -1 to allow this code to work
both with and without a tracing enabled kernel.</p>

<p>
When the problem is detected, writing the ASCII character "0"
into the <tt>trace_fd</tt> file descriptor stops tracing. As discussed
in part 1, this only disables the recording into the Ftrace ring buffer,
but the tracers are still incurring overhead.</p>

<p>
When using the initialization code above, tracing will be enabled
at the beginning of the application because
the tracer runs in overwrite mode. That is, when the trace buffer
fills up, it will remove the old data and replace it with the new.
Since only the most recent trace information is relevant when the problem
occurs 
there is no need to stop and start the tracing during the normal
running of the application. The tracer only needs to be disabled when
the problem is detected so the trace will have the history of what led
up to the error. If interval tracing is needed within the application, it can
write an ASCII "1" into the trace_fd to enable the tracing.

<p>Here is an example of a simple program called <tt>simple_trace.c</tt>
that uses
the initialization process described above:</p>

<pre>
    req.tv_sec = 0;
    req.tv_nsec = 1000;
    write(marker_fd, "before nano\n", 12);
    nanosleep(&amp;req, NULL);
    write(marker_fd, "after nano\n", 11);
    write(trace_fd, "0", 1);
</pre>

<p>(No error checking was added due to this being a simple program for
example purposes only.)</p>

<p>Here is the process to trace this simple program:</p>

<pre>
    [tracing]# echo 0 &gt; tracing_on
    [tracing]# echo function_graph &gt; current_tracer
    [tracing]# ~/simple_trace
    [tracing]# cat trace
</pre>

<p>The first line disables tracing because the program will enable it at
start up. Next the function graph tracer is selected.  The program is
executed, which results in the following trace.  Note that the output can
be a little verbose so much of it has been cut and replaced with
<tt>[...]</tt>:</p>

<pre>
    [...]
     0)               |      __kmalloc() {
     0)   0.528 us    |        get_slab();
     0)   2.271 us    |      }
     0)               |      /* before nano */
     0)               |      kfree() {
     0)   0.475 us    |        __phys_addr();
     0)   2.062 us    |      }
     0)   0.608 us    |      inotify_inode_queue_event();
     0)   0.485 us    |      __fsnotify_parent();
    [...]
     1)   0.523 us    |          _spin_unlock();
     0)   0.495 us    |    current_kernel_time();
     1)               |          it_real_fn() {
     0)   1.602 us    |  }
     1)   0.728 us    |            __rcu_read_lock();
     0)               |  sys_nanosleep() {
     0)               |    hrtimer_nanosleep() {
     0)   0.526 us    |      hrtimer_init();
     1)   0.418 us    |            __rcu_read_lock();
     0)               |      do_nanosleep() {
     1)   1.114 us    |            _spin_lock_irqsave();
    [...]
     0)               |      __kmalloc() {
     1)   2.760 us    |  }
     0)   0.556 us    |        get_slab();
     1)               |  mwait_idle() {
     0)   1.851 us    |      }
     0)               |      /* after nano */
     0)               |      kfree() {
     0)   0.486 us    |        __phys_addr();
</pre>

<p>Notice that the writes to <tt>trace_marker</tt> show up as comments in
the function graph tracer.</p>

<p>The first column here represents the CPU. When we have the CPU traces
interleaved like this, it may become hard to read the trace. The tool
<tt>grep</tt> can easily filter this, or the <tt>per_cpu</tt> trace files
may be used.  The <tt>per_cpu</tt> trace files are located in the debugfs
tracing directory under <tt>per_cpu</tt>.</p>

<pre>
    [tracing]# ls per_cpu
    cpu0  cpu1  cpu2  cpu3  cpu4  cpu5  cpu6  cpu7
</pre>

<p>There exists a trace file in each one of these CPU directories that
only show the trace for that CPU.</p>

<p>To get a nice view of the function graph tracer without the interference of
other CPUs just look at <tt>per_cpu/cpu0/trace</tt>.</p>

<pre>
    [tracing]# cat per_cpu/cpu0/trace
     0)               |      __kmalloc() {
     0)   0.528 us    |        get_slab();
     0)   2.271 us    |      }
     0)               |      /* before nano */
     0)               |      kfree() {
     0)   0.475 us    |        __phys_addr();
     0)   2.062 us    |      }
     0)   0.608 us    |      inotify_inode_queue_event();
     0)   0.485 us    |      __fsnotify_parent();
     0)   0.488 us    |      inotify_dentry_parent_queue_event();
     0)   1.106 us    |      fsnotify();
    [...]
     0)   0.721 us    |    _spin_unlock_irqrestore();
     0)   3.380 us    |  }
     0)               |  audit_syscall_entry() {
     0)   0.495 us    |    current_kernel_time();
     0)   1.602 us    |  }
     0)               |  sys_nanosleep() {
     0)               |    hrtimer_nanosleep() {
     0)   0.526 us    |      hrtimer_init();
     0)               |      do_nanosleep() {
     0)               |        hrtimer_start_range_ns() {
     0)               |          __hrtimer_start_range_ns() {
     0)               |            lock_hrtimer_base() {
     0)   0.866 us    |              _spin_lock_irqsave();
    [...]
     0)               |      __kmalloc() {
     0)               |        get_slab() {
     0)   1.851 us    |      }
     0)               |      /* after nano */
     0)               |      kfree() {
     0)   0.486 us    |        __phys_addr();
</pre>


<h4>Disabling the Tracer Within the Kernel</h4>

<p>During the development of a kernel driver there may exist strange
errors that occur during testing. Perhaps the driver gets stuck in a sleep
state and never wakes up.  Trying to disable the tracer from user space
when a kernel event occurs is difficult and usually results in a buffer
overflow and loss of the relevant information before the user can stop
the trace.</p>

<p>There are two functions that work well inside the kernel:
<tt>tracing_on()</tt> and <tt>tracing_off()</tt>.  These two act just like
echoing "1" or "0" respectively into the <tt>tracing_on</tt> file.  If there is
some condition that can be checked for inside the kernel, then the tracer
may be stopped by adding something like the following: </p>

<pre>
    if (test_for_error())
	    tracing_off();
</pre>

<p>Next, add several <tt>trace_printk()</tt>s (see part 1), recompile, and
boot the kernel.  You can then enable the function or function graph tracer
and just
wait for the error condition to happen. Examining the <tt>tracing_on</tt>
file will let you know when the error condition occurred. It will switch
from "1" to "0" when the kernel calls <tt>tracing_off()</tt>.</p>

<p>After examining the trace, or saving it off in another file with:

<pre>
cat trace &gt; ~/trace.sav
</pre> 
you can continue the trace to examine another
hit. To do so, just echo "1" into <tt>tracing_on</tt>, and the trace will
continue. This is also useful if the condition that triggers the
<tt>tracing_off()</tt> call can be triggered legitimately. If the condition was
triggered by normal operation, just restart the trace by echoing a "1" back
into <tt>tracing_on</tt> and hopefully the next time the condition is hit
will be because of the abnormality.</p>


<h4>ftrace_dump_on_oops</h4>

<p>There are times that the kernel will crash and examining the memory and
state of the crash is more of a CSI science than a program debugging
science.  Using <tt>kdump</tt>/<tt>kexec</tt> with the <tt>crash</tt>
utility is a valuable way to examine the state of the system at the point
of the crash, but it does not let you see what has happened prior to the
event that caused the crash.</p>

<p>Having Ftrace configured and enabling <tt>ftrace_dump_on_oops</tt> in
the kernel boot parameters, or by echoing a "1" into
<tt>/proc/sys/kernel/ftrace_dump_on_oops</tt>, will enable Ftrace to dump
to the console the entire trace buffer in ASCII format on oops or panic.
Having the console output to a serial log makes debugging crashes much
easier.  You can now trace back the events that led up to the crash.</p>

<p>Dumping to the console may take a long time since the default Ftrace
ring buffer is over a megabyte per CPU. To shrink the size of the ring
buffer, write the number of kilobytes you want the ring buffer to be to
<tt>buffer_size_kb</tt>.  Note that the value is per CPU, not the total
size of the ring buffer.

<pre>
    [tracing]# echo 50 &gt; buffer_size_kb
</pre>

The above will shrink the Ftrace ring buffer down to 50 kilobytes per
CPU. 

<p>You can also trigger a dump of the Ftrace buffer to the console with
<tt>sysrq-z</tt>.</p>

<p>To choose a particular location for the kernel dump, the kernel may call
<tt>ftrace_dump()</tt> directly.  Note, this may permanently disable Ftrace
and a reboot may be necessary to enable it again.  This is because
<tt>ftrace_dump()</tt> reads the buffer. The buffer is made to be written
to in all contexts (interrupt, NMI, scheduling) but the reading of the
buffer requires locking.  To be able to perform <tt>ftrace_dump()</tt> the
locking is disabled and the buffer may end up being corrupted after the
output.</p>

<pre>
    /*
     * The following code will lock up the box, so we dump out the
     * trace before we hit that location.
     */
    ftrace_dump();

    /* code that locks up */
</pre>


<h4>Stack Tracing</h4>

<p>The final topic to discuss is the ability to examine the size of the
kernel stack and how much stack space each function is using. Enabling the
stack tracer (<tt>CONFIG_STACK_TRACER</tt>) will show where the biggest use
of the stack takes place.</p>

<p>The stack tracer is built from the function tracer infrastructure. It
does not use the Ftrace ring buffer, but it does use the function tracer to
hook into every function call. Because it uses the function tracer
infrastructure, it does not add overhead when not enabled. To enable the
stack tracer, echo 1 into
<tt>/proc/sys/kernel/stack_tracer_enabled</tt>. To see the max stack size
during boot up, add "<tt>stacktrace</tt>" to the kernel boot parameters.</p>

<p>The stack tracer checks the size of the stack at every function call. If it
is greater than the last recorded maximum, it records the stack trace and
updates the maximum with the new size. To see the current maximum, look at the
<tt>stack_max_size</tt> file.

<pre>
    [tracing]# echo 1 &gt; /proc/sys/kernel/stack_tracer_enabled
    [tracing]# cat stack_max_size
    2928
    [tracing]# cat stack_trace
            Depth    Size   Location    (34 entries)
            -----    ----   --------
      0)     2952      16   mempool_alloc_slab+0x15/0x17
      1)     2936     144   mempool_alloc+0x52/0x104
      2)     2792      16   scsi_sg_alloc+0x4a/0x4c [scsi_mod]
      3)     2776     112   __sg_alloc_table+0x62/0x103
    [...]
     13)     2072      48   __elv_add_request+0x98/0x9f
     14)     2024     112   __make_request+0x43e/0x4bb
     15)     1912     224   generic_make_request+0x424/0x471
     16)     1688      80   submit_bio+0x108/0x115
     17)     1608      48   submit_bh+0xfc/0x11e
     18)     1560     112   __block_write_full_page+0x1ee/0x2e8
     19)     1448      80   block_write_full_page_endio+0xff/0x10e
     20)     1368      16   block_write_full_page+0x15/0x17
     21)     1352      16   blkdev_writepage+0x18/0x1a
     22)     1336      32   __writepage+0x1a/0x40
     23)     1304     304   write_cache_pages+0x241/0x3c1
     24)     1000      16   generic_writepages+0x27/0x29
    [...]
     30)      424      64   bdi_writeback_task+0x3f/0xb0
     31)      360      48   bdi_start_fn+0x76/0xd7
     32)      312     128   kthread+0x7f/0x87
     33)      184     184   child_rip+0xa/0x20
</pre>

<p>Not only does this give you the size of the maximum stack found, it also
shows the breakdown of the stack sizes used by each function.  Notice that
<tt>write_cache_pages</tt> had the biggest stack with 304 bytes being used,
followed by <tt>generic_make_request</tt> with 224 bytes of stack.</p>

<p>To reset the maximum, echo "0" into the <tt>stack_max_size</tt>
file.</p>

<pre>
    [tracing]# echo 0 &gt; stack_max_size
</pre>

<p>Keeping this running for a while will show where the
kernel is using a bit too much stack. But remember that the stack tracer
only has no overhead when it is not enabled. When it is running you may notice a
bit of a performance degradation.</p>

<p>Note that the stack tracer will not trace the max stack size when the
kernel is using a separate stack. Because interrupts have their own stack,
it will not trace the stack usage there. The reason is that currently
there is no easy way to quickly see what the top of the stack is when the
stack is something other than the current task's stack. When using split
stacks, a process stack may be two pages but the interrupt stack may only
be one.  This may be fixed in the future, but keep this in mind when using
the stack tracer.</p>

<h4>Conclusion</h4>

<p>Ftrace is a very powerful tool and easy to configure. No extra tools are
necessary. Everything that was shown it this tutorial can be used on
embedded devices that only have Busybox installed. Taking advantage of the
Ftrace infrastructure should cut the time needed to debug that hard-to-find
race condition. I seldom use <tt>printk()</tt> any more because using the
function and function graph tracers along with <tt>trace_printk()</tt> and
<tt>tracing_off()</tt> have become my main tools for debugging the Linux
kernel.</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Development_tools-Kernel_tracing">Development tools/Kernel tracing</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Ftrace">Ftrace</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Tracing-Ftrace">Tracing/Ftrace</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Rostedt_Steven">Rostedt, Steven</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/366796/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor919713"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Debugging the kernel using Ftrace - part 2</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 12, 2023 6:32 UTC (Thu)
                               by <b>psc</b> (guest, #151343)
                              [<a href="/Articles/919713/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
could you give me a C program example about start ftrace , execute app,stop ftrace,  thank you very much<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/919713/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2009, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
