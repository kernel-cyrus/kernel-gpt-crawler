        <!DOCTYPE html>
        <html lang="en">
        <head><title>Support for atomic block writes in 6.13 [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/1009298/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/1011012/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/1009298/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Support for atomic block writes in 6.13</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Did you know...?</b>
<p>
LWN.net is a subscriber-supported publication; we rely on subscribers
       to keep the entire operation going.  Please help out by <a
       href="/Promo/nst-nag4/subscribe">buying a subscription</a> and keeping LWN on the
       net.
</blockquote>
<div class="GAByline">
           <p>February 20, 2025</p>
           <p>This article was contributed by Ritesh Harjani and Ojaswin Mujoo</p>
           </div>
Atomic block writes, which <a
href="/Kernel/Index/#Atomic_IO_operations">have been discussed here</a> a
few times in the past, are block operations that either complete fully or
do not occur at all, ensuring data consistency and preventing partial (or
"torn") writes.  This means the disk will, at all times, contain either the
complete new data from the atomic write operation or the complete old data
from a previous write. It will never have a mix of both the old and the new
data, even if a power failure occurs during an ongoing atomic write
operation. Atomic writes have been of interest to many Linux users,
particularly database developers, as this feature can provide significant
performance improvements.

<p>
The Linux 6.13 merge window included a pull request from VFS
maintainer Christian Brauner titled "<a
href="/ml/all/20241115-vfs-untorn-writes-7229611aeacc@brauner/">vfs untorn
writes</a>", which added the initial atomic-write capability to the
kernel. In this article, we will briefly cover what these atomic writes
are, why they are important in database world, and what is currently
supported in the 6.13 kernel.

<p>To support atomic writes, changes were required across various layers of the
Linux I/O stack. At the VFS level,
an interface was introduced to allow applications to request atomic write
I/O, along with enhancements to <a
href="https://man7.org/linux/man-pages/man2/statx.2.html"><tt>statx()</tt></a>
to query atomic-write capabilities.  Filesystems had to ensure that
physical extent allocations were aligned to the underlying device's
constraints, preventing extents from crossing atomic-write boundaries.  For
example, NVMe namespaces may define atomic boundaries; writes that
straddle these boundaries will lose atomicity guarantees.
<p>
The block layer <a
href="/ml/all/20240620125359.2684798-1-john.g.garry@oracle.com/">was
updated</a> to prevent the splitting of in-flight I/O operations for atomic
write requests and to propagate the device constraints for atomic writes to
higher layers.  Device drivers were also modified to correctly queue atomic
write requests to the hardware. Finally, the underlying disk itself must
support atomic writes at the hardware level. Both NVMe and SCSI provide
this feature, but in different ways; NVMe implicitly supports atomic writes
for operations that remain within specified constraints, but SCSI requires
a special command to ensure atomicity.

<h4>Why do databases care?</h4>

<p>A common practice in databases is to perform disk I/O in fixed-size chunks,
with 8KB and 16KB being popular I/O sizes. Databases also, however,
maintain a journal that records enough information to enable recovery from
a possible write error. The idea is that, if the write of new data fails,
the database can take the old data present on disk as a starting point and
use the information in the journal to reconstruct the new data. However,
this technique is based on the assumption that the old data on disk is still
consistent after the error, which may not hold if a write operation has
been torn.
<p>
Tearing may happen if the I/O stack doesn't guarantee atomicity. The
multi-KB write issued by the database could be split by the kernel (or the
hardware) into multiple, smaller write operations. This splitting could
result in a mix of old and new data being on disk after a write failure,
thus leading to inconsistent on-disk data which can't be used for
recovery.

<p>
To work around this possibility, databases employ an additional technique
called "double write". In this approach, they first write a copy of the
older data to a temporary storage area on disk and ensure that the
operation completes successfully before writing to the actual on-disk
tables. In case of an error in that second write operation, databases can
recover by performing a journal replay on the saved copy of the older data,
thus ensuring an accurate data recovery. But, as we can guess, these double
writes come at a significant performance cost, especially for write-heavy
workloads. This is the reason atomicity is sought after by databases; if
the I/O stack can ensure that the chunks will never be torn, then databases
can safely disable double writes without risking data corruption and, hence,
can get that lost performance back.

<h4>Current state in Linux</h4>

<p>
As discussed during <a href="https://lwn.net/Articles/974578/">LSFMM+BPF
2024</a>, some cloud vendors might already advertise atomic-write support
using the ext4 filesystem with <a
href="https://docs.kernel.org/filesystems/ext4/overview.html#bigalloc">bigalloc</a>,
a feature that enables cluster-based allocation instead of per-block
allocation. This helps to properly allocate aligned physical
blocks (clusters) for atomic write operations. However, claiming to support
atomic writes after auditing code to convince oneself that the kernel
doesn't split a write request is one thing, while properly integrating
atomic-write support with a well-defined user interface that guarantees
atomicity is another.

<p>With the Linux 6.13 release, the kernel provides a user interface for atomic
writes using direct I/O. Although it has certain limitations (discussed
later in this article), this marks an important step toward enabling
database developers to explore these interfaces.

<p>
A block device's atomic-write capabilities are stored in <a
href="https://elixir.bootlin.com/linux/v6.13.2/source/include/linux/blkdev.h#L358"><tt>struct
queue_limits</tt></a>. These limits are exposed to user space via the sysfs
interface at <tt>/sys/block/&lt;device&gt;/queue/atomic_*</tt>. The files
<tt>atomic_write_unit_min</tt> and <tt>atomic_write_unit_max</tt> indicate
the minimum and maximum number of bytes that can be written atomically. If
these values are nonzero, the underlying block device supports atomic
writes. However, hardware support alone is not sufficient; as mentioned
earlier, the entire software stack, including the filesystem, block layer,
and VFS, must also support atomic writes.

<h4>How to use the atomic-write feature</h4>

<p>
Currently, atomic-write support is only enabled for a single filesystem
block.  Multi-block support is <a
href="/ml/all/20241204154344.3034362-1-john.g.garry@oracle.com/">under
development</a>, but those operations bring some more constraints that are
still being discussed in the community. To utilize the current atomic write
feature in Linux 6.13, the filesystem must be formatted with a block
size that is suitable for the application's needs.  A good choice is often
16KB.
<p>
Note, though, that ext4 does not support filesystem block sizes greater
than the system's page size, so, on systems with 4KB page size (such as
x86), ext4 cannot use a block size of 16KB and, thus, cannot support atomic
write operations of that size. On the other hand, XFS recently got <a
href="/Articles/933437/">large block size support</a>, allowing it to
handle block sizes greater than page size. Note also that there is no
problem with ext4 or XFS if the page size of the system itself is either
16KB or 64KB (such as on arm64 or powerpc64 systems), as both filesystems
can handle block sizes less than or equal to the system's page size.
<p>
The following steps show how to make use of the atomic-write feature:

<ol class="spacylist">

<li> First create a filesystem (ext4 or xfs) with a suitable block size
     based on the atomic-write unit supported by the underlying block
     device. For example:

<pre>
    mkfs.ext4 -b 16K /dev/sdd
    mkfs.xfs -bsize=16K /dev/sdd
</pre>

</li>

<li> Next, use the <tt>statx()</tt> system call to confirm whether atomic
     writes are supported on a file by the underlying filesystem. Unlike
     checking the block device sysfs path, which only indicates whether the
     underlying disk supports atomic writes, <tt>statx()</tt> allows the
     application to query whether it is possible to request an atomic write
     operation on a file and determine the supported unit size, which also
     ensures that the entire I/O stack supports atomic writes.

<p>
     To facilitate atomic writes, <tt>statx()</tt> now exposes the
     following fields when the <tt>STATX_WRITE_ATOMIC</tt> flag is passed:

<ul>

<li> <tt>stx_atomic_write_unit_min</tt>: Minimum size of an atomic write request.</li>

<li> <tt>stx_atomic_write_unit_max</tt>: Maximum size of an atomic write request.</li>

<li> <tt>stx_atomic_write_segments_max</tt>: Upper limit for segments â€” the
     number of separate memory buffers that can be gathered into a write
     operation 
     (e.g., the <tt>iovcnt</tt> parameter for
     <tt>IOV_ITER</tt>). Currently, this is always set to one.</li>

<li> The <tt>STATX_ATTR_WRITE_ATOMIC</tt> flag in <tt>statx-&gt;attributes</tt>
     is set if atomic writes are supported.</li>
</ul>
<p>An example <tt>statx()</tt> snippet would look like the following:

<pre>
    statx(AT_FDCWD, file_path, 0, STATX_BASIC_STATS | STATX_WRITE_ATOMIC, &amp;stat_buf);

    printf("Atomic write Min: %d\n", stat_buf.stx_atomic_write_unit_min);
    printf("Atomic write Max: %d\n", stat_buf.stx_atomic_write_unit_max);
</pre>

</li>

<li> Finally, to perform an atomic write, open the file in
     <tt>O_DIRECT</tt> mode and issue a <a
     href="https://man7.org/linux/man-pages/man2/readv.2.html"><tt>pwritev2()</tt></a>
     system call with the <tt>RWF_ATOMIC</tt> flag set. Ensure that the total
     length of the write is a power of two that falls between
     <tt>atomic_write_unit_min</tt> and <tt>atomic_write_unit_max</tt>, and that the
     write starts at a naturally aligned offset in the file with respect to
     the total length of the write.

</li>
</ol>
<p>Currently, <tt>pwritev2()</tt> with <tt>RWF_ATOMIC</tt> supports only a single <tt>iovec</tt>
and is limited to a single filesystem block write. This means that
filesystems, when queried via <tt>statx()</tt>, report both the minimum and
maximum atomic-write unit as a single filesystem block (e.g., 16KB in
the example above).

<h4>The future</h4>

<p>
Kernel developers have implemented initial support for direct I/O atomic
writes that are limited to a single filesystem block. However, there is an
ongoing work which aims to extend the support to multi-block atomic writes
for both the <a
href="/ml/all/f5bd55d32031b49bdd9e2c6d073787d1ac4b6d78.1729825985.git.ritesh.list@gmail.com/">ext4</a>
and <a
href="/ml/all/20241204154344.3034362-1-john.g.garry@oracle.com/">XFS</a>
filesystems.  Despite its limitations, this feature provides a foundation
for those interested in atomic-write support in Linux. This also presents
an opportunity for users, such as database developers, to start exploring
and experimenting with this feature. One can still collaborate with the
community to enhance this feature, as it is still under active <a
href="/ml/all/Z6O6g4pCu-pXJql5@bombadil.infradead.org/">discussion</a> and
<a
href="/ml/all/Z5nTaQgLGdD6hSvL@li-dc0c254c-257c-11b2-a85c-98b6c1322444.ibm.com/">development</a>.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Atomic_IO_operations">Atomic I/O operations</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Block_layer-Atomic_operations">Block layer/Atomic operations</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Harjani_Ritesh">Harjani, Ritesh</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/1009298/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor1011107"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Atomic writes should be the default... ideally</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 20, 2025 16:15 UTC (Thu)
                               by <b>meven-collabora</b> (subscriber, #168883)
                              [<a href="/Articles/1011107/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Any application if it has the opportunity would want to use atomic writes provided it isn't too much overhead neither too much hassle.<br>
Like the direct I/O requirement and limited file size support of the current state.<br>
Detecting hardware support is nicely exposed through statx already.<br>
Hopefully this will benefit also regular user and mobile and not just database servers.<br>
<p>
Cat pictures, and account spreadsheets are precious too.<br>
<p>
Great work regardless.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011107/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor1011116"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Atomic writes should be the default... ideally</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 20, 2025 17:36 UTC (Thu)
                               by <b>iabervon</b> (subscriber, #722)
                              [<a href="/Articles/1011116/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Most applications don't really want block-level atomicity properties; instead, they want whole-file atomicity, where the standard pattern is to write the new data to a new inode, and then make the filename refer to the new inode after the whole thing has been written. For a cat picture, if the file ends up containing partially old data and partially new data, it doesn't solve anything if the transitions are on block boundaries or not.<br>
<p>
The thing that's special about databases isn't that their data is more precious, it's that small, well-defined parts of the file are being changed frequently and independently, so it's necessary to modify the stored data in place, and it's feasible and worthwhile to use a file structure where individual block changes correspond to valid files states.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011116/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor1011111"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">large atomic writes for xfs</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 20, 2025 16:27 UTC (Thu)
                               by <b>garrier79</b> (subscriber, #171723)
                              [<a href="/Articles/1011111/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
JFYI, latest support for large atomics on xfs is posted here... <a href="https://lore.kernel.org/linux-xfs/0f983090-4399-4cba-910d-299bf5e0da2c@oracle.com/T/#m77f00f31830b5ad55cad204e8671355e30f1f518">https://lore.kernel.org/linux-xfs/0f983090-4399-4cba-910d...</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011111/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor1011135"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Why write twice</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 20, 2025 19:55 UTC (Thu)
                               by <b>jengelh</b> (subscriber, #33263)
                              [<a href="/Articles/1011135/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<span class="QuotedText">&gt;To work around this possibility, databases employ an additional technique called "double write".</span><br>
<p>
Why do databases (still) need a double write? E.g. git, btrfs, liblmdb, seem to do just fine with writing the data block and then (atomically) updating a pointer.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011135/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor1011149"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Why write twice</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 20, 2025 22:21 UTC (Thu)
                               by <b>butlerm</b> (subscriber, #13312)
                              [<a href="/Articles/1011149/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If you have atomic block writes you do not need to write two different versions of the block in a "double write".  That said, most databases use a redo log and block updates are committed to redo a long time before data blocks are updated in a checkpoint of some sort.<br>
<p>
Filesystems like the NetApp filesystem, zfs, and btrfs use a phase tree approach that is not yet common for (relational) databases.  And one of the reasons it is not common is because most relational databases were and are designed to give acceptable performance on spinning rust type hard disks and internal pointers in the database - in database indexes in particular -  in most designs need to translate to the physical address of the referenced block without doing any additional physical disk I/O.<br>
<p>
That means that they run more efficiently on direct mapped non-phase tree filesystems like xfs, ext4, or ntfs if not actual raw disk devices, which used to be quite common in some environments.  If you put a typical relational database on a filesystem like btrfs or zfs it will slow down dramatically for that reason. It can be done of course, especially with something like zfs, but most people don't do it.  That goes for Oracle, MySQL, PostgreSQL, DB2, MS SQL Server, Sybase, and a number of other older relational databases that are not so popular anymore.<br>
<p>
If you want to design a relational or similar database to use a phase tree approach internally the place you probably ought to start is with typical B-tree or hash indexes, which are already multiversioned in most designs, and sometimes with versions that last for a considerable amount of time to do index rebuilds without taking a table offline. <br>
<p>
And although it is usually slower it is possible to store primary key references instead pf physical or logical database block references in secondary indexes and use an index organized table that basically puts the row data in the leaves of a B-tree or similar tree that  is ordinarily only accessed by primary key value instead of by something like (datafile, block, row).  Then of course it doesn't really matter if data blocks and rows have several versions at new file / block offsets because the database would not generally access them by file / block / row number anyway except at a very low level.<br>
<p>
PostgreSQL might be more amenable to this because if I recall correctly Postgres table data is index organized already and old row versions are stored inline and have to be vacuumed or essentially garbage collected later.  Oracle stores old row versions to allow multiversion read consistency in a separate areas referred to as "rollback segments", which is one of the reasons why although it supports very long running transactions it originally had a hard time keeping up with simpler non MVCC designs like DB2, Ingres, Informix, Sybase, and MS SQL, and (of course) MySQL especially before MySQL even had automated support for transactions and ACID properties in the first place.  There was a major tradeoff there for years that was usually solved by throwing lots of disk spindles at the problem, like separate disks or RAID 1 mirrored pairs for different tablespaces, data files, index segments, rollback segments, control files, and redo logs.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011149/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor1011166"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The real experience</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 21, 2025 2:10 UTC (Fri)
                               by <b>ikm</b> (guest, #493)
                              [<a href="/Articles/1011166/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Do those things work in practice? I mean, safe recovery from a physical power failure, ideally on a consumer-grade hardware. Every time this happens to me, I can't help but pray that the database *will* actually recover, even if in theory it must...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011166/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor1011170"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The real experience</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 21, 2025 4:21 UTC (Fri)
                               by <b>willy</b> (subscriber, #9762)
                              [<a href="/Articles/1011170/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Well. This feature is being developed for systems which are sold to you as an appliance. Your vendor has tested the feature works with the certified drives they sell to you with it.<br>
<p>
If you're using consumer grade hardware, then you have to either take the manufacturer's word for it or test it yourself.<br>
<p>
Most consumer grade hardware does not advertise that it supports multi-block atomicity though, so the question doesn't arise.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011170/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor1011168"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The real experience</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 21, 2025 4:24 UTC (Fri)
                               by <b>Thalience</b> (subscriber, #4217)
                              [<a href="/Articles/1011168/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>Consumer-grade nvme devices (that are already employing a flash-translation layer) have no reason <i>not</i> to do an atomic update when the spec says they should.</p>

<p>But it no-longer surprises me when exposing an api contract to wider testing also exposes some vendors/devices as doing the wrong thing for no good reason.</p>


      
          <div class="CommentReplyButton">
            <form action="/Articles/1011168/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor1011167"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The real experience</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 21, 2025 6:12 UTC (Fri)
                               by <b>butlerm</b> (subscriber, #13312)
                              [<a href="/Articles/1011167/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It should recover just fine as long as the sector or page size for the physical hardware is as large or in some cases larger than the database block size, and the drive in question can either write a full sector while spinning down after a power loss, or you have a battery backed cache on your drive controller, or your SSDs have capacitors big enough so that it can commit anything that is supposed to be forced to disk before it loses power, and of course your drive firmware does not have pathological bugs of the sort that used to be common in solid state drives for a while, or you have a reliabile UPS with appropriate shut everything down in case of power failure lasting more than X minutes software, or your datacenter has one that actually works.<br>
<p>
<p>
Most physical spinning rust style hard drives that I am aware of these days have 4 KB sector sizes, and most SSDs have 128 KB page sizes.  In the case of the former ideally you would have 4 KB database data block sizes as well, but most databases have been using a default block size of 8192 bytes or more for some time now so they presumably account for that possibility.  And a typical way that is done is to store an adequate checksum and block id of some kind inline with the database data block so that a torn write or other unusual write failure or memory corruption can be detected when the block is next processed or read back in.  Some filesystems like zfs of course do something quite similar, with block checksums or secure hashes stored with all or almost all internal block pointers.  SHA-256 and CRC-32c are typically supported with CPU instructions on most modern enterprise class hardware so that isn't too difficult or too slow.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011167/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor1011454"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">How does this work at a physical level?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 23, 2025 2:37 UTC (Sun)
                               by <b>KJ7RRV</b> (guest, #153595)
                              [<a href="/Articles/1011454/">Link</a>] (8 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
How is an atomic write possible on physical media? Since writing data has to happen at a finite rate, thus taking nonzero time, isn't there always the possibility of abruptly losing power halfway through the write?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011454/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor1011459"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">How does this work at a physical level?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 23, 2025 4:35 UTC (Sun)
                               by <b>Cyberax</b> (<b>&#x272D; supporter &#x272D;</b>, #52523)
                              [<a href="/Articles/1011459/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
A capacitor can store enough charge to power the chip long enough to finish writing. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011459/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor1011464"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">How does this work at a physical level?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 23, 2025 7:25 UTC (Sun)
                               by <b>KJ7RRV</b> (guest, #153595)
                              [<a href="/Articles/1011464/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
That makes sense; thank you! So the drive has to be built with a capacitor to enable this feature?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011464/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor1011476"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">How does this work at a physical level?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 23, 2025 13:01 UTC (Sun)
                               by <b>farnz</b> (subscriber, #17727)
                              [<a href="/Articles/1011476/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      It doesn't need a capacitor, necessarily. There's two routes you can take in an SSD to enable this feature:
<ol>
<li>Have a capacitor or other energy store on the device, so that when power is lost, you can complete all the writes before the energy store drains.
<li>Use the FTL's block mapping to allow you to atomically switch in a new mapping with a single bit write, and do not return that the command is complete until the new mapping is switched in. Then, you can write the new data and associated mapping, followed by the single bit write to switch the mapping over. If that bit write succeeds, the swap over is done; if it doesn't, the swap fails to happen.
</ol>
<p>Capacitor is more likely, because it lets you have a write cache, too, and thus a performance advantage in enterprise drives. But it's possible without one in an SSD.


      
          <div class="CommentReplyButton">
            <form action="/Articles/1011476/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor1011510"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">How does this work at a physical level?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 24, 2025 1:32 UTC (Mon)
                               by <b>Paf</b> (subscriber, #91811)
                              [<a href="/Articles/1011510/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
"Use the FTL's block mapping to allow you to atomically switch in a new mapping with a single bit write, and do not return that the command is complete until the new mapping is switched in. Then, you can write the new data and associated mapping, followed by the single bit write to switch the mapping over. If that bit write succeeds, the swap over is done; if it doesn't, the swap fails to happen."<br>
<p>
I like that this is basically double writes - sometimes, it's turtles all the way down.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011510/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor1012796"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">How does this work at a physical level?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 3, 2025 17:09 UTC (Mon)
                               by <b>mebrown</b> (subscriber, #7960)
                              [<a href="/Articles/1012796/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
No, it's not a double write.<br>
<p>
The new data is written to a new block, then the mapping table entry is atomically switched so that the old data is unmapped/freed and the new data is swapped in.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1012796/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor1011480"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">How does this work at a physical level?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 23, 2025 13:50 UTC (Sun)
                               by <b>kleptog</b> (subscriber, #1183)
                              [<a href="/Articles/1011480/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
For non-SSDs you have hardware RAID controllers with a battery-backed memory that will hold the blocks waiting to be written and if the power fails it will keep the data and write it out when the power comes back.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1011480/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor1013162"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">How does this work at a physical level?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 6, 2025 8:32 UTC (Thu)
                               by <b>ras</b> (subscriber, #33059)
                              [<a href="/Articles/1013162/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Spinning Rust has always had to solve this problem so some extent.  You can't have a 1/2 written block causing disk errors, so they ensured they had enough power around to complete writing a sector once it started. I'm not sure how they did it.  One explanation I heard was they used rotating power in the platters.  Extending that time with a super capacitor wouldn't be a big change.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1013162/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor1014516"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">How does this work at a physical level?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 18, 2025 18:20 UTC (Tue)
                               by <b>sammythesnake</b> (guest, #17693)
                              [<a href="/Articles/1014516/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
With transfer speeds of GiB/s (or even MiB/s if we're talking about the Good Old Days) a 4KiB sector will take bugger all time to write, so a supercap is colossal overkill for "finish the sector" power. Flushing the whole of a sizeable cache would likely be into the realm of a non-super capacitor, though, especially in the pathological case of the cached writes all being single sectors nowhere near each other...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1014516/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2025, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
