        <!DOCTYPE html>
        <html lang="en">
        <head><title>Calibrating your fear of big bad optimizing compilers [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/799218/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/801995/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/799218/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Calibrating your fear of big bad optimizing compilers</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ready to give LWN a try?</b>
<p>
With a subscription to LWN, you can stay current with what is happening in the Linux and free-software community and take advantage of subscriber-only site features.  We are pleased to offer you <b><a href="https://lwn.net/Promo/nst-trial/claim">a free trial subscription</a></b>, no credit card required, so that you can see for yourself.  Please, join us!
</blockquote>
<div class="GAByline">
           <p>October 11, 2019</p>
           <p>(Many contributors)</p>
           </div>
<p>This article was contributed by
	   Jade Alglave, Will Deacon, Boqun Feng, David Howells, Daniel
	   Lustig, Luc Maranget, Paul E. McKenney, Andrea Parri, Nicholas
	   Piggin, Alan Stern, Akira Yokosawa, and Peter Zijlstra.
	   </p>

<p>
As noted
<a href="/Articles/793253/">earlier</a>,
when compiling Linux-kernel code that does a plain C-language load or
store, as in
"<tt>a=b</tt>", the C standard grants the compiler the right
to assume that the affected variables are neither accessed nor modified
by any other thread at the time of that load or store.
The compiler is therefore permitted to carry out a surprisingly
large number of optimizations, any number of which might ruin your
concurrent code's day.
Given that current compilers usually do not emit diagnostics warning of
potential ruined days, it would be good to have other tools take on this
task.
One such tool is the
<a href="https://github.com/google/ktsan/wiki">Kernel Thread Sanitizer (KTSAN)</a>,
but its great strength, the ability to analyze huge bodies of code such
as the Linux kernel, is also its great weakness, namely the need to use
approximate (though still quite good) analysis techniques.

<div class="tlr">
<a name="Quick Quiz 1"><b>Quick Quiz 1</b>:</a>
	But we shouldn't be afraid at all for things like
	on-stack or per-CPU variables, right?
<br><a href="#qq1answer">Answer</a>
</div>



<p>
What is needed is a tool that can do exact analyses of huge bodies of
code, but unfortunately the universe is under no compunction to give
us what we think we need.
We have therefore upgraded the
<a href="https://github.com/torvalds/linux/tree/master/tools/memory-model">Linux Kernel Memory Model (LKMM)</a>
to do exact analyses of small bodies of code, and this upgrade was
accepted into the Linux kernel during the v5.3 merge window.
The challenge of doing exact analyses of large bodies of code thus remains
open, but in the meantime we have another useful tool at our disposal.

<p>
The following sections describe how to use this upgrade to LKMM:

<ol>
<li>	<a href="#Goals and Non-Goals">Goals and non-goals</a>
<li>	<a href="#A Plain Example">A plain example</a>
<li>	<a href="#A Less-Plain Example">A less-plain example</a>
<li>	<a href="#Locking">Locking</a>
<li>	<a href="#Reference Counting">Reference counting</a>
<li>	<a href="#Read-Copy Update (RCU)">Read-copy update (RCU)</a>
<li>	<a href="#Debug Output">Debug output</a>
<li>	<a href="#Access-Marking Policies">Access-marking policies</a>
<li>	<a href="#Limitations">Limitations</a>
<li>	<a href="#Summary">Summary</a>
</ol>

<p>
This is followed by the inevitable
<a href="#Answers to Quick Quizzes">answers to the quick quizzes</a>.

<h4><a name="Goals and Non-Goals"></a>Goals and non-goals</h4>

<p>
TL;DR: The goal of LKMM is to help people understand Linux-kernel
concurrency.

<p>
A key point from the first article
is that we simply do not have a full catalog of all compiler optimizations
that currently exist, let alone of all possible compiler options that
might one day exist.
Furthermore, the kernel must, in many cases,
<a
href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0124r6.html">live
outside of the bounds of the C standard</a>, 
and thus cannot simply make direct use of the C11 memory model.
The details of the compiler, of the compiler options used in Linux-kernel
builds, and all of the architecture-specific code therefore impinge on
LKMM&mdash;and vice versa.

<p>
Because of all of these complications and uncertainties, LKMM cannot
possibly be a cut-and-dried judge and juror for all Linux-kernel
memory-ordering matters.
It should instead be seen as an advisor.
Now, in generic, non-performance-critical code, it might be wise to
pay extremely close attention to LKMM's advice.
On the other hand, developers writing fastpath code might need to take an
LKMM warning as a sign of the need to be careful, rather than as an
error message to be fixed at all costs.

<p>With that in mind, let's look at some LKMM litmus-test examples
involving plain C-language accesses.

<h4><a name="A Plain Example"></a>A plain example</h4>

<p>
Consider the following message-passing litmus test using plain
C-language accesses and read and write memory barriers:

<blockquote>
Litmus&nbsp;Test&nbsp;#1
<pre>
  1 C C-MP+p-wmb-p+p-rmb-p
  2
  3 {
  4 }
  5
  6 P0(int *x0, int *x1)
  7 {
  8         *x0 = 1;
  9         smp_wmb();
 10         *x1 = 1;
 11 }
 12
 13 P1(int *x0, int *x1)
 14 {
 15         int r1;
 16         int r2;
 17
 18         r1 = *x1;
 19         smp_rmb();
 20         r2 = *x0;
 21 }
 22
 23 exists (1:r1=1 /\ 1:r2=0)
</pre>
</blockquote>

<p>As always, this litmus test can be run from within the kernel's
<tt>tools/memory-model</tt> directory using the following command:

<blockquote>
<pre>
herd7 -conf linux-kernel.cfg /path/to/litmus/tests/C-MP+p-wmb-p+p-rmb-p.litmus
</pre>
</blockquote>

<p>
Here, the "<tt>/path/to/litmus/tests</tt>" is of course
replaced by the path to the directory containing your litmus tests.
(See the <tt>README</tt> file in that same directory for installation
instructions and
<a href="/Articles/720550/">an earlier LWN article</a>
for more details on litmus tests.)
The output of this command is shown below:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#1 (linux-kernel model)
<pre>
 1 Test C-MP+p-wmb-p+p-rmb-p Allowed
 2 States 4
 3 1:r1=0; 1:r2=0;
 4 1:r1=0; 1:r2=1;
 5 1:r1=1; 1:r2=0;
 6 1:r1=1; 1:r2=1;
 7 Ok
 8 Witnesses
 9 Positive: 1 Negative: 3
10 Flag data-race
11 Condition exists (1:r1=1 /\ 1:r2=0)
12 Observation C-MP+p-wmb-p+p-rmb-p Sometimes 1 3
13 Time C-MP+p-wmb-p+p-rmb-p 0.00
14 Hash=055863a755bfaf3667f1667e6d660349
</pre>
</blockquote>

<div class="tlrw">
<a name="Quick Quiz 2"><b>Quick Quiz 2</b>:</a>
	But suppose only one of the accesses to a given variable is a 
	plain C-language access, and that access is the only store.
	Should this be considered a data race?
<br><a href="#qq2answer">Answer</a>

<p><a name="Quick Quiz 3"><b>Quick Quiz 3</b>:</a>
	Why the cop-out?
	Why not just do the work required to ensure that the list of
	states and the <tt>Observation</tt> line are all accurate?
<br><a href="#qq3answer">Answer</a>
</div>
<p>
Line&nbsp;10 contains the key advice: "<tt>Flag data-race</tt>".
This advice means that the <tt>Observation</tt> line's verdict is
untrustworthy and that the list of states on lines&nbsp;3-6 is unreliable.
The problem is that this litmus test has at least one data race, meaning
that there are multiple concurrent accesses to a given variable,
at least one of which is a plain C-language access and at least one of
which is a store.

<p>
The variable <tt>x1</tt> is clearly subject to a data race because
it can be accessed concurrently by a pair of plain accesses, at least
one of which is a write.
However, <tt>x1</tt> only ever takes on the values zero
and one, so the data race on that variable
<a href="http://lkml.kernel.org/r/20190606061438.nyzaeppdbqjt3jbp@gondor.apana.org.au">might be tolerable</a>,
at least assuming a healthy fear of the big bad optimizing compiler.
But what if we want to check for other data races?

<p>
The solution is to tell LKMM that you are excluding <tt>x1</tt> from
data-race flagging.
One way to do this is to add <tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt>
to the litmus test (as opposed to your Linux-kernel code),
preferably with a comment explaining the situation:

<blockquote>
Litmus&nbsp;Test&nbsp;#2
<pre>
  1 C C-MP+p-wmb-o+o-rmb-p
  2
  3 {
  4 }
  5
  6 P0(int *x0, int *x1)
  7 {
  8         *x0 = 1;
  9         smp_wmb();
 10         WRITE_ONCE(*x1, 1); // Tolerate data race
 11 }
 12
 13 P1(int *x0, int *x1)
 14 {
 15         int r1;
 16         int r2;
 17
 18         r1 = READ_ONCE(*x1); // Tolerate data race
 19         smp_rmb();
 20         r2 = *x0;
 21 }
 22
 23 exists (1:r1=1 /\ 1:r2=0)
</pre>
</blockquote>

<p>
LKMM still flags a data race:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#2 (linux-kernel model)
<pre>
 1 Test C-MP+p-wmb-o+o-rmb-p Allowed
 2 States 3
 3 1:r1=0; 1:r2=0;
 4 1:r1=0; 1:r2=1;
 5 1:r1=1; 1:r2=1;
 6 No
 7 Witnesses
 8 Positive: 0 Negative: 3
 9 Flag data-race
10 Condition exists (1:r1=1 /\ 1:r2=0)
11 Observation C-MP+p-wmb-o+o-rmb-p Never 0 3
12 Time C-MP+p-wmb-o+o-rmb-p 0.00
13 Hash=743f0171133035c53a5a29972b0ba0fd
</pre>
</blockquote>

<p>
The reason for this is that the plain C-language accesses to <tt>x0</tt>
can also execute concurrently, and one of these accesses is a write.
We could fix this by also marking the <tt>x0</tt> accesses with
<tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt>, but an alternative
is to avoid concurrency on <tt>x0</tt> as follows:

<blockquote>
Litmus&nbsp;Test&nbsp;#3
<pre>
  1 C C-MP+p-wmb-o+o+ctrl-rmb-p
  2
  3 {
  4 }
  5
  6 P0(int *x0, int *x1)
  7 {
  8         *x0 = 1;
  9         smp_wmb();
 10         WRITE_ONCE(*x1, 1); // Tolerate data race
 11 }
 12
 13 P1(int *x0, int *x1)
 14 {
 15         int r1;
 16         int r2;
 17
 18         r1 = READ_ONCE(*x1); // Tolerate data race
 19         if (r1) {
 20                 smp_rmb();
 21                 r2 = *x0;
 22         }
 23 }
 24
 25 exists (1:r1=1 /\ 1:r2=0)
</pre>
</blockquote>

<p>
The <tt>if</tt> statement on line&nbsp;19, when combined with the
<tt>smp_wmb()</tt> on line&nbsp;9, is intended to guarantee that
lines&nbsp;8 and&nbsp;21 never execute concurrently.
Running the model yields:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#3 (linux-kernel model)
<pre>
 1 Test C-MP+p-wmb-o+o+ctrl-rmb-p Allowed
 2 States 2
 3 1:r1=0; 1:r2=0;
 4 1:r1=1; 1:r2=1;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 2
 8 Condition exists (1:r1=1 /\ 1:r2=0)
 9 Observation C-MP+p-wmb-o+o+ctrl-rmb-p Never 0 2
10 Time C-MP+p-wmb-o+o+ctrl-rmb-p 0.00
11 Hash=01fe003cd2759d9284d40c081007c282
</pre>
</blockquote>

<p>
<div class="tlr">
<a name="Quick Quiz 4"><b>Quick Quiz 4</b>:</a>
	But the outcome "<tt>1:r1=0; 1:r2=1;</tt>" also disappeared.
	Why?
<br><a href="#qq4answer">Answer</a>
</div>


There is no longer a data race flagged, and the cyclic outcome no
longer occurs.
Therefore, if we are willing to live in sufficient fear of the compiler
to keep accesses to <tt>x1</tt> sane on the one hand and if we add a
conditional check protecting <tt>x0</tt> on the other,
we can obtain the required outcome.

<p>
In this case, because of the <tt>smp_wmb()</tt> and the fact that there
was only a single use of the value read, all that was needed to tell
LKMM about a tolerated data race was to use <tt>WRITE_ONCE()</tt> and
<tt>READ_ONCE()</tt> in the corresponding litmus test.
Unfortunately, some situations require a bit more work, as
will be hinted at in the next section.

<h4><a name="A Less-Plain Example">A less-plain example</a></h4>

<p>
The compiler has
great freedom to optimize plain accesses,
and with this great freedom comes great complexity.
To see this, consider the following litmus test:

<blockquote>
Litmus&nbsp;Test&nbsp;#4
<pre>
  1 C C-read-multiuse
  2
  3 {
  4 }
  5
  6 P0(int *a)
  7 {
  8         *a = 1;
  9 }
 10
 11 P1(int *a, int *b, int *c)
 12 {
 13         int r1;
 14
 15         r1 = *a;
 16         *b = r1;
 17         *c = r1;
 18 }
 19
 20 locations [1:r1; a; b; c]
 21 exists(b=1 /\ c=0)
</pre>
</blockquote>

<p>
As we should by now expect, this results in a data race:
<p>
<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#4 (linux-kernel model)
<pre>
 1 Test C-read-multiuse Allowed
 2 States 2
 3 1:r1=0; a=1; b=0; c=0;
 4 1:r1=1; a=1; b=1; c=1;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 2
 8 Flag data-race
 9 Condition exists (b=1 /\ c=0)
10 Observation C-read-multiuse Never 0 2
11 Time C-read-multiuse 0.00
12 Hash=0cab074d9a510f141aae9026ce447828
</pre>
</blockquote>

<p>
Creating a data-race-tolerant litmus test is straightforward:

<blockquote>
Litmus&nbsp;Test&nbsp;#5
<pre>
  1 C C-read-multiuse-drt1
  2
  3 {
  4 }
  5
  6 P0(int *a)
  7 {
  8         WRITE_ONCE(*a, 1); // Tolerate data race
  9 }
 10
 11 P1(int *a, int *b, int *c)
 12 {
 13         int r1;
 14
 15         r1 = READ_ONCE(*a); // Tolerate data race
 16         *b = r1;
 17         *c = r1;
 18 }
 19
 20 locations [1:r1; a; b; c]
 21 exists(b=1 /\ c=0)
</pre>
</blockquote>

<p>
And this both tolerates the data race and excludes the undesirable
outcome:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#5 (linux-kernel model)
<pre>
 1 Test C-read-multiuse-drt1 Allowed
 2 States 2
 3 1:r1=0; a=1; b=0; c=0;
 4 1:r1=1; a=1; b=1; c=1;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 2
 8 Condition exists (b=1 /\ c=0)
 9 Observation C-read-multiuse-drt1 Never 0 2
10 Time C-read-multiuse-drt1 0.00
11 Hash=96b3ae01a3c486885df1aec4d978bad9
</pre>
</blockquote>

<p>
Job done, right?

<p>
Not quite, courtesy of the aforementioned complexity.
Recall that compilers can
<a href="/Articles/793253/#Invented%20Loads">invent loads</a>.
Therefore, a better translation to a data-race-tolerant litmus test would
duplicate the load from shared variable <tt>a</tt> as follows:

<blockquote>
Litmus&nbsp;Test&nbsp;#6
<pre>
  1 C C-read-multiuse-drt2
  2
  3 {
  4 }
  5
  6 P0(int *a)
  7 {
  8         WRITE_ONCE(*a, 1); // Tolerate data race
  9 }
 10
 11 P1(int *a, int *b, int *c)
 12 {
 13         int r1;
 14         int r2;
 15
 16         r1 = READ_ONCE(*a); // Tolerate data race
 17         *b = r1;
 18         r2 = READ_ONCE(*a); // Tolerate data race
 19         *c = r2;
 20 }
 21
 22 locations [1:r1; a; b; c]
 23 exists(b=1 /\ c=0)
</pre>
</blockquote>

<p>
And this still tolerates the data race and excludes the undesirable
outcome:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#6 (linux-kernel model)
<pre>
 1 Test C-read-multiuse-drt2 Allowed
 2 States 3
 3 1:r1=0; a=1; b=0; c=0;
 4 1:r1=0; a=1; b=0; c=1;
 5 1:r1=1; a=1; b=1; c=1;
 6 No
 7 Witnesses
 8 Positive: 0 Negative: 3
 9 Condition exists (b=1 /\ c=0)
10 Observation C-read-multiuse-drt2 Never 0 3
11 Time C-read-multiuse-drt2 0.01
12 Hash=17ff8b2e2c285776994d4488fcdcd3bb
</pre>
</blockquote>

<p>
So <i>now</i> the job is done, right?

<p>
Still not quite.
Recall that compilers can
<a href="/Articles/793253/#Code%20Reordering">reorder code</a>.
And there is nothing telling the compiler that the store to <tt>b</tt>
needs to precede the store to <tt>c</tt>; additionally, the fact that the actual
code uses a plain C-language load from shared variable <tt>a</tt> allows
the compiler to assume (incorrectly, in this case) that shared
variable <tt>a</tt> isn't changing.
We therefore need to account for that with another data-race-tolerant
litmus test that does the reordering, for example, as follows:

<blockquote>
Litmus&nbsp;Test&nbsp;#7
<pre>
  1 C C-read-multiuse-drt3
  2
  3 {
  4 }
  5
  6 P0(int *a)
  7 {
  8         WRITE_ONCE(*a, 1); // Tolerate data race
  9 }
 10
 11 P1(int *a, int *b, int *c)
 12 {
 13         int r1;
 14         int r2;
 15
 16         r2 = READ_ONCE(*a); // Tolerate data race
 17         *c = r2;
 18         r1 = READ_ONCE(*a); // Tolerate data race
 19         *b = r1;
 20 }
 21
 22 locations [1:r1; a; b; c]
 23 exists(b=1 /\ c=0)
</pre>
</blockquote>

<p>
This still tolerates the data race, but allows the undesirable outcome:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#7 (linux-kernel model)
<pre>
 1 Test C-read-multiuse-drt3 Allowed
 2 States 3
 3 1:r1=0; a=1; b=0; c=0;
 4 1:r1=1; a=1; b=1; c=0;
 5 1:r1=1; a=1; b=1; c=1;
 6 Ok
 7 Witnesses
 8 Positive: 1 Negative: 2
 9 Condition exists (b=1 /\ c=0)
10 Observation C-read-multiuse-drt3 Sometimes 1 2
11 Time C-read-multiuse-drt3 0.01
12 Hash=61f32f3a79e57808d348f31f5800ae1d
</pre>
</blockquote>

<div class="tlr">
<a name="Quick Quiz 5"><b>Quick Quiz 5</b>:</a>
	But wait!
	Given that <tt>READ_ONCE()</tt> provides no ordering,
	why would
	Litmus&nbsp;Test&nbsp;#5
	avoid the undesirable outcome?
<br><a href="#qq5answer">Answer</a>
</div>

This example illustrates the need to carefully think through the
possible compiler optimizations when using plain C-language loads
and stores in situations involving data races.
It also illustrates the possible need to use multiple litmus tests
to fully analyze the possible outcomes.

<p>
So should use of plain C-language loads and stores for shared variables
be completely abolished throughout the kernel?

<p>
Absolutely not.

<p>
For one thing, it is often the case that a given plain C-language load
and store will be data-race free, as illustrated by the next few sections.

<h4><a name="Locking">Locking</a></h4>

<p>
The prevalence and usefulness of locking, particularly on systems
with modest numbers of CPUs, is one reason why C and C++ did not
add concurrency features for the first few decades of their
existence.
We should therefore expect that fully locked concurrent code should
do fine with plain C-language accesses.
For example, consider this fully locked store-buffering litmus test:

<blockquote>
Litmus&nbsp;Test&nbsp;#8
<pre>
  1 C C-SB+l-p-p-u+l-p-p-u
  2
  3 {
  4 }
  5
  6 P0(int *x0, int *x1, spinlock_t *s)
  7 {
  8         int r1;
  9
 10         spin_lock(s);
 11         *x0 = 1;
 12         r1 = *x1;
 13         spin_unlock(s);
 14 }
 15
 16 P1(int *x0, int *x1, spinlock_t *s)
 17 {
 18         int r1;
 19
 20         spin_lock(s);
 21         *x1 = 1;
 22         r1 = *x0;
 23         spin_unlock(s);
 24 }
 25
 26 exists (0:r1=0 /\ 1:r1=0)
</pre>
</blockquote>

<p>
As expected, LKMM shows that this litmus test produces only the
expected serialized outcomes, and does so without data races:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#8 (linux-kernel model)
<pre>
 1 Test C-SB+l-p-p-u+l-p-p-u Allowed
 2 States 2
 3 0:r1=0; 1:r1=1;
 4 0:r1=1; 1:r1=0;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 2
 8 Condition exists (0:r1=0 /\ 1:r1=0)
 9 Observation C-SB+l-p-p-u+l-p-p-u Never 0 2
10 Time C-SB+l-p-p-u+l-p-p-u 0.01
11 Hash=a1b190dd8375d869bc8826836e05f943
</pre>
</blockquote>

<p>
But locking is not the only data-race-free synchronization primitive.

<h4><a name="Reference Counting">Reference counting</a></h4>

<p>
Reference counting has, if anything, been in use longer than has locking.
It should therefore be no surprise that it is possible to atomically
manipulate reference counts in such a way as to permit plain C-language
access to shared variables.
One approach uses <tt>atomic_dec_and_test()</tt> so that the task
that decrements the reference count to zero owns all the data.
The following (fanciful) litmus test illustrates this design pattern:

<blockquote>
Litmus&nbsp;Test&nbsp;#9
<pre>
  1 C C-SB+p-rc-p-p+p-rc-p-p
  2
  3 {
  4         atomic_t rc=2;
  5 }
  6
  7 P0(int *x0, int *x1, atomic_t *rc)
  8 {
  9         int r0;
 10         int r1;
 11
 12         *x0 = 1;
 13         if (atomic_dec_and_test(rc)) {
 14                 r0 = *x0;
 15                 r1 = *x1;
 16         }
 17 }
 18
 19 P1(int *x0, int *x1, atomic_t *rc)
 20 {
 21         int r0;
 22         int r1;
 23
 24         *x1 = 1;
 25         if (atomic_dec_and_test(rc)) {
 26                 r0 = *x0;
 27                 r1 = *x1;
 28         }
 29 }
 30
 31 exists ~((0:r0=1 /\ 0:r1=1 /\ 1:r0=0 /\ 1:r1=0) \/
 32          (0:r0=0 /\ 0:r1=0 /\ 1:r0=1 /\ 1:r1=1))
</pre>
</blockquote>

<p>
Initially, each process owns its variable, that is, <tt>P0()</tt> owns
<tt>x0</tt> and <tt>P1()</tt> owns <tt>x1</tt>.
This reference count <tt>rc</tt> is initialized to the value 2 on line&nbsp;4,
indicating that both processes still own their respective variables.
Each process updates its variable (lines&nbsp;12 and&nbsp;24), then
releases its reference on <tt>rc</tt> (lines&nbsp;13 and&nbsp;25).
The "winning" process that decrements <tt>rc</tt> to zero
reads out both values, so that its values of <tt>r0</tt> and <tt>r1</tt>
are equal to the value 1.
The "losing" process's local variables remain zero.
The <tt>exists</tt> clause on line&nbsp;31 verifies this relationship:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#9 (linux-kernel model)
<pre>
 1 Test C-SB+p-rc-p-p+p-rc-p-p Allowed
 2 States 2
 3 0:r0=0; 0:r1=0; 1:r0=1; 1:r1=1;
 4 0:r0=1; 0:r1=1; 1:r0=0; 1:r1=0;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 2
 8 Condition exists (not (0:r0=1 /\ 0:r1=1 /\ 1:r0=0 /\ 1:r1=0 \/ 0:r0=0 /\ 0:r1=0 /\ 1:r0=1 /\ 1:r1=1))
 9 Observation C-SB+p-rc-p-p+p-rc-p-p Never 0 2
10 Time C-SB+p-rc-p-p+p-rc-p-p 0.02
11 Hash=7692409758270a77b577b11ab7cca3e3
</pre>
</blockquote>

<p>
<div class="tlrw"><a name="Quick Quiz 6"><b>Quick Quiz 6</b>:</a>
	I have seen plain C-language incrementing and decrementing
	of reference counters.
	How can that possibly work?
<br><a href="#qq6answer">Answer</a>
</div>

As expected, there are no data races and the "winner"
always safely reads out the data.
<br clear="all">

<h4><a name="Read-Copy Update (RCU)">Read-copy update (RCU)</a></h4>

<p>
A common RCU use case inserts items into a linked data structure.
If these items are initialized prior to insertion and if the
non-pointer fields are never changed after insertion, then plain
C-language accesses can be used throughout, as illustrated by
this litmus test:

<blockquote>
Litmus&nbsp;Test&nbsp;#10
<pre>
  1 C C-MP+p-rap+rl-rd-p-rul
  2
  3 {
  4         int z=42;  (* Initial garbage value *)
  5         int y=2;
  6         int *x=&amp;y; (* x is the list head; initially it points to y *)
  7 }
  8
  9 P0(int **x, int *y, int *z)
 10 {
 11         *z = 1;
 12         rcu_assign_pointer(*x, z); // Now x points to z.
 13 }
 14
 15 P1(int **x, int *y, int *z)
 16 {
 17         int *r1;
 18         int r2;
 19
 20         rcu_read_lock();
 21         r1 = rcu_dereference(*x); // Pick up list head.
 22         r2 = *r1; // Pick up value.
 23         rcu_read_unlock();
 24 }
 25
 26 locations [x; y; z]
 27 exists (1:r1=z /\ 1:r2=42) (* Better not be pre-initialization value!!! *)
</pre>
</blockquote>

<p>
<div class="tlrw">
<a name="Quick Quiz 7"><b>Quick Quiz 7</b>:</a>
	But given that
	Litmus&nbsp;Test&nbsp;#10
	has no <tt>synchronize_rcu()</tt>, what is the purpose of
	the <tt>rcu_read_lock()</tt> on line&nbsp;17 and the
	<tt>rcu_read_unlock()</tt> on line&nbsp;20?
<br><a href="#qq7answer">Answer</a>
</div>

(Note that herd requires <tt>(*</tt>a different comment syntax<tt>*)</tt>
in the initializer portion of the file.)
Lines&nbsp;5 and&nbsp;6 abuse <tt>herd7</tt> to create a rudimentary linked
data structure, with <tt>x</tt> initially referencing <tt>y</tt>.
<tt>P0()</tt> initializes <tt>z</tt> on line&nbsp;11
and links it into the list on line&nbsp;12.
<tt>P1()</tt> then picks up pointer <tt>x</tt> and dereferences it
within the confines of an RCU read-side critical section in the
normal manner.


<p>
This avoids data races and also prevents <tt>P0()</tt> from seeing
pre-initialization garbage in <tt>z</tt>, which LKMM confirms:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#10 (linux-kernel model)
<pre>
 1 Test C-MP+p-rap+rl-rd-p-rul Allowed
 2 States 2
 3 1:r1=y; 1:r2=2; x=z; y=2; z=1;
 4 1:r1=z; 1:r2=1; x=z; y=2; z=1;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 2
 8 Condition exists (1:r1=z /\ 1:r2=42)
 9 Observation C-MP+p-rap+rl-rd-p-rul Never 0 2
10 Time C-MP+p-rap+rl-rd-p-rul 0.01
11 Hash=fbe83006932079946732b23c5af9033d
</pre>
</blockquote>

<p>
It is also necessary to remove data from linked data structures and
free them, at least if we are to avoid memory leaks.
This process is illustrated with a similar litmus test:

<blockquote>
Litmus&nbsp;Test&nbsp;#11
<pre>
  1 C C-MP+rap-sync-p+rl-rd-rd-rul
  2
  3 {
  4         int z=1;
  5         int y=2;
  6         int *x=&amp;y; (* x is the list head; initially it points to y *)
  7 }
  8
  9 P0(int **x, int *y, int *z)
 10 {
 11         rcu_assign_pointer(*x, z); // Now x points to z.
 12         synchronize_rcu();
 13         *y = 0; // Emulate kfree(y).
 14 }
 15
 16 P1(int **x, int *y, int *z)
 17 {
 18         int *r1;
 19         int r2;
 20
 21         rcu_read_lock();
 22         r1 = rcu_dereference(*x); // Pick up list head.
 23         r2 = *r1; // Pick up value.
 24         rcu_read_unlock();
 25 }
 26
 27 locations [1:r1; x; y; z]
 28 exists (1:r2=0) (* Better not be freed!!! *)
</pre>
</blockquote>

<p>
This again avoids data races and also prevents readers from creating
a use-after-free bug:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#11 (linux-kernel model)
<pre>
 1 Test C-MP+rap-sync-p+rl-rd-rd-rul Allowed
 2 States 2
 3 1:r1=y; 1:r2=2; x=z; y=0; z=1;
 4 1:r1=z; 1:r2=1; x=z; y=0; z=1;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 2
 8 Condition exists (1:r2=0)
 9 Observation C-MP+rap-sync-p+rl-rd-rd-rul Never 0 2
10 Time C-MP+rap-sync-p+rl-rd-rd-rul 0.00
11 Hash=abfbb3196e583a4f3945a3e3846442b0
</pre>
</blockquote>

<p>
It is also possible to use <tt>synchronize_rcu()</tt> as an
<a href="/Articles/573497/">extremely heavy memory barrier</a>,
gaining an effect similar to
Litmus&nbsp;Test&nbsp;#3:

<blockquote>
Litmus&nbsp;Test&nbsp;#12
<pre>
  1 C C-MP+p-sync-o+rl-o-ctrl-p-rul
  2
  3 {
  4 }
  5
  6 P0(int *x0, int *x1)
  7 {
  8         *x0 = 1;
  9         synchronize_rcu();
 10         WRITE_ONCE(*x1, 1);
 11 }
 12
 13 P1(int *x0, int *x1)
 14 {
 15         int r1;
 16         int r2;
 17
 18         rcu_read_lock();
 19         r1 = READ_ONCE(*x1);
 20         if (r1) {
 21                 r2 = *x0;
 22         }
 23         rcu_read_unlock();
 24 }
 25
 26 exists (1:r1=1 /\ 1:r2=0)
</pre>
</blockquote>

<p>
LKMM confirms that this avoids both data races and the undesirable outcome
flagged by the <tt>exists</tt> clause:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#12 (linux-kernel model)
<pre>
 1 Test C-MP+p-sync-o+rl-o-ctrl-p-rul Allowed
 2 States 2
 3 1:r1=0; 1:r2=0;
 4 1:r1=1; 1:r2=1;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 2
 8 Condition exists (1:r1=1 /\ 1:r2=0)
 9 Observation C-MP+p-sync-o+rl-o-ctrl-p-rul Never 0 2
10 Time C-MP+p-sync-o+rl-o-ctrl-p-rul 0.00
11 Hash=7672d2fc273055d3dcf0fc68801e113a
</pre>
</blockquote>

<p>
In short, these past few sections have shown a few of the great many
situations in which plain C-language accesses to shared variables are
perfectly safe and legitimate.
However, <a
href="https://en.wikipedia.org/wiki/Murphy%27s_law">Mr. Murphy</a>
guarantees that complications can always arise, 
and one such complication is presented in the following section.

<h4><a name="Debug Output">Debug output</a></h4>

<p>
Suppose that you have a nice simple reference-counting scheme like
the one shown in
Litmus&nbsp;Test&nbsp;#9,
but you need to add a <tt>printk()</tt> or an event trace to help
debug some related problem.
The straightforward approach might result in the following:

<blockquote>
Litmus&nbsp;Test&nbsp;#13
<pre>
  1 C C-SBr+p-rc-p-p+p-rc-p-p+p
  2
  3 {
  4         atomic_t rc=2;
  5 }
  6
  7 P0(int *x0, int *x1, atomic_t *rc)
  8 {
  9         int r0;
 10         int r1;
 11
 12         *x0 = 1;
 13         if (atomic_dec_and_test(rc)) {
 14                 r0 = *x0;
 15                 r1 = *x1;
 16         }
 17 }
 18
 19 P1(int *x0, int *x1, atomic_t *rc)
 20 {
 21         int r0;
 22         int r1;
 23
 24         *x1 = 1;
 25         if (atomic_dec_and_test(rc)) {
 26                 r0 = *x0;
 27                 r1 = *x1;
 28         }
 29 }
 30
 31 P2(int *x0, int *x1) // Emulate debug output.
 32 {
 33         int r0;
 34         int r1;
 35
 36         r0 = *x0;
 37         r1 = *x1;
 38 }
 39
 40 exists ~(0:r0=0:r1 /\ 1:r0=1:r1 /\ ~(0:r0=1:r0) /\ ~(0:r0=1:r1))
</pre>
</blockquote>

<p>
Unfortunately, this straightforward approach results in data races:

<blockquote>
Outcome for Litmus&nbsp;Test&nbsp;#13 (linux-kernel model)
<pre>
 1 Test C-SBr+p-rc-p-p+p-rc-p-p+p Allowed
 2 States 2
 3 0:r0=0; 0:r1=0; 1:r0=1; 1:r1=1;
 4 0:r0=1; 0:r1=1; 1:r0=0; 1:r1=0;
 5 No
 6 Witnesses
 7 Positive: 0 Negative: 8
 8 Flag data-race
 9 Condition exists (not (0:r0=0:r1 /\ 1:r0=1:r1 /\ not (0:r0=1:r0) /\ not (0:r0=1:r1)))
10 Observation C-SBr+p-rc-p-p+p-rc-p-p+p Never 0 8
11 Time C-SBr+p-rc-p-p+p-rc-p-p+p 0.05
12 Hash=f752f7f65493e036e734709bdb9233be
</pre>
</blockquote>

<p>
One response to this situation would be to quickly apply
<tt>WRITE_ONCE()</tt> to all the now-conflicting plain C-language
stores, namely those on lines&nbsp;12 and&nbsp;24.
However, in larger code bases, the typos that are likely to
ensue might introduce bugs, and frequent applying and removing of
<tt>WRITE_ONCE()</tt> would certainly be a maintenance nightmare.

<p>
Another response would be to take a look at the
<a href="/Articles/793253/#How%20Real%20Is%20All%20This?">table in the
first article in this series</a>
and to note that the only common-case store transformation is
<a href="/Articles/793253/#Store%20Fusing">store fusing</a>,
which should not be problem for otherwise correct concurrent code.
This suggests that use of <tt>READ_ONCE()</tt> is much more important
than use of <tt>WRITE_ONCE()</tt>, a position recently
<a href="https://lore.kernel.org/lkml/CAHk-=wiOhiAJVU71968tAND6rrEJSaYPg7DXK6Y6iiz7_RJACw@mail.gmail.com/">taken</a>
and later
<a href="https://lore.kernel.org/lkml/CAHk-=whjEq6uEt0o0Ur9Epa7EKVvEFUVJVFJ+heJCv9ehV7pyA@mail.gmail.com/">reiterated</a>
by none other than Linus Torvalds.

<p>
Some might attack this position as a head-in-the-sand denial of the
C standard, but as Torvalds
<a href="https://lore.kernel.org/lkml/CAHk-=wi_KeD1M-_-_SU_H92vJ-yNkDnAGhAS=RR1yNNGWKW+aA@mail.gmail.com/">pointed out</a>:

<div class="BigQuote">
	<p>If such garbage happens, we need to fix the compiler, the
	same way we already do with

	<blockquote>
	<p>
	<tt>-fno-strict-aliasing</tt><br>
	<tt>-fno-delete-null-pointer-checks</tt><br>
	<tt>-fno-strict-overflow</tt><br>
	</blockquote>

	<p>
	because all those "optimizations" are just
	fundamentally unsafe and wrong.
</div>

<p>
In short, the kernel community will be
taking on the responsibility of ensuring that new releases of the compiler
won't break their code, 
and taking appropriate actions to deal with any problematic optimizations
that might appear.  For an example, consider
<a href="https://lore.kernel.org/lkml/20190821103200.kpufwtviqhpbuv2n@willie-the-truck/">this one</a>,
<a href="https://gcc.gnu.org/ml/gcc-patches/2019-08/msg01538.html">which
has a fix for <tt>volatile</tt></a> on the way. 
And, to be fair, this community has had its share of successes, so that
many past
<a href="/Articles/478657/">problems</a>
have been resolved.

<p>
But what about those of us who would
<a
href="https://lore.kernel.org/lkml/20190820135612.GS2332@hirez.programming.kicks-ass.net/">prefer
not to live in quite so much fear of the big bad optimizing compiler</a>?
Again quoting <a
href="https://lore.kernel.org/lkml/CAHk-=wiOhiAJVU71968tAND6rrEJSaYPg7DXK6Y6iiz7_RJACw@mail.gmail.com/">Torvalds</a>: 
<p>
<div class="BigQuote">
	In the end, the most common reason for a WRITE_ONCE() is mostly just
	"to visually pair up with the non-synchronized read that uses
	READ_ONCE()".
</div>

<p>
<div class="tlrw"><a name="Quick Quiz 8"><b>Quick Quiz 8</b>:</a>
	Are you <i>sure</i> that <i>all</i> situations involving data
	races need at least one <tt>READ_ONCE()</tt>?
<br><a href="#qq8answer">Answer</a>
</div>

Thus, if you want to use <tt>WRITE_ONCE()</tt> for a data-racy store,
Torvalds is OK with that as long as there is a corresponding
<tt>READ_ONCE()</tt> of that same variable.

<br clear="all">
<h4><a name="Access-Marking Policies">Access-marking policies</a></h4>

<p>
One approach is to mark all accesses that are subject to data races,
both loads and stores.
To this end, here is a list of situations allowing plain loads and stores
for some accesses to a given variable, while requiring markings (such
as <tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt>) for other accesses
to that same variable:

<ol class="spacylist">
<li>	A shared variable is only modified by a given owning CPU or
	thread, but is read by other CPUs or threads.
	All stores must use <tt>WRITE_ONCE()</tt>.
	The owning CPU or thread may use plain loads.
	Everything else must use <tt>READ_ONCE()</tt> for loads.

<li>	A shared variable is only modified while holding a given
	lock, but is read by code not holding that lock.
	All stores must use <tt>WRITE_ONCE()</tt>.
	CPUs or threads holding the lock may use plain loads.
	Everything else must use <tt>READ_ONCE()</tt> for loads.

<li>	A shared variable is only modified while holding a given
	lock by a given owning CPU or thread, but is read by other
	CPUs or threads or by code not holding that lock.
	All stores must use <tt>WRITE_ONCE()</tt>.
	The owning CPU or thread may use plain loads, as may any
	CPU or thread holding the lock.
	Everything else must use <tt>READ_ONCE()</tt> for loads.

<li>	A shared variable is only accessed by a given CPU or thread
	and by a signal or interrupt handler running in that CPU's
	or thread's context.
	The handler can use plain loads and stores, as can any code
	that has prevented the handler from being invoked, that is,
	code that has blocked signals and/or interrupts.
	All other code must use <tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt>.

<li>	A shared variable is only accessed by a given CPU or thread
	and by a signal or interrupt handler running in that CPU's
	or thread's context, and the handler always restores the values of any
	variables that it has written before return.
	The handler can use plain loads and stores, as can any code
	that has prevented the handler from being invoked, that is,
	code that has blocked signals and/or interrupts.
	All other code can use plain loads, but must use <tt>WRITE_ONCE()</tt>
	to prevent store tearing, store fusing, and invented stores.
</ol>
<p>
<div class="tlr"><a name="Quick Quiz 9"><b>Quick Quiz 9</b>:</a>
	What needs to happen if an interrupt or signal handler
	might itself be interrupted?
<br><a href="#qq9answer">Answer</a>
</div>

In most other cases, loads from and stores to a shared variable must
use <tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt> or stronger,
respectively.
But it bears repeating that neither <tt>READ_ONCE()</tt> nor
<tt>WRITE_ONCE()</tt> provide any ordering guarantees other than within
the compiler.

<p>
Other developers might choose to
omit the <tt>WRITE_ONCE()</tt> calls
(perhaps give or take
stores of constants),
but otherwise follow the advice shown above.
Still other developers might choose more aggressive paths.

<p>
LKMM now handles plain loads and stores, but at the end of the day, coding
decisions are of course in the hands of the developers and maintainers.

<h4><a name="Limitations">Limitations</a></h4>

<p>
Many of the limitations 
<a href="/Articles/720550/#Conclusions">called out in the 2017 LKMM LWN
article</a> 
still apply, but they do bear repeating:

<ol class="spacylist">
<li>	Multiple access sizes are not supported.
<li>	Partially overlapping access sizes are not supported.
<li>	Nontrivial variables, including arrays and structures, are not
	supported.
	However, trivial linked lists are still supported.
<li>	Dynamic memory allocation is not supported.
<li>	Exceptions and interrupts are not supported.
<li>	I/O, including DMA, is not supported.
<li>	Self-modifying code is not supported, despite its being used
	in a surprisingly large number of places in the kernel,
	including the "alternative" mechanism,
	the function tracer, the eBPF JIT compiler, and the module loader.
<li>	This memory model does not constitute an official statement by the
	various CPU vendors on their respective architectures, despite
	some of their employees being on the author list.
	For example, any of these vendors might report bugs at any time
	against any version of this memory model.
	This memory model is therefore not a substitute for a carefully
	designed and vigorously executed validation regime.
	In addition, this memory model is under active development and
	might change at any time.
	Finally, despite much welcome progress, there are still quite
	a few CPU families lacking formal memory models.
<li>	It is quite possible that this memory model will disagree with
	CPU architectures or with real hardware.
	For example, the model might well choose to allow behavior that
	all CPUs forbid if forbidding that behavior would render the
	model excessively complex.
	On the other hand, any situation where the model forbids behavior
	that some CPU allows constitutes a bug, either in the model or
	in the CPU.
	However, there is work underway to automatically check that LKMM's
	verdict on specific litmus tests is compatible with herd-based
	formal models for the underlying hardware.
<li>	This tool is exponential in nature.
	Litmus tests that seem quite small compared to the entire Linux
	kernel might well take geologic time for the herd tool to analyze.
	That said, this tool can be extremely effective in exhaustively
	analyzing the code at the core of a synchronization primitive.
<li>	The herd tool can only detect problems for which you have coded
	an assertion.
	This weakness is common to all formal methods, and is one reason
	that we expect testing to continue to be important.
	In the <a
	href="https://www-cs-faculty.stanford.edu/~knuth/faq.html">immortal
	words of Donald Knuth (scroll to the bottom)</a>: "<q>Beware of
	bugs in the above 
	code; I have only proved it correct, not tried it.</q>"
</ol>

<p>
However, there have been some areas of progress since 2017:

<ol class="spacylist">
<li>	Limited arithmetic is now available.
<li>	A great many read-modify-write atomic operations are now
	supported, but the kernel community creates new
	ones at a surprisingly rapid rate.
	Therefore, it is unlikely that LKMM will be able to claim
	full coverage of all the kernel's read-modify-write atomic
	operations, at least not for very long.
<li>	<a href="https://mirrors.edge.kernel.org/pub/linux/kernel/people/paulmck/LWNLinuxMM/srcu.html">SRCU</a>
	is now supported.
	However, the modeling of RCU and SRCU still excludes asynchronous
	grace-period primitives such as <tt>call_rcu()</tt> and
	<tt>srcu_barrier()</tt>.
<li>	<a href="https://mirrors.edge.kernel.org/pub/linux/kernel/people/paulmck/LWNLinuxMM/lock.html">Locking</a>
	is now supported, but only exclusive locking.
	Reader-writer locking is still on the to-do list, as is the
	recently proposed double-lock that can have multiple readers
	or multiple writers, but not both readers and writers at the same
	time.
<li>	Plain C-language accesses are now supported, and compiler
	optimizations are modeled by (conservatively) flagging data races.
</ol>

<p>
A number of LKMM's limitations appear to be inherent, but the good news
is that significant progress has been made.
However, the conservative treatment of data races means that LKMM should
not be put forward as the final arbiter of what constitutes correct use
of plain C-language accesses.
As noted in the first article,
in some cases developers and maintainers will continue to need to live
with a healthy fear of the big bad optimizing compiler.

<h4><a name="Summary">Summary</a></h4>

<p>
This article has demonstrated LKMM's new ability to handle plain C-language
accesses using a pair of extended examples, and then shown how locking,
reference counting, and RCU can be used in conjunction with plain accesses
in a data-race-free manner.
It then looked at complications due to debug output, presented a couple
of possible access-marking policies, and finally presented an updated view
of LKMM's limitations and progress.

<p>
This article showed that, although LKMM takes an expansive view of the
concept of data races, it is easy to force it to model less expansive views.
One approach is to mark selected accesses with <tt>READ_ONCE()</tt>
or <tt>WRITE_ONCE()</tt> in the litmus test.
For cases where the compiler has more freedom, it may be necessary to
supply a number of litmus tests, each representing a different set
of possible compiler optimizations.

<p>
LKMM is thus useful for modeling plain C-language accesses across a wide
range of access-marking policies, and should thus be useful to a wide
range of developers and maintainers.

</p><h4>Acknowledgments</h4>

<p>As before, we owe thanks to a surprisingly large number of compiler
writers and members of the C and C++ standards committees who introduced us
to some of the things a big bad optimizing compiler can do,
and to SeongJae Park for his help in rendering an
earlier draft of
<a href="#Access-Marking Policies">the access-marking polices section</a>
human-readable.
We are also grateful to Kara Todd for her support of this effort.


<h4><a name="Answers to Quick Quizzes">
Answers to quick quizzes</a></h4>

<a name="qq1answer"></a>
<p><b>Quick Quiz 1</b>:
	But we shouldn't be afraid at all for things like
	on-stack or per-CPU variables, right?

</p><p><b>Answer</b>:
	Although on-stack and per-CPU variables are often guaranteed
	to be untouched by other CPUs and tasks, the kernel really
	does allow them to be concurrently accessed in many cases.
	You do have to go out of your way to make this happen,
	say by explicitly passing the address of such a variable
	to another thread, but it's certainly not impossible.

	<p>
	For example, the <tt>_wait_rcu_gp()</tt> function uses an
	on-stack <tt>__rs_array[]</tt> array of <tt>rcu_synchronize</tt>
	structures which, in turn, contain <tt>rcu_head</tt>
	and <tt>completion</tt> structures.
	The address of the <tt>rcu_head</tt> structure is passed
	to <tt>call_rcu()</tt>, which results in concurrent
	accesses to this structure, and eventually also to the
	<tt>completion</tt> structure.

	<p>
	Similar access patterns may be found for per-CPU variables.


</p><p><a href="#Quick%20Quiz%201"><b>Back to Quick Quiz 1</b>.</a>

<a name="qq2answer"></a>
<p><b>Quick Quiz 2</b>:
	But suppose only one of the accesses to a given variable is a 
	plain C-language access, and that access is the only store.
	Should this be considered a data race?

</p><p><b>Answer</b>:
	Yes, this would definitely be a data race.

	<p>
	The plain C-language access might be subject to store
	tearing, code reordering, invented stores, and store-to-load
	transformations.
	Any of these transformations could ruin your concurrent algorithm's
	day.

	<p>
	However, as will be discussed in the
	<a href="#Debug Output">Debug output</a> section, there is
	some reason to believe that compilers are less likely to
	adversely optimize stores than loads.
	It all depends on how much fear you need in your life.


</p><p><a href="#Quick%20Quiz%202"><b>Back to Quick Quiz 2</b>.</a>

<a name="qq3answer"></a>
<p><b>Quick Quiz 3</b>:
	Why the cop-out?
	Why not just do the work required to ensure that the list of
	states and the <tt>Observation</tt> line are all accurate?


</p><p><b>Answer</b>:
	Because providing perfect accuracy would require perfect
	foresight, in particular, knowing exactly what optimizations
	all compilers, past, present, and future, might apply to this
	code.
	Worse yet, this list of optimizations will vary from compiler
	to compiler, and even with different command-line options for
	the same compiler.
	Therefore, LKMM's only real alternative is to throw up its
	hands and warn the user of the data race.


</p><p><a href="#Quick%20Quiz%203"><b>Back to Quick Quiz 3</b>.</a>

<a name="qq4answer"></a>
<p><b>Quick Quiz 4</b>:
	But the outcome "<tt>1:r1=0; 1:r2=1;</tt>" also disappeared.
	Why?

</p><p><b>Answer</b>:
	If <tt>r1</tt> is zero, the load into <tt>r2</tt> never
	happens, which means that <tt>r2</tt> retains its initial value
	of zero.
	The outcome "<tt>1:r1=0; 1:r2=1;</tt>&rdquo; therefore
	cannot happen.

	<p>
	Had we instead marked accesses to <tt>x0</tt> in
	Litmus&nbsp;Test&nbsp;#2
	with <tt>READ_ONCE()</tt> and <tt>WRITE_ONCE()</tt>, all three
	outcomes would still be possible.
	(But don't take our word for it, try it out!

</p><p><a href="#Quick%20Quiz%204"><b>Back to Quick Quiz 4</b>.</a>

<a name="qq5answer"></a>
<p><b>Quick Quiz 5</b>:
	But wait!
	Given that <tt>READ_ONCE()</tt> provides no ordering,
	why would
<a href="#litmus5">Litmus&nbsp;Test&nbsp;#5</a>
	avoid the undesirable outcome?


</p><p><b>Answer</b>:
	First, please note that <tt>READ_ONCE()</tt> really does provide
	<i>some</i> ordering, namely, it prevents the compiler from
	reordering the <tt>READ_ONCE()</tt> with any other marked access.
	However, this restriction in no way applies to the CPU.

	<p>
	But CPU-level ordering is not required because, as the name
	suggests, <tt>READ_ONCE(a)</tt> is guaranteed to read <tt>a</tt>
	only once, and thus store the same value to both <tt>b</tt>
	and <tt>c</tt>.
	Because the undesirable outcome shown in the <tt>exists</tt>
	clause requires different final values for <tt>b</tt>
	and <tt>c</tt>, <tt>READ_ONCE()</tt> suffices despite its
	lack of ordering properties.


</p><p><a href="#Quick%20Quiz%205"><b>Back to Quick Quiz 5</b>.</a>

<a name="qq6answer"></a>
<p><b>Quick Quiz 6</b>:
	I have seen plain C-language incrementing and decrementing
	of reference counters.
	How can that possibly work?

</p><p><b>Answer</b>:
	It can work if the reference counter in question is protected
	by a lock.
	But yes, if there is no lock, then incrementing and decrementing
	of reference counters must be done via the handy and convenient
	atomic operations that the kernel provides for this purpose.


</p><p><a href="#Quick%20Quiz%206"><b>Back to Quick Quiz 6</b>.</a>

<a name="qq7answer"></a>
<p><b>Quick Quiz 7</b>:
	But given that
	Litmus&nbsp;Test&nbsp;#10
	has no <tt>synchronize_rcu()</tt>, what is the purpose of
	the <tt>rcu_read_lock()</tt> on line&nbsp;17 and the
	<tt>rcu_read_unlock()</tt> on line&nbsp;20?

</p><p><b>Answer</b>:
	In theory, they could be omitted because there is in fact no
	<tt>synchronize_rcu()</tt> for them to interact with.
	They nevertheless serve as valuable documentation.
	In addition, their presence could save considerable time and
	frustration should someone later add an updater to this
	litmus test.

</p><p><a href="#Quick%20Quiz%207"><b>Back to Quick Quiz 7</b>.</a>

<a name="qq8answer"></a>
<p><b>Quick Quiz 8</b>:
	Are you <i>sure</i> that <i>all</i> situations involving data
	races need at least one <tt>READ_ONCE()</tt>?

</p><p><b>Answer</b>:
	First, developers who are concerned about store tearing, fused
	stores, invented stores, or store-to-load transformations will
	consider a situation involving concurrent stores to the same
	variable to be a data race if at least one of them is a plain
	C-language store, regardless of <tt>READ_ONCE()</tt>.

	<p>
	But suppose that the variable is both loaded from and stored to,
	and that there are concurrent stores which might reasonably be
	marked with <tt>WRITE_ONCE()</tt> by sufficiently fearful
	developers.
	Are we sure that at least one of the loads from that variable
	will need to use <tt>READ_ONCE()</tt>?

	<p>
	We should be reasonably sure, but of course not
	<a href="https://lore.kernel.org/lkml/20190817222834.GJ28441@linux.ibm.com/"><i>absolutely</i> sure</a>.
	For example, in theory, all of the stores to a given variable
	could be executed while read-holding a given reader-writer lock
	and all loads could be executed while write-holding that same lock.
	In this case, only the stores are involved in data races.
	In practice, what would be the use case for such a thing?

</p><p><a href="#Quick%20Quiz%208"><b>Back to Quick Quiz 8</b>.</a>

<a name="qq9answer"></a>
<p><b>Quick Quiz 9</b>:
	What needs to happen if an interrupt or signal handler
	might itself be interrupted?

</p><p><b>Answer</b>:
	Then that interrupt handler must follow the same rules that
	are followed by other interrupted code.
	Only those handlers that cannot be themselves interrupted
	or that access no variables shared with an interrupting handler
	may safely use plain accesses, and even then only if those
	variables cannot be concurrently accessed by some other CPU or
	thread.

</p><p><a href="#Quick%20Quiz%209"><b>Back to Quick Quiz 9</b>.</a><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Development_tools-Linux_kernel_memory_model">Development tools/Linux kernel memory model</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#McKenney_Paul_E.">McKenney, Paul E.</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/799218/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor802088"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 11, 2019 14:30 UTC (Fri)
                               by <b>vegard</b> (subscriber, #52330)
                              [<a href="/Articles/802088/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This is kind of cryptic.<br>
<p>
There's a link to a previous article hidden in a single word of the second paragraph: "As noted earlier [...]"<br>
<p>
Later it launches into "A key point from the first article" and I go: Huh? Which first article? Maybe I can't read.<br>
<p>
For those who know nothing about LKMM (like me) this is a pretty tough read. The introduction could have been gentler, or at least the link to the previous article should be much more prominent, i.e. a "This article is based on so-and-so and the reader is urged to read it first"-style disclaimer.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802088/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor802116"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 11, 2019 18:36 UTC (Fri)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/802116/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Good catch!  I will send a suggested update once I get to a place where my laptop containing the article source has Internet connectivity.  And apologies for the unscheduled literary cryptography!!!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802116/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor802130"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 11, 2019 21:30 UTC (Fri)
                               by <b>scientes</b> (guest, #83068)
                              [<a href="/Articles/802130/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The C++ memory model atomics are way easier to use than these kernel macros that predate them and use volatile. Using volatile like this, now that atomics exists, is code smell, IMHO. I am not sure if C exposes them, but it should.<br>
<p>
<a href="https://www.llvm.org/docs/Atomics.html">https://www.llvm.org/docs/Atomics.html</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802130/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor802132"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 11, 2019 21:58 UTC (Fri)
                               by <b>scientes</b> (guest, #83068)
                              [<a href="/Articles/802132/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Nevermind.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802132/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor802143"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 12, 2019 9:17 UTC (Sat)
                               by <b>hsivonen</b> (subscriber, #91034)
                              [<a href="/Articles/802143/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Atomics require the other thread of execution to be conforming to the C++1/C11 memory model. There is no such guarantee for userland processes, so using atomics to access userland memory from the kernel is technically UB.<br>
<p>
The only thing in C or C++ that allows you to access (in a non-UB way) memory that doesn’t participate in the memory model is volatile, but since the use case it is designed for is memory-mapped devices, it inhibits more optimizations than would be necessary for the use cases of kernel accessing userland memory when responding to a syscall, a hypervisor accessing guest memory when implementing a virtual device, or a Wasm host assessing a SharedArrayBuffer Wasm heap when responing to a call to a host service.<br>
<p>
Considering that this type of software is typically implemented in languages that inherit the C++11 memory model (C++ itself plus C11 and Rust), it’s surprising that this facility is missing.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802143/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor802153"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 12, 2019 16:03 UTC (Sat)
                               by <b>scientes</b> (guest, #83068)
                              [<a href="/Articles/802153/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt;so using atomics to access userland memory from the kernel is technically UB.</font><br>
<p>
But don't we only look at user-land data from the same thread that sent the data, so there are no races (and we don't trust the data, so if another thread with access to that data changes it, that is their problem.)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802153/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor802154"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 12, 2019 16:47 UTC (Sat)
                               by <b>excors</b> (subscriber, #95769)
                              [<a href="/Articles/802154/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; (and we don't trust the data, so if another thread with access to that data changes it, that is their problem.)</font><br>
<p>
If the access from the kernel is undefined behaviour (because another user thread modified that memory in violation of the rules), that's the kernel's problem. Undefined behaviour doesn't just mean the kernel will read an incorrect value, it means absolutely anything could happen (and would happen with kernel privileges).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802154/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor802162"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 12, 2019 19:12 UTC (Sat)
                               by <b>hsivonen</b> (subscriber, #91034)
                              [<a href="/Articles/802162/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Right. The C++11/C11 memory model has just UB and doesn’t say which thread of execution experiences the UB. For use cases like kernel vs. userland, hypervisor vs. guest, Web browser UI vs. renderer, and Wasm host vs. Wasm program, you want to have things defined such that the more privileged side can’t experience UB if the less privileged side doesn’t follow the rules.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802162/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor802303"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 15, 2019 13:37 UTC (Tue)
                               by <b>klempner</b> (subscriber, #69940)
                              [<a href="/Articles/802303/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The one thing that jumps out is the invented load issue with #5, which is a problem that relaxed loads and stores don't have but apparently a STORE_ONCE/LOAD_ONCE pair do.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802303/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor802273"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 14, 2019 17:47 UTC (Mon)
                               by <b>rweikusat2</b> (subscriber, #117920)
                              [<a href="/Articles/802273/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The "optimized away" in gdb output does not mean the compiler "pessimized" the source code by adding gratuitious memory accesses to the generated machine code. It means that the value of some source-level named object isn't available to the debugger because it losts its identity in translation: There was no reason to allocate a memory location for it, hence, it became a 'virtual' entity whose value (or values) only ever live in a register or - over the course of a given codepath - some set of registers the debugger cannot map back to the name.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802273/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor802280"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Calibrating your fear of big bad optimizing compilers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 14, 2019 21:25 UTC (Mon)
                               by <b>ThinkRob</b> (guest, #64513)
                              [<a href="/Articles/802280/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Wow!  Yet again, another excellent deep dive article by LWN!<br>
<p>
LWN is really second to none when it comes to this sort of in-depth, technical-yet-approachable content.<br>
<p>
Keep up the fantastic work!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/802280/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2019, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
