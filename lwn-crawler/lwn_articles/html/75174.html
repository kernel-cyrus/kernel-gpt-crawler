        <!DOCTYPE html>
        <html lang="en">
        <head><title>Virtual Memory I: the problem [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/75174/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/74295/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/75174/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Virtual Memory I: the problem</h1>
<div class="Byline">[Posted March 10, 2004 by corbet]
               <p>
               </div>
</div>
<div class="ArticleText">
This article serves mostly as background to help understand why the kernel
developers are considering making fundamental virtual memory changes at
this point in the development cycle.  It can probably be skipped by readers
who understand how high and low memory work on 32-bit systems.
<p>

A 32-bit processor can address a maximum of 4GB of memory.  One could, in
theory, extend the instruction set to allow for larger pointers, but, in
practice, nobody does that; the effects on performance and compatibility
would be too strong.  So the limitation remains: no process on a 32-bit
system can have an address space larger than 4GB, and the kernel cannot
directly address more than 4GB.
<p>

In fact, the limitations are more severe than that.  Linux kernels split
the 4GB address space between user processes and the kernel; under the most common
configuration, the first 3GB of the 32-bit range are given over to user
space, and the kernel gets the final 1GB starting at <tt>0xc0000000</tt>.
Sharing the address space gives a number of performance benefits; in
particular, the hardware's address translation buffer can be shared between
the kernel and user space.
<p>

If the kernel wishes to be able to access the system's physical memory
directly, however, it must set up page tables which map that memory into
the kernel's part of the address space.  With the default 3GB/1GB mapping,
the amount of physical memory which can be addressed in this way is
somewhat less than 1GB - part of the kernel's space must be set aside for
the kernel itself, for memory allocated with <tt>vmalloc()</tt>, and
various other purposes.  That is why, until a few years ago, Linux could
not even fully handle 1GB of memory on 32-bit systems.  In fact, back in
1999, Linus <a href="http://lwn.net/1999/0128/a/lt-never.html">decreed</a>
that 32-bit Linux would never, ever support more than 2GB of memory.
"<q>This is not negotiable.</q>"
<p>

Linus's views notwithstanding, the rest of the world continued on with the
strange notion that 32-bit 
systems should be able to support massive amounts of memory.  The processor
vendors added paging modes which could use physical addresses which exceed
32 bits in length, thus ending the 4GB limit for physical memory.  The
internal addressing limitations in the Linux kernel remained, however.
Happily for users of large systems, Linus can acknowledge an error and
change his mind; he did eventually allow large memory support into the 2.3
kernel.  That support came with its own costs and limitations, however.
<p>

On 32-bit systems, memory is now divided into "high" and "low" memory.  Low
memory continues to be mapped directly into the kernel's address space, and
is thus always reachable via a kernel-space pointer.  High memory, instead,
has no direct kernel mapping.  When the kernel needs to work with a page in
high memory, it must explicitly set up a special page table to map it into
the kernel's address space first.  This operation can be expensive, and
there are limits on the number of high-memory pages which can be mapped at
any particular time.
<p>

For the most part, the kernel's own data structures must live in low
memory.  Memory which is not permanently mapped cannot appear in linked
lists (because its virtual address is transient and variable), and the
performance costs of mapping and unmapping kernel memory are too high.
High memory is useful for process pages and some kernel tasks (I/O buffers,
for example), but the core of the kernel stays in low memory. 

<p>
Some 32-bit processors can now address 64GB of physical memory, but the
Linux kernel is still not able to deal effectively with that much; the
current limit is around 8GB to 16GB, depending on the load.  The problem
now is that larger systems simply run out of low memory.  As the system
gets larger, it requires more kernel data structures to manage, and
eventually room for those structures can run out.  On a very large system,
the system memory map (an array of <tt>struct page</tt> structures which
represents physical memory) alone can occupy half of the available low
memory. 

<p>
There are users out there wanting to scale 32-bit Linux systems up to 32GB
or more of main memory, so the enterprise-oriented Linux distributors have
been scrambling to make that possible.  One approach is the <a
href="http://lwn.net/Articles/39925/">4G/4G patch</a> written by Ingo
Molnar.  This patch separates the kernel and user address spaces, allowing
user processes to have 4GB of virtual memory while simultaneously expanding
the kernel's low memory to 4GB.  There is a cost, however: the translation
buffer is no longer shared and must be flushed for every transition between
kernel and user space.  Estimates of the magnitude of the performance hit
vary greatly, but numbers as high as 30% have been thrown around.  This
option makes some systems work, however, so Red Hat ships a 4G/4G kernel
with its enterprise offerings.

<p>
The 4G/4G patch extends the capabilities of the Linux kernel, but it
remains unpopular.  It is widely seen as an ugly solution, and nobody likes
the performance cost.  So there are efforts afoot to extend the scalability
of the Linux kernel via other means.  Some of these efforts will likely go
forward - in 2.6, even - but the kernel developers seem increasingly unwilling to distort
the kernel's memory management systems to meet the needs of a small number
of users who are trying to stretch 32-bit systems far beyond where they
should go.  There will come a time where they will all answer as Linus did
back in 1999: go get a 64-bit system.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Object-based_reverse_mapping">Memory management/Object-based reverse mapping</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/75174/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor75311"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Virtual Memory I: the problem</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 11, 2004 5:27 UTC (Thu)
                               by <b>oconnorcjo</b> (guest, #2605)
                              [<a href="/Articles/75311/">Link</a>] 
      </p>
      
      </div>
      </summary>
      I agree with Linus on this one.  Opterons and AMD64 are out now and Intel will have an x86-64 in the next year or so.  If you really need the RAM then one might as well get a 64 bit chip to go with it.  Racking up the RAM on a 32 bit system is like stuffing 10 pounds of potatoes in a five pound bag.
      
          <div class="CommentReplyButton">
            <form action="/Articles/75311/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor75326"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Virtual Memory I: the problem</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 11, 2004 8:20 UTC (Thu)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/75326/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      I think you have the 3:1 split backwards. as I understand it the kernel gets the 3G portion and userspace gets 1G.<p>there are patches to allow you to change it to 2G:2G and I believe I've seen either a 3:1 or a 2.5:1.5 (I don't remember which at the moment) but as you cut down the amount of address space available to the kernel other problems become more common. 
      
          <div class="CommentReplyButton">
            <form action="/Articles/75326/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor75338"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Virtual Memory I: the problem</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 11, 2004 10:34 UTC (Thu)
                               by <b>axboe</b> (subscriber, #904)
                              [<a href="/Articles/75338/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Nah, it is you who gets it backward.
      
          <div class="CommentReplyButton">
            <form action="/Articles/75338/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor75344"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Virtual Memory I: the problem</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 11, 2004 11:51 UTC (Thu)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/75344/">Link</a>] 
      </p>
      
      </div>
      </summary>
      If that were true any given process would only be able to address a third of the physical RAM in the system (on a fully-populated non-highmem box).<p>This is considered silly, since process virtual memory requirements can be far higher than their physical requirements. :)
      
          <div class="CommentReplyButton">
            <form action="/Articles/75344/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor75328"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Virtual Memory I: the problem</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 11, 2004 9:06 UTC (Thu)
                               by <b>dale77</b> (guest, #1490)
                              [<a href="/Articles/75328/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Yep, buy yourself an AMD64.<p>Perhaps one of these:<p>http://www.gamepc.com/shop/systemfamily.asp?family=gpdev<p>Dale
      
          <div class="CommentReplyButton">
            <form action="/Articles/75328/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor75432"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Virtual Memory I: the problem</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 11, 2004 17:23 UTC (Thu)
                               by <b>parimi</b> (guest, #5773)
                              [<a href="/Articles/75432/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      Jon, Thanks for such an informative article! <p>I thought SGI's Altix was able to handle a huge amount of memory. Does anyone know if SGI's kernel also uses the 4G/4G patch? 
      
          <div class="CommentReplyButton">
            <form action="/Articles/75432/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor75434"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Altix</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 11, 2004 17:30 UTC (Thu)
                               by <b>corbet</b> (editor, #1)
                              [<a href="/Articles/75434/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>
"<i>I thought SGI's Altix was able to handle a huge amount of memory. Does anyone know if SGI's kernel also uses the 4G/4G patch?</i>"
</blockquote>
<p>
I do believe that Altix systems are Itanium-based, so they don't have to deal with all this obnoxious stuff.
      
          <div class="CommentReplyButton">
            <form action="/Articles/75434/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor76546"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Virtual Memory I: the problem</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 20, 2004 1:35 UTC (Sat)
                               by <b>mysticalreaper</b> (guest, #20326)
                              [<a href="/Articles/76546/">Link</a>] 
      </p>
      
      </div>
      </summary>
      As the other reply stated, SGI's altix runs on Intel's Itanium 2 processors, which are 64 bit, and thus, can address a silly amount of memory (2^64 bytes) and so do not suffer these silly problems.
      
          <div class="CommentReplyButton">
            <form action="/Articles/76546/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor75447"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Virtual Memory I: the problem</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 11, 2004 18:36 UTC (Thu)
                               by <b>mmarkov</b> (guest, #4978)
                              [<a href="/Articles/75447/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <blockquote>
If the kernel wishes to be able to access the system's physical memory directly, however, it must set up page tables which map that memory into the kernel's part of the address space. With the default 3GB/1GB mapping, the amount of physical memory which can be addressed in this way is somewhat less than 1GB - part of the kernel's space must be set aside for the kernel itself, for memory allocated with vmalloc(), and various other purposes.
</blockquote>

Honestly, I don't understand here why only 1GB is accessible under
these premises. 
<p>
PS Great article, Jon. In fact, great articles, both part I and part II.
      
          <div class="CommentReplyButton">
            <form action="/Articles/75447/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor75466"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Virtual Memory I: the problem</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 11, 2004 22:17 UTC (Thu)
                               by <b>jmshh</b> (guest, #8257)
                              [<a href="/Articles/75466/">Link</a>] 
      </p>
      
      </div>
      </summary>
      The keyword here is &quot;directly&quot;, i.e. without any manipulation of page <br>tables. So all physical RAM has to live inside the 1GB virtual address <br>space of the kernel, together with some other stuff, like video buffers. <br> 
      
          <div class="CommentReplyButton">
            <form action="/Articles/75466/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor75495"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Why only 1 G is directly accessible</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 12, 2004 9:51 UTC (Fri)
                               by <b>Duncan</b> (guest, #6647)
                              [<a href="/Articles/75495/">Link</a>] 
      </p>
      
      </div>
      </summary>
      First, keep in mind that we are talking about a less than 4 gig address <br>space, the physical limit of the &quot;flat&quot; memory model, 32-bits of address, <br>with each address serving one byte of memory.  One can of course play with <br>the byte-per-address model and make it, say, two bytes or a full 32-bit <br>4-bytes, but there again, we get into serious compatibility problems with <br>current software that assumes one-byte handling.  The implications of that <br>would be HUGE, and NOBODY wants to tackle the task of ensuring <br>4-byte-per-address clean code, since the assumption has been <br>byte-per-address virtually forever and virtually ALL programs have that <br>axiom written so deep into their code you might as well start over again <br>(which is sort of what Intel argued should be the case with Itanic, clean <br>start approach, anyway, taking the opportunity to move cleanly to 64-bit, <br>which is why it never really took off, but that's an entirely different <br>topic).  It's simply easier to move to 64-bit address space than to tinker <br>with the byte-per-address assumption.  Thus, 32-bit is limited to 4-gig of <br>directly addressable memory in any practical case. <br> <br>Another solution, as generally used back in the 16-bit era, is called <br>&quot;segmented&quot; memory.  The address back then consisted of a 16-bit &quot;near&quot; <br>address, and a 16-bit &quot;segment&quot; address.  The issue, as one would expect, <br>ammounted to one of performance.  It was comparatively fast to access <br>anything within the same segment, much slower to address anything OUT of <br>the segment.  As it happened, 64k was the segment size, and if you <br>remember anything from that era, it might be that editors, for instance, <br>quite commonly had a limit on the size of the editable file of somewhat <br>less than 64k, so they could access both their own operational memory AND <br>the datafile being edited, all within the same 64k segment.  However, the <br>benefits of &quot;flat&quot; memory are such that few want to go back to a segmented <br>memory model, if at all possible to stay away from it.  (That said, the <br>various high memory models do essentially that, but try to manage it at <br>the system level so at least individual applications don't have to worry <br>about it, as they did back in the 16-bit era.) <br> <br>That still doesn't &quot;address&quot; (play on words intentional) the lower 1-gig <br>kernel-space, 3-gig user-space, &quot;soft&quot; limit.  As you mention, yes, in <br>theory the kernel /can/ address the full 4-gig.  The problem, however, is <br>hinted at elsewhere in the article where it talks about the 4G/4G patch -- <br>use all available direct address space for the kernel, and switching <br>between usermode and kernelmode becomes even MORE tremendously expensive <br>than it already is, in performance terms, because if they use the same <br>address space, the entire 4-gig &quot;picture&quot; has to be flushed (more on that <br>below), so the new &quot;picture&quot; of the other mode can be substituted without <br>losing data.  As explained in the article each mode then has to manage its <br>own memory picture, and the performance issues of flushing that picture so <br>another one can replace it at each context switch are enormous. <br> <br>As already mentioned in other replies, there are a number of solutions, <br>each with their own advantages and disadvantages.  One is the 2G/2G split, <br>which BTW is what MSWormOS uses.  This symmetric approach allows both the <br>kernel and userspace to access the same four gig maximum &quot;picture&quot;, each <br>from their own context, but sharing the picture, so the performance issues <br>in flushing it don't come into play.  It does give the kernel more <br>comfortable room to work in, but at the expense of that extra gig for <br>userspace.  While few applications need more than their two-gig share of <br>memory to work in, the very types of applications that do, huge database <br>applications and other such things, happen to be run on the same sorts of <br>systems that need that extra room for the kernel.. huge enterprise systems <br>with well over eight gig of physical memory.  Thus, the 2G/2G solution is <br>a niche solution that will fit only a very limited subset of those running <br>into the problem in the first place.  The 4G/4G solution is more practical <br>-- EXCEPT that it carries those huge performance issues.  Well, there's <br>also the fact that even a 4G/4G solution only doubles the space available <br>to work with, and thus is only a temporary solution at best, perhaps two <br>years worth, maybe 3-4 by implimenting other &quot;tricks&quot; with their own <br>problems, even if the base performance issue didn't apply.  That's where <br>the next article comes in. <br> <br>The loose end left to deal with is that flushing, mentioned above.  I must <br>admit to not fully understanding this myself, but a very simplistic view <br>of things would be to imagine a system with 8 gig of physical memory, <br>dealt with using the previously mentioned &quot;segments&quot;, of which there would <br>be two, one each for userspace and kernel space.  A mode switch would then <br>simply mean changing the segment reference, ensuring all cache memory is <br>flushed out to the appropriate segment before one does so, of course. <br> <br>Practice of course doesn't match that concept perfectly very often at all, <br>however, and even if a system DID happen to have exactly eight gig of <br>memory, such a simplistic model wouldn't work in real life because of <br>/another/ caveat.. that being that each application has its own virtual <br>address space map, and few actually use the entire thing, so one would be <br>writing to swap (a 100 to 1000 times slower solution than actual memory, <br>so a generally poor solution if not absolutely necessary) entirely <br>unnecessarily with only one application being runnable at once. <br> <br>That of course is where vm=virtual memory comes in. as it allows all the <br>space unused by one app or the kernel itself to be used by another, with <br>its own remapping solutions.  However, that's the part I don't really <br>understand, so won't attempt to explain it.  Besides, this post is long <br>enough already.  &lt;g&gt;  Just understand that flushing is a necessary process <br>of low enough performance that it should be avoided if possible, and that <br>the concept is one of clearing the slate so it can be used for the new <br>memory picture, while retaining the data of the first one so it can be <br>used again. <br> <br>Duncan <br> 
      
          <div class="CommentReplyButton">
            <form action="/Articles/75495/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor76575"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Virtual Memory I: the problem</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 21, 2004 1:02 UTC (Sun)
                               by <b>alpharomeo</b> (guest, #20341)
                              [<a href="/Articles/76575/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Some questions/comments:<p>1) Why not cause the kernel to manage memory in de fact pages larger than 4K? A larger page is how other OS's manager large memory efficiently, whether we are talking 32 bit or 64 bit addressing. To avoid breakage, why not keep the current 4K page size but have the kernel always allocate/free pages in blocks of, say, 16 pages, or even 256 pages? Then the page table would be vastly smaller.<p>2) It may be convenient to say &quot;use a 64 bit machine&quot;. The fact is that 64 bit addressing is inefficient and overkill for many situations. Experience with several architectures that support simultaneous 32-bit and 64-bit applications has shown that the 64-bit builds run at least 25-30% slower than the corresponding 32-bit builds. Bigger addresses means bigger programs, bigger stacks and heaps, etc.. Some applications may require nearly twice as much memory when run in 64-bit mode. So, why not optimize the kernel to provide better support for 32-bit addressing?  In particular, what is so wrong with supporting infinite physical memory but limiting process address space to 4 GB (or 3 GB)?<p>3) Why is shared memory such a big problem?  We have never been able to get Linux to allow shared memory segments larger than slightly less than 1 GB. Is there some trick to it?  Linux reports that there is insufficient swap space, but it does not matter how many swap partitions you allocate - you always get the same error.<p>Thanks!<p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/76575/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2004, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
