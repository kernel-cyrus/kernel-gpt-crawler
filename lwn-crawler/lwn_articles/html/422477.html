        <!DOCTYPE html>
        <html lang="en">
        <head><title>The CHOKe packet scheduler [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/422477/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/421784/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/422477/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>The CHOKe packet scheduler</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>LWN.net needs you!</b>
<p>
Without subscribers, LWN would simply not exist.  Please consider
       <a href="/Promo/nst-nag2/subscribe">signing up for a subscription</a> and helping
       to keep LWN publishing.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>January 11, 2011</br>
           </div>
A packet on the network typically passes through several machines on the way from
its source to its destination.  One of those machines (or, more correctly,
one of the outbound links from one of those machines) will be the limiting
factor on how many packets can traverse that path in a given period of
time.  If a system tries to send too many packets through the limiting
link, the packet queue on the router attached to that link will grow.  A
growing queue affects other users of that router and will eventually hit
its limits, causing packet loss.
<p>
The TCP protocol has, for many years, included congestion control
algorithms which attempt to determine the carrying capacity of a path and
to avoid exceeding that capacity.  These algorithms have successfully prevented
a repeat of the meltdowns which plagued the early Internet.  But congestion
control isn't working as well as it should, for a few reasons.  Some TCP
implementations are more dutiful than others when it comes to congestion
control.  An increasing amount of traffic on the net uses other protocols
(UDP in particular) which do not have congestion control built into them.
Excessive queue sizes in routers ("<a
href="https://gettys.wordpress.com/bufferbloat-faq/">bufferbloat</a>") can
also disguise congestion problems until it is too late.  All of these
problems are motivating a search for better ways of controlling congestion.
<p>
The key signal for congestion control on the net is dropped packets; TCP
will continue to ramp up its transmit rate until the occasional lost packet
makes it clear that the limit has been hit.  So the way for a router in the
middle of the network to tell a specific sender that it's transmitting too
much data is to drop some of that data on the floor.  The idea is simple in
concept, but it can be harder in practice for a simple reason: network
routers can deal with many thousands of packets every second; they cannot
afford to spend significant amounts of time on any one of those packets.
<p>
An obvious way for a router to schedule packets would be to maintain a
queue for every flow (source/destination pair with port numbers) through
the system.  Packets could then be dequeued and transmitted with absolute
fairness, and, any time the queue for a flow gets too long, packets could
be dropped from that queue.  Implementing this algorithm would require some
complex data structures and a fair amount of processor time, though, so it
is not an option for a router which handles a significant amount of
traffic.
<p>
An alternative is the <a
href="http://www.stanford.edu/~balaji/papers/choke_info.ps">CHOKe algorithm
[PS]</a>; CHOKe stands either for "CHOose and Kill" or "CHOose and Keep,"
depending on one's attitude toward the problem.  Stephen Hemminger has
recently <a href="/Articles/422481/">posted</a> a CHOKe implementation for
Linux, so this seems like a good time to look at how this algorithm works.
<p>
CHOKe is intended for points where multiple flows come together - routers
and bridges, primarily.
The idea behind CHOKe is to keep the length of transmit queues under
control and to penalize flows with excessive traffic while avoiding the
need to maintain any sort of per-flow state.   To that end, the packet
queuing algorithm works essentially like the following.  When a packet
arrives for a given outbound link, the CHOKe code will:
<p>
<ul>
<li> Calculate a moving average of the length of the queue.  The algorithm 
     includes a parameter for the period over which the average is
     calculated; a longer period will allow longer load spikes before the
     algorithm starts CHOKing traffic.
<p>
<li> If the average queue length is below a minimum watermark, there is no
     problem with congestion, so the packet will simply be queued and
     the job is done.
<p>
<li> If the queue length is above the minimum, the CHOKe algorithm picks a
     random packet from the queue.  If that packet belongs to the same flow
     as the packet under consideration, <i>both</i> packets will be
     dropped.  When a randomly-picked packet comes from the same flow,
     chances are good that packets from that flow occupy a substantial
     amount of queue space, so that flow is likely to be a source of the
     problem.
<p>
<li> If the packets are from different flows, but the queue length is above
     an administrator-set maximum, then the new packet (only) will be dropped.
<p>
<li> In the final case, the algorithm calculates a probability that the
     packet will be dropped, even though the maximum queue length has not
     been reached.  The probability grows as the queue length increases,
     but, by default, it remains low - about 2% at the maximum.  Thus, for
     mid-length queues, the algorithm will occasionally send a signal to a
     transmitter that it should back off a bit, but most packets will be
     queued normally.
</ul>
<p>
The key feature of CHOKe - the one which distinguishes it from RED (from
which it is derived) - is the check against a random packet in the queue.
That is a heuristic mechanism for identifying problematic flows without
actually having to track what each flow is doing.  Experience, as reported
in the CHOKe paper, suggest that it works pretty well.
<p>
An important factor in successful use of CHOKe in the real world will
be careful selection of the controlling parameters: the minimum and maximum
queue lengths, average period, and drop probability.  In particular, there
is mounting evidence (thanks to the efforts by Jim Gettys) that overly long
queues lead to all kinds of pathological network behavior, and could even
threaten a net collapse at some point.  Use of algorithms like CHOKe,
combined with reasonably-sized queues, could help keep the Internet working
well into the future.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Networking-Congestion_control">Networking/Congestion control</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/422477/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor422804"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2011 10:26 UTC (Thu)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/422804/">Link</a>] (10 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yet another brilliant summary, thanks. Two comments.<br>
<p>
The only congestion signal available to TCP is packet loss for a practical reason: *inter*-networking. Among other design goals, the *Inter*net was meant to connect different type of networks together. Now guess which congestion signal "technology" is supported across every single type of network, even the most primitive ones?<br>
Dropping packets is also consistent with the End To End principle, which states the network should be as dumb and stateless as possible for a number of reasons, not the least scalability.<br>
<p>
I do not think CHOKe is related to bufferbloat. Bufferbloat is quite obviously about unreasonable queue sizes (more than 10 milliseconds), while CHOKe or RED should also apply to manage queues of reasonable size. In other words, bufferbloat is a plain bug while queue management is an optimization. Queues of unreasonable sizes should not just be "managed", they should first of all be made smaller.<br>
<p>
I suspect that Jim Gettys' opinion might differ on this latter point. Unfortunately his summary writing skills do not seem as good as LWN's and my life is too short.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/422804/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor422940"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2011 19:53 UTC (Thu)
                               by <b>njs</b> (guest, #40338)
                              [<a href="/Articles/422940/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Bufferbloat is quite obviously about unreasonable queue sizes (more than 10 milliseconds), while CHOKe or RED should also apply to manage queues of reasonable size</font><br>
<p>
Bufferbloat is about unreasonable *average* queue sizes; if you receive 100 ms worth of traffic in a lump every 100 ms, then you aren't oversubscribed at all, and the right thing to do is to buffer all of it. (In general, the proper queue size grows with the RTT of the flows, which may be *way* above 10 ms.) So it makes sense to have a reasonably large queue; the point of AQM algorithms is to make sure that this queue is only used to smooth out burstiness, instead of becoming a simple delay line.<br>
<p>
IIUC.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/422940/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor422995"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2011 22:07 UTC (Thu)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/422995/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If you receive 100 ms worth of traffic in a lump and buffer them all then the last packets to go out will suffer a 100 ms extra delay (just on this link!). Unless you do not care a bit about latency, you do not want that. What you want is to drop a large number of these packets so a similar burst does not happen again.<br>
<p>
Note: since TCP is ACK-clocked, it is not bursty at all.<br>
<p>
<font class="QuotedText">&gt; In general, the proper queue size grows with the RTT of the flows,</font><br>
<p>
I do not see why. The RTT matters only for end to end buffers.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/422995/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor423004"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2011 22:55 UTC (Thu)
                               by <b>Shewmaker</b> (guest, #1126)
                              [<a href="/Articles/423004/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Note: since TCP is ACK-clocked, it is not bursty at all.</font><br>
<p>
How do you define a burst?  If it is more than one packet <br>
sent without waiting between them, then isn't the window <br>
size of a TCP connection its burst size?<br>
<p>
Of course, a qdisc or something at a lower level may <br>
break up a window's worth of packets.  Still, saying <br>
TCP is not bursty at all doesn't seem accurate.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423004/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor423044"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 14, 2011 6:48 UTC (Fri)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/423044/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; How do you define a burst? If it is more than one packet </font><br>
sent without waiting between them, then isn't the window <br>
size of a TCP connection its burst size?<br>
<p>
TCP does not send a receive window size at a time because it is also constantly limited by the congestion window. Sending is then regulated by the reception of ACK (one every two packets).<br>
<p>
So a (single!) TCP connection is practically never bursty in normal conditions.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423044/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor423020"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 14, 2011 2:20 UTC (Fri)
                               by <b>njs</b> (guest, #40338)
                              [<a href="/Articles/423020/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; If you receive 100 ms worth of traffic in a lump and buffer them all then the last packets to go out will suffer a 100 ms extra delay (just on this link!). Unless you do not care a bit about latency, you do not want that. What you want is to drop a large number of these packets so a similar burst does not happen again.</font><br>
<p>
Dropping packets tells the sender to slow down. But in this case, the sender is already sending at the proper speed! You don't want them to reduce throughput, you just want them to smooth out their sending. But dropping packets doesn't tell them to do that, it just tells them to slow down.<br>
<p>
Note that if they smoothed out their sends, so you got 1 ms of traffic every 1 ms, then that last packet would just get sent 100 ms later. There's no unnecessary latency being added here.<br>
<p>
<font class="QuotedText">&gt; I do not see why.</font><br>
<p>
To tell the truth, I'm not sure either, but I'm quoting Van Jacobson et al (<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.22.9406">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.2...</a>) so I believe it. Perhaps someone will come along shortly to explain better.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423020/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor423045"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 14, 2011 6:53 UTC (Fri)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/423045/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Dropping packets tells the sender to slow down. But in this case, the sender is already sending at the proper speed! You don't want them to reduce throughput, you just want them to smooth out their sending. But dropping packets doesn't tell them to do that, it just tells them to slow down.</font><br>
<p>
TCP sending is smooth by design, check the literature.<br>
<p>
If it is not TCP, yes you are right this might be too drastic and harm throughput. But it's only because your application does not behave. And it will preserve latency. And the bandwidth lost by killing the burst might be reused by better behaved applications.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423045/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor423064"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 14, 2011 9:03 UTC (Fri)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/423064/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; If it is not TCP, yes you are right this might be too drastic and harm throughput. But it's only because your application does not behave.</font><br>
<p>
By the way, if you need to smooth UDP-like traffic then DCCP has been designed expressly for you (Datagram Congestion Control Protocol).<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423064/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
<a name="CommAnchor423001"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2011 22:50 UTC (Thu)
                               by <b>paulj</b> (subscriber, #341)
                              [<a href="/Articles/423001/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes, buffer-bloat is just a plain bug. RED and CHOKe are means to tickle sender TCP's congestion control to activate in a more progressive fashion, which is more network friendly and less likely to cause those TCPs to synchronise (i.e. all back off at same time, and all ramp up again at same time) if congestion is applied uniformly to most flows. As the queue size increases above the min-threshold, the probability of dropping a newly arrived packet linearly increases, until it reaches 1 at the max-threshold.<br>
<p>
The problem with fixing buffer-bloat is finding an economic justification for reducing buffers. Other than in quite high-rate routers, memory for buffering is generally cheap and there's little economic incentive to not over-spec buffers. The crux of the problem is that it is not entirely clera what the correct smallest size is. Indeed that optimal size may vary for different deployments. If you make the buffers too small, your router will under-perform - especially in benchmarks in high-bandwidth settings. Making them too large OTOH is unlikely to cost you sales: few people benchmark performance in real-world scenarios, with congestion - except network congestion researchers.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423001/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor423046"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 14, 2011 6:59 UTC (Fri)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/423046/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; The crux of the problem is that it is not entirely clera what the correct smallest size is. Indeed that optimal size may vary for different deployments. If you make the buffers too small, your router will under-perform - especially in benchmarks in high-bandwidth settings. Making them too large OTOH is unlikely to cost you sales: few people benchmark performance in real-world scenarios, with congestion - except network congestion researchers.</font><br>
<p>
Agreed that the exact *optimal* size is not clear. However this is not an excuse for unreasonable sizes that harm latency with NO throughput benefit. <br>
<p>
This research topic is *not* new! This 2004 paper demontrates that just 1ms (!) is enough: <a href="http://portal.acm.org/citation.cfm?id=1015499">http://portal.acm.org/citation.cfm?id=1015499</a><br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423046/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor430010"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 27, 2011 6:10 UTC (Sun)
                               by <b>gmaxwell</b> (guest, #30048)
                              [<a href="/Articles/430010/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It's absolutely _trivial_ to demonstrate that 1ms is not unconditionally enough.<br>
<p>
Take a long pipe with a several ms of delay. Run a single TCP flow across it.  Observe that your flow gets nowhere near line rate, but instead it sawtooths against line rate and leaves the link idle for a significant amount of time.<br>
<p>
Yes, a single flow is a corner case but not not an outrageous one. The behavior also holds true for a small number of flows, especially if they experience identical end to end delays.<br>
<p>
So there is the excuse you were missing.<br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/430010/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor422830"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2011 12:06 UTC (Thu)
                               by <b>Velmont</b> (guest, #46433)
                              [<a href="/Articles/422830/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Sooo... Is this something for my local server-and-router for our home LAN? I guess it is way too small, this is more for ISPs, and more central routers? Or is it really part of our problem?<br>
<p>
Or do I only have to think about bufferbloat? Are there any guides telling me how to fix my Ubuntu Linux-based server/router to not be a part of the bufferbloat problem.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/422830/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor422974"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2011 21:07 UTC (Thu)
                               by <b>jhhaller</b> (guest, #56103)
                              [<a href="/Articles/422974/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The only thing you can control within your network are transmitted packets. If you have much upstream traffic, or significant interference in your wireless network, those are places which could benefit from this scheduler. But, if you have asymmetrical traffic, with most traffic received from your ISP, and have no long transmit queues, your ISP has to do this scheduling on your flows.<br>
<p>
One could do something similar by emulating a slightly slower link after receipt from your ISP. For example, if you have a 8  Mbps link from your ISP, you could put an artificial link of 7 Mbps out of your router (method for this left as an exercise for the reader). Then, if the queues start growing on that 7 Mbps link, packets could be discarded there. This would tend to prevent your 8 Mbps link from being congested, at the expense of not getting your full 8 Mbps. But, it would be much better for the ISP to install the CHOKe scheduler, so it would only start dropping packets when the average was over 8 Mbps.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/422974/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor422998"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2011 22:26 UTC (Thu)
                               by <b>paulj</b> (subscriber, #341)
                              [<a href="/Articles/422998/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
There are 2 things you might wish to tweak:<br>
<p>
- the size of the ring buffer used to transfer packets from the kernel to the NIC. See 'ethtool -g ethX' and 'ethtool -g &lt;dev&gt; tx X'<br>
<p>
- the number of packets the kernel's network layer will queue, it's 1000 by default on ethernet interfaces, which is way too large if your ethernet has a wifi segment in the middle of it. Set this to something lower with 'ip link set &lt;dev&gt; txqueuelen Y'<br>
<p>
<p>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/422998/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor423067"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 14, 2011 9:28 UTC (Fri)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/423067/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I think "in the middle of it" is misleading.<br>
<p>
A queue size matters only when it becomes a bottleneck. When a queue is empty its maximum size obviously does not matter.<br>
<p>
If your traffic goes first to a gigabit wire, and then through wifi, the queue size of your gigabit wire will never matter. Because the wifi queue will bottleneck first, fill up and drop the packets first.<br>
<p>
It does not hurt to fine tune the queue size of every link just in case. But if you only want a quick fix you just need to look at your usual bottlenecks.<br>
<p>
<p>
By the way, is the TX ring size in Linux finally adjusted according to the link speed? This should be a very basic thing to implement...<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423067/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor423071"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 14, 2011 9:54 UTC (Fri)
                               by <b>paulj</b> (subscriber, #341)
                              [<a href="/Articles/423071/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Over-sized buffers matter greatly, *especially* when they back on to a much slower link. Your GigE NIC will *NOT* respond to congestion at the wifi link, it'll keep blasting out packets (at least, it will seem so from the POV of a much slower wifi link). Which will just make the congestion on your wifi link even worse, particularly so given 802.11's malfeature of trying to implement reliability in a low-level link-layer - which just amplifies congestion problems. <br>
<p>
There's no way for Linux to know just from your local link-speed what the correct size is. Ethernets in the past tended to be relatively homogeneous wrt segments, but these days they can be extraordinarily mismatched - with GigE segments often bridged together with 802.11 links whose reliability, latency and bandwidth make you yearn fondly for the thinnet of 20+ years ago.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423071/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor423084"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 14, 2011 10:50 UTC (Fri)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/423084/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Your GigE NIC will *NOT* respond to congestion at the wifi link, it'll keep blasting out packets </font><br>
<p>
For sure the NIC *alone* would, but TCP (or DCCP) do NOT.<br>
<p>
TCP is ACK-clocked on the bottleneck. Just try it! The name of this feature is "congestion avoidance", google it.<br>
<p>
<p>
<font class="QuotedText">&gt; There's no way for Linux to know just from your local link-speed what the correct size is.</font><br>
<p>
ethtool eth0<br>
<p>
<p>
<font class="QuotedText">&gt; Ethernets in the past tended to be relatively homogeneous wrt segments, but these days they can be extraordinarily mismatched</font><br>
<p>
It does not matter: every link needs to adjust according to its *own* speed.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423084/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor423125"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 14, 2011 15:31 UTC (Fri)
                               by <b>njs</b> (guest, #40338)
                              [<a href="/Articles/423125/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; By the way, is the TX ring size in Linux finally adjusted according to the link speed? This should be a very basic thing to implement...</font><br>
<p>
Nope. (And it's "ring sizes", not "ring size"; every driver has its own TX queue handling code, plus there's the TX queue in the network layer itself.) I do have some patches to auto-tune the iwlwifi driver's queues, but haven't had a chance to benchmark them properly...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423125/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor423314"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">QoS not always desirable</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 16, 2011 22:54 UTC (Sun)
                               by <b>job</b> (guest, #670)
                              [<a href="/Articles/423314/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
For many networks it will make more sense investing in your interfaces than investing in your processing power. Just a thought.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/423314/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor424309"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 23, 2011 23:36 UTC (Sun)
                               by <b>jnareb</b> (subscriber, #46500)
                              [<a href="/Articles/424309/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      I wonder if there is <b>adaptive</b> variant of CHOKe, equivalent to ARED (Adaptive RED).

<p>
I wonder if there is similar algorithm, but which is not variant of RED, but of Blue... well, there is SFB.

<p>
BTW. CHOKe is mentioned in <a rel="nofollow" href="http://www.ee.ust.hk/~heixj/publication/thesis/node37.html">Variants of RED</a> in 'The Earliest Deadline First Scheduling for Real-Time Traffic in the Internet' thesis.
      
          <div class="CommentReplyButton">
            <form action="/Articles/424309/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor430036"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 28, 2011 0:39 UTC (Mon)
                               by <b>gmaxwell</b> (guest, #30048)
                              [<a href="/Articles/430036/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Well, SFB isn't this SFB uses bloom filters to discriminate flows while this uses sampled queue occupancy.   <br>
<p>
It would be interesting to see the two compared in simulation.  I'd expect SFB to be more fair until its hash tables start saturating and then CHOKe to be more fair after that point. <br>
<p>
It might be interesting to combine them, but I'm not sure what a proper update rule would look like because the CHOKe matches are stochastic. I suppose you'd have an update rule for the blue constants that clocks two different values through a filter depending on the CHOKe match status.  In effect, you'd have SFBish behavior until the buckets saturate and then each saturated bucket would behave CHOKe-ish.<br>
<p>
Unfortunately, as described, CHOKe is not hardware friendly at all.  The random queue access can be pipelined (or, better, replaced with a single memory slot remembering a random flow at the time it was enqueued) but I don't see an obvious way to drop both in the case of a match without taking more memory bandwidth than RED or even SFB like schemes.<br>
<p>
<p>
<p>
<p>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/430036/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor430041"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 28, 2011 3:05 UTC (Mon)
                               by <b>jthill</b> (subscriber, #56558)
                              [<a href="/Articles/430041/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <p><blockquote><I>not hardware friendly</i></blockquote>
Router hardware is so taut that lighting a don't-transmit-me flag in the packet header is excessive?
      
          <div class="CommentReplyButton">
            <form action="/Articles/430041/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor430042"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 28, 2011 3:19 UTC (Mon)
                               by <b>gmaxwell</b> (guest, #30048)
                              [<a href="/Articles/430042/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
An additional read-modify-write cycle out to whatever memory is storing the en-queued descriptors, potentially for every packet ingress?  And what happens if you hit a don't transmit packet on your next sample? Stall the pipeline and try again?<br>
<p>
At best it would halve the worst case throughput of a memory bandwidth bottlenecked system (e.g. 10g+ packet forwarding engines)<br>
<p>
Compared to RED (just needs a RNG and a fullness counter) and SFB (whos state can be made 'arbitrarily' small without compromising the queue capacity, and so can be kept on chip)  this sounds pretty unfriendly.<br>
<p>
Of course, not an issue on some small software driven router handling only a few tens of megabits. but most of those devices could also do real flow-aware queuing which was far more fine grained than CHOKe.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/430042/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor430043"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 28, 2011 3:24 UTC (Mon)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/430043/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
if you are pumping data out a 10Gb pipe, you are unlikely to need this sort of thing. this is needed when the link you are sending out of is the bottleneck of the communications path.<br>
<p>
allow this to be configured on a per-interface basis and you can disable it on your links where the hardware can barely keep up, but still have it in place where you are going to be buffering the data that you send.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/430043/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor430044"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 28, 2011 3:41 UTC (Mon)
                               by <b>gmaxwell</b> (guest, #30048)
                              [<a href="/Articles/430044/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I wonder what bit of misinformation makes people think that simply because a link is fast that it won't be congested.  This isn't the case and fast links tend to be major traffic aggregation points where fairness is a bigger issue, and where insufficient buffering can result in very costly under-utilization.<br>
<p>
As I mentioned, in the sort of place where you're using a purely software forwarding path and where the design of CHOKe wouldn't be a performance impediment you could also do per-flow queuing which would be considerably more fair than CHOKe (and potentially much better for loss sensitive flows), perhaps falling back to CHOKe/SFB if the flow lookups become too expensive.<br>
<p>
AFAIK, Linux doesn't even have a true per-flow qdisc though there have been patches and SFQ approximates it with acceptable performance.  Can you suggest a case where CHOKe would be needed but the SFQ qdisc in Linux would be inappropriate?<br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/430044/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor430045"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The CHOKe packet scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 28, 2011 6:19 UTC (Mon)
                               by <b>jthill</b> (subscriber, #56558)
                              [<a href="/Articles/430045/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>
<blockquote><i>At best it would halve the worst case throughput of a memory bandwidth bottlenecked system (e.g. 10g+ packet forwarding engines</i></blockquote>
That implies that internal bandwidth to packet metadata can be more of a bottleneck than transmission bandwidth to the actual packet data, and that one read and one write to a random packet envelope costs roughly as much as allocating and queuing it did in the first place.
<p>
So far as the envelope is concerned, that would mean each envelope is written as (some equivalent of) a single cache line. Hauling the envelope back and rewriting a bit would then actually cost the same bandwidth. That seems sensible enough.
<p>
I don't think full interlock on the update is necessary -- that's what LL/SC is for, yes? Just ignore the result from the conditional store, if it works, great, if not, so what?  Just as for a duplicate tag, the inbound packet is still dropped, as it should be, and the goal is to approximate, to "differentially penalize", which this still achieves.
<p>
It's still really hard for me to imagine metadata bandwidth being more of a bottleneck than actual data bandwidth, though.
      
          <div class="CommentReplyButton">
            <form action="/Articles/430045/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2011, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
