        <!DOCTYPE html>
        <html lang="en">
        <head><title>Runtime filesystem consistency checking [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/490291/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/489309/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/490291/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Runtime filesystem consistency checking</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Benefits for LWN subscribers</b>
<p>
The primary benefit from <a href="/Promo/nst-nag5/subscribe">subscribing to LWN</a>
       is helping to keep us publishing, but, beyond that, subscribers get
       immediate access to all site content and access to a number of extra
       site features.  Please sign up today!
</blockquote>
<div class="FeatureByline">
           By <b>Jake Edge</b><br>April 3, 2012</br>
           </div>
This year's edition of the Linux Storage, Filesystem, and Memory Management
Summit took place in San Francisco April&nbsp;1-2, just prior to the Linux
Foundation Collaboration Summit.
Ashvin Goel of the University of Toronto was invited to the summit to
discuss the work that he and others at the university had done on
consistency checking as filesystems are updated, rather than doing offline
checking using tools like <tt>fsck</tt>.  One of the students who had
worked on the project, Daniel Fryer, was also present to offer his
perspective from the audience.  Goel said that the work is not ready for
production use, and Fryer echoed that, noting that the code is not 100%
solid by any means.  They are researchers, Goel said, so the community
should give them some leeway, but that any input to make their work more
relevant to Linux would be appreciated.
</p>

<p>
Filesystems have bugs, Goel said, producing a list of bugs that
caused filesystem corruption over the last few years.  Existing solutions
can't deal with these problems because they start with the assumption that
the filesystem is correct.  Journals, RAID, and checksums on data are nice
features but they depend on offline filesystem checking to fix up any
filesystem damage that may occur.  Those solutions protect against problems
below the 
filesystem layer and not against bugs in the filesystem implementation itself.
</p>

<p>
But, he said, offline checking is slow and getting slower as disks get
larger.  In 
addition, the data is not available while the <tt>fsck</tt> is being done.
Because of that, checking is usually only done after things have obviously gone
wrong, which makes the repair that much more difficult.  The example given
was a file and directory inode that both point to the same data block; how
can the checker know which is correct at that point?
</p>

<p>
James Bottomley asked if there were particular tools that were used to
cause various kinds of filesystem corruption, and if those tools were
available for kernel hackers and others to use.  Goel said that they have
tools for both ext3 and btrfs, while audience members chimed in with other
tools to cause filesystem corruptions.  Those included fsfuzz, mentioned by
Ted Ts'o, which will do random corruptions of a filesystem.  It is often
used to test whether malformed filesystems on USB sticks can be used to
crash or subvert the kernel.  There were others, like fswreck for the OCFS2
filesystem, as well as similar tools for XFS noted by Christoph Hellwig and
another 
that Chris Mason said he had written for btrfs.  Bottomley's suggestion
that the block I/O scheduler could be used to pick blocks to corrupt was
met with a response from another in the audience joking that the block
layer didn't really need any help corrupting data&mdash;widespread laughter
ensued. 
</p>

<p>
Returning to the topic at hand, Goel stated that
doing consistency checking at runtime is faced with the problem that
consistency properties are global in nature and are therefore expensive to
check. To find two pointers to the same data block, one must scan the
entire filesystem, for example.  In an effort to get around this
difficulty, the researchers
hypothesized that global consistency properties could be transformed into
local consistency invariants.  If only local invariants need to be
checked, runtime consistency checking becomes a more tractable problem.
</p>

<p>
They started with the assumption that the initial filesystem is consistent,
and that something below the filesystem layer, like checksums, ensures that
correct data reaches the disk.  At runtime, then, it is only necessary to
check that the local invariants are maintained by whatever data is being changed
in any metadata writes.  This checking happens before those changes become
"durable", so they reason by induction that the filesystem resulting from
those is
also consistent.  By keeping any inconsistent state changes from reaching
the disk, the "Recon" system makes filesystem repair unnecessary.
</p>

<p>
As an example, ext3 maintains a bitmap of the allocated blocks, so to
ensure consistency when a block is allocated, Recon needs to test that the
proper bit in the bitmap flips from zero to one and that the pointer used is the
correct one (i.e. it corresponds to the bit flipped).  That is the
"consistency invariant" for determining that the block has been allocated
correctly.  A bit in the bitmap can't be set without a corresponding block
pointer being set and vice versa.  Additional checks are done to make sure
that the block had not already been allocated, for example.  That requires
that Recon maintain its own block bitmap.  
</p>

<p>
These invariants (they came up with 33 of them for ext3) are checked at the
transaction commit point.  The design of Recon is based on a fundamental
mistrust of the filesystem code and data structures, so it sits between the
filesystem and the
block layer.  When the filesystem does a metadata write, Recon records
that operation.  Similarly, it caches the data from metadata reads, so that
the invariants can be validated without excessive disk reads.  When the
commit of a metadata update is done, the read cache is updated if the
invariants are upheld in the update. 
</p>

<p>
When filesystem metadata is updated, Recon needs to determine what
logical change is being performed.  It does that by examining the metadata
block to determine what type of block it is, and then does a "logical diff"
of the changes.  The result is a "logical change record" that records
five separate fields for each change: block type, ID, the field that
changed, the old value, and the new value.  As an example, Goel listed the
change records that might result from appending a block to inode 12:
<blockquote>
<table>
<tr><th>Type</th><th>ID</th><th>Field</th><th>Old</th><th>New</th></tr>
<tr class="Odd"><td>inode</td><td>12</td><td>blockptr[1]</td><td>0</td><td>501</td></tr>
<tr class="Even"><td>inode</td><td>12</td><td>i_size</td><td>4096</td><td>8192</td></tr>
<tr class="Odd"><td>inode</td><td>12</td><td>i_blocks</td><td>8</td><td>16</td></tr>
<tr class="Even"><td>bitmap</td><td>501</td><td>--</td><td>0</td><td>1</td></tr>
<tr class="Odd"><td>bgd</td><td>0</td><td>free_blocks</td><td>1500</td><td>1499</td></tr>
</table>
</blockquote>
Using those records, the invariants can be checked to ensure that the
block pointer referenced in the inode is the same as the one that has its bit
set in the bitmap, for example.
</p>

<p>
Currently, when any invariant is violated, the filesystem is stopped.
Eventually there may be ways to try to fix the problems before writing to
disk, but for now, the safe option is to stop any further writes.
</p>

<p>
Recon was evaluated by measuring how many consistency errors were detected
by it vs. those caught by <tt>fsck</tt>.  Recon caught quite a few errors
that were not detected by <tt>fsck</tt>, while it only missed two that
<tt>fsck</tt> caught.  In both cases, the filesystem checker was looking at
fields that are not currently used by ext3.  Many of the inconsistencies
that Recon found and <tt>fsck</tt> didn't were changes to unallocated data,
which are not important from a consistency standpoint, but still should not
be changed in a correctly operating filesystem.
</p>

<p>
There are some things that neither <tt>fsck</tt> nor Recon can detect, like
changes to filenames in directories or time field changes in inodes.  In
both cases, there isn't any redundant information to do a consistency check
against. 
</p>

<p>
The performance impact of Recon is fairly modest, at least in terms of I/O
operations.  With a cache size of 128MB, Recon could handle a web server
workload with only a reduction of approximately 2% I/O operations/second
based on a graph that was shown.  The
cache size was tweaked to find a balance based on the working set size of
the workload so that the cache would not be flushed prematurely, which
would otherwise cause expensive reads of the metadata information.  The
tests were 
run on a filesystem on a 1TB partition with 15-20GB of random files
according to Fryer, 
and used small files to try to stress the metadata cache.
</p>

<p>
No data was presented on the CPU impact of Recon, other than to say that
there was "significant" CPU overhead.  Their focus was on the I/O cost, so
more investigation of the CPU cost is warranted.  Based on comments from
the audience, though, some would be more than willing to spend some CPU in
the name of filesystem consistency so that the far more expensive offline
checking could be avoided in most cases.
</p>

<p>
The most important thing to take away from the talk, Goel said, is that
as long as the integrity of written block data is assured, all
of the ext3 properties that can checked by <tt>fsck</tt> can instead be
done at runtime.  As Ric Wheeler and others in the audience pointed out,
that doesn't eliminate the need for an offline checker, but it may help
reduce how often it's needed.  Goel agreed with that, and noted that in 4%
of their tests with 
corrupted filesystems, <tt>fsck</tt> would complete successfully, but that
a second run would find more things to fix.  Ts'o was very interested to
hear that and asked that they file bugs for those cases.
</p>

<p>
There is ongoing work on additional consistency invariants as well as
things like reducing the memory overhead and increasing the number of
filesystems that are covered.  Dave Chinner noted that invariants for some
filesystems may be hard to come up with, especially for filesystems like
XFS that don't necessarily do metadata updates through the page cache.
</p>

<p>
The reaction to Recon was favorable overall.  It is an interesting project
and surprised some that it was possible to do runtime consistency checking
at all. As always, there is more to do, and the team has limited resources,
but most attendees seemed favorably impressed with the work.
</p>
<p>
[Many thanks are due to Mel Gorman for sharing his notes from this session.]<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Filesystems">Filesystems</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Storage_Filesystem_and_Memory-Management_Summit-2012">Storage, Filesystem, and Memory-Management Summit/2012</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/490291/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor490415"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 16:41 UTC (Tue)
                               by <b>Tara_Li</b> (guest, #26706)
                              [<a href="/Articles/490415/">Link</a>] (14 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This is *DEFINITELY* going to become more and more critical, as spinning media becomes more and more unsuited to random accesses.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490415/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490460"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 18:58 UTC (Tue)
                               by <b>martinfick</b> (subscriber, #4455)
                              [<a href="/Articles/490460/">Link</a>] (13 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I don't understand your point?  Have random accesses slowed down?  Are they anticiapted to slow down?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490460/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490468"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 20:00 UTC (Tue)
                               by <b>drag</b> (guest, #31333)
                              [<a href="/Articles/490468/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The slowdown is relative to other metrics related to computer performance, I imagine.<br>
<p>
Also while reliability and capacity has  both increased, capacity has far outstripped reliability. So that while today's drives are generally more reliable then older ones (as in bad/corrupt blocks lost per GB)  the chances of you losing part of your data is much higher simply because there is so much more of it. <br>
<p>
This sort of stuff why online fsck and scrubs (reading in data and comparing it to checksums to detect and correct corruption) is so important on modern file systems.  Previously the only people that needed to care were ones that could justify the expense of purchasing big SAN devices and whatnot.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490468/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor490469"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 20:01 UTC (Tue)
                               by <b>cmccabe</b> (guest, #60281)
                              [<a href="/Articles/490469/">Link</a>] (11 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Hard disk sizes have continued increasing exponentially, while rotations per minute (RPMs) have more or less stopped increasing.  So seeks are becoming more expensive, and fsck in general is starting to take much longer on hard disks.<br>
<p>
SSDs don't have these limitations, however.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490469/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490552"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 8:00 UTC (Wed)
                               by <b>dgm</b> (subscriber, #49227)
                              [<a href="/Articles/490552/">Link</a>] (10 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
That doesn't make a lot of sense. <br>
<p>
Disk capacity may have increased, but disk platters are exactly the same size as before: 3.5 inches. So, moving the read head around should cost mostly the same as before. The only factor I can think of is that the head has to be more precisely positioned, and that may (or may not) be more costly because of physical limitations (rebounds).<br>
<p>
On the other hand there are two factors that should make seek time decrease: improved machinery and more density. More density means that more data goes faster under the read head, so more often seeks can be satisfied without moving the read head, just waiting for the data to pass below.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490552/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490565"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 9:22 UTC (Wed)
                               by <b>epa</b> (subscriber, #39769)
                              [<a href="/Articles/490565/">Link</a>] (8 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I thought the other poster's point was about rotational speed.  If the disk rotates at 100 revolutions per second then you may have to wait ten milliseconds in the worst case, even if the head is already positioned correctly.  That ten milliseconds is not getting any shorter because disks are not spinning faster.  However, the other components in the system are getting faster, so the ten millisecond overhead becomes more and more significant.  Similarly, the disk head takes almost as long to move into position today as it did twenty years ago, even though processors and RAM are many times faster.<br>
<p>
Or maybe the point is that larger filesystems necessarily require more random accesses and hence more disk seeks when you fsck them.  Larger RAM would mitigate this but I don't know whether increased RAM for caching has kept pace with filesystem sizes enough.  An fsck expert would be able to give some numbers.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490565/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490571"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 10:27 UTC (Wed)
                               by <b>khim</b> (subscriber, #9252)
                              [<a href="/Articles/490571/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      <p>Actually the original poster was wrong: seeks are no more expensive. They have the same cost, but you need more of them. Even if you'll grown filesystem data structures to reduce fragmentation undeniable fact is that number is <b>tracks</b> is growing and time to read a single track is constant.</p>

<p>This means that time needed to read the whole disk from the beginning to the end is growing.</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/490571/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490585"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 12:17 UTC (Wed)
                               by <b>epa</b> (subscriber, #39769)
                              [<a href="/Articles/490585/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Makes sense.  I imagine that the number of tracks grows with the square root of disk capacity.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490585/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490594"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 12:59 UTC (Wed)
                               by <b>khim</b> (subscriber, #9252)
                              [<a href="/Articles/490594/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <p>More or less. This means that when you go from Linux 0.1 (with typical size of HDD 200-300MB) to Linux 3.0 (with typical size of HDD 2-4TB) filesystem slows by a factor of 100, not by a factor of 10'000. But 100x slowdown is still <b>a lot</b>.</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/490594/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490630"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 16:01 UTC (Wed)
                               by <b>wazoox</b> (subscriber, #69624)
                              [<a href="/Articles/490630/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I'm currently testing 4TB drives right now. RAID rebuild now reaches 48 hours, up from 10 hours for 1 TB.<br>
The individual 4 TB drive needs more than 9 hours to simply fill it up sequentially.<br>
We'll need to index blocks on our spinning rust on SSD cache before long :)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490630/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490676"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 19:41 UTC (Wed)
                               by <b>khim</b> (subscriber, #9252)
                              [<a href="/Articles/490676/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <p>Contemporary 4TB HDDs are especially slow because they use 5 plates (where your 1TB disks probably used 2 or 3). This means that not only you see the slowdown from growing number of tracks, you see additional slowdown from growing number of plates!</p>

<p>Thankfully in this direction 5 is the limit: I doubt we'll see return of 30 plates monsters like the infamous <a href="http://en.wikipedia.org/wiki/History_of_IBM_magnetic_disk_drives#IBM_3340">Winchester</a>… all 3.5" HDDs to date had 5 plates or less.</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/490676/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490756"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 5, 2012 9:18 UTC (Thu)
                               by <b>misiu_mp</b> (guest, #41936)
                              [<a href="/Articles/490756/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I dont think its clear why would more plates be slower. More plates means more heads, with possibility for concurrency - that should increase sequential transfer speed. <br>
If data is written cylinder-wise, the latency should be similar to one-plate disk. <br>
If it is written plate-wise, the latency should vary up and down in relation to block numbers. Its possible the average latency would still be comparable.<br>
The only clear negative about multi-platter systems is the increased inertia of the head assembly. It's not so clear whether it has a practical implication.<br>
Apart from this unclear performance implication, there is of course the decreased reliability and increased cost of multi-platter solutions. That is the main reason we don't see that many of them. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490756/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490767"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 5, 2012 10:00 UTC (Thu)
                               by <b>khim</b> (subscriber, #9252)
                              [<a href="/Articles/490767/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <blockquote><font class="QuotedText">More plates means more heads, with possibility for concurrency - that should increase sequential transfer speed.</font></blockquote>

<p>Good idea. Sadly it's about ten years too late. Today's tracks are too small: when the head is on a track on one plate all other heads are <b>not</b> on this same track. In fact they are not on track at all. They just randomly drift between 2-3 tracks adjacent to each other. That's why you can only use one head actively (how can we use even one if it's all is so unstable? well, it's easy: there are active scheme which dynamically moves head to keep it on track).</p>

<blockquote><font class="QuotedText">If data is written cylinder-wise, the latency should be similar to one-plate disk.</font></blockquote>

<p>Latency of seeks - yes, number of tracks - no. If you use the same plates then filesystem on a single plate HDD will be roughly five times faster then filesystem on five plates HDD.</p>

<blockquote><font class="QuotedText">That is the main reason we don't see that many of them.</font></blockquote>

<p>The main reason we don't see many of them is cost. They are more expensive to produce and since they are less reliable they incur more warranty overhead. They are also slower, but this secondary problem.</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/490767/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor492205"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 13, 2012 8:47 UTC (Fri)
                               by <b>ekj</b> (guest, #1524)
                              [<a href="/Articles/492205/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
So, we "only" need to make the arms move independently then. :-)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/492205/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor490843"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 5, 2012 19:01 UTC (Thu)
                               by <b>cmccabe</b> (guest, #60281)
                              [<a href="/Articles/490843/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
When I said "seeks are becoming more expensive" meant in relation to other things going on in the system, not in an absolute sense.<br>
<p>
From a programmer's perspective, the growth in hard disk capacity has not been matched by a corresponding increase in either throughput or worst-case latency.<br>
<p>
Because hard disk throughput has not kept pace, in a high performance setup, your only hope for reasonable throughput is to use RAID with striping.  But RAID increases the minimum size that you can read-- before, that minimum was a sector-- with RAID, it's a stripe.  This makes hard disks even less of a random-access medium, since you never want to be reading just a few bytes-- you want to read a whole RAID stripe at a time in order to be efficient.<br>
<p>
Most programmers don't know about these details because the database does all this for you.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490843/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
<a name="CommAnchor490435"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 17:13 UTC (Tue)
                               by <b>nybble41</b> (subscriber, #55106)
                              [<a href="/Articles/490435/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Many of the inconsistencies that Recon found and fsck didn't were changes to unallocated data, which are not important from a consistency standpoint, but still should not be changed in a correctly operating filesystem.</font><br>
<p>
That may be true of ext3, but in general there are a few reasons why one might want to write to space which has not been allocated *on disk*. Atomic updates come to mind: reserve space in memory, write the new data, and finally--after the data has been committed--reserve it on disk and update the metadata. Online defragmentation or resizing could be implemented this way as well. Unallocated data is "don't care"; it shouldn't be a problem to change it even if the reason for the change is not yet apparent.<br>
<p>
This also seems to introduce a second point of failure; the system can cease to function due to a filesystem bug, as before, or due to a bug in Recon which unnecessarily blocks access to the filesystem. That risk would have to be weighed against the cost of filesystem corruption in the absence of Recon, of course.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490435/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490466"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 19:58 UTC (Tue)
                               by <b>NAR</b> (subscriber, #1313)
                              [<a href="/Articles/490466/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <I>This also seems to introduce a second point of failure</I>
<P>
This was my first thought too. They are using code to check code, which is kind of like automated tests. In my experience tests are wrong about as many times as the code itself (but this could be due to our fragile test environment), so it's one more thing to get right. On the other hand if Recon is changed a lot fewer times than the filesystem code itself, then Recon can reach sufficient maturity to be actually useful.
      
          <div class="CommentReplyButton">
            <form action="/Articles/490466/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490512"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 23:28 UTC (Tue)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/490512/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It reminds me a lot of lockdep.<br>
<p>
lockdep is brilliant for developers as it warns you early of your bugs, just as this 'recon' would warn ext3 developers of their bugs.<br>
But lockdep used to report lots of false positives - this has got a lot better over the years though.<br>
<p>
I'm not sure I'd enable lockdep or recon in production though.  There is a real cost, and it is not at all likely to help more than it hurts.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490512/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor490596"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 13:10 UTC (Wed)
                               by <b>ashvin</b> (guest, #83894)
                              [<a href="/Articles/490596/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
We expect that Recon will initially be used mainly for development. As it matures, it could be deployed in production use. The need to change it over time should be comparable to the need to change fsck.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490596/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor490595"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 13:07 UTC (Wed)
                               by <b>ashvin</b> (guest, #83894)
                              [<a href="/Articles/490595/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
We do handle "unallocated" writes due to shadow paging (e.g., copy-on-write on btrfs) where metadata is written to unallocated regions and then linked to the file-system on commit. We find this linkage at commit point and will not report an error. We haven't worked with online resizing but I suspect the handling should be similar on commit. Writing to unallocated data to which there is no linkage at commit seems suspect: how would the file system know that data is useful in anyway after a crash?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490595/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490625"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 15:30 UTC (Wed)
                               by <b>nybble41</b> (subscriber, #55106)
                              [<a href="/Articles/490625/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Writing to unallocated data to which there is no linkage at commit seems suspect: how would the file system know that data is useful in anyway after a crash?</font><br>
<p>
The data would not be useful after a crash; up to the point where the allocation is recorded on disk, there are no references to it, and it can simply revert to unallocated space, canceling the incomplete "transaction".<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490625/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor490445"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 17:33 UTC (Tue)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/490445/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It seems like this could also catch hardware problems, such as bit flips in main memory (for folks that lack ECC), and bugs in non-filesystem code, if it results in memory corruption.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490445/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490583"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 12:07 UTC (Wed)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/490583/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
There's a bigger problem: it is possible to tell a disk to write something somewhere, and it reports success, but has actually either written something different, lost it entirely, or overwritten something different. Local consistency checks on read would detect the first two cases, but no local check can spot the third case, as far as I can see. (This case is certainly not common, though: I have seen only one disk problem that was possibly attributable to this class of failure. I've been trying to get info on the frequency of this sort of missed-seek or mis-seek error, but all I can find is rumours. The secrecy of disk manufacturers regarding info critical to the integrity of one's data is quite distressing at times.)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490583/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490598"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 13:16 UTC (Wed)
                               by <b>ashvin</b> (guest, #83894)
                              [<a href="/Articles/490598/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Recon can catch bit flips that occur in memory and that corrupt file system metadata buffers before the Recon code is run. Catching bit flips after the Recon checks require checksumming and replication of file system metadata buffers. Recon will also not detect lost and misdirected writes if they occur after the Recon checks. However, they can be caught using version numbers, but the file system needs to support that, e.g., generation numbers in btrfs.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490598/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor491950"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 12, 2012 12:47 UTC (Thu)
                               by <b>nye</b> (subscriber, #51576)
                              [<a href="/Articles/491950/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt;There's a bigger problem: it is possible to tell a disk to write something somewhere, and it reports success, but has actually either written something different, lost it entirely, or overwritten something different</font><br>
<p>
My ZFS experience on a ~5TB pool consisting of six commodity HDs under fairly light load (ie. it's a home file server) is that every couple of months scrub detects checksum errors in a block or a small handful of blocks, without any corresponding read/write errors being given by the device.<br>
<p>
Not sure if that's the situation you're talking about.<br>
<p>
(Also, the same experience has taught me that Western Digital should be avoided like ebola. I actually wonder if their green series might be drives that have failed QC and been re-badged for the unsuspecting consumer.)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/491950/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor492219"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 13, 2012 10:33 UTC (Fri)
                               by <b>etienne</b> (guest, #25256)
                              [<a href="/Articles/492219/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; every couple of months scrub detects checksum errors in a block or a small handful of blocks, without any corresponding read/write errors being given by the device.</font><br>
<p>
I am not sure to interpret exactly what is happening on my own PC, but I suspect something like:<br>
- one block of sectors develop a bit fault in the magnetic data<br>
- the ECC correct it each times the PC reads the sector resulting in a *very long* delay of few seconds<br>
- the Linux driver do not noticed there was long ECC correction and do not decide to rewrite the sector identically to get the magnetic data corrected<br>
- long term a second error will appear on the magnetic data and the ECC will no more be sufficient.<br>
<p>
I do not know why the sector is not rewritten by the Linux driver, I know that I did solve same problem on another PC by touching a file in a directory, forcing the sector containing the directory entry to be rewritten.<br>
I never noticed the problem when the "old" ATA/IDE driver was used, but I am not sure I interpret correctly what happens on my PC during the last few days...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/492219/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor492235"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 13, 2012 12:34 UTC (Fri)
                               by <b>james</b> (subscriber, #1325)
                              [<a href="/Articles/492235/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I understand that these days, it's the disk firmware's job to do this. It knows that there's a read error (which Linux doesn't, although it can sometimes guess ¹); it knows that sector is dodgy (which Linux doesn't, because it doesn't get told when the hardware remaps sectors), it can try re-writing the sector, and if that fails, it can remap in a spare sector (which Linux can't do, because it doesn't have access to the disk's spare sectors) if (and only if) it knows what that sector's contents should be, either because it's managed to read something, or the computer is overwriting that sector.<br>
<p>
And it can do all of that without having to worry about which operating system is running, or it's a database using raw access, or if it's a light layer using BIOS calls but no filesystem. It can preserve this information across reformats.<br>
<p>
In your case, by causing the sector containing the directory entry to be rewritten, the disk probably decided that this was a great time to remap in a spare sector, so it actually went to a different part of the disk. (Unless the filesystem you were using put the new directory entry somewhere else anyway.)<br>
<p>
And ECC correction doesn't take seconds; re-reading the same sector repeatedly in the hope that you can get a last good read does.<br>
<p>
¹ If you've got command queueing turned on, several requests outstanding, and there's a delay, which sector caused the problem?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/492235/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor492266"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 13, 2012 14:51 UTC (Fri)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/492266/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Adding to what James said above me, I think you might want to look into installing the SMART tools to query your drive.  The "smartctl" tool will read out and display the various statistics the drive's been collecting about corrected errors and remapped sectors.<br>
<p>
It will also let you fire up background health checks (these can take quite a long time to complete -- as long as a day, as I recall) that may help turn up other problems.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/492266/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
<a name="CommAnchor490446"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 17:53 UTC (Tue)
                               by <b>cesarb</b> (subscriber, #6266)
                              [<a href="/Articles/490446/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Goel stated that doing consistency checking at runtime is faced with the problem that consistency properties are global in nature and are therefore expensive to check. To find two pointers to the same data block, one must scan the entire filesystem, for example.</font><br>
<p>
Now that this problem has been recognized, could future filesystems be designed so that all relevant consistency properties are local instead of global?<br>
<p>
In the quoted example, for instance, the filesystem could record an "owner" identifier for each data block, instead of a single "used/free" bit. Then the check "two owners point to the same data block" becomes instead "the data block points back to the correct owner".<br>
<p>
In an ext3-style implementation of this concept, the owner identifier could be the block which points to this data block. So if you are looking at a data block pointed to by an indirect block you have to check 3 invariants, all local: "the data block owner is the indirect block", "the indirect block points to the data block", and "there are no duplicate data blocks within this indirect block". The same applies if you have a block containing inodes instead of an indirect block.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490446/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490454"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 18:05 UTC (Tue)
                               by <b>dtlin</b> (subscriber, #36537)
                              [<a href="/Articles/490454/">Link</a>] 
      </p>
      
      </div>
      </summary>
      According to <a rel="nofollow" href="http://oss.oracle.com/projects/btrfs/dist/documentation/btrfs-design.html">Btrfs Design</a>, btrfs has backrefs from each btree node and file extent to its parents — plural, because there may be multiple.
      
          <div class="CommentReplyButton">
            <form action="/Articles/490454/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor490554"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 8:05 UTC (Wed)
                               by <b>dgm</b> (subscriber, #49227)
                              [<a href="/Articles/490554/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
In general, the path to reliability is to add redundancy and increase locality. Redundancy decreases the probability of complete failure, and locality limits the impact of the failure.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490554/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor490458"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2012 18:51 UTC (Tue)
                               by <b>dcg</b> (subscriber, #9198)
                              [<a href="/Articles/490458/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I am surprised that the "integrity check" btrfs feature included in 3.3 wasn't mentioned. It seems to be very similar in concept: (see comments in <a href="http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git;a=blob;f=fs/btrfs/check-integrity.c;hb=HEAD">http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-...</a>)<br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490458/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor490549"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 6:58 UTC (Wed)
                               by <b>hisdad</b> (subscriber, #5375)
                              [<a href="/Articles/490549/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
btrfs more reliable?<br>
Not for me. I have an Ml110G6 with P212 raid controller.<br>
That should be either all ok or all fail, right? Nope. One disk had a part fail and that somehow got through the controller and corrupted the file systems. btrfsck happily tells me there are errors. When I look for the "-f" it just smiles at me. The ext4 partitions were recoverable.<br>
<p>
Oh yes we need better metadata, but also background scrubs.<br>
--Dad<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490549/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor491077"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 7, 2012 15:24 UTC (Sat)
                               by <b>dcg</b> (subscriber, #9198)
                              [<a href="/Articles/491077/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I just pointed out the existence of a integrity checker, I never said btrfs was more reliable.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/491077/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor492185"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 13, 2012 6:04 UTC (Fri)
                               by <b>Duncan</b> (guest, #6647)
                              [<a href="/Articles/492185/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Btrfs is marked experimental for a reason, and it's public knowledge that until recently (like late kernel 3.3 cycle) the available fsck was read-only, no fix option.  AFAIK there's a fix option version available now, but only in dangerdonteveruse branch of Chris's btrfs-tools tree ATM, not yet even in the main master branch, as it's being tested to ensure that at worst it doesn't make any problems WORSE instead of better.<br>
<p>
IOW, as both the wiki and kernel options clearly state or from an even perfunctory scan of recent list posting, btrfs is clearly experimental and only suitable for test data that is either entirely throwaway or is available elsewhere ATM.  While a responsible admin will always have backups for data even on production quality filesystems, there, backups are backups, the primary copy can be the copy on the working filesystem.  But things are rather different for btrfs or any filesystem at its development state, where the primary copy should be thought of as existing on some non-btrfs volume, backed up as should be any data of value, and anything placed on btrfs is purely testing data -- if it happens to be there the next time you access it, particularly after the next umount/mount cycle, great, otherwise, you have a bug and as a tester of an experimental filesystem, should be following the development list close enough to know whether it has been reported or not yet, and a responsibility to try to trace and report it, including running various debug patches, etc, as may be requested for tracing it down.  Otherwise, if you're not actively testing it, what are you doing running such an experimental and in active development filesystem in the first place?<br>
<p>
So /of/ /course/ btrfs is not likely to be more reliable at this point.  It's still experimental, and while it is /beginning/ to stabilize, development activity and debugging is still very high, features are still being added, it only recently got a writing fsck at all and that's still in dangerdonteveruse for a reason.  As a volunteer tester of a filesystem in that state, if it's as stable as a mature filesystem for you, you probably simply aren't pushing it hard enough in your tests! =:^)<br>
<p>
But of course every filesystem had a point at which it was in a similar state, and unlike many earlier filesystems, btrfs has been designed from the ground up with data/metadata checksumming and other reliability features as primary design features, so by the time it reaches maturity and that experimental label comes off for mainline (actually, arguably before that as kernel folks are generally quite conservative about removing such labels), it should be well beyond ext* in terms of reliability, at least when run with the defaults (many of the features including checksumming can be turned off, it can be run without the default metadata duplication, etc).<br>
<p>
So while btrfs as a still experimental filesystem fit only for testing /of/ /course/ doesn't yet have the reliability of ext3/4, it will get there, and then surpass them... until at a similar maturity to what they are now, it should indeed be better than they are now, or even than they will be then, for general purpose usage reliability, anyway.<br>
<p>
Duncan (who has been following the btrfs list for a few weeks now, and all too often sees posts from folks wondering how to recover data... from a now unmountable but very publicly testing-quality-only filesystem that never should have had anything but throwaway quality testing data on it in the first place.)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/492185/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor490600"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 13:21 UTC (Wed)
                               by <b>ashvin</b> (guest, #83894)
                              [<a href="/Articles/490600/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
We are aware of the btrfs integrity checker and plan to incorporate some ideas from there into Recon. There are two main differences between the btrfs integrity checker and Recon right now. The btrfs integrity checker depends on the file system code while Recon works outside, at the block layer. A bug in the file system may affect the integrity checker, while the hope is that bugs in the file system and in Recon are going to be unrelated. Second, the integrity checker mainly checks that updated blocks are destined to the correct locations, while Recon checks the contents of the updated blocks.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490600/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor490695"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2012 20:47 UTC (Wed)
                               by <b>travelsn</b> (guest, #48694)
                              [<a href="/Articles/490695/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Does anybody know if they have tested Recon on flash based filesystem. For embedded devices JFFS2/UBIFS fs are of interest. If anybody follows mtd mailing list there are many instances where file system does become corrupted it would be nice to know at run time rather than finding out that filesystem is corrupted when the device boots!
      
          <div class="CommentReplyButton">
            <form action="/Articles/490695/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor490719"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 5, 2012 2:36 UTC (Thu)
                               by <b>asj</b> (subscriber, #74238)
                              [<a href="/Articles/490719/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thanks for the article. if it included any links to the original work on this that would have been nicer.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490719/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor499226"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Runtime filesystem consistency checking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 30, 2012 11:50 UTC (Wed)
                               by <b>aigarius</b> (guest, #7329)
                              [<a href="/Articles/499226/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Would it not be easier to have a low priority kernel thread that runs in the background and periodically checks the integrity of the whole filesystem? It could then both fix it and also do the defrag actions in a continuous way.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/499226/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2012, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
