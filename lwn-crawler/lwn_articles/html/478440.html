        <!DOCTYPE html>
        <html lang="en">
        <head><title>What happened to disk performance in 2.6.39 [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/478440/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/477352/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/478440/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>What happened to disk performance in 2.6.39</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>We're bad at marketing</b>
<p>
We can admit it, marketing is not our strong suit. Our strength is
writing the kind of articles that developers, administrators, and
free-software supporters depend on to know what is going on in the
Linux world. Please <a href="/Promo/nsn-bad/subscribe">subscribe today</a> to help us keep doing that, and so
we donâ€™t have to get good at marketing.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>January 31, 2012</br>
           </div>
Herbert Poetzl recently <a href="/Articles/478441/">reported</a> an
interesting performance problem.  His SSD-equipped laptop could read data
at about 250MB/s with the 2.6.38 kernel, but performance dropped to
25-50MB/s on anything more recent.  An order-of-magnitude performance drop
is just not the sort of benefit that most people look forward to when
upgrading their kernel, so this report quickly gained the attention of a
number of developers.  The resolution of the problem turned out to be
simple, but it offers an interesting view of how high-performance disk I/O
works in the kernel.
<p>
An explanation of the problem requires just a bit of background, and, in
particular, the definition of a couple of terms.  "Readahead" is the
process of speculatively reading file data into memory with the idea that
an application is likely to want it soon.  Reasonable performance when
reading a file sequentially depends on proper readahead; that is the only
way to ensure that reading and consuming the data can be done in parallel.
Without readahead, applications will spend more time than necessary waiting
for data to be read from disk.
<p>
"Plugging," instead, is the process of stopping I/O request submissions to
the low-level device for a period of time.  The motivation for plugging is
to allow a number of I/O requests to accumulate; that lets the I/O
scheduler sort them, merge adjacent requests, and apply any sort of
fairness policy that might be in effect.  Without plugging, I/O requests
would tend to be smaller and more scattered across the device, reducing
performance even on solid-state disks.
<p>
Now imagine that we have a process about to start reading through a
long file, as indicated by your editor's unartistic rendering here:
<p>
<img src="https://static.lwn.net/images/2012/plug-ra1.png" width=573 height=95 alt="[Bad art]">
<p>
Once the application starts reading from the beginning of the file, the kernel
will set about filling the first readahead window (which is 128KB with
larger files) and submit I/O for the second window, so the situation will
look something like this:
<p>
<img src="https://static.lwn.net/images/2012/plug-ra2.png" width=573 height=115 alt="[Reading begins]">
<p>
Once the application reads past 128KB into the file, the data it needs will
hopefully be in memory.  The readahead machinery starts up again,
initiating I/O for the window starting at 256KB; that yields a situation
that looks something like this:
<p>
<img src="https://static.lwn.net/images/2012/plug-ra3.png" width=573 height=115 alt="[Next window]">
<p>
This process continues indefinitely with the kernel running to always stay
ahead of the application and have the data there by the time that
application gets around to reading it.
<p>
The 2.6.39 kernel saw <a href="/Articles/438256/">some significant changes
to how plugging is handled</a>, with the result that the plugging and
unplugging of queues is now explicitly managed in the I/O submission
code.  So, starting with 2.6.39, the readahead code will plug the request
queue before it submits a batch of read operations, then unplug the queue
at the end.  The function that handles basic buffered file I/O
(<tt>generic_file_aio_read()</tt>) also now does its own plugging.  And
that is where the problems begin.
<p>
Imagine a process that is doing large (1MB) reads.  As the first large read
gets into <tt>generic_file_aio_read()</tt>, that function will plug the
request queue and start working through the file pages already in memory.
When it gets to the end of the first readahead window (at 128KB), the
readahead code will be invoked as described above.  But there's a problem:
the queue is still plugged by <tt>generic_file_aio_read()</tt>, which is
still working on that 1MB read request, so the I/O
operations submitted by the readahead code are not passed on to the
hardware; they just sit in the queue.
<p>
So, when the application gets to the end of the second readahead window, we
see a situation like this:
<p>
<img src="https://static.lwn.net/images/2012/plug-ra4.png" width=573 height=115 alt="[Bummer]">
<p>

At this point, everything comes to a stop.  That will cause the queue to be
unplugged, allowing the readahead I/O requests to be executed at last, but
it is too late.  The application will have to wait.  That wait is enough to
hammer performance, even on solid-state devices.
<p>
The <a href="/Articles/478459/">fix</a> is to simply remove the top-level
plugging in <tt>generic_file_aio_read()</tt> so that readahead-originated
requests can get through to the hardware.  Developers who have been able to
reproduce the slowdown report that this patch makes the problem go away, so
this issue can be considered solved.  Look for this fix to appear in a
stable kernel release sometime soon.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Block_layer-Plugging">Block layer/Plugging</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/478440/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor478932"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 2, 2012 9:15 UTC (Thu)
                               by <b>alankila</b> (guest, #47141)
                              [<a href="/Articles/478932/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Plugging sounds like another voodoo feature of dubious utility.<br>
<p>
Why can't plugging occur naturally in sense that if device is already busy with I/O, let the additional I/O sit in queue and get adjacent reads merged and other such transformations? But if there's no utilization of device, it would seem that it would probably be better just to submit the I/O right away.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/478932/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor479132"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 2, 2012 20:45 UTC (Thu)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/479132/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
the problem is the queue size<br>
<p>
if the queue size is not large enough, then you can't fit enough requests into the queue to have them available to combine later.<br>
<p>
If the queue size is too large, then a new process making a request will not get it's request serviced until everything ahead of it in the queue gets processed (unless you have some fairness process to not put the new processes request at the end of the queue)<br>
<p>
I don't like the concept of plugging, but it seems to be a hack that tends to work.<br>
<p>
as an example.<br>
<p>
In rsyslog, when the ability to process multiple messages from the queue at once was added (so that multiple messages could be inserted to a database in a single transaction for example), we discussed delaying pulling the first message from the queue to give the queue a chance to build up several messages that would then be handled more efficiently (in one pass), but we decided to not do this because the process ended up being self-regulating.<br>
<p>
If the messages arrived slowly enough, they are handled one at a time.<br>
<p>
If the messages arrive faster than this, some messages queue up while the prior messages are handled and then the backlog gets processed at one time (up to a limit)<br>
<p>
This is very good for latency, but the trade-off is that the output is doing far more work than it would need to do if the work was batched more. As the load builds up, it will ramp up the utilisation of the output in the most inefficient mode (one message at a time), and then when it saturates the output, it will become more efficient to process more messages while keeping the output at max utilisation.<br>
<p>
<p>
Networks have the same type of problem (the too large buffer situation is what's called bufferbloat), the answer there seems to be to put in a more complex queuing engine (SFQ seems to be the winner right now) that priorities packets from new or sparse connections ahead of heavy connections.<br>
<p>
I wonder if a similar approach could work for disk I/O? If this would allow for significantly larger queue sizes without the latency problems that usually come with large queues, it may give almost the same long-term effect of plugging, without the problems that plugging introduces.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/479132/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor479221"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 3, 2012 4:54 UTC (Fri)
                               by <b>raven667</b> (subscriber, #5198)
                              [<a href="/Articles/479221/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Networks have the same type of problem</font><br>
<p>
It would be interesting to see more sharing of notes between network and disk IO systems because some of the problems they solve are broadly similar. IO throughput and contention behaviors are a matter of science and I'm sure share a lot of math.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/479221/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor482595"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 20, 2012 23:35 UTC (Mon)
                               by <b>jmm82</b> (guest, #59425)
                              [<a href="/Articles/482595/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Networking does have this same concept build into tcp called Nagle's algorithm.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/482595/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor479289"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 3, 2012 13:05 UTC (Fri)
                               by <b>alankila</b> (guest, #47141)
                              [<a href="/Articles/479289/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Plugging or not, I'm pretty sure there are still queues involved just the same. Reading the other links in this article, it seems that plugging goes away as soon as the system determines that it has any work in its internal queues to do, therefore it's strictly a "first request" optimization. In any case, it doesn't seem to improve throughput (because it gets disabled) and worsens latency (because it delays first request service time), so it sounds useless to me in every case.<br>
<p>
Disk schedulers already use their own variant of fair queueing, afaik CFQ gives all processes their chance to do some disk transaction when it comes their turn, in this being fairly similar to SFQ which arranges outbound network traffic into number of pre-existing queues, submitting the head element of each queue in turn (if any), giving all flows a fairly equal chance to progress.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/479289/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor479468"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 4, 2012 21:04 UTC (Sat)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/479468/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <p>
I've always been a fierce opponent of queue plugging.  I'm not saying there's no case where it's good, but everywhere I see it, it's based on the misconception that capacity matters when you're not using it all.  I'm talking about the principle that a 10,000 liter tank is no better than a 5,000 liter tank for an application that never stores more than 2,000 liters.  
<p>
Sending small scattered I/Os to a disk drive is not a problem as long as the drive is keeping up with it, and if the drive isn't, then your queue is building up anyway, without a plug.
<p>
I've seen plugging used to overcome a defect in the thing serving the queue wherein it improperly speed-matches.  I think this is what's going on with the network "buffer bloat" issue.  I saw it more simply in a disk storage server that thought it was doing its client a favor by accepting I/Os as fast as the client could send them and sticking them in a buffer, then passing them one by one, FIFO, to the disk arms.  The server was essentially lying and saying it had capacity when it was really overloaded.
<p>
This was fixed with queue plugging in the client, but later fixed better just by making the client send ahead enough work to overwhelm the server's buffer and make it admit that it couldn't keep up.
<p>
dlang, in your defense of an application of queue plugging:
<blockquote>
the trade-off is that the output is doing far more work than it would need to do if the work was batched more
</blockquote>
you omit an important factor:  what is wrong with the output doing more work than it otherwise would?  In many cases, that doesn't make any difference.

      
          <div class="CommentReplyButton">
            <form action="/Articles/479468/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor479535"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 6, 2012 2:48 UTC (Mon)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/479535/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I agree that most of the time it really doesn't matter that the resource is working a little harder than it would need to be. But that is the only justification I can see for plugging.<br>
<p>
the resource being busier can make it take more power.<br>
<p>
the resource being busier could cause added latency for a new request.<br>
<p>
there are probably other ways that the resource being busier can cost, even if it's not completely maxed out.<br>
<p>
but overall I agree that these are probably not significant in almost all conditions.<br>
<p>
<p>
I think the biggest problem is that large queues have not been handled sanely in the past, which has made "large queue" == "high latency" in many people's minds<br>
<p>
what's needed is a large queue to gather possible work, but then smart management of that queue.<br>
<p>
In the case of disk I/O that smart management has to do with combining work that's in the queue, but not together, prioritizing reads over rights (except for writes with sync dependencies), elevator reordering, etc.<br>
<p>
If you have a raid array it can mean trying to schedule work so that different spindles can be working at the same time.<br>
<p>
if you have a SSD or raid array, it can mean trying to do things in larger blocks (stripe size and alignment, eraseblock size and alignment)<br>
<p>
In the case of network buffers, it has to do with prioritizing interactive, traffic management, and blocking packets ahead of bulk transfers, dropping packets that you aren't going to be able to get through before they are worthless (which is not just bulk transfers that will get there after a retry has already been sent, but also VoIP packets that have been deleyed too much)<br>
<p>
As processors get faster compared to the I/O, it becomes possible to spend more effort in smart queue management while still keeping up with the I/O channel.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/479535/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor478943"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 2, 2012 10:08 UTC (Thu)
                               by <b>jezuch</b> (subscriber, #52988)
                              [<a href="/Articles/478943/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I've just run a test and my SSD can read at full speed. I'm running 3.2.2 so I guess the fix is already included in at least one stable release?<br>
<p>
Also, it is interesting that it took so long to discover this problem. Does that mean that people don't really care about speed of sequential file access? :) [Well, I know that I do care more about random access performance, that's why I bought the SSD in the first place. And I also know that sequential read performance used to be a major selling point for manufacturers of drives with horrendous random access performance.]<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/478943/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor479001"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 2, 2012 14:13 UTC (Thu)
                               by <b>corbet</b> (editor, #1)
                              [<a href="/Articles/479001/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Did you test with large reads?  That is the failure case.  If you do smaller operations, the plug gets pulled between them.
      
          <div class="CommentReplyButton">
            <form action="/Articles/479001/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor478973"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 2, 2012 12:57 UTC (Thu)
                               by <b>petkan</b> (subscriber, #54713)
                              [<a href="/Articles/478973/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
One wonders what exactly the patch author(s) has been testing so he missed an order of magnitude slowdown.  It looks like the issue either shows up rarely or we've been neglecting block I/O performance for about an year.<br>
<p>
The fix is not present in 3.2.2 and i am not finding it in Greg's 3.2.3-pre patches.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/478973/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor479467"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 4, 2012 20:49 UTC (Sat)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/479467/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Actually, I wonder what the patch author intended to accomplish (and that his testing presumably demonstrated he did).  The article mentions larger less scattered I/Os, but in a situation where the queue tends to be empty, I can't see where that would accomplish anything.  When I look at this change, I just see a frontal assault on doing stuff in parallel with the I/O turnaround time.

      
          <div class="CommentReplyButton">
            <form action="/Articles/479467/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor479342"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">What happened to disk performance in 2.6.39</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 3, 2012 18:15 UTC (Fri)
                               by <b>lonely_bear</b> (subscriber, #2726)
                              [<a href="/Articles/479342/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I am running 3.2.2, and just happened to play an audio CD, it chokes frequently after a while. After switching to 2.6.38.4 (my stock Slackware kernel), it plays smoothly. Will try the fixed and see what happened.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/479342/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor480447"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Regressions galore?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 9, 2012 22:58 UTC (Thu)
                               by <b>blujay</b> (guest, #39961)
                              [<a href="/Articles/480447/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Is it just me or is Linux suffering more needless regressions than ever before?  I'm getting the impression that some devs are writing code that's too smart for its own good.  I honestly think that 10 years ago my Debian system running the then-current kernel had better interactive performance, especially while swapping, than 2.6 or 3.0 have today.  Yeah, I know a bunch of interactivity-related patches have been added during this time--but in the end, I remember using systems with less than half as much memory as I have now and swapping taking less time and apps blocking less.  I don't remember my cursor movement lagging back then--now it happens whenever swapping happens.  Is the kernel's desktop suitability on the decline?  :(<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/480447/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor480537"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Regressions galore?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 10, 2012 12:59 UTC (Fri)
                               by <b>jospoortvliet</b> (guest, #33164)
                              [<a href="/Articles/480537/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Kernel 3.2 is certainly noticeably better than 3.1 and 3.0 in the interactivity regard, esp in low memory/swap situations and on high IO. But you're right in that older linux versions had better behavior in many situations - worse in others, however. Like how often it happened that one high-cpu task would hog your system and make your mouse cursor or even music skip. That rarely happens these days, with the exception of cases with high swapping.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/480537/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor490809"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Regressions galore?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 5, 2012 15:55 UTC (Thu)
                               by <b>Andrew_Cady</b> (guest, #83993)
                              [<a href="/Articles/490809/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Maybe your memory usage has grown faster than the speed of your swap disk.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/490809/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2012, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
