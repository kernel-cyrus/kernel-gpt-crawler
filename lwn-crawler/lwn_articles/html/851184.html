        <!DOCTYPE html>
        <html lang="en">
        <head><title>The multi-generational LRU [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/851184/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/851383/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/851184/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>The multi-generational LRU</h1>
</div>
<div class="ArticleText">
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>April 2, 2021</br>
           </div>
One of the key tasks assigned to the memory-management subsystem is to
optimize the system's use of the available memory; that means pushing out
pages containing unused data so that they can be put to better use
elsewhere.  Predicting which pages will be accessed in the near future is a
tricky task, and the kernel has evolved a number of mechanisms designed to
improve its chances of guessing right.  But the kernel not only often gets
it wrong, it also can expend a lot of CPU time to make the incorrect
choice.  The <a
href="/ml/linux-kernel/20210313075747.3781593-1-yuzhao@google.com/">multi-generational
LRU patch set</a> posted by Yu Zhao is an attempt to improve that
situation.
<p>
In general, the kernel cannot know which pages will be accessed in the near
future, so it must rely on the next-best indicator: the set of pages that have been
used recently.  Chances are that pages that have been accessed in the
recent past will be useful again in the future, but there are exceptions.
Consider, for example, an application that is reading sequentially through
a file.  Each page of the file will be put into the page cache as it is
read, but the application will never need it again; in this case, recent
access is not a sign that the page will be used again soon.
<p>
The kernel tracks pages using a pair of least-recently-used (LRU) lists.
Pages that have been recently accessed are kept on the "active" list, with
just-accessed pages put at the head of the list.  Pages are taken off the
tail of the list if they have not been accessed recently and placed at the
head of the "inactive" list.  That list is a sort of purgatory; if some
process accesses a page on the inactive list, it will be promoted back to
the active list.  Some pages, like those from the sequentially read file
described above, start life on the inactive list, meaning they will be
reclaimed relatively quickly if there is no further need for them.
<p>

There are more details, of course.  It's worth noting that there are
actually two pairs of lists, one for anonymous pages and one for
file-backed pages.  If memory control groups are in use, there is a whole
set of LRU lists for each active group.
<p><blockquote class="ad">
<b><tt>$ sudo subscribe today</tt></b>
<p>
Subscribe today and elevate your LWN privileges. You’ll have
access to all of LWN’s high-quality articles as soon as they’re
published, and help support LWN in the process.  <a href="https://lwn.net/Promo/nst-sudo/claim">Act now</a> and you can start with a free trial subscription.
</blockquote>
<p>
Zhao's patch set identifies a number of problems with the current state of
affairs.  The active/inactive sorting is too coarse for accurate decision
making, and pages often end up on the wrong lists anyway.  The use of
independent lists in control groups makes it hard for the kernel to compare
the relative age of pages across groups.  The kernel has a
longstanding bias toward evicting file-backed pages for a number of
reasons, which can cause useful file-backed pages to be tossed while idle anonymous
pages remain in memory.  This problem has gotten worse in cloud-computing
environments, where clients have relatively little local storage and, thus,
relatively few file-backed pages in the first place.
Meanwhile, the scanning of anonymous pages is expensive,
partly because it uses a complex <a href="/Articles/77106/">reverse-mapping
mechanism</a> that does not perform well when a lot of scanning must be
done. 
<p>
<h4>Closing the generation gap</h4>
<p>
The multi-generational LRU patches try to address these problems with two
fundamental changes:
<p>
<ul class="spacylist">
<li> Add more LRU lists to cover a range of page ages between the current
     active and inactive lists; these lists are called "generations".
<li> Change the way page scanning is done to reduce its overhead.
</ul>
<p>
Newly activated pages are assigned to the youngest generation (though there
are some exceptions described below).  Over time, the memory-management
subsystem 
will scan over a process's pages to determine whether each has been used
since the last scan; any that have remained idle are moved to the next
older generation.  Pages of any generation that show activity are moved
back to the youngest generation.
<p>
The result of this work is a spectrum of page ages,
from those quite recently accessed to those that have not been used in some
time.  The number of generations can be configured into the kernel; that
number seems to be as small as four for phones to several times that for
cloud-based servers.
<p>
When the time comes to reclaim pages, only the oldest generation need be
considered.  The "oldest generation" can be different for anonymous and
file-backed pages; anonymous pages can be harder to reclaim in general
(they must always be written to swap) and the new code retains some of the
bias toward reclaiming file-backed pages more aggressively.  So file-backed
pages may not escape reclaim for as many generations as anonymous pages
do.  The current patch only allows reclaim of file-backed pages to get one
generation ahead of that for anonymous pages, though.
<p>
The multi-generational mechanism, it is claimed, is more accurate than the
current two-list approach; by the time a page makes it to the oldest
generation, its chances of being unneeded are rather higher than they are
for pages on the inactive list.  That, in turn, means that these pages can
be reclaimed more aggressively, making more memory available for tasks that
will actually make use of it.  This mechanism allows for ready comparison
of the ages of anonymous and file-backed pages, and, by tracking the
creation time of each generation, of the ages of pages in
different control groups; this information is lost in
current kernels.  That, in turn, makes it easier to identify and reclaim
idle anonymous pages.  
<p>
The other claimed advantage is in the change to how pages are scanned.
Pages are accessed via the page-table entries (PTEs) in every process that has
them mapped; the "recently accessed" bit lives in those page-table
entries.  Current kernels, though, scan through the pages themselves, and
must use reverse-mapping to find and check the associated PTEs; that is
expensive.  The multi-generational LRU code, instead, scans over PTEs directly,
an approach with better locality.  A hook in the scheduler helps to track
processes that have actually run since the last scan, so idle processes can
be skipped.
<p>
The multi-generational LRU also benefits from skipping many of the heuristics
that are used in current kernels to decide which pages should be
reclaimed.  There are still a few, though.  For example, when a page is
first established, its generation is picked with these rules:
<p>
<ul class="spacylist">
<li> Pages that are being faulted in are assigned to the youngest
     generation, as one would expect.
<li> The activation of pages that are unmapped (pages resident in memory
     but with no PTEs pointing to them; these can include pages chosen for
     reclaim but not actually reclaimed before being referenced again) are
     added to the second-youngest generation.  This is seemingly done to
     avoid making the youngest generation look too big, which might delay
     further page scanning until the next generation can be created.
<li> Pages that are being reclaimed, but which must persist while their contents
     are written to backing store, are added to the second-oldest
     generation.  That prevents another attempt to reclaim them while the
     writeback is underway.
<li> Pages that are being deactivated go into the oldest generation.  That
     is also the fate of pages that were brought in by the readahead
     mechanism; reading those pages is a speculative act on the kernel's
     part in the first place, with no guarantee that they will ever be
     useful.
</ul>
<p>
There are a few knobs exported to user space to control this mechanism,
including the ability to turn the multi-generational code off entirely; see <a
href="/ml/linux-kernel/20210313075747.3781593-15-yuzhao@google.com/">this
documentation patch</a> for more information.
<p>
<h4>Generational change</h4>
<p>
The end result of all this work, it is claimed, is that page reclaim is
much more efficient and better targeted
than before.  Systems like Android, when using this code, record fewer
low-memory kills (when an app process is killed due to memory pressure),
Chrome&nbsp;OS shows fewer out-of-memory kills, and server systems are
better able to use available memory.  It looks like an improvement all
around.
<p>
Given that, one might wonder why the multi-generational algorithm is kept
separate from the rest of the memory-management code and is made optional.
It is, in essence, an independent approach to page aging and reclaim that
exists alongside the current LRU lists.  The answer, presumably, is that
there are a lot of workloads out there, and some of them may not benefit
from the multi-generational approach.  There will need to be a lot more testing
done to learn where the multi-generational LRU falls down and what might need to
be done to keep that from happening.
<p>
The multi-generational LRU might eventually win over the memory-management
developers, most of whom have not yet commented on this patch set.  It does
seem likely, though, that it will need to demonstrate better performance
(or at least a lack of performance regressions) across the bulk of the
workloads out there, to the point that it could be considered as a
replacement for the current LRU rather than an addition to it.  The idea of
maintaining two separate LRU schemes is 
going to be a hard sell in the kernel community; it would be far better to
just switch over completely to the multi-generational LRU if it is truly better.
<p>
Answering that question is certain to be a long process.  Even relatively
small memory-management changes can take a while to merge; it is just too
easy to introduce performance penalties for some users.  This change is not
"relatively small", so the bar for inclusion will be high.  But if the
multi-generational LRU lives up to its claims, it may just be able to clear that
bar — eventually.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Page_replacement_algorithms">Memory management/Page replacement algorithms</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/851184/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor851568"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2021 11:27 UTC (Sat)
                               by <b>linusw</b> (subscriber, #40300)
                              [<a href="/Articles/851568/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This is exactly the kind of content I want to see in LWN. Excellent article.<br>
<p>
My first thought is that as engineers we are good at looking at one thing in isolation and optimize it, as the economists say &quot;ceteris paribus&quot; (all other things being equal).<br>
<p>
What I&#x27;m asking myself is how other parts of the memory hierarchy affect and play with the LRU mechanism.<br>
<p>
Especially the block layer. How does the previous code and this code perform depending on whether we use none, deadline, BFQ or kyber as block scheduler?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/851568/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor851569"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2021 11:39 UTC (Sat)
                               by <b>Sesse</b> (subscriber, #53779)
                              [<a href="/Articles/851569/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I would assume it doesn&#x27;t matter, since they work on entirely different timescales. I/O schedulers work on times from microseconds up to milliseconds (or perhaps seconds on rotating rust), evicting pages works on times of seconds to hours. So what one does is unlikely to impact the other one much.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/851569/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor851570"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 3, 2021 11:59 UTC (Sat)
                               by <b>matthias</b> (subscriber, #94967)
                              [<a href="/Articles/851570/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
In the case of memory pressure, the time scales might be much closer to each other. It is entirely possible, that a page is evicted almost immediately after usage. But I would think that the nature of the storage device would play a much bigger role than the I/O scheduler. But this is just a guess.<br>
<p>
At the end these are all heuristics and it is impossible to test all possible combinations. Optimizing one system on its own is hard enough. The more systems you bring in to that equation, the more combinations you will get. And the combinatoric explosion will prohibit to test all possible combinations. This is why it is important that such patches are tested on real life workloads and real life configurations. This way, at least the most important combinations of configuration of subsystems are covered.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/851570/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor851593"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2021 7:13 UTC (Sun)
                               by <b>ibukanov</b> (guest, #3942)
                              [<a href="/Articles/851593/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This essentially tries to use more CPU time to predict the future by doing more work at managing the pages. I guess with all those cores on modern CPU that can be afforded.<br>
<p>
What is not clear is that why the patch helps with OOM killer. Is it because it helps to identify the apps that are expected not to be used?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/851593/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor851594"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2021 7:50 UTC (Sun)
                               by <b>rsidd</b> (subscriber, #2582)
                              [<a href="/Articles/851594/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Anything that reclaims memory helps the OOM killer, right? Or rather, helps avoid resorting to the OOM killer. One doesn&#x27;t want to call the OOM killer unless it&#x27;s desperate. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/851594/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor851595"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Multi-generational approach is better optimised for CPU.</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 4, 2021 10:00 UTC (Sun)
                               by <b>xoddam</b> (guest, #2322)
                              [<a href="/Articles/851595/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The multi-generational version uses *less* CPU time, ie. &quot;demonstrates 51% less CPU usage from kswapd&quot; under one workload.  This is possible because the existing code has suboptimal algorithms which scan the global page array and must do costly reverse lookups for each page into the per-process page tables, touching tables that are not necessarily in cache for any other reason.<br>
<p>
The new code improves on this by doing new-generation scans on active processes directly, improving cache locality on the &quot;fast path&quot;, avoiding the reverse lookups altogether, making better decisions on what pages get evicted and when, and seems even to reduce the amount of work that must be done when an eviction is necessary.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/851595/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor851605"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 5, 2021 4:47 UTC (Mon)
                               by <b>yuzhao@google.com</b> (guest, #132005)
                              [<a href="/Articles/851605/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Hi,<br>
<p>
I&#x27;m one of the engineers working on this project. I want to clarify that multigenerational lru does NOT use more CPU. In fact, for all the workloads we could benchmark, it uses less, much less.<br>
<p>
But then what&#x27;s the catch? It retains more (lru) information for each page, in spare space in page-&gt;flags. It also stores extra information for each memcg, node, and process. Specifically, it has ~500 bytes per-memcg and per-node and ~50 bytes per-process memory overhead.<br>
<p>
Please feel free to send your questions, suggestions, and concerns to page-reclaim@google.com.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/851605/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor851680"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 5, 2021 19:33 UTC (Mon)
                               by <b>ms-tg</b> (subscriber, #89231)
                              [<a href="/Articles/851680/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thank you for this clarification of the trade-offs and invitation for the community to ask further questions!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/851680/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor851931"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 8, 2021 14:01 UTC (Thu)
                               by <b>smurf</b> (subscriber, #17840)
                              [<a href="/Articles/851931/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
These memory overheads seem rather minor, not to say insignificant, compared to the benefits.<br>
<p>
Did you identify any workload that fares worse under your algorithm? One may assume that Google has quite a few wildly different workloads to experiment with …<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/851931/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor852459"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 13, 2021 9:09 UTC (Tue)
                               by <b>yuzhao@google.com</b> (guest, #132005)
                              [<a href="/Articles/852459/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Sorry for the late reply.<br>
<p>
Your assumption is correct. But our &quot;wildly different workloads&quot; are only a fraction of all real-world workloads.  AFAIK, we don&#x27;t use Postgresql, and we do plan to reach out to the Postgresql community and see if they could help us with benchmarking.<br>
<p>
And we don&#x27;t use io_uring (yet). Jens Axboe, the io_uring maintainer helped us identify a regression in buffered I/O and verify the fix. Now there is an improvement compared with the mainline: <a href="https://lore.kernel.org/linux-mm/20210413065633.2782273-1-yuzhao@google.com/.">https://lore.kernel.org/linux-mm/20210413065633.2782273-1...</a><br>
<p>
By design, the multigenerational LRU shouldn&#x27;t make any workload worse -- why should it make worse decisions after it gathered more information? But that&#x27;s just the theory :)<br>
<p>
The bottomline is we&#x27;ll do our best to fix any regressions the community reports to us. Again, the email address is page-reclaim@google.com.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/852459/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor851608"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU and ELRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 5, 2021 7:15 UTC (Mon)
                               by <b>hsu</b> (guest, #151475)
                              [<a href="/Articles/851608/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I presented very similar algorithm with further improvements in my master&#x27;s thesis in 1995, and did some analysis and performance evaluation through simulation models on it.  I called the algorithm ELRU, for Extended Least Recently Used algorithm. The letter E also conveniently presents the data structure in abstract form. <br>
<p>
Please check my thesis for more stuff. Some quick comments:<br>
<p>
- I put the new pages to &quot;insert list&quot;, not the top list (youngest generation). If new pages are put on youngest generation list, with smaller memories would essentially reduce the algorithm LRU case anyway, when a large sequential access would happen.  Insert list would be dynamically defined, and I simulated different configurations (see ELRU Treshold).  Simulation graphics on page 60 show why this is important at least for my simulated workloads.<br>
<p>
- Further, for pages which are known to be of a specific type, they can be insert to lists representing different priorities. If the kernel makes a wrong prediction, it likely gets corrected by accesses bumping the pages to upper list. I think I did not do simulations for this though.<br>
<p>
- I moved the accessed pages to one list higher. Not straight to youngest generation. If the access pattern is very hierachical, which it often case with filesystems, you get better results with this. See simulation graphs. I think putting active pages back to youngest list would end up corresponding ELRU(n, 0), which has substantially lower performance.<br>
<p>
- See priorities, 3.3 in thesis, may be relevant in page cache. I did not simulate it during my work, further testing might be useful. It would be simple to implement, to allow high priority stuff to have better chance to stay in memory.<br>
<p>
- I think for simulations I used fixed list set, but it can be dynamic, new lists are created when needed. I do not remember if we did dynamic list allocation in real implementation/<br>
<p>
We also implemented the algorithm as part of the Shadows Database Project at Helsinki University of Technology (HUT), now part of Aalto Univerity in Helsinki. Shadow paging (similar concept to what is now called &quot;copy on write&quot;) creates strongly hierarchical workloads due to page tables and metadata accessed very frequently. Same might be true for other copy on write filesystems as well, such as ZFS, depending on the implementation. We considered implementing a filesystem using code base created during Shadows project but it did not materialize due to other stuff taking all the time. The code can be released under public source license, though it is database &amp; userland stuff. Shadows had some useful ideas which I do not have seen anywhere else, such as RAID model works with disks of different sizes, works well with flash without wear levelling as it naturally does large block sequential writes through garbage collection.<br>
<p>
I think the Master&#x27;s thesis was published in CS department publication, so it should count as prior art in case of IPR issues. I did not file patents at time, so it is possibly safe to use. <br>
<p>
I also did some literature research during the project so there are some references in the Master&#x27;s thesis as well, caching algorithms are pretty old field, already was 25 years ago. The oldest stuff might not be googleable, I spent a lot of time in dusty libraries back then. This can be further prior art source.<br>
<p>
The full Master&#x27;s thesis is at <br>
<p>
<a href="http://www.suonsivu.net/masters-thesis-Heikki-Suonsivu-1995.pdf">http://www.suonsivu.net/masters-thesis-Heikki-Suonsivu-19...</a><br>
<p>
BibTex and URN can be found at<br>
<p>
<a href="https://aaltodoc.aalto.fi/handle/123456789/83375">https://aaltodoc.aalto.fi/handle/123456789/83375</a><br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/851608/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor854451"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The multi-generational LRU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 26, 2021 14:40 UTC (Mon)
                               by <b>JohnDyson</b> (guest, #151896)
                              [<a href="/Articles/854451/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The mult-generational LRU seems very close to the scheme that I developed (along with David Greenman) back in the early 1990s.  My scheme was not very scalable, but allowed running X windows in about 4MB on FreeBSD (actually usefully at 8MB.)   The scalability was good enough into the 100&#x27;s of MB range, but beyond that size,  it would need some algorithmic help. It sometimes made a substantial difference, sometimes not much at all.  I forget what we called it, but it had both an active/inactive along with accumulating usage counts on a page basis.   The pages would cycle though the queues and increment (or decrement) usage counts as appropriate.  Pages could become fairly sticky or be made eligible for quick reuse.   I truly do not know if FreeBSD still uses the scheme.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/854451/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2021, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
