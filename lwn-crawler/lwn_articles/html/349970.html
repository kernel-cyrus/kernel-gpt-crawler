        <!DOCTYPE html>
        <html lang="en">
        <head><title>Ext3 and RAID: silent data killers? [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/349970/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/349005/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/349970/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Ext3 and RAID: silent data killers?</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ready to give LWN a try?</b>
<p>
With a subscription to LWN, you can stay current with what is happening in the Linux and free-software community and take advantage of subscriber-only site features.  We are pleased to offer you <b><a href="https://lwn.net/Promo/nst-trial/claim">a free trial subscription</a></b>, no credit card required, so that you can see for yourself.  Please, join us!
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>August 31, 2009</br>
           </div>
Technologies such as filesystem journaling (as used with ext3) or RAID are
generally adopted with the purpose of improving overall reliability.  Some
system administrators may thus be a little disconcerted by a recent
linux-kernel thread suggesting that, in some situations, those technologies
can actually increase the risk of data loss.  This article attempts to
straighten out the arguments and reach a conclusion about how worried
system administrators should be.
<p>
The conversation actually began last March, when Pavel Machek posted <a
href="/Articles/349977/">a proposed documentation patch</a> describing the
assumptions that he saw as underlying the design of Linux filesystems.
Things went quiet for a while, before springing back to life at the end of
August.  It
would appear that Pavel had run into some data-loss problems when using a
flash drive with a flaky connection to the computer; subsequent tests done
by deliberately removing active drives confirmed that it is easy to lose
data that way.  He <a
href="/Articles/349978/">hadn't expected that</a>:
<p>
<div class="BigQuote">
	Before I pulled that flash card, I assumed that doing so is safe,
	because flashcard is presented as block device and ext3 should cope
	with sudden disk disconnects.  And I was wrong wrong wrong. (Noone
	told me at the university. I guess I should want my money back).
</div>
<p>
In an attempt to prevent a surge in refund requests at universities
worldwide, Pavel tried to get some warnings put into the kernel
documentation.  He has run into a surprising amount of opposition, which he
(and some others) have taken as an attempt to sweep shortcomings in Linux
filesystems under the rug.  The real story, naturally, is a bit more
complex.
<p>
Journaling technology like that used in ext3 works by writing some data to
the filesystem twice.  Whenever the filesystem must make a metadata change,
it will first gather together all of the block-level changes required and
write them to a special area of the disk (the journal).  Once it is known
that the full description of the changes has made it to the media, a
"commit record" is written, indicating that the filesystem code is
committed to the change.  Once the commit record is also safely on the
media, the filesystem can start writing the metadata changes to the
filesystem itself.  Should the operation be interrupted (by a power
failure, say, or a system crash or abrupt removal of the media), the
filesystem can recover the plan for the changes from the journal and start
the process over again.  The end result is to make metadata changes
transactional; they either happen completely or not at all.  And that
should prevent corruption of the filesystem structure.
<p>
One thing worth noting here is that actual data is not normally written to
the journal, so a certain amount of recently-written data can be lost in
an abrupt failure.  It is possible to configure ext3 (and ext4) to write
data to the journal as well, but, since the performance cost is
significant, this
option is not heavily used.  So one should keep in mind that most
filesystem journaling is there to protect metadata, not the data itself.
Journaling does provide some data protection anyway - if the metadata is
lost, the associated data can no longer be found - but that's not its
primary reason for existing.
<p>
It is not the lack of journaling for data which has created grief for Pavel
and others, though.  The nature of flash-based storage makes another
"interesting" failure mode possible.  Filesystems work with fixed-size
blocks, normally 4096 bytes on Linux.  Storage devices also use fixed-size
blocks; on traditional rotating media, those blocks are traditionally 512
bytes in length, though <a href="http://lwn.net/Articles/322777/">larger
block sizes are on the horizon</a>.  The key point is that, on a normal
rotating disk, the filesystem can write a block without disturbing any
unrelated blocks on the drive.
<p>
Flash storage also uses fixed-size blocks, but they tend to be large -
typically tens to hundreds of kilobytes.  Flash blocks can only be
rewritten as a unit, so writing a 4096-byte "block" at the operating system
level will require a larger read-modify-write cycle within the flash drive.  It is
certainly possible for a careful programmer to write flash-drive firmware
which does this operation in a safe, transactional manner.  It is also possible
that the flash drive manufacturer was rather more interested in getting a
cheap device to market quickly than careful programming.  In the commodity
PC hardware market, that possibility becomes something much closer to a
certainty. 
<p>
What this all means is that, on a low-quality flash drive, an interrupted
write operation could result in the corruption of blocks unrelated to that
operation.  If the interrupted write was for metadata, a journaling
filesystem will redo the operation on the next mount, ensuring that the
metadata ends up in its intended destination.  But the filesystem cannot
know about any unrelated blocks which might have been trashed at the same
time.  So journaling will not protect against this kind of failure - even
if it causes the sort of metadata corruption that journaling is intended to
prevent. 
<p>
This is the "bug" in ext3 that Pavel wished to document.  He further
asserted that journaling filesystems can actually make things worse in this
situation.  Since a full fsck is not normally required on journaling
filesystems, even after an improper dismount, any "collateral" metadata
damage will go undetected.  At best, the user may remain unaware for some
time that random data has been lost.  At worst, corrupt metadata could
cause the code to corrupt other parts of the filesystem over the course of
subsequent operation.  The skipped fsck may have enabled the system to come
back up quickly, but it has done so at the risk of letting corruption
persist and, possibly, spread.
<p>
One could easily argue that the real problem here is the use of hidden
translation layers to make a flash device look like a normal drive.  David
Woodhouse <a href="/Articles/349985/">did exactly that</a>:
<p>
<div class="BigQuote">
	This just goes to show why having this "translation layer" done in
	firmware on the device itself is a _bad_ idea. We're much better
	off when we have full access to the underlying flash and the OS can
	actually see what's going on. That way, we can actually debug, fix
	and recover from such problems.
</div>
<p>
The manufacturers of flash drives have, thus far, proved impervious to this
line of reasoning, though.
<p>
There is a similar failure mode with RAID devices which was also
discussed.  Drives can be grouped into a RAID5 or RAID6 array, with the
result that the array as a whole can survive the total failure of any drive
within it.  As long as only one drive fails at a time, users of RAID arrays
can rest assured that the smoke coming out of their array is not taking
their data with it.
<p>
But what if more than one drive fails?  RAID works by combining blocks into
larger stripes and associating checksums with those stripes.  Updating a
block requires rewriting the stripe containing it and the associated
checksum block.  So, if writing a block can cause the array to lose the
entire stripe, we could see data loss much like that which can happen with
a flash drive.  As a normal rule, this kind of loss will not occur with a
RAID array.  But it <i>can</i> happen if (1)&nbsp;one drive has already
failed, causing the array to run in "degraded" mode, and (2)&nbsp;a second
failure occurs (Pavel pulls the power cord, say) while the write is
happening.
<p>
Pavel concluded from this scenario that RAID devices may actually be more
dangerous than storing data on a single disk; he started a whole separate
subthread (under the subject "<a href="/Articles/349987/">raid is dangerous
but that's secret</a>") to that effect.  This claim caused a fair amount of
concern on the list; many felt that it would push users to forgo
technologies like RAID in favor of single, non-redundant drive
configurations.  Users who do that will avoid the possibility of data loss
resulting from a specific, unlikely double failure, but at the cost of
rendering themselves entirely vulnerable to a much more likely single
failure.  The end result would be a lot more data lost.
<p>
The real lessons from this discussion are fairly straightforward:
<p>
<ul>
<li> Treat flash drives with care, do not expect them to be more reliable 
     than they are, and do not remove them from the system until all writes
     are complete.
<p>
<li> RAID arrays can increase data reliability, but an array which is not
     running with its full complement of working, populated drives has lost
     the redundancy which provides that reliability.  If the consequences
     of a second failure would be too severe, one should avoid writing to
     arrays running in degraded mode.
<p>
<li> As Ric Wheeler <a href="/Articles/349989/">pointed out</a>, the
     easiest way to lose data on a Linux system is to run the disks with
     their write cache enabled.  This is especially true on RAID5/6
     systems, where write barriers are still not properly supported.  There
     has been some talk of 
     disabling drive write caches and enabling barriers by default, but no
     patches have been posted yet.
<p>
<li> There is no substitute for good backups.  Your editor would add that
     any backups which have not been checked recently have a strong chance
     of not being good backups.
</ul>
<p>
How this information will be reflected in the kernel documentation remains
to be seen.  Some of it seems like the sort of system administration
information which is not normally considered appropriate for inclusion in
the documentation of the kernel itself.  But there is value in knowing what
assumptions one's filesystems are built on and what the possible failure
modes are.  A better understanding of how we can lose data can only help us
to keep that from actually happening.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Data_integrity">Data integrity</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Filesystems-ext3">Filesystems/ext3</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#RAID">RAID</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/349970/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor349997"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 31, 2009 21:32 UTC (Mon)
                               by <b>chrish</b> (guest, #351)
                              [<a href="/Articles/349997/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
One small nit. RAID6 protects from a double failure (that the whole point of it). So people who are worried about the impact of a double failure (which *is* bad) on their RAID5 array should run RAID6 instead.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/349997/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350051"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 6:05 UTC (Tue)
                               by <b>k8to</b> (guest, #15413)
                              [<a href="/Articles/350051/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
From what we know about device failure patterns, everyone should be worried about this.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350051/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350154"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">partially degraded raid 6 _IS_ vunerable to partial writes on power failure</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 17:33 UTC (Tue)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/350154/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Neil brown posted a message explaining how raid 6 is still vunerable to unclean shutdown problems <br>
<p>
Date: Wed, 26 Aug 2009 09:28:50 +1000<br>
From: Neil Brown &lt;neilb@suse.de&gt;<br>
Subject: Re: [patch] ext2/3: document conditions when reliable operation is     possible<br>
<p>
On Monday August 24, greg.freemyer@gmail.com wrote:<br>
<font class="QuotedText">&gt; &gt; +Don't damage the old data on a failed write (ATOMIC-WRITES)</font><br>
<font class="QuotedText">&gt; &gt; +~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</font><br>
<font class="QuotedText">&gt; &gt; +</font><br>
<font class="QuotedText">&gt; &gt; +Either whole sector is correctly written or nothing is written during</font><br>
<font class="QuotedText">&gt; &gt; +powerfail.</font><br>
<font class="QuotedText">&gt; &gt; +</font><br>
<font class="QuotedText">&gt; &gt; +       Because RAM tends to fail faster than rest of system during</font><br>
<font class="QuotedText">&gt; &gt; +       powerfail, special hw killing DMA transfers may be necessary;</font><br>
<font class="QuotedText">&gt; &gt; +       otherwise, disks may write garbage during powerfail.</font><br>
<font class="QuotedText">&gt; &gt; +       This may be quite common on generic PC machines.</font><br>
<font class="QuotedText">&gt; &gt; +</font><br>
<font class="QuotedText">&gt; &gt; +       Note that atomic write is very hard to guarantee for RAID-4/5/6,</font><br>
<font class="QuotedText">&gt; &gt; +       because it needs to write both changed data, and parity, to</font><br>
<font class="QuotedText">&gt; &gt; +       different disks. (But it will only really show up in degraded mode).</font><br>
<font class="QuotedText">&gt; &gt; +       UPS for RAID array should help.</font><br>
<font class="QuotedText">&gt; </font><br>
<font class="QuotedText">&gt; Can someone clarify if this is true in raid-6 with just a single disk</font><br>
<font class="QuotedText">&gt; failure?  I don't see why it would be.</font><br>
<p>
It does affect raid6 with a single drive missing.<br>
<p>
After an unclean shutdown you cannot trust any Parity block as it<br>
is possible that some of the blocks in the stripe have been updated,<br>
but others have not.  So you must assume that all parity blocks are<br>
wrong and update them.  If you have a missing disk you cannot do that.<br>
<p>
To take a more concrete example, imagine a 5 device RAID6 with<br>
3 data blocks D0 D1 D2 as well a P and Q on some stripe.<br>
Suppose that we crashed while updating D0, which would have involved<br>
writing out D0, P and Q.<br>
On restart, suppose D2 is missing. It is possible that 0, 1, 2, or 3<br>
of D0, P and Q have been updated and the others not.<br>
We can try to recompute D2 from D0 D1 and P, from<br>
D0 P and Q or from D1, P and Q.<br>
<p>
We could conceivably try each of those and if they all produce the<br>
same result we might be confident of it.<br>
If two produced the same result and the other was different we could<br>
use a voting process to choose the 'best'.  And in this particular<br>
case I think that would work.  If 0 or 3 had been updates, all would<br>
be the same.  If only 1 was updated, then the combinations that<br>
exclude it will match.  If 2 were updated, then the combinations that<br>
exclude the non-updated block will match.<br>
<p>
But if both D0 and D1 were being updated I think there would be too<br>
many combinations and it would be very possibly that all three<br>
computed values for D2 would be different.<br>
<p>
So yes: a singly degraded RAID6 cannot promise no data corruption<br>
after an unclean shutdown.  That is why "mdadm" will not assemble such<br>
an array unless you use "--force" to acknowledge that there has been a<br>
problem. <br>
<p>
NeilBrown<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350154/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350931"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">partially degraded raid 6 _IS_ vunerable to partial writes on power failure</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 4, 2009 23:32 UTC (Fri)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/350931/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>
But you don't have to build a RAID6 array that way.  Ones I've looked at use a journaling scheme to provide atomic parity update.  No matter where you get interrupted in the middle of updating a stripe, you can always get back the pre-update parity-consistent stripe (minus whatever 1 or 2 components that might have died at the same time).
<p>
I suspect Linux 'md' doesn't have the resources to do this feasibly, but a SCSI RAID6 unit probably would.  I don't expect there's much market for the additional component loss protection of RAID6 without getting the interrupted write protection too.

      
          <div class="CommentReplyButton">
            <form action="/Articles/350931/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor349995"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 31, 2009 21:33 UTC (Mon)
                               by <b>yohahn</b> (guest, #4107)
                              [<a href="/Articles/349995/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Given the second lesson provided above, is there a standard method for remounting a volume, read-only, if the underlying raid becomes degraded?<br>
<p>
I can imagine much script writing, but if it is a general need, shouldn't there be a general method?<br>
<p>
(an even more fun question would be, "Will applications fail in a reasonable fashion if they suddenly have their backing store mounted read-only".)<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/349995/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350080"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 11:54 UTC (Tue)
                               by <b>Klavs</b> (guest, #10563)
                              [<a href="/Articles/350080/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
mount -o remount,ro /<br>
<p>
Will remount the device mounted on / - read-only.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350080/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350645"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 3, 2009 15:37 UTC (Thu)
                               by <b>yohahn</b> (guest, #4107)
                              [<a href="/Articles/350645/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Right, but what standard method to trigger this when a raid goes degraded. (and how will applications respond to their disks becoming read-only suddenly)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350645/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350722"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 3, 2009 21:42 UTC (Thu)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350722/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
When disks are remounted read-only, there is no message to the end user (at least on Ubuntu) - as a result, one PC where this happened had a read-only root filesystem for weeks until I noticed this from the logs.<br>
<p>
Sending notifications of serious system events like this would be very helpful, with a bundle of standard event filters that can easily generate an email or other alert.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350722/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor352197"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 11, 2009 17:59 UTC (Fri)
                               by <b>jengelh</b> (subscriber, #33263)
                              [<a href="/Articles/352197/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
You can only remount ro when there are no files open in write mode. And there usually are on /.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/352197/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350797"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 4, 2009 8:22 UTC (Fri)
                               by <b>njs</b> (guest, #40338)
                              [<a href="/Articles/350797/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
mdadm has a hook to let you run an arbitrary script when a RAID device changes state (degrades, etc.); I don't have a remount -o ro script handy myself, though.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350797/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor350932"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 4, 2009 23:39 UTC (Fri)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/350932/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>
 (and how will applications respond to their disks becoming read-only suddenly)
</blockquote>
<p>
I think this would be only marginally better than shutting the whole system down.  In many ways it would be worse, since users have ways to deal with a missing system but not a system acting strangely.


      
          <div class="CommentReplyButton">
            <form action="/Articles/350932/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor349998"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 31, 2009 21:49 UTC (Mon)
                               by <b>me@jasonclinton.com</b> (subscriber, #52701)
                              [<a href="/Articles/349998/">Link</a>] (25 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I'm a little surprised at lack of any discussion of RAID battery backups. <br>
All RAID enclosures and RAID host-adapters worth their salt have a BBU <br>
(battery backup unit) option for exactly this purpose. Why the small block <br>
write buffer on an SSD cannot be backed up by a suitably small zinc-air <br>
battery is a mystery to me.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/349998/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350002"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 31, 2009 22:31 UTC (Mon)
                               by <b>proski</b> (subscriber, #104)
                              [<a href="/Articles/350002/">Link</a>] (12 responses)
      </p>
      
      </div>
      </summary>
      I imagine that at least the more expensive SSDs have something like that, or maybe they can finish the write if the external power is disconnected.  But when it comes to flash cards, like those used in digital cameras, the cost difference would be prohibitive.
      
          <div class="CommentReplyButton">
            <form action="/Articles/350002/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350004"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 31, 2009 22:34 UTC (Mon)
                               by <b>me@jasonclinton.com</b> (subscriber, #52701)
                              [<a href="/Articles/350004/">Link</a>] (11 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
SD, MemoryStick, and CF cards do not have firmware.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350004/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350007"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 31, 2009 22:45 UTC (Mon)
                               by <b>pizza</b> (subscriber, #46)
                              [<a href="/Articles/350007/">Link</a>] (10 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
of course they have firmware; how else would (for example) a CF card translate the ATA commands into individual read/write ops on the appropriate flash chips and deal with write levelling?<br>
<p>
Granted, that "firmware" may be in the form fo mask ROM, but I know of at least one case where a CF card had a firmware update released for it.<br>
<p>
SD and MS are a lot simpler, but even they require something to translate the SD/MS wire protocols into flash read/write ops.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350007/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350016"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 31, 2009 22:52 UTC (Mon)
                               by <b>me@jasonclinton.com</b> (subscriber, #52701)
                              [<a href="/Articles/350016/">Link</a>] (9 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Sorry, you're right about CF. I haven't seen one of those in ages. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350016/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350020"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 31, 2009 23:27 UTC (Mon)
                               by <b>drag</b> (guest, #31333)
                              [<a href="/Articles/350020/">Link</a>] (8 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
AND SD and Memorystick and any other remotely consumer-related device.<br>
<p>
They all are 'smart devices'.<br>
<p>
If it was not for the firmware MTD-to-Block translation then you could not use them in Windows and they could not be formatted Fat32. <br>
<p>
When I have dealt with Flash in the past, the raw flash type, the flash just appears as a memory region. Like I have this old i386 board I am dealing with that has it's flash just starting at 0x80000 and it goes on for about eight megs or so. <br>
<p>
That's it. That's all the hardware does for you. You have to know then how to communicate with it and it's underlining structure and know the proper way to write to it and everything. All that has to be done in software.<br>
<p>
I suppose most of that is rather old fashioned.. the flash was soldiered directly into the traces on the board.<br>
<p>
I can imagine it would be quite difficult and would require new hardware protocols to allow a OS to manage flash directly properly over something like SATA or USB.<br>
<p>
But fundamentally MTD are quite a bit different from Block devices. It's a different class of I/O completely. Just like how a character device like a mouse or a keyboard can't be written to with Fat32. You can fake MTD by running a Block-to-MTD layer on SD flash or a file or anything else and some poeple think that helps with wear leveling, but I think that is foolish and may actually end up being self-defeating as you have no idea how the algorithms in the firmware work. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350020/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350028"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 31, 2009 23:59 UTC (Mon)
                               by <b>BenHutchings</b> (subscriber, #37955)
                              [<a href="/Articles/350028/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>AND SD and Memorystick and any other remotely consumer-related device.

They all are 'smart devices'.</blockquote>

<p>Not all.  SmartMedia, xD and Memory Stick variants provide a raw flash interface - that's a major reason why they have had to be revised repeatedly to allow for higher-capacity chips. They rely on an external controller to do write-buffering, and do not support any wear-leveling layer.</p>

<blockquote>When I have dealt with Flash in the past, the raw flash type, the flash just appears as a memory region</blockquote>

<p>It is possible for a flash controller to map NOR flash into memory since it is random-access for reading. However, large flash chips are all NAND flash which only supports block reads.</p>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350028/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor350029"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 0:00 UTC (Tue)
                               by <b>me@jasonclinton.com</b> (subscriber, #52701)
                              [<a href="/Articles/350029/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      Isn't the ATA/MMC<->MTD translation done in the consumer "reader" that you 
stick these devices in? CF is electrically compatible with ATA. That's not 
even remotely the case with the electrical interfaces on either SD or MS.

      
          <div class="CommentReplyButton">
            <form action="/Articles/350029/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350031"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 0:52 UTC (Tue)
                               by <b>drag</b> (guest, #31333)
                              [<a href="/Articles/350031/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Maybe. I don't think so. At least not for SD.<br>
<p>
Remember that SD stands for 'Secure Digital' and is DRM'd. So there has to be some smarts in it to do that.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350031/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350063"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 6:22 UTC (Tue)
                               by <b>Los__D</b> (guest, #15263)
                              [<a href="/Articles/350063/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Almost no SD support the DRM features, according to Wikipedia.<br>
<p>
(Still doesn't change the point, though. SDs are probably designed with internal firmware)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350063/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350078"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 9:36 UTC (Tue)
                               by <b>alonz</b> (subscriber, #815)
                              [<a href="/Articles/350078/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      That's not what Wikipedia says&mdash;they say few <em>devices</em> support CPRM.  Which is more-or-less true&mdash;almost no devices in the western market use CPRM, while in Japan <em>every single device</em> does (it is required as part of i-Mode, which is mandated by DoCoMo).
<p>
As for firmware, the SD card interface (available for free at <a href="http://www.sdcard.org/developers/tech/sdcard/pls/">www.sdcard.org</a> defines accesses in terms of 512-byte &ldquo;logical&rdquo; sectors, practically mandating the card to implement a flash translation layer.
      
          <div class="CommentReplyButton">
            <form action="/Articles/350078/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350085"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 12:49 UTC (Tue)
                               by <b>Los__D</b> (guest, #15263)
                              [<a href="/Articles/350085/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Doh, of course.<br>
<p>
I read "devices" as the SD cards themselves.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350085/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor350129"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 16:57 UTC (Tue)
                               by <b>Baylink</b> (guest, #755)
                              [<a href="/Articles/350129/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Generally, I think that's true, yes; the only small-flash technology that actually *looks like an ATA drive at the connector* is CF; the others require a smart reader to do the interfacing -- which may itself *not* look like ATA at the back; there are clearly other better ways to do this stuff.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350129/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor350141"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 17:37 UTC (Tue)
                               by <b>iabervon</b> (subscriber, #722)
                              [<a href="/Articles/350141/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
SD is MMC with a few extra features nobody uses. The readers do USB-storage&lt;-&gt;SD, but SD is still 512-byte chunks (it's a card-reported value, and the host can actually try changing it, but 512 is the only value that is ever supported).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350141/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor350042"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 3:16 UTC (Tue)
                               by <b>zlynx</b> (guest, #2285)
                              [<a href="/Articles/350042/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
All the RAID discussion on the list was about the Linux MD/DM software RAID. It isn't as reliable as other options.<br>
<p>
From what I gather, MD does not use write-intent logging by default, and when it is enabled it is very inefficient. Probably because it doesn't spread the write intent logs around the disks. Also, MD does not detect a unclean shutdown, so it does not start a RAID scrub and go into read+verify mode. And all that is a problem even when the array isn't degraded.<br>
<p>
And of course it doesn't have a battery backup. :)<br>
<p>
All that said, Linux MD hasn't given me any problems, and I prefer it over most cheap hardware RAID.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350042/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350048"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 5:14 UTC (Tue)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/350048/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I don't think "is very inefficient" is correct.  There is a real performance impact, but the size of that impact is very dependent on workload and configuration.  It is easy to add or remove the write intent logging while the array is active, so there is minimal cost in experimenting to see what impact it really has in an given usage.<br>
<p>
And MD most certainly does detect an unclean shutdown and will validate all parity block on restart.<br>
<p>
But you are right that it doesn't have battery backup.  If fast NVRAM were available on commodity server hardware, I suspect we would get support for it in md/raid5 in fairly short order.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350048/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350102"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 15:30 UTC (Tue)
                               by <b>zlynx</b> (guest, #2285)
                              [<a href="/Articles/350102/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
As far as I could tell, MD will not verify parity during regular reads while the array is unclean.<br>
<p>
It may start a background verify, although it seemed to me that was dependent on what the distro's startup scripts did...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350102/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor350249"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 2, 2009 0:09 UTC (Wed)
                               by <b>Richard_J_Neill</b> (subscriber, #23093)
                              [<a href="/Articles/350249/">Link</a>] (8 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; I'm a little surprised at lack of any discussion of RAID battery backups.</font><br>
<font class="QuotedText">&gt; All RAID enclosures and RAID host-adapters worth their salt have a BBU</font><br>
<font class="QuotedText">&gt;(battery backup unit) option for exactly this purpose.</font><br>
<p>
Yes...but it's only good for a few hours. So if your power outage lasts more than that, then the BBWC (battery backed write cache) is still toast.<br>
<p>
On a related note, I've just bought a pair of HP servers (DL380s) and an IBM X3550. It's very annoying that there is no way to buy either of these without hardware raid, nor can the raid card be turned off in the BIOS. For proper reliability, I only really trust software (md) raid in Raid 1 mode (with write caching off). [Aside: this kills the performance for database workloads (fdatasync), though the Intel X25-E SSDs outperform 10k SAS drives by a factor of about 12.]<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350249/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350250"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 2, 2009 0:13 UTC (Wed)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/350250/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
actually, in many cases the batteries for the raid cards can last for several weeks.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350250/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350813"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 4, 2009 10:32 UTC (Fri)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/350813/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes indeed. My Areca RAID card claims a month's battery life. Thankfully I've never had cause to check this, but I guess residents of Auckland in the 1998 power-generation fiasco would have liked it. :)<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350813/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350933"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 5, 2009 0:01 UTC (Sat)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/350933/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <p>The battery in RAID adapter card only barely addresses the issue, I don't care how long it lives.  

<p>But the comment also addressed "RAID enclosures," which I take to mean storage servers that use RAID technology.  Those, if they are at all serious, have batteries that power the disk drives as well, and only for a few seconds -- long enough to finish the write.  It's not about backup power, it's about a system in which data is always consistent and persistent, even if someone pulled a power cord at some point.

      
          <div class="CommentReplyButton">
            <form action="/Articles/350933/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350938"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 5, 2009 0:31 UTC (Sat)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/350938/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
actually, there are a LOT of enclosures that don't provide battery backup for the drives at all, just for the cache.<br>
<p>
it's possible that they have heavy duty power supplies that keep power up for a fraction of a second after the power fail signal goes out to the drives, but they defiantly do not keep the drives spinning long enough to flush their caches<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350938/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor351316"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 7, 2009 22:47 UTC (Mon)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/351316/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Ah, I see, the point is that even if you turn off the power *and pull the <br>
disk* halfway through a write, the disk state is still consistent? Yeah, <br>
battery-backed cache alone obviously can't ensure that.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/351316/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor351318"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 7, 2009 23:18 UTC (Mon)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/351318/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <blockquote>
Ah, I see, the point is that even if you turn off the power *and pull the 
disk* halfway through a write, the disk state is still consistent? Yeah, 
battery-backed cache alone obviously can't ensure that.
</blockquote>

<p>
No one said anything about pulling a disk.  I did mention pulling a power cord.  I meant the power cord that supplies the RAID enclosure (storage server).
<p>
A RAID enclosure with a battery inside that powers only the memory can keep the data consistent in the face of a power cord pull, but fails the persistence test, because the battery eventually dies.  I think when people think persistent, they think indefinite.  High end storage servers do in fact let you pull the power cord and not plug it in again for years and still be able to read back all the data that was completely written to the server before the pull.  Some do it by powering disk drives (not necessarily the ones that normally hold the data) for a few seconds on battery. 
<p>
Also, I think some people expect of persistence that you can take the machine, once powered down, apart and put it back together and the data will still be there.  Battery backed memory probably fails that test.

      
          <div class="CommentReplyButton">
            <form action="/Articles/351318/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor351357"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 8, 2009 4:56 UTC (Tue)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/351357/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I don't know what 'high end storage servers' you are talking about, the even the multi-million dollar arrays from EMC and IBM do not have the characteristics that you are claiming.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/351357/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor351360"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 8, 2009 6:25 UTC (Tue)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/351360/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>
I don't know what 'high end storage servers' you are talking about, the even the multi-million dollar arrays from EMC and IBM do not have the characteristics that you are claiming.
</blockquote>
<p>
Now that you mention it, I do remember that earlier IBM Sharks had nonvolatile storage based on a battery.  Current ones don't, though.  The battery's only job is to allow the machine to dump critical memory contents to disk drives after a loss of external power.  I think that's the trend, but I haven't kept up on what EMC, Hitachi, etc. are doing.  IBM's other high end storage server, the former XIV Nextra, is the same.

      
          <div class="CommentReplyButton">
            <form action="/Articles/351360/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor350019"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Are these issues really unique to Ext3?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 31, 2009 23:22 UTC (Mon)
                               by <b>pr1268</b> (subscriber, #24648)
                              [<a href="/Articles/350019/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <p>I can't imagine that these issues (especially the flash-based disk problems Pavel experienced) are unique to Ext3.  Microsoft's NTFS and Mac OS X's HFS+ are both journaling file systems that perform transactional commits, don't they?</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/350019/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350282"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Are these issues really unique to Ext3?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 2, 2009 7:01 UTC (Wed)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350282/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
See <a href="http://www.cs.wisc.edu/adsl/Publications/iron-sosp05.pdf">http://www.cs.wisc.edu/adsl/Publications/iron-sosp05.pdf</a> for a good paper on how hard disks fail, including partial failures, and the failure/recovery behaviour of ext3, reiserfs, JFS and NTFS.  Also talks about ixt3, an ext3 variant by the authors that's intended to have a stronger and more consistent failure/recovery model.  This includes journal and data block checksums.  <br>
<p>
There was a 'journal checksum patch' for ext3 by the authors, I think, but I can't track it down.<br>
<p>
Not sure about NTFS, but HFS+ does seem to have journal checksums - see <a href="http://developer.apple.com/mac/library/technotes/tn/tn1150.html#Checksum">http://developer.apple.com/mac/library/technotes/tn/tn115...</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350282/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350030"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 0:41 UTC (Tue)
                               by <b>ncm</b> (guest, #165)
                              [<a href="/Articles/350030/">Link</a>] (13 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Every time I see discussion of a journaling file system, somebody implies they expect it to protect against corruption on power interruptions.  I recall somebody who reported repeatedly turning his system on and off just to revel in watching it recover (without fsck) each time.  It's not clear where people got the idea, but it's dead clear that people promoting journaling file systems have, again and again, utterly failed to make it clear that a journaling file system does not protect against corruption on power interruptions.  (Crashes, usually.  Power drops, often, but no promises.)<br>
<p>
Pavel's complaint is a consequence of this failure.  <br>
<p>
I note in passing that there is no need, in general, for a file system that journals data as well as metadata to write the data twice.  That's just a feature of common, naive designs.  Journaling data along with metadata, howsoever sophisticated, doesn't protect against power drops either.  Nothing does.  Use battery backup if you care.  A few seconds is enough if you can shut down the host fast enough.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350030/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350064"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 6:40 UTC (Tue)
                               by <b>IkeTo</b> (subscriber, #2122)
                              [<a href="/Articles/350064/">Link</a>] (11 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
My understanding is that with a "good" system (e.g., hard disk write in disk blocks, RAM power not going off when hard disk has enough power to write the data in it into the disk, etc), a journaling file system does offer protection against corruption of filesystem (and, depend on filesystem actually being used, corruption of the data already written).  I believe you think I'm wrong, and I'd like to understand your reasoning.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350064/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350065"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 7:58 UTC (Tue)
                               by <b>ncm</b> (guest, #165)
                              [<a href="/Articles/350065/">Link</a>] (10 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It seems to be extremely common to believe in disks that use the spinning-down platter to drive the motor as a generator to power a last few sectors' writes.  When I speak to engineers at drive manufacturers, they say it's a myth.  (It might have been done decades ago.)  They say they happily stop writing halfway in the middle of a sector, and respond to power drop only by parking the head.<br>
<p>
Some drives only report blocks written to the platter after they really have been, but that's bad for benchmarks, so most drives fake it, particularly when they detect benchmark-like behavior.  Everyone serious about reliability uses battery backup, so whoever's left isn't serious, and (they reason) deserve what they get, because they're not paying.  Building in better reliability manifestly doesn't improve sales or margins.<br>
<p>
If you pay twice as much for a drive, you might get better behavior.  Or you might only pay more.<br>
<p>
If you provide a few seconds' battery backup for the drive but not the host, then the blocks in the buffer that the drive said were on the disk get a chance to actually  get there.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350065/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350138"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 17:09 UTC (Tue)
                               by <b>Baylink</b> (guest, #755)
                              [<a href="/Articles/350138/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; most drives fake it, particularly when they detect benchmark-like behavior.</font><br>
<p>
{{citation-needed}}<br>
<p>
<font class="QuotedText">&gt; If you pay twice as much for a drive, you might get better behavior. Or you might only pay more.</font><br>
<p>
I generally find the difference per GB to be 6:1 going from even enterprise SATA drives to Enterprise SCSI (U-160 or faster, 10K or faster).  My experience is that I get what I pay for, YMMV.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350138/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor350144"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 17:20 UTC (Tue)
                               by <b>markusle</b> (guest, #55459)
                              [<a href="/Articles/350144/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Some drives only report blocks written to the platter after they really</font><br>
<font class="QuotedText">&gt; have been, but that's bad for benchmarks, so most drives fake it,</font><br>
<font class="QuotedText">&gt; particularly when they detect benchmark-like behavior.</font><br>
<p>
I'd be very interested in some additional references or a list of drives <br>
that do or don't do this.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350144/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350152"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 17:44 UTC (Tue)
                               by <b>ncm</b> (guest, #165)
                              [<a href="/Articles/350152/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Start by looking at very, very expensive, slow drives.  Then forget about them.  Instead, rely on redundancy and battery backup.  There are lots of companies that aggregate cheap disks, batteries, cache, and power in a nice box, and each charges what they can get for it.  Some work well, others less so.  Disk arrays work like insurance: spread the risk, and cover for failures.  Where they inadvertently concentrate risk, you get it all.
<p>
The storage industry is as mature as any part of the computer business.  It is arranged such as to allow you to spend as much money as you like, and can happily absorb as much as you throw at it.  If you know what you're doing, you can get full value for your money.  If you don't know what you're doing, you can spend just as much and get little more value than 
the raw disks in the box.  There is no substitute for competence.
      
          <div class="CommentReplyButton">
            <form action="/Articles/350152/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350237"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 23:28 UTC (Tue)
                               by <b>dododge</b> (guest, #2870)
                              [<a href="/Articles/350237/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; They say they happily stop writing halfway in the middle of a sector, and respond to power drop only by parking the head.</font><br>
<p>
The old DeskStar drive manual (circa 2002) explicitly stated that power loss in the middle of a write could lead to partially-written sectors, which would trigger a hard error if you tried to read them later on.  According to an LKML discussion back then, the sectors would stay in this condition indefinitely and would not be remapped; so the drive would continue to throw hard errors until you manually ran a repair tool to find and fix them.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350237/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor350934"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 5, 2009 0:10 UTC (Sat)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/350934/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>
If you provide a few seconds' battery backup for the drive but not the host, then the blocks in the buffer that the drive said were on the disk get a chance to actually get there.
</blockquote>
<p>
But then you also get the garbage that the host writes in its death throes (e.g. update of a random sector) while the drive is still up.
<p>
To really solve the problem, you need much more sophisticated shutdown sequencing.

      
          <div class="CommentReplyButton">
            <form action="/Articles/350934/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor351521"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 8, 2009 20:54 UTC (Tue)
                               by <b>anton</b> (subscriber, #25547)
                              [<a href="/Articles/351521/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <blockquote> [Engineers at drive manufacturers] say they happily stop
writing halfway in the middle of a sector, and respond to power drop
only by parking the head.
</blockquote>

The results from <a
href="http://www.complang.tuwien.ac.at/anton/hdtest/">my experiments
on cutting power on disk drives</a> are consistent with the theory
that the drives I tested complete the sector they write when the power
goes away.  However, I have seen drives that corrupt sectors on
unusual power conditions; the manufacturers of these drives (IBM,
Maxtor) and their successors (Hitachi) went to my don't-buy list and
are still there.

<blockquote>Some drives only report blocks written to the platter
after they really have been, but that's bad for benchmarks, so most
drives fake it, particularly when they detect benchmark-like
behavior.</blockquote>

Write-back caching (reporting completion before the data hits the
platter) is normally enabled in PATA and also SATA drives (running
benchmarks or not), because without tagged commands (mostly absent in
PATA, and not universally supported for SATA) performance is very bad
otherwise.  You can disable that with <code>hdparm -W0</code>.  Or you
can ask for barriers (e.g., as an ext3 mount option), which should
give the same consistency guarantees at lower cost if the file system
is implemented properly; however, my trust in the proper
implementation in Linux is severely undermined by the statements that
some prominent kernel developers have made in recent months on file
systems.

<blockquote> Everyone serious about reliability uses battery
backup</blockquote>

Do you mean a UPS?  So how does that help when the UPS fails?  Yes, we
have had that (while power was alive), and we concluded that our power
grid is just as reliable as a UPS.  One could protect against a
failing UPS with dual (redundant) power supplies and dual UPSs, but
that would probably double the cost of our servers.  A better option
would be to have an OS that sets up the hardware for good reliability
(i.e., disable write caching if necessary) and works hard in the OS to
ensure data and metadata consistency.  Unfortunately, it seems that
that OS is not Linux.

      
          <div class="CommentReplyButton">
            <form action="/Articles/351521/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor352047"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 10, 2009 20:58 UTC (Thu)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/352047/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Great to see your testing tool, I will try this out on a few spare hard drives to see what happens.<br>
<p>
UPSs are useful at least to regulate the voltage and cover against momentary power cuts, which are very frequent where I live, and far more frequent than UPS failures in my experience.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/352047/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor352064"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 10, 2009 21:34 UTC (Thu)
                               by <b>anton</b> (subscriber, #25547)
                              [<a href="/Articles/352064/">Link</a>] 
      </p>
      
      </div>
      </summary>
      It depends on where you live.  Here power outages are quite
infrequent, but mostly take so long that the UPS will run out of
power.  So then the UPS only gives the opportunity for a clean
shutdown (and that opportunity was never realized by our sysadmin when
we had UPSs), and that is unnecessary if you have all of the
following: decent drives that complete the last sector on power
failure; a good file system; and a setup that gives the file system
what it needs to stay consistent (e.g., barriers or hdparm -W0).  And
of course we have backups around if the worst comes to worst.  And
while we don't have the ultimate trust in ext3 and the hard drives we
use, we have not yet needed the backups for that.

      
          <div class="CommentReplyButton">
            <form action="/Articles/352064/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor351871"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 10, 2009 9:00 UTC (Thu)
                               by <b>hensema</b> (guest, #980)
                              [<a href="/Articles/351871/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; They say they happily stop writing halfway in the middle of a sector, and respond to power drop only by parking the head.</font><br>
<p>
Which is no problem. The CRC for the sector will be incorrect, which will be reported to the host adapter. The host adapter will then reconstruct the data and write back the correct sector.<br>
<p>
Of course you do need RAID for this.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/351871/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor352045"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 10, 2009 20:52 UTC (Thu)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/352045/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
And of course RAID has its own issues with RAID 6 really being required with today's large disks to protect against the separate-failure-during-rebuild case.<br>
<p>
Without RAID, the operating system will have no idea the sector is corrupt - this is why I like ZFS's block checksumming, as you can get a list of files with corrupt blocks in order to restore from backup.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/352045/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor350112"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Journaling no protection against power drop</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 16:10 UTC (Tue)
                               by <b>davecb</b> (subscriber, #1574)
                              [<a href="/Articles/350112/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If you use flash as a commit cache and write both data and metatdata, you can both protect against failure and gain performance.  The one thing you can't protect against is losing the data being written to cache at the time the failure or power outage occurs.<br>
This, by the way, is an oversimplified description of ZFS (;-))<br>
<p>
--dave<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350112/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350036"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 1:35 UTC (Tue)
                               by <b>flewellyn</b> (subscriber, #5047)
                              [<a href="/Articles/350036/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I can't believe a kernel developer thought that a degraded RAID5 having data corruption problems if it suffered power loss (or another fault) while still degraded, or rebuilding, is at all noteworthy.<br>
<p>
It's right in the definition of RAID5: you cannot expect to maintain data integrity after a double-fault.  The filesystem used on top of it is irrelevant.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350036/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350045"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 3:22 UTC (Tue)
                               by <b>zlynx</b> (guest, #2285)
                              [<a href="/Articles/350045/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I think it's noteworthy.<br>
<p>
Most people, myself included, expect a degraded RAID array to fail **only if another drive fails**. I do NOT expect losing 256KB of data because a single 4KB write failed.<br>
<p>
And in fact, the array didn't lose it. It just can't tell which 4KB went bad, which it could if MD did good write-intent logging.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350045/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor350068"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 7:51 UTC (Tue)
                               by <b>job</b> (guest, #670)
                              [<a href="/Articles/350068/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It's the fact that it's silent that is the problem. Writes fail under certain circumstances, and that's acceptable, but when a failed write perhaps affects other data silently and now your system reports healthy but you don't know if it really is... That's just .. ouch.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350068/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350047"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 4:09 UTC (Tue)
                               by <b>sureshb</b> (guest, #25018)
                              [<a href="/Articles/350047/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If SSDs are smart devices, in future can they use some part of memory for journaling ? All writes go through this and in back ground the data is moved to final destination. This will have performance hit, but it shouldn't be that bad.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350047/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350066"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 7:45 UTC (Tue)
                               by <b>job</b> (guest, #670)
                              [<a href="/Articles/350066/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
There are experimental object storage devices where the devices themselves house the file system logic. I'm not sure I would want one of those, I'd prefer the opposite: stupid flash memory connected to the bus. Things are generally easier to fix in software.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350066/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350049"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 5:16 UTC (Tue)
                               by <b>k8to</b> (guest, #15413)
                              [<a href="/Articles/350049/">Link</a>] (18 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
RAID 5 is completely undepdendable.  Anyone who uses RAID5 and expects reliability is ignorant or incompetent.  It also has terrible performance.<br>
<p>
RAID 6 is slightly less bad.  If you want to avoid problems with crashes, outages, you should have multiple hot standbys.  if you want performance you should use RAID 10.<br>
<p>
Either way you should use a backup as your data loss reduction strategy.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350049/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350067"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 7:46 UTC (Tue)
                               by <b>job</b> (guest, #670)
                              [<a href="/Articles/350067/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I would expect the same problem to affect RAID10, as a double fault can kill them too if you're very unlucky.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350067/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350070"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 8:05 UTC (Tue)
                               by <b>drag</b> (guest, #31333)
                              [<a href="/Articles/350070/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Well as single fault can destroy any data if you want to look at it that way... But generally with one drive gone either Raid 6 or Raid 10 should still be adequate.<br>
<p>
With RAID 5 the amount of time it takes to recover is so long nowadays that the chances of having a double fault is pretty good. It was one thing to have 20GB with 30MB/s performance, but it's quite another to have 1000GB with 50MB/s performance...<br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350070/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor352093"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 11, 2009 1:18 UTC (Fri)
                               by <b>Pc5Y9sbv</b> (guest, #41328)
                              [<a href="/Articles/352093/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I agree you cannot blindly use RAID5 without considering the sizing, but what do you consider an acceptable recovery time?<br>
<p>
My cheap MD RAID5 with three 500 GB SATA drives allows me to have 1TB and approximately 100 MB/s per drive throughput, which implies a full scan to re-add a replacement drive might take 2 hours or so (reading all 500 GB from 2 drives and writing 500 GB to the third at 75% of full speed).  I have never been in a position where this I/O time was worrisome as far as a double fault hazard.  Having a commodity box running degraded for several days until replacement parts are delivered is a more common consumer-level concern, which has not changed with drive sizes.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/352093/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350514"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 3, 2009 5:05 UTC (Thu)
                               by <b>k8to</b> (guest, #15413)
                              [<a href="/Articles/350514/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Double fault can kill raid 10 also, but you're much less likely to have the fault propogate as discussed in the article, and the downtime for bringing in a standby is much smaller, so standby drives are more effective.<br>
<p>
Meanwhile, you also get vastly better performance, and higher reliability of implementation.<br>
<p>
It's really a no brainer unless you're poor.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350514/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350516"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 3, 2009 5:26 UTC (Thu)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/350516/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
actually, if you have a read-mostly workload raid 5/6 can end up being as fast as raid 10. I couldn't believe this myself when I first ran into it, but I have a large (multiple TB) database used for archiving log data and discovered that read/search performance was the same with raid 6 as with raid 10. <br>
<p>
in digging further I discovered that they key to performance was to have enough queries in flight to keep all disk heads fully occupied (one outstanding query per drive spindle), and you can do this with both raid 6 and raid 10.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350516/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor350071"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 8:11 UTC (Tue)
                               by <b>drag</b> (guest, #31333)
                              [<a href="/Articles/350071/">Link</a>] (11 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The way I look at it is like this:<br>
<p>
RAID = availability/performance<br>
BACKUPS = data protection.<br>
<p>
Anything other way of looking at is pretty much doomed to be flawed. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350071/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350103"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 15:43 UTC (Tue)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350103/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This is a good way to look at it.  Starting with a near-CDP tool such as rsnapshot is a good approach to snapshots, backing up data as frequently as every hour with low overhead, through rsync with multi-version support through hard links between snapshots.  Then if the overhead of a scan every hour is too much, or you need very fast recovery from a disk fault, add RAID as well.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350103/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350111"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 16:05 UTC (Tue)
                               by <b>jonabbey</b> (guest, #2736)
                              [<a href="/Articles/350111/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thanks for the reference to rsnapshot!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350111/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350119"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 16:47 UTC (Tue)
                               by <b>martinfick</b> (subscriber, #4455)
                              [<a href="/Articles/350119/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
BACKUPS are poor, version control is the only sane backup.  Backups are horrible to recover from.  Backups provide no sane automatable mechanism for pruning older data (backups) that doesn't suffer from the same corruption/accidental deletion problem that originals have, but worse, amplified since they don't even have a good mechanism for sanity checking (usage)!  Backups tend to backup corrupted data without complaining.<br>
<p>
Backups are good for certain limited chores such as backing up your version control system! :)  But ONLY if you have a mechanism to verify the sanity of your previous backup and the original before making the next backup.  Else, you are back to backing up corrupted data.  <br>
<p>
A good version control system protects you from corruption and accidental deletion since you can always go to an older version.  And the backup system with checksums (often built into VCS) should protect the version control system.  <br>
<p>
If you don't have space for VCing your data you don't likely really have space for backing it up either, so do not accept this as an excuse to not vcs your data instead of backing it up.<br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350119/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350155"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 17:44 UTC (Tue)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350155/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Since I've researched this a lot recently, here are some rsync/librsync based tools that work somewhat like version control systems but are intended for system backups.  They qualify as 'near-CDP' since rsync is efficient at scanning for changes.<br>
<p>
rsnapshot is pretty good as a 'sort of' version control system for any type of file including binaries.  It doesn't do any compression, just rsync plus hard links, but works very well within its design limits.  It can backup filesystems including the hard links (use rsync -avH in the config file), and is focused on 'pull' backups i.e. backup server ssh's into the server to be backed up.  It's used by some web hosting providers who back up tens of millions of files every few hours, with scans taking a surprisingly short time due to the efficiency of rsync.  Generally rsnapshot is best if you have a lot of disk space available, and not much time to run the backups in.<br>
<p>
rdiff-backup may be closer to what you are thinking of - unlike rsnapshot it only stores the deltas between versions of a file, and stores permissions etc as metadata (so you don't have to have root on the box being backed up to rsync arbitrary files).  It's a bit slower than rsnapshot but a lot of people like it.  It does include checksums which is a very attractive feature.<br>
<p>
duplicity is somewhat like rsnapshot, but can also do encryption, so it's more suitable for backup to a system you don't control.<br>
<p>
There are a lot of these tools around, based on Mike Rubel's original ideas, but these ones seem the most actively discussed.<br>
<p>
For a non-rsync backup, dar is excellent but not widely mentioned - it includes per-block encryption and compression, and per-file checksums, and is generally much faster for recovery than tar, where you must read through the whole archive to recover.<br>
<p>
rdiff-backup, like VCS tools, will have difficulty with files of 500 MB or more - it's been reported that such files don't get backed up, or are not delta'ed.  Very large files that change frequently (databases, VM images, etc) are a problem for all these tools.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350155/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor350164"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 17:55 UTC (Tue)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/350164/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
unless your version control stores your data somewhere other than on your computer, it's a poor substitute for a backup.<br>
<p>
there are lots of things that can happen to your computer (including your house burning down) that will destroy everything on it.<br>
<p>
no matter how much protection you put into your storage system, you still need backups.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350164/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350169"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 18:05 UTC (Tue)
                               by <b>martinfick</b> (subscriber, #4455)
                              [<a href="/Articles/350169/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Local backups suffer from the same problem as local version control.<br>
<p>
Thus, locality is unrelated to whether your are using backups or version control.  Yes, it is better to put it on another computer, or, at least another physical device.  But, this is in no way an argument for using backups instead of version control.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350169/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350171"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 18:05 UTC (Tue)
                               by <b>joey</b> (guest, #328)
                              [<a href="/Articles/350171/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; If you don't have space for VCing your data you don't likely really have </font><br>
<font class="QuotedText">&gt; space for backing it up either, so do not accept this as an excuse to not </font><br>
<font class="QuotedText">&gt; vcs your data instead of backing it up.</font><br>
<p>
I'd agree, but you may not have memory to VCS your data. Git, in particular, scales memory usage badly with large data files.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350171/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350176"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 18:16 UTC (Tue)
                               by <b>martinfick</b> (subscriber, #4455)
                              [<a href="/Articles/350176/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If you have disk space, you have memory: it's called swap.  Use it appropriately.   With ~$60 TB disks, there is no excuse for either not having enough memory or enough space to VC your data.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350176/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350252"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 2, 2009 0:39 UTC (Wed)
                               by <b>drag</b> (guest, #31333)
                              [<a href="/Articles/350252/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; BACKUPS are poor, version control is the only sane backup.</font><br>
<p>
If your using version control for backups then that is your backup. Your <br>
sentence does not really make a whole lot of sense and is nonsensical. <br>
There is no difference.<br>
<p>
My favorite form of backup is to use Git to sync data on geographically <br>
disparate machines. But this is only suitable for text data. If I have to <br>
backup photographs then source code management systems are utter shit.<br>
<p>
<font class="QuotedText">&gt; Backups are horrible to recover from. </font><br>
<p>
They are only horrible to recover with if the backup was done poorly. If <br>
you (or anybody else) does a shitty job of setting them up then it's your <br>
(or their's) fault they are difficult. <br>
<p>
Backing up is a concept. <br>
<p>
Anyways its much more horrible to recover data that has ceased to <br>
exist. <br>
<p>
<p>
<font class="QuotedText">&gt; Backups provide no sane automatable mechanism for pruning older data </font><br>
<font class="QuotedText">&gt; (backups) that doesn't suffer from the same corruption/accidental deletion </font><br>
<font class="QuotedText">&gt; problem that originals have, but worse, amplified since they don't even </font><br>
<font class="QuotedText">&gt; have a good mechanism for sanity checking (usage)! Backups tend to backup </font><br>
<font class="QuotedText">&gt; corrupted data without complaining.</font><br>
<p>
Your doing it wrong. <br>
<p>
The best form of backup is to full backups to multiple places. Ideally they <br>
should be in a different region. You don't go back and prune data or clean <br>
them up. Thats WRONG. Incremental backups are only useful to reduce the <br>
amount of dataloss between full backups. A full copy of _EVERYTHING_ is a <br>
requirement. And you save it for as long as that data is valuable. Usually <br>
5 years.<br>
<p>
It depends on what your doing but a ideal setup would be like this:<br>
* On-site backups every weekend. Full backups. Stored for a few months. <br>
* Incremental backups twice a day, and resets at the weekend with the full <br>
backup.<br>
* Every month 2 full backups are stored for 2-3 years.<br>
* Off-site backups 1 a month, stored for 5 years.<br>
etc. etc.<br>
<p>
That would probably be a good idea for most small/medium businesses.<br>
<p>
If your relying on a server or a single datacenter to store your data <br>
reliably then your a fool. I don't give a shit on how high quality your <br>
server hardware is or file system or anything. A single fire, vandalism, <br>
hardware failure, disaster, sabotage, or any number of things can utterly <br>
destroy _everything_. <br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350252/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350532"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 3, 2009 7:51 UTC (Thu)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350532/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
On full backups: one of the nice things about rsnapshot and similar rsync-based tools is that every backup is both a full backup and an incremental backup.  Full in that previous backups can be deleted without any effect on this backup (thanks to hard links), and incremental in that the data transfer required is proportional to the specific data blocks that have changed (thanks to rsync).<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350532/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor350515"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 3, 2009 5:06 UTC (Thu)
                               by <b>k8to</b> (guest, #15413)
                              [<a href="/Articles/350515/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes agreed, RAID is for availability and performance.  RAID 5 doesn't offer performance, and the availability story isn't great either.  So don't use it.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350515/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350816"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and RAID: silent data killers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 4, 2009 10:38 UTC (Fri)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/350816/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
'Terrible performance' is in the eye of the beholder. So is reliability. Software RAID is constrained by bus bandwidth, so RAID 10 writes may well be slower than RAID 5 if you're bus-limited: and even RAID 5 writes are no slower than writes to a single drive. TBH, 89Mb/s writes and 250MB/s reads (which my Areca card can manage with a four-drive RAID 5 array) don't seem too 'terrible' to me.<br>
<p>
Furthermore, reliability is fine *if* you can be sure that once RAID parity computations have happened the stripe will always hit the disk, even if there is a power failure. With battery-backed RAID, this is going to be true (modulo RAID controller card failure or a failure of the drive you're writing to). Obviously if the array is sufficiently degraded reliability isn't going to be good anymore, but doesn't everyone know that?<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350816/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor350072"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 8:15 UTC (Tue)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350072/">Link</a>] (22 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
In my experience of massive data loss (thousands of files) using ext3 on a hard disk with a default data=ordered setup with LVM and no RAID, using Linux and ext3 is quite dangerous in its default configuration.  This seems to be due to drives that reorder blocks in the write cache, and lack of journal checksumming in ext3 to cope with this (and possibly also LVM issues).  See <a href="http://lwn.net/Articles/342978/">http://lwn.net/Articles/342978/</a> for the details.<br>
<p>
My standard setup now is to:<br>
<p>
1. Avoid LVM completely <br>
<p>
2. Disable write caching on all hard drives using hdparm -W0 /dev/sdX. <br>
<p>
3. Enable data=journal on ext3 (tune2fs -o journal_data /dev/sdX is the best way to ensure partitions are mounted with this option, including the root partition and when installed in another system, post-reinstall, etc).<br>
<p>
The performance hit from these changes is trivial compared to the two days I spent rebuilding a PC where the root filesystem lost thousands of files and the backup filesystem was completely lost.<br>
<p>
I suspect that the reason LVM is seen as reliable despite being the default for Fedora and RHEL/CentOS is that enterprise Linux deployment use hardware RAID cards with battery-backed cache, and perhaps higher quality drives that don't lie about write completion.  <br>
<p>
Linux is far worse at losing data with a default ext3 setup than I once thought it was, unfortunately.  If correctly configured it's fine, but the average new Linux user has no way to know how to configure this.  I can't recall losing data like this on Windows in the absence of a hardware problem.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350072/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350074"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 8:51 UTC (Tue)
                               by <b>tialaramex</b> (subscriber, #21167)
                              [<a href="/Articles/350074/">Link</a>] (10 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
When I follow your reference, I come face to face with myself suggesting perfectly ordinary explanations and you have no answer.<br>
<p>
It is always nice to imagine that if you find the right combination of DIP switches, set the right values in the configuration file, choose the correct compiler flags, your problems will magically vanish.<br>
<p>
But sometimes the real problem is just that your hardware is broken, and all the voodoo and contortions do nothing. You've changed _three_ random things about your setup based on, AFAICT, no evidence at all, and you think it's a magic formula. Until something bad happens again and you return in another LWN thread to tell us how awful ext3 is again...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350074/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350077"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 9:03 UTC (Tue)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350077/">Link</a>] (9 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I don't have time to do a scientific experiment across a number of PCs using different setups so I had to go with the evidence I had, and could find through searches.  <br>
<p>
I did base these changes mostly on the well known lack of journal checksumming in ext3 (going to data=journal and avoiding write caching) - see <a href="http://en.wikipedia.org/wiki/Ext3#No_checksumming_in_journal">http://en.wikipedia.org/wiki/Ext3#No_checksumming_in_journal</a>.  Dropping LVM is harder to justify, it's really just a hunch based on a number of reports of LVM being involved in data corruption, and on my own data point that the LVM volumes on one disk were completely inaccessible (i.e. corrupted LVM metadata) - hence it was not just ext3 involved here, though it might have been write caching as well.<br>
<p>
I'm interested to hear responses that show these steps are unnecessary, of course.  <br>
<p>
I really doubt the hardware is broken: there are no disk I/O errors in any of the logs, there were 2 disks corrupted (1 SATA, 1 PATA), and there are no symptoms of memory errors (random application/system crashes).  <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350077/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350158"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 17:48 UTC (Tue)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/350158/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
of the three changes you are making<br>
<p>
disabling write caches<br>
<p>
this is mandatory unless you have battery backed cache to recover from failed writes. period, end of statement. if you don't do this you _will_ loose data when you loose power.<br>
<p>
avoiding LVM<br>
<p>
I have also run into 'interesting' things with LVM, and so I also avoid it. I see it as a solution in search of a problem for just about all users (just about all users would be just as happy, and have things work faster with less code involved, if they just used a single partition covering their entire drive.)<br>
<p>
I suspect that some of the problem here is that ordering of things gets lost in the LVM layer, but that's just a guess.<br>
<p>
data=journal,<br>
<p>
this is not needed if the application is making proper use of fsync. if the application is not making proper use of fsync it's still not enough to make the data safe.<br>
<p>
by the way, ext3 does do checksums on journal entries. the details of this were posted as part of the thread on linux-kernel.<br>
<p>
<p>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350158/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350165"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 18:05 UTC (Tue)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350165/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Possibly data=journal is overkill, I was going by the Wikipedia page on ext3, link above.  However a conservative setup is attractive at present as performance is far less important than reliability, for this PC anyway.<br>
<p>
Do you know roughly when ext3 checksums were added, or by whom, as this contradicts the Wikipedia page?  Must be since 2007, based on <a href="http://archives.free.net.ph/message/20070519.014256.ac3a2e07.en.html">http://archives.free.net.ph/message/20070519.014256.ac3a2...</a>.  I thought journal checksumming was only added to ext4 (see first para of <a href="http://lwn.net/Articles/284037/">http://lwn.net/Articles/284037/</a>) not ext3.<br>
<p>
This sort of corruption issue is one reason to have multiple partitions; parallel fscks are another.  In fact, it would be good if Linux distros automatically scheduled a monthly fsck for every filesystem, even if journal-based.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350165/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350175"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 18:15 UTC (Tue)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/350175/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Ted Tso detailed the protection of the journal in this thread (I've deleted the particular message or I'd quote it for you)<br>
<p>
I'm not sure I believe that parallel fscks on partitions on the same drive do you much good. the limiting factor for speed is the throughput of the drive. do you really gain much from having it bounce around interleaving the different fsck processes?<br>
<p>
as for protecting against this sort of corruption, I don't think it really matters.<br>
<p>
for flash, the device doesn't know about your partitions, so it will happily map blocks from different partitions to the same eraseblock, which will then get trashed on a power failure, so partitions don't do you any good.<br>
<p>
for a raid array it may limit corruption, but that depends on how your partition boundaries end up matching the stripe boundaries.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350175/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350179"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 18:44 UTC (Tue)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350179/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I still can't find that email, but this outlines that journal checksumming was added to JBD2 to support ext4: <a href="http://ext4.wiki.kernel.org/index.php/Frequently_Asked_Questions#What_are_the_key_differences_between_jbd_and_jbd2.3F">http://ext4.wiki.kernel.org/index.php/Frequently_Asked_Qu...</a><br>
<p>
This Usenix paper mentions that JBD2 will ultimately be usable by other filesystems, so perhaps that's how ext3 does (or will) support this: <a href="http://www.usenix.org/publications/login/2007-06/openpdfs/mathur.pdf">http://www.usenix.org/publications/login/2007-06/openpdfs...</a> - however, I don't think ext3 has journal checksums in (say) 2.6.24 kernels.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350179/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor350278"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 2, 2009 6:36 UTC (Wed)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350278/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I grepped the 2.6.24 sources, fs/ext3/*.c and fs/jbd/*.c, for any mention of checksum, and couldn't find it.  However the email lists do have some reference to a journal checksum patch for ext3 that didn't make it into 2.6.25.<br>
<p>
One other thought: perhaps LVM is bad for data integrity with ext3 because, as well as stopping barriers from working, LVM generates more fragmentation in the ext3 journal - that's one of the conditions mentioned by Ted Tso as potentially causing write reordering and hence FS corruption here: <a href="http://linux.derkeiler.com/Mailing-Lists/Kernel/2008-05/msg07849.html">http://linux.derkeiler.com/Mailing-Lists/Kernel/2008-05/m...</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350278/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor350231"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 22:37 UTC (Tue)
                               by <b>cortana</b> (subscriber, #24596)
                              [<a href="/Articles/350231/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; disabling write caches</font><br>
&gt;<br>
<font class="QuotedText">&gt; this is mandatory unless you have battery backed cache to recover from </font><br>
<font class="QuotedText">&gt; failed writes. period, end of statement. if you don't do this you _will_ </font><br>
<font class="QuotedText">&gt; loose data when you loose power.</font><br>
<p>
If this is true (and I don't doubt that it is), why on earth is it not the default? Shipping software with such an unsafe default setting is stupid. Most users have no ideas about these settings... surely they shouldn't be handed a delicious pizza smeared with nitroglycerin topping, and then be blamed when they bite into it and it explodes...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350231/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350233"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 22:41 UTC (Tue)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/350233/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
simple, enabling the write cache gives you a 10x (or better) performance boost for all the times when your system doesn't loose power.<br>
<p>
the market has shown that people are willing to take this risk by driving all vendors that didn't make the change out of the marketplace<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350233/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350533"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 3, 2009 7:58 UTC (Thu)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350533/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
True, but it would be good if there was something simple like "apt-get install data-integrity" in major distros, which would then help the user configure the system for high integrity by default and this was well publicised.  This could include things like: disabling write cache, periodic fsck's, ext3 data=journal, etc.<br>
<p>
It would still be better if distros made this the default but I don't see much prospect of this.<br>
<p>
One other example of disregard for data integrity that I've noticed is that Ubuntu (and probably Debian) won't fsck a filesystem (including root!) if the system is on batteries.  This is very dubious - the fsck might exhaust the battery, but the user might well prefer a while without use of their laptop due to no battery to a long time without use of their valuable data when the system gets corrupted later on... <br>
<p>
Fortunately on my desktop with a UPS, on_ac_power returns 255 which counts as 'not on battery' for the /etc/init.d/check*.sh scripts.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350533/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor350738"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 3, 2009 23:18 UTC (Thu)
                               by <b>landley</b> (guest, #6789)
                              [<a href="/Articles/350738/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The paragraph starting "But what if more than one drive fails?" is misleading.  You don't need another drive to fail to experience this problem, all you need is an unclean shutdown of an array that's both dirty and degraded.  (Two words: "atime updates".)  The second failure can be entirely a _software_ problem (which can invalidate stripes on other drives without changing them, because the parity information needed to use them is gone).  Software problem != hardware problem, it's not the same _kind_ of failure.<br>
<p>
People expect RAID to protect against permanent hardware failures, and people expect journaling to protect against data loss from transient failures which may be entirely due to software (ala kernel panic, hang, watchdog, heartbeat...).  In the first kind of failure you need to replace a component, in the second kind of failure the hardware is still good as new afterwards.  (Heck, you can experience unclean shutdowns if your load balancer kills xen shares impolitely.  There's _lots_ of ways to do this.  I've had shutdown scripts hang failing to umount a network share, leaving The Button as the only option.)<br>
<p>
Another problematic paragraph starts with "RAID arrays can increase data reliability, but an array which is not running with its full complement of working, populated drives has lost the redundancy which provides that reliability."<br>
<p>
That's misleading because redundancy isn't what provides this reliability, at least in other contexts.  When you lose the redundancy, you open yourself to an _unrelated_ issue of update granularity/atomicity.  A single disk doesn't have this "incomplete writes can cause collateral damage to unrelated data" problem.  (It might start to if physical block size grows bigger than filesystem sector size, but even 4k shouldn't do that on a properly aligned modern ext3 filesystem.)  Nor does RAID 0 have an update granularity issue, and that has no redundancy in the first place.<br>
<p>
I.E. a degraded RAID 5/6 that has to reconstruct data using parity information from multiple stripes that can't be updated atomically is _more_ vulnerable to data loss from interrupted writes than RAID 0 is, and the data loss is of a "collateral damage" form that journaling silently fails to detect.  This issue is subtle, and fiddly, and although people keep complaining that it's not worth documenting because everybody should already know it, the people trying to explain it keep either getting it _wrong_ or glossing over important points.<br>
<p>
Another point that was sort of glossed over is that journaling isn't exactly a culprit here, it's an accessory at best.  This is a block device problem which would still cause data loss on a non-journaled filesystem, and it's a kind of data loss that a fsck won't necessarily detect.  (Properly allocated file data elsewhere on the disk, which the filesystem may not have attempted to write to in years, may be collateral damage.  And since you have no warning you could rsync the damaged stuff over your backups if you don't notice.)  If it's seldom-used data it may be long gone before you notice.<br>
<p>
The problem is that journaling gives you a false sense of security, since it doesn't protect against these issues (which exist at the block device level, not the filesystem level), and can hide even the subset of problems fsck would detect, by reporting a successful journal replay when the metadata still contains collateral damage in areas the journal hadn't logged any recent changes to.  <br>
<p>
I look forward to btrfs checksumming all extents.  That should at least make this stuff easier to detect, so you can know when you _haven't_ experienced this problem.<br>
<p>
Rob<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350738/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor350122"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 16:43 UTC (Tue)
                               by <b>ncm</b> (guest, #165)
                              [<a href="/Articles/350122/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      What's <i>wrong</i> with providing battery backup for your drives?  If they have power for a little while after the last write request arrives, then write caching, re-ordering writes, and lying about what's already on the disk don't matter.  You still need to do backups, of course, but you'll need to use them less often because your file system will be that much less likely to have been corrupted.
<p>
I don't buy that your experience suggests there's anything wrong with ext3, if you didn't protect against power drops. The same could happen with any file system.  The more efficient the file system is, the more likely is corruption in that case -- although some inefficient file systems seem especially corruptible.
      
          <div class="CommentReplyButton">
            <form action="/Articles/350122/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350143"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 17:31 UTC (Tue)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350143/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This PC is on battery backup (UPS) already - that didn't stop the corruption though.  This is a home PC, and in any case it really shouldn't be necessary to use a UPS just to avoid filesystem/LVM corruption.<br>
<p>
Since the rebuild, I have realised that the user of the PC has been turning it off via the power switch accidentally, which perhaps caused the write cache of the disk(s) to get corrupted and is a fairly severe test.  Despite several sudden poweroffs due to this, with the new setup there has been no corruption yet.  It seems unlikely that the writes would be pending in the disk's write cache for so long that they couldn't be written out while power was still, but the fact is that both ext3 and LVM data structures got corrupted.  <br>
<p>
It's acknowledged that ext3's lack of journal checksumming can cause corruption when combined with disk write caching (whereas XFS does have such checksums I think).  The only question is whether the time between power starting to drop and the power going completely is enough to flush pending writes (possibly reordered), while also not having any RAM contents get corrupted.  Betting the data integrity of a remotely administered system on this time window is not something I want to do.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350143/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350160"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 18:06 UTC (Tue)
                               by <b>ncm</b> (guest, #165)
                              [<a href="/Articles/350160/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <i>The only question is whether the time between power starting to drop and the power going completely is enough to flush pending writes (possibly reordered), while also not having any RAM contents get corrupted</i>
<p>
That's easy: <b>No</b>.  When power starts to drop, everything is gone at that moment.  If the disk is writing at that moment, the unfinished sector gets corrupted, and maybe others.  UPS for the computer and disk together helps only a little against corruption unless power drops are almost always shorter than the battery time, or it automatically shuts down the computer before getting used up.  You may be better off if the computer loses power immediately, and only the disk gets the UPS treatment.
<p>
<i>it really shouldn't be necessary to use a UPS just to avoid filesystem/LVM corruption.</i>
<p>
Perhaps, but it is.  (What is this "should"?)  The file system doesn't matter near so much as you would like.  They can be indefinitely bad, but can be no more than fairly good.  The good news is that the UPS only needs to support the disk, and it only needs to keep power up for a few seconds; then many file systems are excellent, although the bad ones remain bad.
      
          <div class="CommentReplyButton">
            <form action="/Articles/350160/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor351744"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 9, 2009 20:35 UTC (Wed)
                               by <b>BackSeat</b> (guest, #1886)
                              [<a href="/Articles/351744/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <i>It's acknowledged that ext3's lack of journal checksumming can cause corruption</i><p>It may only be semantics, but it's unlikely that the lack of journal checksumming <i>causes</i> corruption, although it may make it difficult to detect.<p>As for LVM, I've never seen the point. Just another layer of ones and zeros between the data and the processor. I never use it, and I'm very surprised some distros seem to use it by default.
      
          <div class="CommentReplyButton">
            <form action="/Articles/351744/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor352042"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 10, 2009 20:50 UTC (Thu)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/352042/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
One interesting scenario, mentioned I think elsehwere in the comments to this article: a single 'misplaced write' (i.e. disk doesn't do the seek to new position, writing to old position) means that a data block goes into the ext3 journal. <br>
<p>
In the absence of  ext3 journal checksumming, and if there is a crash requiring replay of this journal block, horrible things will happen - presumably garbage is written to various places on disk from the 'journal' entry.  One symptom may be log entries saying 'write beyond end of partition', which I've seen a few times with ext3 corruption and I think is a clear indicator of corrupt filesystem metadata.<br>
<p>
This is one reason why JBD2 added journal checksumming for use with ext4 - I hope this also gets used by ext3.  In my view, it would be a lot better to make that change to ext3 than to make data=writeback the default, which will speed up some workloads and most likely corrupt some additional data (though I guess not metadata).<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/352042/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor352054"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 10, 2009 21:05 UTC (Thu)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/352054/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Actually the comment about a single incorrect block in a journal 'spraying garbage' over the disk is here: <a href="http://lwn.net/Articles/284313/">http://lwn.net/Articles/284313/</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/352054/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor352177"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 11, 2009 16:33 UTC (Fri)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/352177/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Note that you won't get a whole blockfull of garbage: ext3 will generally <br>
notice that 'hey, this doesn't look like a journal' once the record that <br>
spanned the block boundary is complete. But that's a bit late...<br>
<p>
(this is all supposition from postmortems of shagged systems. Thankfully <br>
we no longer use hardware prone to this!)<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/352177/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor350241"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 1, 2009 23:49 UTC (Tue)
                               by <b>dododge</b> (guest, #2870)
                              [<a href="/Articles/350241/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Well for starters (unless things have changed recently) LVM doesn't support write barriers, so if you put LVM in the loop it probably doesn't matter if the drive reports write completion correctly or not.  If you use XFS on top of LVM you get a big warning about this at mount time.<br>
<p>
I don't use EXT3 much, but from a quick googling it sounds like you have to explicitly turn on barrier support in fstab and it still won't warn you about the LVM issue until it actually tries to use one.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350241/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350284"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 2, 2009 7:18 UTC (Wed)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350284/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
You are right on both points - when ext3 tries to do barriers on top of LVM it complains at that point, not at time of mounting.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350284/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor350525"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Ext3 and write caching by drives are the data killers...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 3, 2009 7:18 UTC (Thu)
                               by <b>job</b> (guest, #670)
                              [<a href="/Articles/350525/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
According to previous comments at LWN barriers should be working through LVM with 2.6.30.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350525/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor350554"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">LVM barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 3, 2009 10:23 UTC (Thu)
                               by <b>Cato</b> (guest, #7643)
                              [<a href="/Articles/350554/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
There are some limitations on this - LVM barriers will only work with a linear target, apparently: <a href="http://lwn.net/Articles/326597/">http://lwn.net/Articles/326597/</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/350554/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2009, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
