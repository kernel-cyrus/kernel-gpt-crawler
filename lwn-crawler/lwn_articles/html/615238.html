        <!DOCTYPE html>
        <html lang="en">
        <head><title>Bulk network packet transmission [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/615238/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/614514/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/615238/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Bulk network packet transmission</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>This article brought to you by LWN subscribers</b>
<p>
Subscribers to LWN.net made this article &mdash; and everything that
       surrounds it &mdash; possible.  If you appreciate our content, please
       <a href="/Promo/nst-nag3/subscribe">buy a subscription</a> and make the next
       set of articles possible.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>October 8, 2014</br>
           </div>
One of the keys to good performance on contemporary systems is batching â€”
getting a lot of work done relative to a given fixed cost.  If, for
example, a lock must be acquired to do one unit of work in a specific
subsystem, doing multiple units of work while the lock is held will reduce
the overall overhead of the system.  Much of the scalability work that has
been done in recent years has, in some way, related to increasing batching
where possible.  Some recent changes in the networking subsystem show that
batching can improve performance there as well.
<p>
Every time a packet is transmitted over the network, a sequence of
operations must be performed.  These include acquiring the lock for the
queue of outgoing packets, passing a packet to the driver, putting the
packet in the 
device's transmit queue, and telling the device to start transmitting.
Some of those operations are inherently per-packet, but others are not.
The acquisition of the queue lock could be amortized across multiple packet
transmissions, for example, and the act of telling the device to start
transmission may be expensive indeed.  It can involve hardware operations
or, even, on some systems, hypervisor calls.
<p>
Often, when there is one packet to transmit, there are others waiting in
the queue as well; network traffic can be inherently bursty.  So it would
make sense for the networking stack to try to split the fixed costs of
starting packet transmission across as many packets as possible.  Some
techniques, such as segmentation offload (wherein the network interface splits
large chunks of data into packets) perform that kind of batching.  But, in
current kernels, if the networking stack has a set of packets ready to go,
they will be sent out the slow way, one at a time.
<p>
That situation will begin to change in 3.18, when a relatively small set of
changes will be merged.  Consider the function exported by drivers now to
send a packet:
<p>
<pre>
    netdev_tx_t	(*ndo_start_xmit) (struct sk_buff *skb, struct net_device *dev);
</pre>
<p>
This function takes the packet pointed to by <tt>skb</tt> and transmits it
via the specified <tt>dev</tt>.  Every call is a standalone operation, with
all the associated fixed costs.  The initial plan for 3.18 was to specify a
new function that drivers could provide:
<p>
<pre>
    void (*ndo_xmit_flush)(struct net_device *dev, u16 queue);
</pre>
<p>
If a driver provided this function, it was indicating to the networking
stack that it is prepared for (and can benefit from) batched transmission.
In this case, the networking stack could make multiple calls to
<tt>ndo_start_xmit()</tt> to queue packets for transmission; the driver
would accept them, but not actually start the transmission operation.  At
the end of a sequence of such calls, <tt>ndo_xmit_flush()</tt> would be
called to indicate the end; at that point, actual hardware transmission
would be started.
<p>
There were concerns, though, that putting another indirect function call
into the transmit path would add too much overhead, so this particular
function was ripped out almost as soon as it landed in the net-next
repository.  In its place, the <tt>sk_buff</tt> structure has gained a new
Boolean variable called <tt>xmit_more</tt>.  If that variable is true, then
there are more packets coming and the driver can defer starting hardware
transmission.  This variable takes out the extra function call while
making the needed information available to drivers that can make use of
it. 
<p>
This mechanism, added by David Miller, makes batching possible.  A couple
of drivers were fixed to support batching, but David did not change the
networking stack to actually do the batching.  That work fell to Jesper
Dangaard Brouer, whose <a href="/Articles/615240/">bulk dequeue support
patches</a> have also been merged for 3.18.  This work, too, is limited in
scope; in particular, it will only work with queuing disciplines that 
have a single transmit queue.
<p>
The change Jesper made is simple enough: in a situation where a packet is
being transmitted, the stack will attempt to send out a series of packets
together while the queue lock is held.  The <a
href="/Articles/454390/">byte queue limits</a> mechanism is used to put an
upper bound on the amount of data that can be in flight at once.  Once the
limit is hit (or the supply of packets runs out), <tt>skb-&gt;xmit_more</tt>
will be set to false and the traffic will be on its way.
<p>
Eric Dumazet looked at the patch set and realized that things could be
taken a bit further: the process of validating packets for transmission
could be moved outside of the queue lock entirely, increasing concurrency
in the system.  The resulting <a href="/Articles/615243/">patch</a> had
benefits that Eric described as <a href="/Articles/615242/">awesome</a>:
full 40Gb/sec wire speed, even in the absence of segmentation offload.
Needless to say, this patch, too, has been accepted into the net-next tree
for the 3.18 merge window.
<p>
All told, the changes are relatively small.  But small changes can have big
effects when they are applied to the right places.  These little changes
should help to ensure that the networking stack in the 3.18 release is the
fastest yet.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Networking-Performance">Networking/Performance</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/615238/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor615671"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bulk network packet transmission</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 9, 2014 19:37 UTC (Thu)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/615671/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
don't delay starting transmission of data, that adds latency when it's not needed.<br>
<p>
It's better to do an inefficient transmission and let the data queue and then the next time through the loop, send all the pending data.<br>
<p>
This approach minimizes the latency and avoids all the possible problems that can show up when the start is blocked and never gets unblocked.<br>
<p>
It sounds as if this doesn't force the hardware to delay it's start of transmission, so the flag can just be 'there is more data available'), so the patch still sounds like it's a reasonable implementation, but the way it's being described is wrong.<br>
<p>
<p>
It will be very interesting to see how this ends up interacting with multiple queue setups. The reason BQL was added in the first place was to prevent large sets of packets from eating up so much time that they caused unacceptable latency for other data. This could aggravate that sort of problem.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/615671/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor615759"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bulk network packet transmission</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 10, 2014 7:26 UTC (Fri)
                               by <b>JesperBrouer</b> (guest, #62728)
                              [<a href="/Articles/615759/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Hi dlang,<br>
<p>
We have tried hard not to introduce latency when using xmit_more.<br>
* Explained in: <a href="http://netoptimizer.blogspot.dk/2014/10/unlocked-10gbps-tx-wirespeed-smallest.html">http://netoptimizer.blogspot.dk/2014/10/unlocked-10gbps-t...</a><br>
<p>
Further more qdisc dequeue bulking will ONLY be done for drivers supporting BQL.  And I've done extensive measurements for Head-of-Line blocking using the netperf-wrapper tool.<br>
<p>
Lots of graphs avail here: <a href="http://people.netfilter.org/hawk/qdisc/">http://people.netfilter.org/hawk/qdisc/</a><br>
<p>
--Jesper Brouer<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/615759/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor615856"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bulk network packet transmission</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 10, 2014 19:26 UTC (Fri)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/615856/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Your post makes it clear that you are doing the right thing, the article was less clear (it talked about when the flag is set the card delays starting to transmit the data)<br>
<p>
The approach of delaying the start of work because it can be done more efficiently later is a bit of a hot button with me. If you have other things to keep the resources busy, it can be a good thing, but if it means keeping a resource idle because it can be done more efficiently later, it's much more questionable (about the only reason to do so is power efficiency), and deciding to _not_ do work now, always adds the problem of how you decide to go ahead and do the work later, with the potential bug of never deciding to actually start the work.<br>
<p>
Thanks for pointing me at the clarification.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/615856/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor615674"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bulk network packet transmission</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 9, 2014 19:54 UTC (Thu)
                               by <b>JesperBrouer</b> (guest, #62728)
                              [<a href="/Articles/615674/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I've written a blogpost on the subject:<br>
<a href="http://netoptimizer.blogspot.com/2014/10/unlocked-10gbps-tx-wirespeed-smallest.html">http://netoptimizer.blogspot.com/2014/10/unlocked-10gbps-...</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/615674/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor615848"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bulk network packet transmission</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 10, 2014 18:04 UTC (Fri)
                               by <b>stressinduktion</b> (subscriber, #46452)
                              [<a href="/Articles/615848/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; This work, too, is limited in scope; in particular, it will only work with queuing disciplines that have a single transmit queue.</font><br>
<p>
multiqueue TX NICs by default setup a mq qdisc scheduler which establishes a 1:1 qdisc &lt;-&gt; txq mapping. So this one-to-one mapping is quite common.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/615848/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor615863"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bulk network packet transmission</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 10, 2014 22:08 UTC (Fri)
                               by <b>jhoblitt</b> (subscriber, #77733)
                              [<a href="/Articles/615863/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Are there any power effeciency gains to be had from batching? Either with current hardware or some future device that could drop into lower power states? 10GBaseT power usage isn't trvial even on a modern cmos process.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/615863/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor615866"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bulk network packet transmission</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 11, 2014 0:21 UTC (Sat)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/615866/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>
Are there any power efficiency gains to be had from batching?
</blockquote>
<p>
That's a different kind of batching - saving up work until you have enough to make it worth incurring the fixed costs.  That's definitely not what this work is aimed at.
<p>
In fact, "batching" may be a misleading term for this work.  It's more like what they call "coalescing" when it happens on disk drive communication links.

      
          <div class="CommentReplyButton">
            <form action="/Articles/615866/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor615868"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bulk network packet transmission</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 11, 2014 3:46 UTC (Sat)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/615868/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
In theory it would be possible if this send the packets faster there would be larger chunks of idle time that power savings could be used.<br>
<p>
But this is not looking at doing that, it's 'just' looking at decreasing the cost of sending packets by only paying the overhead of sending data for several packets instead of paying it for each packet.<br>
<p>
This sort of operation can significantly reduce the contention for locks, so the full effects on performance are probably going to be larger than you would think, and some are going to show up as (small) benefits in odd areas that you may not even think to measure.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/615868/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor616188"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bulk network packet transmission</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 14, 2014 20:59 UTC (Tue)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/616188/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
How much "burstiness" can this add to the traffic? (Sorry I don't have enough time to read all the references - I really wish I had)<br>
<p>
On the one hand, TCP windows and timers are trying hard to pace / smooth traffic to reduce burstiness as much as possible in order to reduce packet losses in switches and optimize utilization.<br>
<p>
On the other hand, operating systems are constantly looking at "batching" opportunities like this one to optimize raw throughput.<br>
<p>
I feel like this ever-lasting tension provides an infinite source of research problems, papers and prototypes...<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/616188/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor616192"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bulk network packet transmission</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 14, 2014 22:44 UTC (Tue)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/616192/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
not a lot, all the packets that would be transmitted are already scheduled to e sent ASAP. Unless the CPU is not able to keep up with the network, this doesn't result in more traffic on the wire, it's just getting there more efficiently.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/616192/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2014, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
