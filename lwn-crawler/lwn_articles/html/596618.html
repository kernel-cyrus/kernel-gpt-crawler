        <!DOCTYPE html>
        <html lang="en">
        <head><title>Understanding __GFP_FS [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/596618/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/595951/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/596618/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Understanding __GFP_FS</h1>
</div>
<div class="ArticleText">
<div class="GAByline">
           <p>April 30, 2014</p>
           <p>This article was contributed by Neil&nbsp;Brown</p>
           </div>
<p>As we discovered <a href="/Articles/595652/">last
week</a>, using NFS to mount a filesystem onto the same host that is
exporting the files has a valuable use case, but is susceptible to
deadlocks. These deadlocks involve the <code>nfsd</code> server process
allocating memory, the memory allocation code choosing some memory pages in
the NFS filesystem to free, and the NFS filesystem waiting for a writeout
to complete — which, of course, needs that <code>nfsd</code> server process
to make some progress.</p>

<p><blockquote class="ad">
<b><tt>$ sudo subscribe today</tt></b>
<p>
Subscribe today and elevate your LWN privileges. You’ll have
access to all of LWN’s high-quality articles as soon as they’re
published, and help support LWN in the process.  <a href="https://lwn.net/Promo/nst-sudo/claim">Act now</a> and you can start with a free trial subscription.
</blockquote>
<p>As noted, these deadlocks are similar to the situations that
triggered the introduction of the <code>__GFP_FS</code>
memory allocation flag and later the <code>PF_FSTRANS</code> process
flag. Avoiding the former, or setting the latter, tells the allocation code
to never risk waiting for any filesystem operation, so setting
<code>PF_FSTRANS</code> for <code>nfsd</code> threads should remove the
deadlocks. It isn't quite that easy, though.</p>

<p>In most cases, separate filesystems are quite separate. Locks held while
working on one filesystem will never conflict with locks needed for another
filesystem. So when code for, say, XFS needs to allocate memory, the
decision whether to set <code>__GFP_FS</code> or not can be made entirely
within the context of XFS. There are a fixed number of entry points from
the memory reclaim code into XFS, and XFS &quot;knows&quot; which locks
those entry points might need. If none of those locks are held, then
<code>__GFP_FS</code> can safely be set to allow calling back into the
filesystem if necessary, even if some other lock is held.</p>

<h4>Multi-lock deadlocks</h4>

<p>When a lock outside of a filesystem is taken during memory reclaim, it
can have hard-to-foresee consequences. Just such a lock was <a
href="http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=35cd78156c499ef83f60605e4643d5a98fef14fd">introduced</a>
in Linux 2.6.32. The
purpose of this lock was to limit the number of processes that would be
trying to reclaim memory at any one time, so it behaved to some extent
like a <a
href="http://en.wikipedia.org/wiki/Semaphore_%28programming%29">counting
semaphore</a>.

Rather than counting processes, it actually counts pages of memory that
have been taken off some LRU (least recently used) list to be considered
for freeing. The effect is much the same, particularly as each process
normally examines 32 pages (<code>SWAP_CLUSTER_MAX</code>) at a time. If
too many pages have been taken off the list (described in the code as being
&quot;isolated&quot;), then any new process entering reclaim will 
have to wait until the number of isolated pages drops below a threshold.
<p>
This delay is the one we postponed discussion of
last week. As it is being used to implement a semaphore, we can see it has a
different role than the other delays we considered then and is not
likely to cause a general slow down of NFS traffic.  There is a different
kind of hazard associated with this delay mechanism, though.</p>

<p>If the maximum allowed number of pages have been isolated by processes that
are all performing reclaim with the <code>__GFP_FS</code> flag set (allowing access
into filesystems), those processes could all end up blocking on some
filesystem lock. If the process holding this lock also tried to reclaim
some memory to fulfill an allocation request, it would naturally use
<code>__GFP_FS</code>. While this would stop it from entering any
filesystem, it would not help with the counting semaphore. The process
holding the filesystem lock would block on the semaphore which, itself, was
held by various processes blocking on the filesystem lock. Thus we get a
two-lock deadlock.</p>

<p>This problem is somewhat akin to priority inversion if we think of the
<code>GFP</code> flag as indicating a priority: an allocation with
<code>__GFP_FS</code> has a lower priority than an allocation without the
flag. As with priority inversion, one resolution could be to increase the
priority of any process while it holds the contentious lock. In the present
case that would be a terrible solution as it would mean that every process
entering reclaim would need to clear <code>__GFP_FS</code> while holding
the semaphore, and so no reclaimer could ever call into any filesystem.</p>

<p>The <a
href="http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=3cf23841b4b76eb94d3f8d0fb3627690e4431413">actual
fix</a> that was applied in Linux 3.8 (3 years later) was to restrict
<code>__GFP_FS</code> processes to just a small subset (about
one-eighth) of the allowed processes; other slots are
reserved for processes without that flag. This is a simple strategy which
works well with a counting semaphore. With a binary mutex it wouldn't work,
as one-eighth of one process doesn't get very far.</p>

<h4>Finding those deadlocks</h4>

<p>When I tried setting <code>PF_FSTRANS</code> for <code>nfsd</code>
threads (to disable <code>__GFP_FS</code>), I hit a similar set of
problems. Where previously a filesystem only had to be careful about locks
that filesystem might take, we now had multiple players that could
interact with each other. The local filesystem, the <code>nfsd</code>
thread, the NFS filesystem and the networking layer in between all have
their own specific locking needs and aren't designed to be careful of each
other's locks.</p>

<p>Some conflicts were found through testing, but testing is unlikely to
find all possible conflicts. The counting semaphore problem was not fixed
for three years simply because it took that long to find. Careful examination
of the code might find more but, with many filesystems to examine and with
the kernel under constant change, it would probably take even more than
three years to be confident.</p>

<p>Fortunately Linux has a clever locking validator known as <a
href="https://lwn.net/Articles/185666/">lockdep</a> that is good at
finding these transitive locking issues.
Since <a
href="http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=cf40bd16fdad42c053040bcd3988f5fdedbb6c57">Linux
2.6.30</a>, this validator has known about memory-reclaim context, and will
report a possible deadlock when the memory allocator takes a lock with
<code>__GFP_FS</code> set if that lock can also be held while a memory allocation
request is made.

Had the code which limits the number of processes in reclaim been
annotated so that lockdep knew it was a semaphore, the potential deadlock
would very likely have been detected much more quickly. This was never
done, probably because this code doesn't really <em>look</em> like it is
implementing a semaphore.</p>

<p>To enable lockdep validation for <code>nfsd</code> is it (<a
href="http://permalink.gmane.org/gmane.linux.kernel.mm/115745">almost</a>)
as simple as calling</p>
<p>
<pre>
    lockdep_set_current_reclaim_state(GFP_KERNEL);
</pre>
<p>
<p>
at the same time that <tt>PF_FSTRANS</tt> is set. This tells lockdep that <code>nfsd</code> is
part of the memory reclaim process and other reclaimers could be waiting
for it. Adding this setting easily triggered a number of warnings.

Interpreting the results is not entirely straightforward and there is a
possibility of occasional false positives. The overall message quickly
became clear though: there are really quite a few locks which are held
over a memory allocation and which are taken by <code>nfsd</code>, either directly
or via some call into a filesystem.</p>

<p>Modifying all these allocations to avoid <code>__GFP_FS</code> or
changing all the locking calls to set <code>PF_FSTRANS</code> while the
lock is held would be possible, but that idea would not be (<a
href="http://permalink.gmane.org/gmane.linux.nfs/62273">and was not</a>) 
popular. It would risk upsetting the balance in memory usage, cause
performance problems, and in general it involves more change than is really
justified to support one narrow feature.

So while working with <code>__GFP_FS</code> could well lead to a
solution, it is not a desirable solution. Fortunately there is another
option, as Dave Chinner <a
href="http://permalink.gmane.org/gmane.linux.nfs/62317">helped me to
see</a>.</p> 

<h4>An alternative approach</h4>

<p>As mentioned last week, the dynamics of <code>__GFP_FS</code> changed
significantly in Linux 3.2, when direct memory reclaim stopped writing dirty
pages out through filesystems. As controlling this
writeout was the original purpose of <code>__GFP_FS</code>, it is
reasonable to wonder if it is still filling any role &mdash; or, more specifically:
what role does it now fill?</p>

<p>If we examine all the places in the kernel where <code>__GFP_FS</code>
is used, we find that they fall in to three general classes.  The first of
these is to allow processes to bypass some restrictions in the memory
allocator that do not apply to them; the semaphore example mentioned above
is one of those.

<p>
More importantly, the second class of use is found in the various object
caches in the kernel that
support the <a href="https://lwn.net/Articles/550463/">shrinker</a>
interface.  Shrinkers allow the memory-management subsystem to ask that
objects be removed from caches (and their memory freed) when memory gets
tight. Shrinker-enabled
caches are passed the <code>GFP</code> flags when asked to free some
objects, and some of them decline if <code>__GFP_FS</code> is set,
presumably because they might need a lock that could already be held.</p>

<p>
To understand if shrinker-related deadlocks might appear when loopback NFS
mounts are in use, we need to
understand the cases where the NFS client might, under reclaim, block and wait for
<code>nfsd</code>. The caches which might affect NFS are the generic icache
and dcache (which store inodes and dentries — directory entries) and the
NFS &quot;access cache,&quot; which records the access permissions for
various local users (NFS is not allowed to interpret the mode bits or 
access control list (ACL)
directly, but must ask the server about each different user).

Careful inspection shows that none of these three caches ever contact
the NFS server while freeing items, and they take relatively few
locks, none of which are held by other code that might call the NFS
server. So, if an allocation from <code>nfsd</code> with
<code>__GFP_FS</code> set ever calls a shrinker for one of these caches, there is no
risk of a deadlock.</p>

<p>That just leaves our third class of <code>__GFP_FS</code> use that might be
relevant for loopback NFS, and that is the
<code>releasepage()</code> method. Not all <code>releasepage()</code>
functions care about <code>__GFP_FS</code>, but a few do, specifically
<code>nfs_release_page()</code>.</p>

<h4>Working with <code>releasepage()</code></h4>

<p>The <code>releasepage()</code> method (found in
<tt>struct&nbsp;address_space_operations</tt>) is provided by filesystems
that 
need to attach extra information to each page in the page cache. Often this
is just some per-page metadata that can easily be detached and
discarded. <code>releasepage()</code> is called when memory allocation code
wants to free a given page and reuse it; this call allows that extra information to
be freed first.</p>

<p>The NFS filesystem attaches something more substantial to each
page. When a page of data is written to the NFS server, it is generally just
stored in memory on the server to be written out later. This allows the
NFS <code>WRITE</code> request to return quickly, and improves throughput. If
the server were to crash before the data is written to stable storage, though, the
data would be lost, so the client must hold on to the data until it
subsequently sends a <code>COMMIT</code> request and gets a successful
reply.</p>

<p>The extra information that NFS attaches to each page effectively says
&quot;I haven't sent a <code>COMMIT</code> yet&quot;;
<code>nfs_release_page()</code> has the job of sending that
<code>COMMIT</code>, waiting for a reply, and then releasing the page. This
can clearly trigger a deadlock if (1)&nbsp;<code>nfsd</code> is waiting for an
allocation, (2)&nbsp;that allocation is trying to free a page by calling
<code>nfs_release_page()</code>, and (3)&nbsp;<code>nfs_release_page()</code> is
waiting for a reply from <code>nfsd</code>.

Like shrinkers, <tt>releasepage()</tt> is passed a set of GFP flags; the
NFS <tt>releasepage()</tt> implementation honors the absence of <tt>__GFP_FS</tt>
by refusing to wait for any <tt>COMMIT</tt> operations to complete.
So it appears that the only real effect of setting
<code>PF_FSTRANS</code> in <code>nfsd</code> threads is to tell
<code>nfs_release_page()</code> not to wait for a <code>COMMIT</code> to
complete. There is nowhere else that NFS is likely to block during
allocation: if there were, we would expect to see some <code>__GFP_FS</code>
related protection.</p>

<p>Simply changing <code>nfs_release_page()</code> to not wait at all would
avoid the deadlock, but that change would, without doubt, cause other
problems. As we saw 
last week, there can be real value in slowing down the memory reclaim
process when freeing memory takes a little while, even to the extent of
inserting explicit delays. For similar reasons, waiting in
<code>nfs_release_page()</code> is generally a good idea. The only problem
is in waiting indefinitely.

Once the problem has been phrased this way the answer almost falls
out. If we replace the indefinite wait in <code>nfs_release_page()</code>
(or more accurately in the <code>nfs_commit_inode()</code> function it
calls) with a timed-out wait, then the problem would disappear but the
benefits of waiting would remain.</p>

<p>Choosing the ideal timeout requires a bit of guesswork, though; as
deadlocks don't happen in practice all that often, a fairly long timeout
(maybe even a few seconds) would probably be acceptable. Varying the
timeout depending on whether the <code>COMMIT</code> request was sent out
via an external interface or was routed internally could also help us get the
best of both worlds. This, together with the fact that the
<code>wait_on_bit()</code> interface in the kernel does not currently support
timeouts, are just minor details which are easily understood and nearly as
easily resolved.</p>

<p>What is important is that the entire problem of lockups with loopback
NFS has boiled down to reducing two timeouts. Last-week we found one or two
100ms timeouts that need to be reduced to zero for <code>nfsd</code>. This
week we found an &quot;infinite timeout&quot; that needed to be reduced to
a small value for NFS. It seems to show a certain level of robustness in
the (evolving) design of the Linux kernel that such a complex problem would
have such a simple solution.</p>

<h4>Practice meets theory</h4>

<p>But there is one small part of the whole puzzle that remains
unexplained. Back when first faced with this problem, I assumed that a
deadlock would be inevitable. Clearly I was wrong, as I cannot fault the
logic that led to a solution. But that sort of reasoning rarely
satisfies. Out of all those details, I needed to extract a big-picture
understanding of why a deadlock is not inevitable.</p>

<p>The best way to reason about this problem is play the taxonomy game and
observe that, with respect to automatic freeing of memory, there are five
sorts of memory allocations in the kernel:</p>

<ul>
<li><p>&quot;Fixed allocations&quot; have a wide range of uses, including
holding kernel code and various fixed-sized data structures. As they are
never freed (without external intervention), they don't concern us.</p></li>

<li><p>At the other end of the scale are &quot;cache allocations&quot;,
which store data that could be read from elsewhere. These include file
pages that have not been dirtied and the inode and dentry
caches. Allocations of this type can
be freed easily (providing we don't try to free them in the wrong context
and trigger a deadlock) and so, again, don't concern us.</p></li>

<li><p>&quot;Transient allocations&quot; are usually small; they will be used
for a specific purpose and then freed. A simple example is the
<code>bio</code> structure which carries data through the block layer and
out to disk. To free these, you need only wait.</p></li>

<li><p>&quot;Dirty file pages&quot; we met briefly last week. When any
change is made to a file, a dirty file page results. The total number of
dirty file pages is limited by default to a percentage of
available memory (the specific percentage has varied over time), though
<code>nfsd</code> gets 
a little bonus thanks to <code>PF_LESS_THROTTLE</code>.</p></li>

<li><p>&quot;Dirty anonymous pages&quot; store the data and stack areas for
running processes as well as data in <code>tmpfs</code> filesystems. There
are two ways that this memory can be freed: it can be written out to a swap
partition or file, or the owning process can be killed by the out-of-memory
killer.</p>

<p>An important requirement when writing pages out to swap is that any memory
allocation that might be required must be a &quot;transient
allocation&quot; and must either be preallocated (typically using a <a
href="/Articles/22909/">mempool</a>) or must be allocated
with <code>__GFP_MEMALLOC</code> (described in <a
href="/Articles/594725/">part 1</a>) so that the emergency
reserves can be used. Any <code>__GFP_MEMALLOC</code> allocation that
isn't used for swap-out and isn't a transient allocation is probably a
misuse of the flag.</p></li>

</ul>
<p>With this understanding, the rules for avoiding deadlocks during memory
reclaim are simple:</p>

<ol style="list-style-type: decimal">

<li>When writing out a page, make only &quot;transient&quot;
allocations.</li>

<li>When writing out an anonymous page, the allocations must come from a
<code>mempool</code> or from <code>__GFP_MEMALLOC</code>.</li>

<li>When writing a file page, it is safe to wait for anonymous pages to be
written out, but it is not safe to wait for file pages. So
<code>__GFP_FS</code> must be absent or disabled in such cases.</li>

</ol>
<p>If these rules are followed, then any memory that can be freed will be
freed. Any allocations required to write to swap will come from the
<code>MEMALLOC</code> reserves and any memory required to write to a file
can come from the 60% or more that doesn't contain dirty file data.</p>

<p>Of course, if we tried to support swap-over-NFS over a loopback mount,
things might get a little more … interesting. But that isn't required
for the current use case.</p>

<p>
<h4>Implications for <code>__GFP_FS</code></h4>
<p>
As I try to distill the important lessons to be learned from this exercise, I
find that the deadlocks themselves, which first motivated the exercise, are
little more than annoying distractions.
<p>
There are two important ideas in managing memory reclaim.
One is to slow down or "throttle" processes that are allocating memory, so
they don't allocate memory faster than it can be freed and so that all
processes can get approximately equal access to memory that does become
available.

The second is to balance the amount of work done by the process that is
allocating memory against the amount of work done by dedicated service
processes.  Performing that work in the allocating process (i.e. direct
reclaim) avoids scheduler overhead, but creates contention between the
multiple reclaiming threads and limits the amount of work that can be done as
a unit.
<p>
Allowing direct reclaim to block on arbitrary locks tends to conflate these
two ideas, as the lock serves to both manage contention and to insert delays.
Keeping these 
two ideas separate would involve having separate explicit delays and using
locking primitives, such as <code>mutex_trylock()</code>, which never block but
which can fail.

The use of "trylock" locking would ensure that we minimize scheduler
activity and would directly allow the reclaimer to do the easy work,
while leaving the harder stuff to dedicated service processes like
<code>kswapd</code>.
<p>
The use of explicit delays would follow the model displayed in the patch we
introduced last week; this approach was also used effectively that same year in the
"<a href="/Articles/456904/">No-I/O dirty throttling</a>" changes that
addressed a related problem.
It is in the choice of these delays that <code>__GFP_FS</code> has an
important role.  Throttling a process while it holds locks can easily have a
multiplying effect by slowing down lots of processes waiting on that lock.
By declaring "I'm holding a filesystem lock", <code>__GFP_FS</code> indicates
that a substantial reduction in any delay would be appropriate.
<p>
Though its original reason for existence was to avoid deadlocks, it seems
that the essence of <code>__GFP_FS</code> is really about process priority.
Deadlocks can be worked around in other ways, as we did for the deadlock
created in <code>nfs_release_page()</code> (essentially by introducing
something a little bit like a trylock operation), but process priority
needs to be managed explicitly.  The role played by <tt>__GFP_FS</tt> is to
make part of that priority management explicit.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#gfp_t">gfp_t</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-GFP_flags">Memory management/GFP flags</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Brown_Neil">Brown, Neil</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/596618/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor597105"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Understanding __GFP_FS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 2, 2014 7:10 UTC (Fri)
                               by <b>lkundrak</b> (subscriber, #43452)
                              [<a href="/Articles/597105/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Excellent article.<br>
Thank you!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/597105/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor612028"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Understanding __GFP_FS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 16, 2014 2:54 UTC (Tue)
                               by <b>firolwn</b> (guest, #96711)
                              [<a href="/Articles/612028/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This is what I want to know, thanks.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/612028/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2014, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
