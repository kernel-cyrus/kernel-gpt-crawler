        <!DOCTYPE html>
        <html lang="en">
        <head><title>The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/286233/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/285790/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/286233/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ready to give LWN a try?</b>
<p>
With a subscription to LWN, you can stay current with what is happening in the Linux and free-software community and take advantage of subscriber-only site features.  We are pleased to offer you <b><a href="https://lwn.net/Promo/nst-trial/claim">a free trial subscription</a></b>, no credit card required, so that you can see for yourself.  Please, join us!
</blockquote>
<div class="GAByline">
           <p>June 18, 2008</p>
           <p>This article was contributed by Valerie Aurora</p>
           </div>
<p>
Moore's Law - we all know it (or at least think we do).

To be annoyingly exact, Moore's Law is a prediction that the number of
components per integrated circuit (for minimum cost per component)
will double every 24 months (revised up from every 12 months in the
original 1965 prediction).  In slightly more useful form, Moore's
Law is often used as a shorthand for the continuing exponential growth
of computing technology in many areas - disk capacity, clock speed,
random access memory.  Every time we approach the limit of some key
computer manufacturing technology, the same debate rages: Is this the
end of Moore's Law?  So far, the answer has always been no.
</p>

<p>
But Moore's Law is inherently a statement about human ingenuity,
market forces, and physics.  Whenever exponential growth falters in
one area - clock speed, or a particular mask technique - engineers
find some new area or new technique to improve at an exponential pace.
No individual technique experiences exponential growth for long,
instead migration to new techniques occurs fast enough that the
overall growth rate continues to be exponential.
</p>

<p>
The discovery and improvement of manufacturing techniques is driven on
one end by demand for computation and limited on the other end by
physics.  In between is a morass of politics, science, and plain old
engineering.  It's hard to understand the myriad forces driving demand
and the many factors affect innovation including economies of scale,
cultural attitudes towards new ideas, vast marketing campaigns, and the
strange events that occur during the death throes of megacorporations.
By comparison, understanding the limits of computation is
easy, as long as you have a working knowledge of quantum physics,
information theory, and the properties of black holes.
</p>

<h3>The "Ultimate Laptop"</h3>

<p>
In a paper published in <a href="http://www.nature.com/nature/">Nature</a> in 2000,
<a href=http://www.nature.com/nature/journal/v406/n6799/full/4061047a0.html>Ultimate
Physical Limits of Computation</a> (free
<a href=http://arxiv.org/pdf/quant-ph/9908043>arXiv preprint
[PDF] here</a>), Dr. Seth Lloyd calculates (and explains) the limits of
computing given our current knowledge of physics.  Of course, we don't
know everything about physics yet - far from it - but just as in other
areas of engineering, we know enough to make some extremely
interesting predictions about the future of computation.  This paper
wraps up existing work on the physical limits of computing and
introduces several novel results, most notably the ultimate speed
limit to computation.  Most interesting in my mind is the calculation
of a surprisingly specific upper bound on how many years a generalized
Moore's Law can remain in effect (keep reading to find out exactly how
long!).
</p>

<p>
Dr. Lloyd begins by assuming that we have no idea what future computer
manufacturing technology will look like.  Many discussions of the
future of Moore's Law center around physical limits on particular
manufacturing techniques, such as the limit on feature size in optical
masks imposed by the wavelength of light.  Instead, he ignores
manufacturing entirely and uses several key physical constants: the
speed of light <em>c</em>, Planck's reduced constant <em>h</em>
(normally written as h-bar, a symbol not available in standard HTML,
so you'll have to just imagine the bar), the gravitational
constant <em>g</em>, and Boltzmann's constant <em>kB</em>.  These
constants and our current limited understanding of general relativity
and quantum physics are enough to derive many important limits on
computing.  Thus, these results don't depend on particular
manufacturing techniques.
</p>

<p>
The paper uses the device of the "Ultimate Laptop" to help make the
calculations concrete.  The ultimate laptop is one kilogram in mass
and has a volume of one liter (coincidentally almost exactly the same
specs as a 2008 <a href=http://eeepc.asus.com/>Eee PC</a>), and
operates at the maximum physical limits of computing.  Applying the
limits to the ultimate laptop gives you a feel for the kind of
computing power you can get in luggable format - disregarding battery
life, of course.
</p>

<h3>Energy limits speed</h3>

<p>
So, what are the limits?  The paper begins with deriving the ultimate
limit on the number of computations per second.  This depends on the
total energy, <em>E</em>, of the system, which can be calculated using
Einstein's famous equation relating mass and energy, <em>E =
mc<sup>2</sup></em>. (Told you we'd need to know the speed of light.)
Given the total energy of the system, we then need to know how quickly
the system can change from one distinguishable state to another -
i.e., flip bits.  This turns out to be limited by the Heisenberg
uncertainty principle.  Lloyd has this to say about the Heisenberg
uncertainty principle:
</p>

<div class="BigQuote">
In particular, the correct interpretation of the time-energy
Heisenberg uncertainty principle <em>&Delta;E&Delta;t &ge; h</em>
is not that it takes time <em>&Delta;t</em> to measure energy to an accuracy
<em>&Delta;E</em> (a fallacy that was put to rest by Aharonov and Bohm) but
rather that that a quantum state with spread in energy <em>&Delta;E</em> takes
time at least <em>&Delta;t = &pi;h/2&Delta;E</em> to evolve to an
orthogonal (and hence distinguishable) state. More recently, Margolus
and Levitin extended this result to show that a quantum system with
average energy E takes time at least <em>&Delta;t = &pi;h/2E</em>
to evolve to an orthogonal state.
</div>

<p>
In other words, the Heisenberg uncertainty principle implies that a
system will take a minimum amount of time to change in some observable
way, and that the time is related to the total energy of the system.
The result is that a system of energy <em>E</em> can
perform <em>2E/&pi;h</em> logical operations per second (a logical
operation is, for example, performing the AND operation on two bits of
input - think of it as single bit operations, roughly).  Since the
ultimate laptop has a mass of 1 kilo, it has energy 
<em>E&nbsp;=&nbsp;mc<sup>2</sup></em>&nbsp;=&nbsp;8.9874&nbsp;x&nbsp;10<sup>16</sup> joules.  The ultimate
laptop can perform a maximum of 5.4258&nbsp;x&nbsp;10<sup>50</sup> operations
per second.
</p>

<p>
How close are we to the 5 x 10<sup>50</sup> operations per second
today?  Each of these operations is basically a single-bit operation,
so we have to convert current measurements of performance to their
single-bit operations per second equivalents.  The most commonly
available measure of operations per seconds is FLOPS (floating point
operations per second) as measured by LINPACK (see
<a href=http://en.wikipedia.org/wiki/FLOPS>the Wikipedia page on
FLOPS</a>).  Estimating the exact number of actual physical single-bit
operations involved in a single 32-bit floating point operation would
require proprietary knowledge of the FPU implementation.  The number
of FLOPS as reported by LINPACK varies wildly depending on compiler
optimization level as well.  For this article, we'll make a wild
estimate of 1000 single-bit operations per second (SBOPS) per FLOPS,
and ask anyone with a better estimate to please post it in a comment.
</p>

<p>
With our FLOPS to SBOPS conversion factor of 1000, the current LINPACK
record holder, the Roadrunner supercomputer (near my home town,
Albuquerque, New Mexico), reaches speeds of one petaflop, or 
1000&nbsp;x&nbsp;10<sup>15</sup>&nbsp;=&nbsp;1&nbsp;x&nbsp;10<sup>18</sup>
SBOPS.  But that's for an entire 
supercomputer - the ultimate laptop is only one kilo in mass and one
liter in volume.  Current laptop-friendly CPUs are around one
gigaflop, or 10<sup>12</sup> SBOPS, leaving us about 39 orders of
magnitude to go before hitting the theoretical physical limit of
computational speed.  Finally, existing quantum computers have already
attained the ultimate limit on computational speed - on a very small
number of bits and in a research setting, but attained it nonetheless.
</p>

<h3>Entropy limits memory</h3>

<p>
What we really want to know about the ultimate laptop is how many
legally purchased DVDs we can store on it.  The amount of data a
system can store is a function of the number of distinguishable
physical states it can take on - each distinct configuration of memory
requires a distinct physical state.  According to Lloyd, we have
"known for more than a century that the number of accessible states of
a physical system, <em>W</em>, is related to its thermodynamic entropy
by the formula: <em>S&nbsp;=&nbsp;kB&nbsp;ln&nbsp;W</em>" (<em>S</em> is the thermodynamic
entropy of the system).  This means we can calculate the number of bits
the ultimate laptop can store if we know what its total entropy is.
</p>

<p>
Calculating the exact entropy of a system turns out to be hard.  From
the paper:
</p>

<div class="BigQuote">
To calculate exactly the maximum entropy for a kilogram of matter in a
liter volume would require complete knowledge of the dynamics of
elementary particles, quantum gravity, etc. We do not possess such
knowledge. However, the maximum entropy can readily be estimated by a
method reminiscent of that used to calculate thermodynamic quantities
in the early universe.  The idea is simple: model the volume occupied
by the computer as a collection of modes of elementary particles with
total average energy E.
</div>

<p>
The following discussion is pretty heavy going; for example, it
includes a note that baryon number may not be conserved in the case of
black hole computing, something I'll have to take Lloyd's word on.  But
the end result is that the ultimate laptop, operating at maximum
entropy, could store at least 2.13&nbsp;x&nbsp;10<sup>31</sup> bits.  Of course,
maximum entropy means that all of the laptop's matter is converted to
energy - basically, the equivalent of a thermonuclear explosion.  As
Lloyd notes, "Clearly, packaging issues alone make it unlikely that
this limit can be obtained."  Perhaps a follow-on paper can discuss
the Ultimate Laptop Bag...
</p>

<p>
How close are modern computers to this limit?  A modern laptop in 2008
can store up to 250GB - about 2&nbsp;x&nbsp;10<sup>12</sup> bits.  We're about
19 orders of magnitude away from maximum storage capacity, or about 64
more doublings in capacity.  Disk capacity as measured in bits per
square inch has
<a href=http://www.sciam.com/article.cfm?id=kryders-law>doubled about
30 times between 1956 and 2005</a>, and at this historical rate, 64
more doublings will only take about 50 - 100 years.  This
isn't the overall limit on Moore's law as applied to computing, but it
suggests the possibility of an end to Moore's law as applied to
storage within some of our lifetimes.  I guess we file system
developers should think about second careers...
</p>

<h3>Redundancy and error correction</h3>

<p>
Existing computers don't approach the physical limits of computing for
many good reasons.  As Lloyd wryly observes, "Most of the energy [of
existing computers] is locked up in the mass of the particles of which
the computer is constructed, leaving only an infinitesimal fraction
for performing logic."  Storage of a single bit in DRAM uses "billions
and billions of degrees of freedom" - electrons, for example - instead of
just one degree of freedom.  Existing computers tend to conduct
computation at temperatures at which matter remains in the form of
atoms instead of plasma.
</p>

<p>
Another fascinating practical limit on computation is the error rate
of operations, which is bounded by the rate at which the computer can
shed heat to the environment.  As it turns out, logical operations
don't inherently require the dissipation of energy, as von Neumann
originally theorized.  Reversible operations (such as NOT) which do
not destroy information do not inherently require the dissipation of
energy, only irreversible operations (such as AND).  This makes some
sense intuitively; the only way to destroy (erase) a bit is to turn
that information into heat, otherwise the bit has just been moved
somewhere else and the information it represents is still there.
Reversible computation has been implemented and shown to have
extremely low power dissipation.
</p>

<p>
Of course, some energy will always be dissipated, whether or not the
computation is reversible.  However, the erasure of bits - in
particular, errors - requires a minimum expenditure of energy.  The
rate at which the system can "reject errors to the environment" in the
form of heat limits the rate of bit errors in the system; or,
conversely, the rate of bit errors combined with the rate of heat
transfer out of the system limits the rate of bit operations.  Lloyd
estimates the rate at which the system can reject error bits to the
environment, relative to the surface area and assuming black-body
radiation, as 7.195&nbsp;x&nbsp;10<sup>42</sup> bits per meter<sup>2</sup> per
second.
</p>

<h3>Computational limits of "smart dust"</h3>

<p>
Right around the same time that I read the "Ultimate Limits" paper, I
also read
<a href=http://www.amazon.com/Deepness-Sky-Zones-Thought/dp/0812536355/>A
Deepness in the Sky</a> by Vernor Vinge, one of many science fiction
books featuring some form of "smart dust."  Smart dust is the concept
of tiny computing elements scattered around the environment which
operate as a sort of low-powered distributed computer.  The smart dust
in Vinge's book had enough storage for an entire systems manual, which
initially struck me as a ludicrously large amount of storage for
something the size of a grain of dust.  So I sat down and calculated the
limits of storage and computation for a computer one &mu;m<sup>3</sup>
in size, under the constraint that its matter remain in the form of
atoms (rather than plasma).
</p>

<p>
Lloyd calculates that, under these conditions, the ultimate laptop
(one kilogram in one liter) can store about 10<sup>25</sup> bits and
conduct 10<sup>40</sup> single-bit operations per second.  The
ultimate laptop is one liter and there are 10<sup>15</sup>
&mu;m<sup>3</sup> in a liter.  Dividing the total storage and
operations per second by 10<sup>15</sup> gives us 10<sup>10</sup> bits
and 10<sup>25</sup> operations per second - about 1 gigabyte in data
storage and so many FLOPS that the prefixes are meaningless.
Basically, the computing potential of a piece of dust far exceeds the
biggest supercomputer on the planet - sci-fi authors, go wild!  Of
course, none of these calculations take into account power delivery or
I/O bandwidth, which may well turn out to be far more important limits
on computation.
</p>

<h3>Implications of the ultimate laptop</h3>

<p>
Calculating the limits of the ultimate laptop has been a lot of fun,
but what does it mean for computer science today?  We know enough now
to derive a theoretical upper bound for how long a generalized Moore's
Law can remain in effect.  Current laptops store 10<sup>12</sup> bits
and conduct 10<sup>12</sup> single-bit operations per second.  The
ultimate laptop can store 10<sup>31</sup> bits and conduct
10<sup>51</sup> single-bit operations per second, a gap of a factor of
10<sup>19</sup> and 10<sup>39</sup> respectively.  Lloyd estimates the
rate of Moore's Law as 10<sup>8</sup> factor of improvement in areal
bit density over the past 50 years.  Assuming that both storage
density and computational speed will improve by a factor of
10<sup>8</sup> per 50 years, the limit will be reached in about 125
years for storage and about 250 years for operations per second.  One
imagines the final 125 years being spent frantically developing better
compression algorithms - or advanced theoretical physics research.

<p>
Once Moore's Law comes to a halt, the only way to increase computing
power will be to increase the mass and volume of the computer, which
will also encounter fundamental limits.  An unpublished paper entitled
<a href=http://arxiv.org/abs/astro-ph/0404510>Universal Limits on
Computation</a> estimates that the entire computing capacity of the
universe would be exhausted after only 600 years under Moore's Law.
</p>

<p>
250 years is a fascinating in-between length of time.  It's too far
away to be relevant to anyone alive today, but it's close enough that
we can't entirely ignore it.  Typical planning horizons for long-term
human endeavors (like managing ecosystems) tend to max out around 300
years, so perhaps it's not unthinkable to begin planning for the end
of Moore's Law.  Me, I'm going to start work on the LZVH compression
algorithm, tomorrow.
</p>

<p>
One thing is clear: we live in the Golden Age of computing.  Let's
make the most of it.
</p>

<p>
Valerie Henson is a <a href=http://vahconsulting.com>Linux consultant
    specializing in file systems</a> and owns a one kilo, one liter laptop.
</P><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Kernel_Hackers_Bookshelf">Kernel Hacker's Bookshelf</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Aurora_Henson_Valerie">Aurora (Henson), Valerie</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/286233/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor286701"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 2:52 UTC (Thu)
                               by <b>dskoll</b> (subscriber, #1630)
                              [<a href="/Articles/286701/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      Ray Kurzweil expands on this topic in his interesting (if somewhat repetitive) book <a href="http://singularity.com/">The Singularity is Near</a>.  Worth reading.

      
          <div class="CommentReplyButton">
            <form action="/Articles/286701/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286739"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 10:12 UTC (Thu)
                               by <b>Hanno</b> (guest, #41730)
                              [<a href="/Articles/286739/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      The singularity is <i>not</i> near. To be blunt, the singularity phenomenon is the quasi-religious expectation that a brighter tomorrow through technology is "certain" and universal deliverance of mankind is just around the corner.<p>

The pretty good (though equally repetitive) book "Future-Hype" by Bob Seidensticker makes a good counter-argument:<p>

Humans always made the mistake to extrapolate the future based on present development. When a rush of development in one technology leads to a jump in innovation, people would expect "exponential growth" in that area.<p>

But that growth is not "exponential", it is only a significant jump compared to history, and it <i>ends</i>. Only because a jump in a different technology niche follows and futurists stop thinking about the previous jump anymore - that new tech is by now commenplace - doesn't mean that technology <i>as such</i> is developing at exponential rate and leading to a singularity.<p>

Look at previous jumps in innovation: Steam, atomic power, plastics - each time when we were in their golden ages, people expected a superbright future based on these innovations.<p>

&gt; We live in the Golden Age of computing.<p>

Indeed. And in history, each of those golden ages ended.
      
          <div class="CommentReplyButton">
            <form action="/Articles/286739/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286757"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Kurzweil</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 11:03 UTC (Thu)
                               by <b>corbet</b> (editor, #1)
                              [<a href="/Articles/286757/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      You missed the book suggestion - it <i>is</i> a worthwhile read - at least much of the first half of it is.  One of the things he asserts is that the exponential growth we are seeing now is not "present development"; it is, instead, a trend which has been going on for a good two billion years.  Contemporary electronics is just the current substrate upon which the growth of complexity is being carried out.
<p>
The notion of the singularity, incidentally, is not necessarily as utopian as you suggest here.
<p>
I'm not saying that arguments like Kurzweil's are necessarily correct - no doubt there's plenty of ways to poke holes in them.  But it's best to understand them first.
      
          <div class="CommentReplyButton">
            <form action="/Articles/286757/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286760"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Kurzweil</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 11:17 UTC (Thu)
                               by <b>Hanno</b> (guest, #41730)
                              [<a href="/Articles/286760/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <i>You missed the book suggestion</i><p>

I read it and found it interesting and tiring.<p>

<i>the exponential growth we are seeing now</i><p>

...would only be "exponential" if it continued. Previously in history, humanity experienced a short period of exponential growth in steam, plastics, atomic power. Where is that exponential innovation now?<p>

Painting this as a trend for two billion years is the result of cherrypicking datapoints.
      
          <div class="CommentReplyButton">
            <form action="/Articles/286760/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286985"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Kurzweil</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 21, 2008 0:25 UTC (Sat)
                               by <b>wahern</b> (subscriber, #37304)
                              [<a href="/Articles/286985/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
I haven't read the book, but it seems to me that the point is that certain advancements in
computation are universal, and previous industries can be considered as serial advancements in
(or facilitators of) general computational capabilities. So it doesn't matter that
advancements in steam engines were finite; rather that subsequent advancements made possible
by steam engines, no matter the material industry, had the effect of in kind furthering
[exponential] growth in computational capabilities in general.

Theoretical computational advancement can continually progress as long as materials science,
no matter how disjoint, continually provides sufficient capabilities for the realization of
the next rung on the theoretical ladder.

The overall argument is not particularly persuasive, I agree, but not obviously fallacious.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286985/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor286779"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 13:12 UTC (Thu)
                               by <b>dskoll</b> (subscriber, #1630)
                              [<a href="/Articles/286779/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Yes, Kurzweil's book does have the tone of religious fervour.  I'm not saying I agree with
everything he says, just that the book was interesting.

I'd read it more as a science-fiction extrapolation that non-fiction.

</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286779/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286784"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 13:35 UTC (Thu)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/286784/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
I find Vinge's original concept of the technological singularity to be much more interesting
than Kurzweil's accelerating-progress thing, which suffers from severe selection bias: had he
written that book in 1920, it would have been obvious that an avionics singularity was
approaching by, say, 1990. It didn't happen, because progress in single technological fields
follows S-shaped curves, not exponential ones.

</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286784/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor289793"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jul 13, 2008 16:13 UTC (Sun)
                               by <b>aigarius</b> (guest, #7329)
                              [<a href="/Articles/289793/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
I like the narrative style of the (CreativeCommons licensed) Accelerando more.
<a href="http://www.accelerando.org/book/">http://www.accelerando.org/book/</a>
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/289793/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor286709"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Hmm... H-bar? What's the problem with it?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 5:15 UTC (Thu)
                               by <b>khim</b> (subscriber, #9252)
                              [<a href="/Articles/286709/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <p>Why to do you claim &#8463; does not exist in HTML? Not all browsers support it, true, but most do. Or you can use &#295; - it has slightly wider support...</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/286709/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286838"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Hmm... H-bar? What's the problem with it?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 17:18 UTC (Thu)
                               by <b>vaurora</b> (guest, #38407)
                              [<a href="/Articles/286838/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Thanks for the pointer!  Due to the browser compatibility issues, I'll stick with
well-supported symbols.  HTML is not the ideal medium for physics.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286838/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286869"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Hmm... H-bar? What's the problem with it?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 21:13 UTC (Thu)
                               by <b>kraney</b> (guest, #52619)
                              [<a href="/Articles/286869/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
That's funny, given that HTML was invented by a physicist for the purpose of sharing physics 
papers. Everyone else is a squatter.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286869/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor286883"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Hmm... H-bar? What's the problem with it?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 22:33 UTC (Thu)
                               by <b>leoc</b> (guest, #39773)
                              [<a href="/Articles/286883/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      Why not render the equations with tex as <a href="http://www-cs-staff.stanford.edu/~uno/">god</a> intended.
      
          <div class="CommentReplyButton">
            <form action="/Articles/286883/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor287666"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Hmm... H-bar? What's the problem with it?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 26, 2008 16:52 UTC (Thu)
                               by <b>SEMW</b> (guest, #52697)
                              [<a href="/Articles/287666/">Link</a>] 
      </p>
      
      </div>
      </summary>
      I'll second the motion.  If anyone's interested, my favourite way of embeding Tex in web pages is <a rel="nofollow" href="http://www.math.union.edu/~dpvc/jsmath/">jsmath</a>, which has excellent browser support and uses the proper TeX fonts if you have them installed (images and unicode fonts if you don't).  

MathML is the other option, but very few browsers support it at the moment (I think Opera 9.5 is the only one to fully support it out-of-the-box, though Firefox is on its way).
      
          <div class="CommentReplyButton">
            <form action="/Articles/287666/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor286973"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Hmm... H-bar? What's the problem with it?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 20, 2008 22:49 UTC (Fri)
                               by <b>dvdeug</b> (guest, #10998)
                              [<a href="/Articles/286973/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
The last browser that had any problem with that was Netscape 4. (No, lynx handles it just
fine.) Basic Latin characters used by major European languages (like Maltese) are supported by
everyone and have been for a long time.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286973/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor286710"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 5:18 UTC (Thu)
                               by <b>pr1268</b> (subscriber, #24648)
                              [<a href="/Articles/286710/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>Neat stuff, thanks for the article.  I am fascinated by physics and quantum mechanics, and it's interesting and fun to ponder and analyze computational limits due to quantum effects.</p>

<p>On a slightly related topic, with regards to computing speed, Bjarne Stroustrup said it best when he exclaimed that the "next generation of Intel chips can do an infinite loop in five minutes!" :-D</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/286710/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor286718"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compression</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 6:28 UTC (Thu)
                               by <b>smurf</b> (subscriber, #17840)
                              [<a href="/Articles/286718/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Nice!

I've already invented the ultimate compression, or rather compression-avoidance, algorithm. It
involves a time machine which sends the file names of all the data that hasn't been accessed
at all in the last 100 years, back to the present.

Somebody else can please invent the time machine. Receiver only, for now; we've got another
100 years for the transmitter.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286718/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286758"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Not just the ultimate compression algorithm</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 11:54 UTC (Thu)
                               by <b>emk</b> (subscriber, #1128)
                              [<a href="/Articles/286758/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <p>Such a time machine also allows you to send bits back in time. Let's say you want to know whether the Cubs win the World Series sometime between now and 2107. Simply create a file named "yes-they-won.txt". If the Chicago Cubs win, access that file. Presto! Your "compression" algorithm can now be used to tell whether or not the victory occurred / will occur.</p>

<p>If you want to place bets, create 100 files named "2008", "2009", "2010", etc. Then, at the beginning of each year the Cubs win the World Series, max out your credit cards and stake your entire fortune on the Cubs winning.</p>

<p>But this turns out to be an amazing waste of your "compression" algorithm. As it turns out, once you can send bits back in time, you can build a <a href="http://64.233.169.104/search?q=cache:1vpaaAWZb9UJ:www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1991/TempComp.html">negative time delay element</a>, a circuit component that shifts its inputs back in time. This, in turn, allows you solve NP-complete problems in polynomial time, as described in the Moravec article I just linked.</p>

<p>And if NP is equal to P, then you've built something much more powerful than a quantum computer. Specifically, you can answer virtually any question you can ask, provided the correctness of that answer can be checked in polynomial time. And this, in turn, has further <a href="http://www.scottaaronson.com/talks/anthropic.html">surprising consequences</a>:</p>

<blockquote>But another reason we believe P&#8800;NP is that otherwise mathematical creativity could be automated! You'd simply ask your computer: "Is there a proof of the Riemann hypothesis with at most a million symbols?" And if there is such a proof, the computer will find it in some way dramatically faster than searching through every possibility. If P=NP, you wouldn't merely have solved one of the seven million-dollar problems from the Clay Math Institute -- presumably you could also solve the other six.</blockquote>

(See also the section titled "Linearity" in <a href="http://www.scottaaronson.com/democritus/lec9.html">another of Scott Aaronson's lectures</a>, which links to a paper analyzing a number of related problems in physics.)

      
          <div class="CommentReplyButton">
            <form action="/Articles/286758/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286780"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Not just the ultimate compression algorithm</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 13:21 UTC (Thu)
                               by <b>alankila</b> (guest, #47141)
                              [<a href="/Articles/286780/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Fascinating article. Thanks a lot for writing it.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286780/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor286724"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 6:57 UTC (Thu)
                               by <b>AlexHudson</b> (guest, #41828)
                              [<a href="/Articles/286724/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
"entire computing capacity of the university" - while no doubt academic institutions carry a
great deal of computing capacity these days, I suspect that should read "universe"? 
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286724/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286750"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 10:08 UTC (Thu)
                               by <b>NRArnot</b> (subscriber, #3033)
                              [<a href="/Articles/286750/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Maybe, but Pratchett fans will be delighted if it's <I>not</i> a typo!
      
          <div class="CommentReplyButton">
            <form action="/Articles/286750/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor286759"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Typo</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 11:05 UTC (Thu)
                               by <b>corbet</b> (editor, #1)
                              [<a href="/Articles/286759/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      What if it's a really <i>big</i> university?
<p>
Clearly a typo, I'm not quite sure how we missed it.  Fixed now.
      
          <div class="CommentReplyButton">
            <form action="/Articles/286759/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286806"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Accademic compression</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 15:20 UTC (Thu)
                               by <b>utoddl</b> (guest, #1232)
                              [<a href="/Articles/286806/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      This nicely ties back to the compression discussion above, as the <em>accademic compression</em> technique can squeeze an entire semester's work down to a single letter and an optional "+" or "-" qualifier.
      
          <div class="CommentReplyButton">
            <form action="/Articles/286806/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286923"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Academic compression</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 20, 2008 14:40 UTC (Fri)
                               by <b>mtorni</b> (guest, #3618)
                              [<a href="/Articles/286923/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
If you drop the optional qualifier you can increase the (already lossy) compression and
achieve a notable compression with a tiny loss in useful resolution.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286923/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor287121"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Academic compression</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 23, 2008 17:17 UTC (Mon)
                               by <b>salimma</b> (subscriber, #34460)
                              [<a href="/Articles/287121/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Yes; from 4 bits to 3 bits; a saving of 25% !
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/287121/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor287565"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Academic compression</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 26, 2008 8:27 UTC (Thu)
                               by <b>forthy</b> (guest, #1525)
                              [<a href="/Articles/287565/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>But most of the mark details are useless, all you require is a single 
bit "pass" or "fail". Nobody is going to read your detailed marks for 
each semester exam later in your career. For all reasonable degrees, it's 
basically a two-bit information: Dropout, Bachelor, Master, PhD. Don't 
think "dropout" is a career limiter: The world's richest man is a 
dropout.</p>

<p>I'm quite sure I'll see several limits to the exponential growth in my 
lifetime (probably the next 50 years), at least I already experience one 
(probably temporal) limit: clock frequency didn't go up much the last 5 
years. There however is a way to get more power out of computers: write 
better software. It is amazing what vintage computer fans get out of 
ancient designs. We are used to write software for computers that get 
faster and have more memory, so we write a lot of slow, bloated 
software.</p>

<p>Due to the fact that single-threaded CPUs don't get (significantly) 
faster anymore, we probably should start right now: Use better algorithms 
to make single-threaded programs faster.</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/287565/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor286732"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Storage increase in laptops:</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 8:04 UTC (Thu)
                               by <b>deleteme</b> (guest, #49633)
                              [<a href="/Articles/286732/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      name: storage, released<br>
<a href="http://en.wikipedia.org/wiki/TRS-80_Model_100_line">TRS-80 Model 100</a>: 8KB, 1983<br>
<a href="http://www.elonexone.co.uk/">Mini Linux Laptop</a>: 2GB, 2008<br>
<p>

That's 6 orders of magnitude in 25 years.. Not that I can buy a Model 100 for 99.
      
          <div class="CommentReplyButton">
            <form action="/Articles/286732/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor287215"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Storage increase in laptops:</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 24, 2008 7:29 UTC (Tue)
                               by <b>ekj</b> (guest, #1524)
                              [<a href="/Articles/287215/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
The scary thing, or atleast the mindboggling one is trying to extrapolate this and imagine
what we'll be DOING with it.

Okay, so you say 6 OOM in 25 years. I think if you compare similarily-priced computers its
actually more than that. The TRS-80 cost a lot more (inflation-corrected) in 1983 than a 2GB
laptop cost today. I think the real number is more like 7OOM.

So, what does that mean if present trends continue for the NEXT 25 years ?

2GB * 10^7 ram.

It's a -gargantuan- number, it means your laptop by then will have more RAM than the
googlecluster has today. Infact it'll have RAM comparable to the sum total of ALL laptops in
USA today, give or take a OOM.




</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/287215/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor287587"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Storage increase in laptops:</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 26, 2008 11:36 UTC (Thu)
                               by <b>Duncan</b> (guest, #6647)
                              [<a href="/Articles/287587/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
However, there's another dimension that you've failed to figure in, that 
of overall computer size.  It turns out that at least for the past 25-50 
years (the 50 years earlier measured, or the 25 here) at least, we've 
found the practical benefits of overall computer miniaturization 
beneficial as well, such that in practice they've absorbed some of those 
OOMs you mention.  It's the oft pointed out main-frame (room size) &gt; 
mini-computer (large appliance size) &gt; desktop (medium appliance size) &gt; 
laptop (small appliance size) &gt; handheld/umpc &gt; cell-phone &gt; watch... 
trend.  As storage and computation increases, we've chosen to trade off an 
OOM every decade or so to graduate to the next smaller sized unit.

If the per-decade size generation trend continues, normal people won't be 
using laptops anymore in 25 or even, really, 10 years, as we'll downshift 
a size or two or three instead.  Just as trends indicate people are now 
switching to laptops instead of desktops and UMPCs instead of laptops, 
because the smaller size now has more power than the larger size did a few 
years previously and it's all the power really needed at that usage point, 
a decade from now, computers the size (and likely cost as well) of today's 
remotes/MP3-players/cell-phones will be the norm (low/high-end), while 
packing the computing power of today's dual-quad-core servers.

OTOH, we're up against the wall of the human body's I/O limitations 
already, probably the reason we didn't migrate smaller several years ago, 
when the computing power of a desktop first exceeded that really necessary 
for office applications and the like.  Some people just like a full sized 
keyboard and a nice sized display, and that human interface is *NOT* 
shrinking with Moore's law, unfortunately.

For decades, Science Fiction's answer has been change the interface, voice 
recognition and eye-glasses displays, with direct neural tap interfaces 
predicted beyond that, but the required AI and materials science hasn't 
really made that first leap practical as yet, tho it /is/ tantalizingly 
close... but we've thought that for over a decade, as well.

Still, the keyboard and large external display as human I/O method is 
simply going to have to give if we're to graduate down below the UMPC 
level.  Or maybe we'll end up with ubiquitous built-in 
keyboard/display/Internet units everywhere, and plugin/wireless-in our 
multi-terabyte-storage-multi-cored-USB-thumb-drive-sized "personal 
computer" everywhere we go, much as folks are doing with the thumb-drives 
themselves today?

Or, just perhaps, the just-a-few-years long trend of actually shrinking 
cost will become the dominant factor going forward, and those now $400 
UMPCs like the Eee and friends will be $30-50 or even &lt;$10, while 
containing the power and storage of today's big-drive quad-core 
desktop/servers, but with the permanent data stored "in the cloud" and 
with I/O to ubiquitous permanent displays/keyboards where needed as 
mentioned above, so the individual units become disposable, like the 
digital watches one can now buy in the dollar store.

I really do think that the average person's usage really is being met now, 
thus the focus on smaller but more important CHEAPER we are seeing, and 
that that fact is not going to change -- UNLESS some "killer app" like 
truly practical general purpose (not limited purpose/vocab as we see now) 
voice recognition and hidef spectacles displays suddenly appear.  
If /that/ happens, then we'll see the drive to smaller (but with whatever 
resources are necessary to drive the voice recognition AI) reassert itself 
over cheaper, down to the point they can be embedded in the eye-glasses 
themselves.  Since such a practical general purpose voice recognition AI, 
should it appear, is likely to be fairly resource intensive for even 
today's multi-core desktops, the process of miniaturizing the hardware 
(and power requirements) to the watch-battery size point, for embedding in  
those spectacles, is going to take a fair bit of that 25 years, anyway.  
Beyond that... well, we'll just have to see where that 
neuromanceresqe "jacking in" tech is, at that point.

Duncan
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/287587/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor287612"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Storage increase in laptops:</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 26, 2008 13:44 UTC (Thu)
                               by <b>ekj</b> (guest, #1524)
                              [<a href="/Articles/287612/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
That's true. You get a 7oom quicker computer for $5000 now, compared to a similar sum of money
(inflation discounted) 25 years ago.

But people don't BUY those. They buy $500 - $1000 computers instead, and spend some extra on
getting small rather than powerful at that. (laptop-hds are much more expensive pro GB than
desktop-hds)

It's already all in the IO. I've got one 17" laptop and one 12", the difference isn't in the
power (it's there, but I rarely care) but in the fact that the 17" is just better if I need a
lot of screen pixels or a lot of physical screen-size.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/287612/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor286733"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Obligatory...</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 8:18 UTC (Thu)
                               by <b>yodermk</b> (guest, #3803)
                              [<a href="/Articles/286733/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
10^31 bits should be enough for anyone ...


Interesting stuff, thanks!
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286733/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor286735"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 8:25 UTC (Thu)
                               by <b>eskild</b> (guest, #1556)
                              [<a href="/Articles/286735/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Lovely! It was nice to get my head out of obscure bugs in obscure networking protocols for a
while.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286735/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor286737"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Power usage?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 8:37 UTC (Thu)
                               by <b>epa</b> (subscriber, #39769)
                              [<a href="/Articles/286737/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
As you mentioned, these numbers don't take any account of power usage or heat dissipation.  It
would be interesting to know the theoretical limits of a one kilogram, one litre computer
drawing one watt of power.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286737/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286768"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Power usage?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 12:02 UTC (Thu)
                               by <b>emk</b> (subscriber, #1128)
                              [<a href="/Articles/286768/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <p>Basically, if you're worried about power and heat, you want to know the fundamental limits of <i>reversible</i> computation. A reversible computation is, of course, a reversible machine, and therefore uses no energy (except for output bits). Richard Feynman actually wrote a <a href="http://www.amazon.com/Feynman-Lectures-Computation-Richard-P/dp/0738202967">nice essay</a> on this problem. And as it turns out, you can still do an insane amount of computation per unit time, under the laws of physics.</p>

<p>Of course, it's probably impossible to actually construct a true reversible machine, although certain small-scale quantum phenomenon, such as superconductivity, come surprisingly close.</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/286768/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286897"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Power usage?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 20, 2008 8:39 UTC (Fri)
                               by <b>epa</b> (subscriber, #39769)
                              [<a href="/Articles/286897/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
I was just thinking of normal, non-reversible computation, constrained to dissipate at most
one watt of heat.

Do any reversible computing devices currently exist?  (Yes, I know a NOT gate exists, but I
mean something computationally more powerful than that, preferably Turing-machine-equivalent,
and specially designed to use the properties of reversible computation to minimize power
consumption.)
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286897/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor287043"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Power usage?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 23, 2008 6:00 UTC (Mon)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/287043/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <A HREF="http://www.eng.fsu.edu/~mpf/CF05/RC-abstracts.htm">There sure are.</A>  One of the papers apparently describes a simple 8-bit reversible CPU.

      
          <div class="CommentReplyButton">
            <form action="/Articles/287043/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor286738"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 8:50 UTC (Thu)
                               by <b>__alex</b> (guest, #38036)
                              [<a href="/Articles/286738/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
"Of course, none of these calculations take into account power delivery or I/O bandwidth,
which 
may well turn out to be far more important limits on computation."

I was under the impression that both of these things pretty much already are the biggest
limits on 
computation?
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286738/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor286745"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 9:45 UTC (Thu)
                               by <b>flewellyn</b> (subscriber, #5047)
                              [<a href="/Articles/286745/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Really glad we're having more of these Val Henson articles.  She always has something
fascinating to write about.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286745/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor286749"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 10:07 UTC (Thu)
                               by <b>produit</b> (guest, #35640)
                              [<a href="/Articles/286749/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Your number of micron cube in the ultimate laptop is wrong.
There are 10^18 micron cube in a m^3 so 10^15 in the laptop.
So the memory you can store in a grain of dust is not so impressive
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286749/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286837"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 17:16 UTC (Thu)
                               by <b>vaurora</b> (guest, #38407)
                              [<a href="/Articles/286837/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Yes, that's an error - thank you for catching it!  The correction is on the way.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286837/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor286755"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 10:44 UTC (Thu)
                               by <b>enodev</b> (guest, #14913)
                              [<a href="/Articles/286755/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Why doesn't the author take the volume of a modern cpu or hard disk into account when
calculating the storage/calculation power of a current laptop? I mean the data storing volume
of a 2.5" hard disk platter is about 
(3.14*6cm^2*50um) = 6e-4 dm^2 ~= 1e-3 dm^3. So only 16 orders of magnitude to go... . Same
applies for the volume of a cpu die. Or do I miss something?
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286755/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286839"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 17:22 UTC (Thu)
                               by <b>vaurora</b> (guest, #38407)
                              [<a href="/Articles/286839/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
In the original article, the author makes it much more clear that we are assuming nothing
about what the technology of computers in the future looks like.  In particular, we're not
assuming that the storage of the computer is compartmentalized into a small box containing
spinning rust-covered disks. :) All the calculations are based solely on the mass and volume
of the computer, with no assumptions about distribution.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286839/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor286775"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 13:32 UTC (Thu)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/286775/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
The ultimate laptop looks like a thermonuclear explosion? If only! There's lots of actual
organized matter in that (e.g. it's not all monatomic hydrogen plasma so there's order in the
nuclei).

It's more like the aftermath of a total annihilation reaction: a blast of elementary particles
and wide-spectrum (mostly high-energy) radiation, all, of course, precisely positioned so that
it interacts neatly.

The engineering challenges involved in building this thing are significant :) and how you do
I/O I have not the least idea. I imagine you'd need smaller computers to mediate between the
ultimate laptop and anything else. This is post-Transcend stuff ;}

(Oh, and, er, why does this need to be on a kernel hacker's bookshelf exactly? I know the life
of a Linux kernel hacker is an exciting and never-ending whirl, but I didn't think it was
*this* exciting.)
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286775/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor286785"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 13:40 UTC (Thu)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/286785/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
As an aside, if you want to consider even higher physical limits by making the computer as
dense as you possibly can in order to push up its mass and energy density, you start getting
into really interesting and bizarre stuff applying to black-hole-density computational
devices, like the holographic principle and the Bekenstein bound.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286785/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor286822"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 19, 2008 17:02 UTC (Thu)
                               by <b>bobort</b> (guest, #5019)
                              [<a href="/Articles/286822/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
The number of SBOPs per FLOP has not been constant over time, and it isn't really obvious how
that's going to change in the future.  Remember you have to account for all of the control
infrastructure, which dwarfs the arithmetical logic on a modern CPU - thousands of
multiplexers, comparators, buffers, lookup tables, signal repeaters, etc. just to get the data
from memory to the ALU and back - and the trip gets farther every year.  I suspect there are
more like 100k SBOPs per FLOP in a typical CPU, but that's a guess.

Will things get more or less "efficient" over time?  It's very hard to say, there are powerful
forces pulling in both directions.  I'd say the biggest undetermined aspect is whether we can
weasel around Amdahl's law, or how much.  How parallelizable will the software running on the
ultimate laptop be?  If everything ends up being highly parallelized, microarchitecture is
likely to evolve towards simplicity and SBOPs per FLOP will probably stay roughly the same or
even come down a bit.  If nobody comes up with a way around Amdahl (which is a rigorous
theorem unlike Moore's "law"), single-thread performance will need to be continually
increased, and that will increase SBOPs per FLOP over time.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286822/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor287044"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 23, 2008 6:05 UTC (Mon)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/287044/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
I imagine an ultimate laptop would look more like a dataflow machine of some sort where
functional units are connected directly to neighboring functional units rather than time
multiplexing instructions through a smaller set of functional units with all the overhead you
describe.

After all, with that many compute elements, why wouldn't you?  I imagine data storage would
largely return to a delay element model too, just for its compactness.  Since compute elements
would be in contact with all the data elements at any given time, you could easily access all
of your data in parallel and do *something* with it, even if it's just moving it along.  The
sheer dynamics of such a dense system would mean that the data has to keep moving though.
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/287044/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor286892"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">gravitational constant is G not g</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 20, 2008 3:27 UTC (Fri)
                               by <b>stuart_hc</b> (guest, #9737)
                              [<a href="/Articles/286892/">Link</a>] 
      </p>
      
      </div>
      </summary>
      A small point, but the gravitational constant by convention is written with a capital <em>G</em> not a lowercase <em>g</em>.
      
          <div class="CommentReplyButton">
            <form action="/Articles/286892/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor286953"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">1000 single bit operations per FLOP</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 20, 2008 17:42 UTC (Fri)
                               by <b>mikov</b> (guest, #33179)
                              [<a href="/Articles/286953/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
I wonder how accurate the 1000 single-bit operations estimation is. Mind you, I am not a
electronic design expert, so this is just rambling. 

I've been thinking that a 1-bit adder has three inputs, so it has a 8-entry truth table. (Each
entry looks like something like "o=i1 &amp; ~i2 &amp; i3").
After optimizations, I am counting 18 single bit operations ("ands" and "nots"). It has two
outputs, I guess that is just double the whole thing  to 36.

So for a 32-bit integer adder we have 32*36=1152 single-bit operations operations. The
straight-forward multiplier, which they thought us in school, will do an addition per set bit,
so  if we assume 16 set bits on average, we get 18432 single bit ops, ignoring the shifts.

So, when using the most simplistic algorithms, the 1000 operations number seems far too
optimistic. 

Can someone do a similar estimation for the super-clever algorithms they actually use the CPUs
? (There is a detailed description in "Computer Architecture: A Quantitative Approach", but I
never understood it well enough to actually keep it in my head, and the book is not with me.
Oh yes, and I am lazy)


</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/286953/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor287045"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">1000 single bit operations per FLOP</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 23, 2008 6:56 UTC (Mon)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/287045/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <P>First, let's assume that each computation is done in the minimum number of steps possible.  Many of the transistors spent in functional units today are spent on making a single copy of the operation go faster.  When computing at an atomic scale, this probably no longer makes sense.  It probably makes more sense to make each operation as simple and economical as possible so you can put down as many copies as you like precisely where they're needed.</P>
<P> With volume computing you'll have so much more connectivity to neighbors that economical implementations would likely win out.  For instance, a carry-select adder, which computes two versions of the result speculatively and throws away one, wouldn't make sense since it's much, much larger than a ripple-carry adder.  (IIRC, a state of the art 32-bit adder is around 3000 transistors, whereas a 32-bit ripple carry adder should be around 700 or so.)</P>
<P>A 1 bit full-adder&mdash;3 inputs, 2 outputs&mdash;consists of two pieces:  The sum computation, which is two two-input XOR gates, and the carry computation, which is 3 two-input AND gates and 2 two-input OR gates. The logic equations are:</P>
<UL><LI>sum_out = a XOR b XOR carry_in</LI>
<LI>carry_out = (a AND b) OR (a AND c) OR (b AND c)</LI>
</UL>
<P>
If you assume a ripple carry implementation, then that's it.  7 operations per bit if you allow the full complement of boolean operations.  So, a 32-bit add will be a mere 224 boolean operations.  Even if you penalize XOR and count them as 3 bit operations each, that's still only 352 boolean operations.  Of course, IEEE-754 floating point isn't built around 32-bit adds. 
You go through the following major steps for a single-precision floating point addition:

<P>(For now I assume a parallel implementation since it doesn't really affect the number of SBOPs.  Also, I assume the more conservative 11 SBOP number for a single bit full adder.)
</P>
<OL>
<LI>Subtract the mantissas to get the "alignment difference" between the two numbers.  This is an 8 bit subtract, IIRC, so would cost 88 SBOPs.</LI>
<LI>Shift the numbers to align them.  To be conservative, I'll say this comprises the following steps in a simplistic implementation:</LI>
<OL type="a"><LI>Swap the two numbers based on the sign of the difference of the magnitudes.  This requires 24 2:1 muxes, and each 2:1 mux costs 3 SBOPs, for a cost of 2 &times; 24 &times; 3 = 144 SBOPs.</LI>
<LI>Shifting the smaller magnitude number to the right by up to 24 positions.  If you structure this as 5 layers of 2:1 muxes (which is overkill, since some of the inputs will be zero and so this could be optimized), you get 5 &times; 24 &times; 3 = 360 SBOPs.</LI>
</OL>
<LI>Apply the sign to both numbers.  IEEE-754 is stored in sign-magnitude form.  To apply the sign, you merely need to XOR the number with the sign and inject an appropriate carry when you do the addition.  Thus, we can estimate this as 48 XORs, which, if you count XOR as 3 SBOPs, is 144 SBOPs.
<LI>Actually add the two 24 bit mantissas.  If we go with 11 SBOPs per bit, this is 264 SBOPs.</LI>
<LI>Strip the sign from the result.  Again, you could simply XOR with the result's sign bit (which should be the carry out of the last adder).  3 &times; 24 = 72 SBOPs.</LI>
<LI>Count the number of leading zeros so that we can renormalize the result.  I don't know off the top of my head how many SBOPs this ought to take.
<LI>Shift the final result to normalize it.  Conservatively, let's use the crummy shifter above which is 5 &times; 24 &times; 3 = 360 SBOPs</LI>
<LI>Update the mantissa.  This is another 8-bit add.  8 &times; 11 = 88 SBOPs.</LI>
</OL>
<P>
So where does that put us in this really basic, if perhaps naive implementation?  Around 1520 SBOPs plus the cost of the priority encoder used for normalization.
</P>
<P>Sure, we haven't handled overflow, underflow, denormals, NaNs and so on.  But, I also have assumed clumsy implementations for some of the more expensive bits, such as the shifters.  If the shifters were half the cost, for example, the total drops to 1160.  Overall, I'd say this quick and dirty analysis validates that Val's SWAG (Scientific Wild Ass Guess) is in the right ball park, and certainly well within an order of magnitude.  Since nearly all the rest of the numbers are expressed in orders of magnitude, being off by 50% ain't so bad.  The log10 of 1.5 is pretty small.</P>
      
          <div class="CommentReplyButton">
            <form action="/Articles/287045/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor287046"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">1000 single bit operations per FLOP</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 23, 2008 7:07 UTC (Mon)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/287046/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <P>Regarding the multiplier...  It turns out that floating point multipliers can get rid of most of the alignment steps that the adder needs to do.  (See my other post.)  You also don't need to apply the sign to your input or your output.  So, you're just left with the addition steps.</P>
<P>A naive 24 &times; 24 multiplier would effectively do 24 24-bit adds.  That's 6336 SBOPs.  Assume for a moment, though, that we can eliminate about half of those because only 24 output bits are needed.  This brings us down to 3168 SBOPs for the multiplier.  Remaining steps:
</P>
<OL><LI>Adding the mantissas:  88 SBOPs.</LI>
<LI>Aligning the result (shift by up to 3 positions, IIRC, implemented as 2 levels of 2:1 mux):  2 &times; 24 &times; 3 = 144 SBOPs</LI>
</OL>
<P>This gives a total of ~3400 SBOPs.  About 2&times; to 3&times; the cost of an adder.</P>
<P>Oh, and that reminds me, you can eliminate one of the argument inversions in my adder estimate above.  That squeezes another 60-70 SBOPs out.  (You do add some other bit inversions here and there on the sign bits, which is why you don't get all 72 back.)</P>

      
          <div class="CommentReplyButton">
            <form action="/Articles/287046/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor287341"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">1000 single bit operations per FLOP</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 24, 2008 22:49 UTC (Tue)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/287341/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
That came off the top of your head?!

Allow me to briefly say 'wow', if so. :)
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/287341/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor287357"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">1000 single bit operations per FLOP</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2008 0:06 UTC (Wed)
                               by <b>mikov</b> (guest, #33179)
                              [<a href="/Articles/287357/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
Wow, thanks! I have nothing to say except to retract my idiotic suggestion of implementing the
adder with a truth table :-)

I have to agree with "nix" that this is very impressive. Your post deserves an article of its
own. 
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/287357/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor287047"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 23, 2008 8:47 UTC (Mon)
                               by <b>ekj</b> (guest, #1524)
                              [<a href="/Articles/287047/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
We're closer than this to universal limits on computation, if it's not reversible computing.

With non-reversible computing, flipping a single bit, as you say, costs energy. There's a
minimum energy it MUST cost, dependant on operating-temperature.

So, how much can a laptop do if it's only allowed to consume 10W, operate non-reversibly, and
operate at room-temperature ? I did the math for rec.arts.sf.science some time back, and may
very well have done it wrong. But I got as a result that we're only ~5 OOM away from the
theoretical limits.

</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/287047/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor288144"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Factoring in I/O</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jul 1, 2008 23:08 UTC (Tue)
                               by <b>jd</b> (guest, #26381)
                              [<a href="/Articles/288144/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
I/O is a relatively simple thing to factor in, provided we assume something analogous to the
Transputer, which communicated to "adjacent" nodes, where "adjacent" would either mean the
physically adjacent Transputers or the ones that would be logically adjacent if you used a
hypercube topology. The latter was generally faster, but here we don't have wires and can't
organize the atoms that way.

Basically, you need to consider a cluster of atoms, such that the cluster supports your
logical operation plus the ability to receive input and the ability to deliver output. The
Transputer used four serial connectors. Could we have more than that, here? Well, that depends
on the maximum density you could pack the atoms and the arrangement they took. The tetrahedron
is a nice, packed structure, and if I remember correctly, gives you 6 bonds per atom. (One
bond to the other three atoms in the tetrahedron, plus one bond to each of the three adjacent
tetrahedrons.) Each bond is capable of conveying data, so each bond can be regarded as a
connector. As with the Transputer, data can flow in either direction but can only flow in one
direction at a given time.

So, your processing atom has 6 lines for I/O. Assuming it can only handle two input lines and
one output line (a very basic gate), you have sufficient lines to process at double the I/O
bandwidth if necessary without running out of data. Assuming an I/O transaction to be simply
the delivery of information to a processing atom used for I/O, a gate operation, and then the
delivery of the result, each I/O operation consumes the time for a gate transaction plus twice
the time it takes for an electron to travel the distance between atoms in this structure.

(Not sending to a specific atom is equal to ANDing with zero, so this drives the heat output
up considerably. We are assuming gate transactions are based on instantaneous input values and
do not need to be actually measured, per se. Otherwise, we need to add in the time for two
independent states to stabilize and be measured, where the two state changes do not take place
simultaneously from the perspective of the observing atom. IIRC, the correct value to use is
1.5x the time it takes to stabilize for a single state.)

So, the total time for a local transaction is now the time for three gate transactions, plus
the time for four electron hops, plus optionally 3x the time it takes for a state to
stabilize. An electron hop is limited by the speed of light, but the exact distance depends on
the forces involved. For simplicity, I will disregard it, but if you want a more accurate
value, I suggest picking the carbon atom and maybe diamond as the structure, then figure out
the correct values from that. The other values are in the article.

However, transactions are multicast. Each I/O atom can deliver to anywhere between zero and
two target processing atoms (assuming it cannot deliver to the originating atom), plus zero to
three other I/O atoms, which can in turn cascade the data to processing atoms and other I/O
atoms. The exact number depends on what happens to be adjacent.

This means a signal can go between any given processing atom and any given set of processing
atoms (excluding any set including itself). We use the per-hop calculation to calculate the
average time for an actual transaction by calculating the average volume you would need to
transmit over. The maximum time is the time for a signal to sweep the entire structure. The
maximum time assuming any-to-any communication will be for the signal to sweep half the
distance.

Because 2/3 of the atoms are used for I/O, and because it takes quite some time for data to
reach a given processing atom, the maximum theoretical speed should be reduced accordingly.

This has assumed we are using electrons to convey data, but we don't have to. An electron, at
suitable speed, striking a nucleus, will release an X-Ray. An X-Ray, at suitable energy,
striking a nucleus, will release an electron. This is known as X-Ray fluorescence and is a
widely-used technique.

This reduces (but does not eliminate) the need to use processing atoms as I/O switches. If
there's line-of-sight, it's possible for an X-Ray to deliver data to a target cluster of
atoms. You would use the cluster to absorb the X-Rays and then deliver the data as electrons
to the processing atom. The processing atom would need to (somehow) fire an electron fast
enough to convert the result back into an X-Ray.

This I/O is point-to-point, not multicast, but has significantly less latency, allowing for
far larger "neighbourhoods".

</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/288144/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor288557"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jul 3, 2008 18:03 UTC (Thu)
                               by <b>mcortese</b> (guest, #52099)
                              [<a href="/Articles/288557/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>So what? It only proves the limits of a 1-kg block of matter, <em>assuming</em> that it will be a reasonable piece of hardware for a laptop.

<p>But by the time we reach the storage limit (to take one), we may have a different concept of what a "laptop" is. For example it could be the union of a 1-kg device with no storage at all, linked to a physically large storage located somewhere far away, with a terabitpersecond wireless connection.

<p>What Dr. Lloyd calls his "Ultimate Laptop", is indeed bound to the current understanding of what a laptop is, which reduces his work back to a mere discussion of the applicability of Moore's Law to a particular manufacturing assumption.

<p>Whether you believe or not that humankind will always find ways to perpetuate Moore's Law through a shift to new techniques, for sure it won't be this paper to give you any proof.
      
          <div class="CommentReplyButton">
            <form action="/Articles/288557/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor293609"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Kernel Hacker's Bookshelf: Ultimate Physical Limits of Computation</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 12, 2008 9:32 UTC (Tue)
                               by <b>muwlgr</b> (guest, #35359)
                              [<a href="/Articles/293609/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment"><pre>
A pair of nanotech/reverscomp articles that amazed me some years ago :
<a rel="nofollow" href="http://www.cise.ufl.edu/research/revcomp/physlim/PhysLim-CiSE/c3fra.pdf">http://www.cise.ufl.edu/research/revcomp/physlim/PhysLim-...</a>
<a rel="nofollow" href="http://www.zyvex.com/nanotech/mechano.html">http://www.zyvex.com/nanotech/mechano.html</a> (like, Babbage engine 
returns!:&gt;)
</pre></div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/293609/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2008, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
