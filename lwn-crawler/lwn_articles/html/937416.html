        <!DOCTYPE html>
        <html lang="en">
        <head><title>A pair of workqueue improvements [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/937416/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/937459/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/937416/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>A pair of workqueue improvements</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Benefits for LWN subscribers</b>
<p>
The primary benefit from <a href="/Promo/nst-nag5/subscribe">subscribing to LWN</a>
       is helping to keep us publishing, but, beyond that, subscribers get
       immediate access to all site content and access to a number of extra
       site features.  Please sign up today!
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>July 7, 2023</br>
           </div>
Over the years, the kernel has developed a number of deferred-execution
mechanisms to take care of work that cannot be done immediately.  For many
(or most) needs, the <a
href="https://www.kernel.org/doc/html/latest/core-api/workqueue.html">workqueue
subsystem</a> is the tool that developers reach for first.  Workqueues
<a href="/Articles/355700/">took their current form</a> over a dozen years
ago, but that does not mean that there are not improvements to be made.
Two sets of patches from Tejun Heo show the pressures being felt by the
workqueue subsystem and the solutions that are being tried — with varying
degrees of success.

<p>
In normal usage, each subsystem creates its own workqueue (with <a
href="https://elixir.bootlin.com/linux/v6.4.1/source/include/linux/workqueue.h#L390"><tt>alloc_workqueue()</tt></a>)
to hold work items. When kernel code needs to defer a task, it can fill in
a <a
href="https://elixir.bootlin.com/linux/v6.4.1/source/include/linux/workqueue.h#L98"><tt>work_struct</tt>
structure</a> with the address of a function to call and some data to pass
to that call.  That structure can be passed, along with the target
workqueue, to a function like <a
href="https://elixir.bootlin.com/linux/v6.4.1/source/include/linux/workqueue.h#L480"><tt>queue_work()</tt></a>,
and the workqueue mechanism will call the function at some future time.
The call is made in process context, meaning that work items can block if
need be.  There is, of course, a long list of variants to
<tt>queue_work()</tt>, and a number of ways in which workqueues themselves
can be created, but the core functionality — call a function in process at
a later time — remains the same.
<p>
Once upon a time, each workqueue had one or more kernel threads associated
with it.  As long as there were work items on a queue, the threads would
remove and execute those items.  The problem with this implementation is
that the kernel contains a large number of workqueues, and they can end up
processing a lot of work items.  That resulted in systems containing many
worker threads, all competing with each other.
<p>
The "concurrency-managed workqueue" mechanism found in current kernels,
also created by Heo, was designed to address these problems.  Workqueues no
longer have dedicated kernel threads associated with them; instead, a globally
managed set of threads runs items from all workqueues.  The workqueue
subsystem tries to have exactly one work item running on each CPU at any
given time — if, of course, there are that many items in need of execution.
Once one work item completes, another is dispatched in its place.
<p>
There is one other complication: since work items are allowed to block, any
given work item could be "running" but not actually runnable for long
periods of time; that could result in a CPU going idle while there are
other work items waiting to be run.  The workqueue mechanism handles this
case by arranging to be notified whenever one of its worker items blocks.
When that happens, another work item will be dispatched (with another
thread created to run it, if needed) so that the CPU remains busy.  Once
the blocked worker wakes up, the workqueue core will notice and stop
dispatching items while that worker runs.
<p>
<h4>Detecting CPU-intensive workers</h4>
<p>
This mechanism handles the case where a work item blocks, but there is
another potentially problematic case.  If a work item runs for a long time,
it will block any others from running on the same CPU, leading to the
starvation of other work items.  There is a flag
(<tt>WQ_CPU_INTENSIVE</tt>) that can be set when a workqueue is created to
indicate that the work items running there may run for a long time; that
flag causes the workqueue to be run outside of the normal
concurrency-management mechanism so that it doesn't block other workers.
Developers are often surprised by which parts of their code take the most
CPU time, though, so it is easy to not remember to set that flag when
creating a workqueue.  As a result, kernel developers occasionally find
themselves tracking down performance problems created by CPU-hog work
items.
<p>
<a href="/ml/linux-kernel/20230518030033.4163274-1-tj@kernel.org/">This
patch set</a> provides a relatively simple solution to this problem.  The
workqueue core will, on a regular basis, look at which workers are running
on each CPU.  If any given worker is found to have run without blocking for
a long time (defined as 10ms by default), it will be marked as being
CPU-intensive and taken out of the concurrency-management regime, allowing
other workers to run.  There is an option to have the kernel report work
functions that repeatedly are marked in this way; developers can use that
information to mark the workqueue from which they are run appropriately.
<p>
This new machinery also makes it relatively easy to track how much CPU time
each work item is using.  This information has been <a
href="https://git.kernel.org/linus/8a1dd1e547c1">made available</a> to user
space, allowing developers to see how much time their workqueues are
consuming.
<p>
This work was pulled into the mainline during the 6.5 merge window.
<p>
<h4>Binding unbound workqueues</h4>
<p>
The discussion to this point has ignored the existence of unbound
workqueues, which are created with the <tt>WQ_UNBOUND</tt> flag.  These
workqueues are documented as running "<q>workers which are not bound to any
specific CPU</q>", and which are not part of the above-described
concurrency-management regime.  Unbound workqueues are described as being
suited for CPU-intensive tasks that are better managed by the CPU
scheduler.
<p>
In practice, as described in <a
href="/ml/linux-kernel/20230519001709.2563-1-tj@kernel.org/">this patch
set</a>, unbound workqueues have not been fully unbound for a while;
instead, the workqueue mechanism tries to contain them within a NUMA node.
That increases the locality of the workqueue, improving performance.
However, it seems that, on current CPUs, NUMA affinity is not enough.  A
single NUMA node might now contain multiple L3 caches; spreading work
across a node will thus spread it across multiple caches, losing some of
the locality that NUMA affinity was meant to produce.  This has led to a
number of complaints about workqueue performance.
<p>
Fixing this problem, it seems, is not easy, and Heo has concluded that
"<q>there is not going to be one good enough behavior for everyone</q>".
So, instead, the patch set creates three new parameters that can be set for
each workqueue:
<p>
<ul class="spacylist">
<li> The "affinity scope", describing the boundaries that should be applied
     to an unbound workqueue.  There are five possible values, binding
     queues to a single CPU, to a CPU and its siblings, to all CPUs sharing
     the same L3 cache, to a NUMA node, or to the system as a whole.  The
     NUMA binding matches current workqueue behavior.
<li> The "affinity strictness": how strongly the workqueue is bound to its
     given scope.  With strict affinity, work items cannot run outside of
     their scope.  With non-strict affinity, work items will be started
     within their scope, but the scheduler will be able to move them
     outside if that improves the performance of the system overall.
<li> "Localization": if set, work items are always started on the CPU
     where they were queued; after that, they can be moved as described by
     the scope and strictness parameters.
</ul>
<p>
Heo included some benchmarks showing the effects of various combinations of
parameters.  Changing the localization parameter has proved not to be
helpful, and he suggested that it may eventually be dropped from the
series.  The others gave some small gains depending on the specific
workload being run.  The overall picture is less than fully clear or, as
Heo put it: "<q>The tradeoff between efficiency gains from improved
locality and bandwidth loss from work-conservation deficit poses a
conundrum</q>".
<p>
Linus Torvalds initially <a
href="/ml/linux-kernel/CAHk-=whA2ztAcVrgsqj39j30LJYhjBSkk6Dju6TY16zGpXpkZQ@mail.gmail.com/">responded</a>
that this work looked overly focused on throughput while ignoring latency,
which he regards as being more important.  He was later <a
href="/ml/linux-kernel/CAHk-=whbP8BjGyGyXcSKi32orb+1+cHSC2HoVAMNVKwmbq8pSg@mail.gmail.com/">convinced</a>
by Heo, though, that this work could improve both throughput and latency.

Brian Norris, who is one of the developers reporting performance problems
with current kernels, <a
href="/ml/linux-kernel/ZIewlkGJJJUXPFL0@google.com/">had the changes
tried</a> but failed to note any performance improvements — results that
Heo <a href="/ml/linux-kernel/ZJNMk9oSp1_IYXLU@slm.duckdns.org/">found
mystifying</a>.  Torvalds <a
href="/ml/linux-kernel/CAHk-=wgXoyxy99HnEFcvf+eUZAS5=ekWt_y84LC3P+0osxh6Jw@mail.gmail.com/">suggested</a>
that the problem might be a bug elsewhere in the workqueue code.
<p>
As of this writing, these workqueue performance problems remain unresolved.
It is thus not surprising that this set of patches was not pushed for the
6.5 release.  Developers are going to have to dig deeper to figure out why
some current system architectures are creating performance problems for
workqueues.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Releases-6.5">Releases/6.5</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Workqueues">Workqueues</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/937416/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor937660"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A pair of workqueue improvements</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jul 8, 2023 4:18 UTC (Sat)
                               by <b>alison</b> (subscriber, #63752)
                              [<a href="/Articles/937660/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Userspace can already pin unbound workqueues via the usual taskset mechanism.      What problem is the new locality mechanism therefore trying to solve?   In particular, applications that allocate an unbound workqueue for a particular task are already able to pin the kworker on the same core where the task runs.   kworkers with a unique CPU affinity are potentially dedicated to the one task, and userspace can therefore also manage their priority with chrt.    As always, all these benefits depend on the ability of developers to reason about what affinities and priorities should be.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/937660/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor937666"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A pair of workqueue improvements</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jul 8, 2023 11:36 UTC (Sat)
                               by <b>fraetor</b> (subscriber, #161147)
                              [<a href="/Articles/937666/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Why don't work queues use the CPU scheduler by default? It seems to me, in my unfamiliarity with this subsystem, that this is a lot of work to implement a scheduler specifically for workqueues.<br>
<p>
Are workqueues are so heavily used that it is worth doing specific optimisations for them, or is there some other reason?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/937666/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2023, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
