        <!DOCTYPE html>
        <html lang="en">
        <head><title>The 2019 Automated Testing Summit [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/804050/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/804121/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/804050/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>The 2019 Automated Testing Summit</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Did you know...?</b>
<p>
LWN.net is a subscriber-supported publication; we rely on subscribers
       to keep the entire operation going.  Please help out by <a
       href="/Promo/nst-nag4/subscribe">buying a subscription</a> and keeping LWN on the
       net.
</blockquote>
<div class="FeatureByline">
           By <b>Jake Edge</b><br>November 13, 2019</br>
           <hr>
<a href="/Archives/ConferenceByYear/#2019-Automated_Testing_Summit">ATS</a>
</div>
<p>
This year saw the second edition of the <a
href="https://events19.linuxfoundation.org/events/ats-2019/">Automated
Testing Summit</a> (ATS) and the first that was open to all.  <a
href="https://elinux.org/Automated_Testing_Summit_2018">Last year's ATS</a> 
was an invitation-only
gathering of around 35 developers (that was described in an <a
href="/Articles/771782/">LWN article</a>),
while this year's event attracted
around 50 attendees;  both were held in conjunction with the
Embedded Linux Conference Europe (ELCE), in Edinburgh, Scotland for 2018
and in Lyon, France this year.  The basic problem has not changed—more
collaboration is needed between the different kernel testing systems—but
the starting points have been identified and work is progressing, albeit
slowly.  Part of the problem, of course, is that all of these testing
efforts have their own constituencies and customers, who must be kept up
and running, even while any of this collaborative development is going on.
</p>

<h4>Setting the stage</h4>

<a href="/Articles/804501/">
<img src="https://static.lwn.net/images/2019/ats-bird-sm.jpg" border=0 hspace=5 align="right"
alt="[Tim Bird]" title="Tim Bird" width=215 height=280>
</a>

<p>
As with the first ATS, this edition was organized by Tim Bird and Kevin
Hilman.  Bird welcomed everyone to the conference then turned things over to Hilman
for something of an overview of the "kernel testing landscape".  Hilman
started by noting
that there were some gatherings and discussions at the <a
href="https://www.linuxplumbersconf.org/">Linux Plumbers Conference</a>
(LPC) in
September, which he <a
href="https://lists.yoctoproject.org/pipermail/automated-testing/2019-September/000499.html">described
in an email</a> to the <a
href="https://lists.yoctoproject.org/listinfo/automated-testing">automated-testing
mailing list</a>.  There were some themes that came out of those
discussions, he said, which led to the title of his talk (<a
href="https://elinux.org/images/3/36/ATS_2019.pdf">slides [PDF]</a>):
"<q>The bugs are too fast (and why we can't catch them)</q>".
</p>

<p>
He gave a brief summary of the new kernel unit-testing frameworks that were
discussed at LPC in order to bring attendees up to date on what kernel
developers have been up to.  The existing kernel test efforts, including <a
href="https://www.kernel.org/doc/html/latest/dev-tools/kselftest.html">kselftest</a>,
<a href="https://linux-test-project.github.io/">Linux 
Test Project</a> (LTP), <a
href="https://github.com/google/syzkaller/blob/master/docs/syzbot.md">syzbot</a>,
and others, are likely pretty familiar to 
attendees, he said.
The <a
href="https://kunit.dev/third_party/kernel/docs/">KUnit</a> framework (<a
href="/Articles/780985/">LWN article from March</a>) has
been merged into linux-next; it is a fast way to test kernel
functionality in an architecture-independent way and can be run in user
space with <a 
href="https://kunit.dev/third_party/kernel/docs/">user-mode Linux</a>
(UML).  The <a href="https://github.com/oracle/ktf">Kernel Test
Framework</a> (KTF) is another unit-test framework that has been posted for
comments.  Since KUnit is headed for the mainline, though, the KTF project will need to
figure out how to add its functionality to KUnit, Hilman said, since there
won't be <a href="/Articles/790235/">multiple unit-test frameworks in
the mainline</a>.  
</p>

<p>
He then turned to the various testing initiatives that are currently
active.  The Intel <a
href="https://01.org/lkp/documentation/0-day-test-service">0-Day test
service</a> is probably the longest running; it is
"mostly Intel focused".  The Linaro <a
href="https://lkft.linaro.org/">Linux kernel functional testing</a> (LKFT)
has "quite a bit of in-depth testing but on a narrower set of hardware".
The Red Hat <a href="https://cki-project.org/">continuous kernel
integration</a> (CKI) project has been around for a while, but has only
recently been seen more publicly, he said; it is focused on testing stable
kernels.  And, of course, there is <a
href="https://kernelci.org/">KernelCI</a> that he cofounded; it was
officially <a href="/Articles/803262/">announced as a Linux Foundation
project</a> earlier in the week.
</p>

<a href="/Articles/804502/">
<img src="https://static.lwn.net/images/2019/ats-hilman-sm.jpg" border=0 hspace=5 align="left"
alt="[Kevin Hilman]" title="Kevin Hilman" width=199 height=300>
</a>

<p>
There is lots of testing going on, Hilman said, but there are a number of problems with
that.  One is that everyone is doing this testing off in their own corner;
there is little collaboration between the efforts, which is the reason for
the existence of ATS.  All of the different players are testing areas that
they care about, vendors are testing their hardware or software, developers
test the platforms they care about, and so on, but the testing coverage of the
kernel is concentrated; much of the kernel is tested, but everyone is
generally testing the same parts of the kernel over and over.  Broadening
that coverage is 
an area that needs work.
</p>

<p>
But even with the fragmentation, these test efforts are finding "lots and
lots of bugs"; "can we actually keep up and fix the bugs as we find them?"
He referred to an <a
href="https://linuxplumbersconf.org/event/4/contributions/554/">LPC
talk</a> from Dmitry 
Vyukov (who was also present at ATS) that outlined some of the parameters
of the size of the bug problem.  Hilman used the statistics from that talk
to note that more than 10% of the patches going into the kernel over the
last few years carried a "Fixes:" tag, which means they are fixing a known
bug that is identified in the tag.  Not all patches that fix bugs use that
tag, however, so the percentage of actual fixes is higher.
</p>

<p>
Beyond that, the raw numbers of bugs being found are mind-boggling.  In two
years, syzbot has found 5,800 crashes by fuzzing the kernel; in doing so, it
has only exercised around 7% of the kernel.  Does the kernel community
actually have the capacity to handle "all" of the bugs that could be found? 
Vyukov estimated that there are 20,000 new bugs added in each major kernel release.
</p>

<p>
The LPC talk led to <a href="/Articles/799134/">discussion at the
Maintainers Summit</a>, which was held a few days later.  Every kernel
developer has their own workflow to handle and track patches, which does
not scale when the number of bugs being reported grows rapidly.
There are efforts underway to figure out ways to  automate some of those of
processes, Hilman said.  The <a
href="http://vger.kernel.org/vger-lists.html#workflows">workflows mailing
list</a> was created to discuss that; there are a  lot of ideas on it, but
"there is not a ton of consensus yet".
</p>

<p>
Hilman said that the fragmentation in the testing landscape (and
elsewhere) is one of the 
things that is preventing the community from digging out from under all of
these bugs. He noted that the reason for ATS is to help fix that
fragmentation, so that "we can actually collaborate on fixing the issues
rather than dealing with understanding each others' frameworks [...] or
competing with each others' frameworks".  The ultimate goal is to stop
as many bugs as possible from even entering the released kernels.
Defragmenting testing is only addressing one half of the problem; the kernel workflow
also needs to work to get there.
</p>

<p>
An attendee noted that Hilman had talked a lot about kernel testing, but
there is other testing being done as well.  Bootloaders, user-space
programs, and other components are being tested too; that kind of testing
should continue.  Hilman agreed; he focused on kernel testing mostly
because the last few events that he was reporting on were also
kernel-focused.  There is definitely fragmentation in those other kinds of
testing efforts, but "we gotta start somewhere" and kernel testing seemed
like a good common denominator.
</p>

<h4>Status updates</h4>

<a href="/Articles/804503/">
<img src="https://static.lwn.net/images/2019/ats-wasilewski-sm.jpg" border=0 hspace=5 align="right"
alt="[Milosz Wasilewski]" title="Milosz Wasilewski" width=199 height=300>
</a>

<p>
A series of "lightning talks" was next on the agenda.  These were short
project overviews and updates for some of the different testing 
frameworks. There was more covered in each talk than is reported below;
the portions 
that introduced the testing system were particularly helpful.
</p>

<p>
Milosz Wasilewski was first, describing
LKFT, which targets both the Arm and x86 architectures.  It focuses on
testing the stable kernels; LKFT was originally set up to help Greg
Kroah-Hartman maintain the long-term stable (LTS) kernels, so it tests the
LTS branches and the most recent stable branch as well.  It has also
expanded into testing the mainline and linux-next kernels over time.
</p>

<p>
LKFT runs a variety of test suites, including LTP, kselftests, tests for <a
href="https://github.com/libhugetlbfs/libhugetlbfs">libhugetlbfs</a>, and
various performance tests, he said.  That adds up to around 25,000 tests
that get run for every release and around one million tests that get run every
every week.  In addition, there has recently been some testing of Android
kernels, though that 
is somewhat "less advertised". 
</p>

<p>
Bird talked about the <a href="http://www.fuegotest.org/">Fuego test
system</a>, which is targeted at testing on embedded devices.  Fuego has
its own Linux "distribution" that is based on Debian, with the <a
href="https://jenkins.io/">Jenkins</a> automation server, a test execution
core, and a bunch tests installed on it.  That is all wrapped up inside of
a Docker container that runs on the host that is controlling the testing.
</p>

<p>
The focus for Fuego is not on testing the upstream kernel, but is instead for
doing "product testing"—"high-level integration testing and benchmarking".
Various facilities needed for testing (e.g. the <a
href="https://hewlettpackard.github.io/netperf/training/Netperf.html">netperf</a>
server) are integrated into the Fuego
distribution, as is a cross-platform toolchain to build the tests
from source.  There are scripts to control test execution, including
handling results parsing, analysis, and visualization.  Multiple transports
for talking with the device under test (DUT) are supported, including TCP,
serial ports, and <a
href="https://developer.android.com/studio/command-line/adb">Android Debug
Bridge</a> (adb). 
</p>

<p>
Fuego does not handle provisioning the device with the code to test; Bird
hopes to be able to reuse the provisioning support from some other tool.
His users mostly handle the provisioning as another Jenkins job in the test
pipeline.  The DUT is not required to have much in the way of capabilities
in order to function with Fuego: just a shell with a limited set of commands, not including
awk or sed, though grep is needed.  All of those are available in <a
href="https://busybox.net/">BusyBox</a>, he said.  Some tests may require
additional support on the DUT, however.
</p>

<p>
Bird was followed by another familiar face as Hilman stepped up to talk
about KernelCI.  That project's goal is to test on a wide range of hardware
platforms, he said, which makes it different from many of the other frameworks.
Today, it is running tests on more than 250 boards, with systems-on-chip
(SoCs) from more than 35 vendors, and for multiple architectures: x86_64,
arm, arm64, mips, arc, and riscv.
</p>

<p>
KernelCI tests multiple trees, including the mainline, linux-next, and the
stable trees (as well as the stable release candidates). It also tests subsystem
trees, maintainer and developer trees, the android-common tree, and the
chrome-platform tree.  It tests multiple kernel configurations, including
all of the upstream defconfigs, and builds with multiple versions of both
GCC and Clang. 
</p>

<a href="/Articles/804504/">
<img src="https://static.lwn.net/images/2019/ats-kabatova-sm.jpg" border=0 hspace=5 align="right"
alt="[Veronika Kabatova]" title="Veronika Kabatova" width=195 height=300>
</a>

<p>
For the most part, KernelCI is simply doing boot testing; it boots to a
shell and does a few simple commands.  For a subset of the boards, more
functional tests are being added.  The main thing is that the project does
not want to develop and maintain its own test suites, but it 
is working with subsystems that have their own test suites to
add them to KernelCI.
</p>

<p>
Veronika Kabatova was up next to describe CKI, which has the goal of
preventing bugs from getting into the kernel in the first place; finding
existing bugs is nice, she said, but not the goal of CKI.  Getting there is
hard, however, so the project has started by testing trees in the upstream
kernel. It is testing the trees of the newest stable branch, stable-next,
arm-next, RDMA, and rt-devel; some testing of other trees is being done,
like net-next and mainline, but the results are not being sent out.  It
runs tests for the x86_64, arm64, ppc64, ppc64le, and s390x architectures.
Overall, CKI is meant to complement the other existing continuous
integration (CI) solutions for the kernel.
</p>

<p>
Unlike others, CKI does not use Jenkins; it uses the <a
href="https://docs.gitlab.com/ee/ci/">GitLab&nbsp;CI</a> system instead.
For actually running the tests, <a
href="https://beaker-project.org/">Beaker</a> is used.  Various kinds of
input can trigger the system, including patches 
from <a href="http://jk.ozlabs.org/projects/patchwork/">Patchwork</a>, Git commits, <a
href="https://fedoraproject.org/wiki/Koji">Koji</a> builds, and more.
Reports from CKI are sent to a mailing list.
</p>

<h4>Kcidb</h4>

<p>
Several of the framework talks referred to <a
href="https://github.com/kernelci/kcidb">kcidb</a>, which is something that
came out of the <a
href="https://cki-project.org/posts/plumbers-summary/">CKI hackfest</a>
that was held right after LPC.
In his talk, Hilman mentioned that there is a huge corpus of test results
that KernelCI has squirreled away but is never used. It would be nice to be able to
do something with all of that data.  Other projects have the same problem,
of course. 
</p>

<p>
At the hackfest, KernelCI,
LKFT, and CKI, got together to work on a simple JSON schema to describe
test results.  It is simply a starting point that can be used to gather all
of this data into a common place, so that it can be processed with common
tools to see what can be found within.  There are tools to submit and query
kcidb
data in a <a
href="https://cloud.google.com/bigquery/">BigQuery</a>
instance in the Google cloud.  The "founding" three test frameworks are also working
on adding a kcidb client to their reporting—as are other frameworks (Bird
mentioned it for Fuego, at least). 
</p>

<h4>Plenty more</h4>

<p>
This article is only scratching the surface of the
all-day conference, covering much of the first quarter of the day.  ATS soon
split into two tracks, as can be seen in the 
<a href="https://ats19.sched.com/">schedule</a>.  There is a lot of
information exchange going on at this point, trying to bring everyone up to
speed on all of the other efforts, tools, frameworks, test hardware, and so
on, which is reflected in the talk topics.  But it seems abundantly clear that there is an
enormous amount of defragmentation 
work to do.
</p>

<p>
The current focus on kcidb was not even two month's old when ATS was held
on October&nbsp;31—because kcidb itself was brand new.  There is some
interest in working on common test definitions that can be shared among
frameworks.  Bird's vision is that some day there would be a "test store"
that is akin to an app store, where users could browse through thousands of
tests to choose the ones that fit their needs.  But for now, that effort is
on the back burner, simmering while the test-results piece is
solidified—starting with kcidb.
</p>

<p>
In the end, there is a lot of work to do and only a limited number of folks
to do it—as is so often the case in the free-software world.  In addition, it seems
likely that LPC (and the CKI hackfest) being held so near in time to ATS
split the participation to some extent.  At the wrapup session at the end
of the day, it was decided to try to focus on a single event, next year's
LPC, rather than to reprise ATS for next year.
</p>

<p>
During that wrapup session, the "key decisions" were gathered, which can be
seen on the <a href="https://elinux.org/Automated_Testing_Summit_2019">ATS
2019 page</a> of the Embedded Linux Wiki at elinux.org.  In addition,
Pengutronix folks took notes that they <a
href="https://lists.yoctoproject.org/pipermail/automated-testing/2019-November/000639.html">posted</a>
to the automated-testing mailing list.</p>

<p>
Over the years, kernel testing has
most certainly gotten a <i>lot</i> better, but there is still a long way to
go.  Collaboration seems like it will be pivotal in pushing kernel testing
to the next level—and beyond.  Gatherings like ATS, LPC, the CKI hackfest,
and others will play an important role.
</p>

<p>
[I would like to thank Linaro for travel assistance to attend the Automated
Testing Summit in Lyon, France.]<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Development_tools-Testing">Development tools/Testing</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Automated_Testing_Summit-2019">Automated Testing Summit/2019</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/804050/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2019, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
