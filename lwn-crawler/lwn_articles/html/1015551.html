        <!DOCTYPE html>
        <html lang="en">
        <head><title>A herd of migration discussions [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/1015551/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/1015513/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/1015551/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>A herd of migration discussions</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Did you know...?</b>
<p>
LWN.net is a subscriber-supported publication; we rely on subscribers
       to keep the entire operation going.  Please help out by <a
       href="/Promo/nst-nag4/subscribe">buying a subscription</a> and keeping LWN on the
       net.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>March 31, 2025</br>
           <hr>
<a href="/Articles/lsfmmbpf2025/">LSFMM+BPF</a>
</div>
Migration is the act of moving data from one location in physical
memory to another.  The kernel may migrate pages for many reasons,
including defragmentation, improving NUMA locality, moving data to or from
memory hosted on a peripheral device, or freeing a range of
memory for other uses.  Given the importance of migration to the
memory-management subsystem, there is a lot of interest in improving its
performance and removing impediments to its success.  Several sessions in
the memory-management track of the 2025 Linux Storage, Filesystem,
Memory-Management, and BPF Summit were dedicated to this topic.
<p>
<h4>Migration with multi-threading</h4>
<p>
The first of those discussions, run by Zi Yan and (remotely) Shivank Garg,
was focused on improving migration performance.  Garg started by pointing
out that migration is critical for optimal performance on both NUMA and
tiered-memory systems.  Yan, instead, is concerned with the migration of
pages to and from device memory, where the devices involved can be GPUs or
AI accelerators.  Both would like migration to happen more efficiently and with
less impact on system performance.
<p>
Garg said that, in current kernels, migration speed is bounded by what
single-threaded, CPU-bound operations can deliver.  But many systems have
hardware accelerators installed.  Once upon a time, there might have been
interest in using those accelerators to perform migration; that interest
still exists, but we live in a different world now.  On at least some of
these systems, the real work is being done on the accelerators, while the
CPUs mostly sit idle waiting for that work to be done.  So it makes sense
to dedicate <i>more</i> CPU time to the migration task.
<p>
One way to improve things is to batch the copying of pages (or, more
correctly, folios) to their new location; that tends to improve the use of
the available memory bandwidth.  Better, though, is to perform a
multi-threaded copy using multiple CPUs in parallel.  Choosing the right
number of threads can be tricky, though; more is not always better.  The
optimal number of threads is, naturally, architecture-specific.  The
placement of the copying operations also affects performance; using
multiple CPUs will not make things any faster if they are all part of the
same cache domain.  The best solution in the end might involve the creation
of a <a href="/Articles/922405/">sched_ext module</a> to manage placement.
<p>
David Hildenbrand said that the batching of page migration could delay the
execution of applications and asked whether any measurements had been done;
Yan answered that these tests have not been run.  But the way the batching
is done, he said, does not increase latency since the page data is copied
first, before the metadata.  There can be some latency increases when
copying 1GB pages, though, so he agreed that it is better to use a smaller
batch size when there is a lot of concurrent access to the data.
<p>
Ryan Roberts reiterated that the limiting factor currently is the memory
bandwidth available to a single CPU; the changes being discussed work around
that by using multiple CPUs.  He wondered if some of the recently added Arm
instructions could help here; another participant answered that the
potential is there, but improvements have not been observed on actual
hardware yet.
<p>
Garg concluded the session with a brief discussion of offloading the
migration copying to hardware on the system, with a fallback to CPU-based
copying of the offloaded operation is not successful.  This approach is
implemented as a copy-offload driver, with static calls used to select the
best approach at boot time.  But the performance of this driver is not as
high as expected, he said, due to the overhead of setting up the DMA
mappings.  Jason Gunthorpe was surprised by that, saying that mapping
overhead should not be a problem.  At the end, Zi reiterated that the goal
of all of this work is to get better migration bandwidth.
<p>
<h4>Migrating the unmovable</h4>
<p>
Not all pages (or folios) can be migrated; migration is only possible if
that memory can be isolated (guaranteeing that nothing is trying to access
it) and any users will still find it correctly after the move.  User-space
pages are usually movable, since they are accessed by way of virtual
addresses; all that is needed is to change the page-table entries to point
to the new location.  The kernel tries hard to separate movable and
unmovable memory so that one unmovable page doesn't block an attempt to
clear a larger region.  But sometimes an ostensibly movable page turns out
not to be; Hildenbrand ran a session on how that situation comes about and
what might be done about it.
<p>
<a href="/Articles/1015655/"><img
src="https://static.lwn.net/images/conf/2025/lsfmm/DavidHildenbrand-sm.png" alt="[David
Hildenbrand]" title="David Hildenbrand" class="rthumb"></a>

He started by listing the various ways in which the system depends on
successful migration.  <a href="/Articles/368869/">Memory compaction</a>
and defragmentation require the ability to move pages around, for example.
NUMA balancing and tiering, the <a href="/Articles/486301/">contiguous
memory allocator (CMA)</a>, the implementation of memory policies, CPU
hotplugging, and device-private memory all need migration to work.  Often,
all it takes is a single unmovable page to create problems.
<p>
Certain kinds of pages are inherently unmovable, he said; these include
slab pages, page tables, and just about anything else that is not mapped
into user space.  On the other hand, most folios are movable, as is balloon
memory in virtual machines, zswap storage, or anything allocated explicitly
with the <tt>__GFP_MOVABLE</tt> flag.  The goal is to have most pages be
movable to give the system as much flexibility as possible.
<p>
But, sometimes, pages that are supposed to be movable become fixed in place,
leading to a number of problems, including CMA allocation failures,
device-private memory being stuck in place, memory-hotplugging failures,
and memory fragmentation.  This lack of mobility can be either temporary or
permanent, with different results.
<p>
One cause of temporarily unmovable pages is simply running out of memory;
if there is no place to move a page <i>to</i>, it cannot be moved.  A
variant of that is caused by fragmentation; a large folio cannot be moved
intact if the destination folio cannot be allocated.  Splitting a large
folio in this case is an option, but some large folios, such as dirty
folios backed by an XFS filesystem, cannot be split for migration, and are
thus unmovable.  These problems usually resolve themselves in time.
<p>
There are also problems with the LRU cache, which doesn't handle large
folios (which add additional references to their pages); Matthew Wilcox
suggested that perhaps that shortcoming should be fixed.  Rik van Riel said
that the LRU lock can be a bottleneck, so it is better to keep larger
folios on the LRU to reduce contention.  That, though, seemingly requires a
redesign of the LRU; Michal Hocko said that this project is worth looking
into, but that it would be a hard one.
<p>
The most serious problem with temporarily unmovable pages is caused by
short-term pinning of pages.  When user space initiates a direct-I/O
operation, for example, the pages involved must be pinned down; if the
application maintains a constant stream of I/O, that pin will never be
released and the pages become, in effect, permanently unmovable.
Hildenbrand suggested that, when a page block has been marked for isolation
(the removal of mappings so that the contents can be migrated), any
subsequently requested direct-I/O operations should be delayed until the
migration is complete.
<p>
Permanently unmovable pages can be created by long-term pinning; this can
happen, for example, with user-space memory that is used as an RDMA buffer.
The kernel tries to migrate such memory out of the movable page blocks
before allowing this kind of pin, but the migration can fail.  Migration is
not a perfect solution in any case; the pages may become movable again in
short order, but now they will be occupying relatively expensive unmovable
zones.  Perhaps, Hildenbrand said, there should be a way for user space to
warn the kernel that a range of memory will be long-term pinned; that would
have to be implemented carefully, though.
<p>
There are also special types of folios that can be permanently unmovable,
including <a href="/Articles/865256/">secret memory</a> or <a
href="/Articles/949277/"><tt>guest_memfd()</tt> areas</a>.  The kernel
tries to keep these folios out of movable zones, and that code is mostly
working as intended.  Pages that have been marked as failed by the <a
href="/Articles/348886/">HWPOISON subsystem</a> are unmovable, but are not
normally a problem.  Another source of unmovable pages is bugs in the
kernel; <a
href="https://man7.org/linux/man-pages/man2/vmsplice.2.html"><tt>vmsplice()</tt></a>
can still pin pages forever, for example.
<p>
The last problem that Hildenbrand raised before the session ran out of time
was "infinite I/O".  Pages that are under readahead or writeback are not
movable, and that I/O can take forever.  This can happen as the result of
I/O errors, connectivity problems in network filesystems, or in FUSE
filesystems.  The last cause is the most serious, since it can be created
by an unprivileged user-space process that simply never gets around to
completing an I/O operation; there perhaps needs to be a way for
the kernel to ask FUSE to cancel an operation, he said.
<p>
Wilcox pointed out that, with network filesystems, the pages involved will
be mapped for DMA I/O, which could happen at any time.  There just is no
way to free the memory without a revocation protocol for the specific
device involved, and those protocols don't exist.  Van Riel pointed out
that these buffers have to be in movable memory, since that is most of the
memory in the system.  Hildenbrand closed by saying that solving this
problem would clearly require a longer discussion at some other time.
<p>
(<a
href="https://drive.google.com/file/d/1uX80M1x86Oz3DFoHif-JLx1rlC_Nh93R/view">The
slides from this session</a> are available.)
<p>
<h4>Non-folio migration</h4>
<p>

Hildenbrand was not done, though; the next session addressed a different
migration-related problem.  Currently, migration is designed to move folios
around in memory.  That works now, since any non-tail page is by definition
a folio.  In the future, though, folios will only be one of many page
types, and there is a strong desire to reduce the memory overhead of
tracking those other page types.  How can page migration work when the
migration code no longer has access to the fields of <tt>struct folio</tt>?
<p>
He started by saying that "<q><a href="/Articles/1000654/">frozen pages</a>
are great</q>", since they no longer use the reference-count field found in
<tt>struct folio</tt> (and <tt>struct page</tt>).  Any page type that can
be made frozen has thus already taken an important step toward moving away
from using folio-specific fields. He wanted to use the frozen-page concept
for types of pages that nobody should touch — "logically offline" pages.
These include pages in balloon drivers that are currently not in use.  But
the balloon drivers currently depend on the reference count, so they cannot use
frozen pages.
<p>
In a future where balloon pages are not folios, the balloon driver will
have to stop using the reference count.  But the problem is worse, in that
other folio fields are used by migration; these include the <tt>lru</tt>
field, which is a doubly linked list head.  Either migration will have to
be weaned off those fields, or every page in the system will have to
provide them.  That would mean allocating <a
href="/Articles/974937/">memory descriptors</a> for all movable pages,
which nobody really wants to do.
<p>
At the lowest levels, the migration task is handled by <a
href="https://elixir.bootlin.com/linux/v6.13.7/source/include/linux/migrate.h#L23"><tt>struct
movable_operations</tt></a>:
<p>
<pre>
    struct movable_operations {
	bool (*isolate_page)(struct page *, isolate_mode_t);
	int (*migrate_page)(struct page *dst, struct page *src, enum migrate_mode);
	void (*putback_page)(struct page *);
    };
</pre>
<p>
The <tt>isolate_page()</tt> callback attempts to remove all references to a
page so it can be moved, <tt>migrate_page()</tt> actually moves it, and
<tt>putback_page()</tt> will only be called if the migration fails and the
page should go back into use in its original location.  These operation do
not need to depend on the folio fields, so it should be possible to manage
migration for non-folio pages.
<p>
Hildenbrand is working on a scheme to accomplish that.  It is intended to
work in the planned future where <tt>struct page</tt> has been replaced by
a single, 64-bit memory descriptor.  That descriptor may be a pointer to a
larger structure, but it is hoped that, for many types of memory, the
descriptor itself will be able to hold the needed information.  Hildenbrand
is specifically targeting those types of memory.  His planned solution will
avoid any folio-specific fields, meaning it is limited to whatever can be
fit into the memory descriptor itself; Wilcox told him that there are
60&nbsp;bits available for that purpose.
<p>
Currently, the migration code uses the <tt>mapping</tt> folio field to
store a pointer to the relevant <tt>movable_operations</tt> structure.
Eliminating that will be easy, Hildenbrand said; the relevant operations
will be found by using the page type instead.  The page flags used to track
the isolation of pages should not be needed, since the driver managing
those pages should know if they can be (and have been) isolated.  There
will be no need for the reference count; the <tt>isolate_page()</tt> and
<tt>putback_page()</tt> callbacks will transfer ownership of the page,
while <tt>migrate_page()</tt> leaves the source page unreferenced.  And,
rather than using the <tt>lru</tt> field to store lists of pages to
migrate, the migration code would simply keep an array of the pages it is
working on.
<p>
So far, this scheme is no more than that; Hildenbrand admitted that he did
not have any code yet.  Wilcox said that the plan looks good, though, and
should solve a lot of problems.  Hildenbrand hoped that this approach could
be used to make more page types movable in the future; page-table-entry
pages, for example, occupy a lot of memory but are not movable now.
<p>
As a sort of coda to the conversation, Hildenbrand returned to balloon
drivers, which store inflated pages in a linked list using the <tt>lru</tt>
field.  He suggested that a bitmask could be used to track those pages
instead.  The <a href="https://docs.kernel.org/core-api/idr.html">ID
allocation (IDA)
subsystem</a> could be used to manage that bitmap, but it would need a few
improvements first.
<p>
(<a
href="https://drive.google.com/file/d/1NIjjwVAonz9WWIoJZ0nh71ovMfSjfqFc/view">The
slides for this presentation</a> are available as well.)<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management">Memory management</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Storage_Filesystem_Memory-Management_and_BPF_Summit-2025">Storage, Filesystem, Memory-Management and BPF Summit/2025</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/1015551/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor1016150"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Clarifications on the &quot;Migration with multi-threading&quot; section in LWN</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 2, 2025 4:57 UTC (Wed)
                               by <b>shivankgarg98</b> (subscriber, #141477)
                              [<a href="/Articles/1016150/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The summary did a great job capturing the key points of what we presented.<br>
I thought I'd just share a couple of quick clarifications that might be helpful:<br>
<p>
1. On the copy-offload driver: while static calls can be used select to best<br>
approach at boot time, the implementation can dynamically select the optimal<br>
approach at runtime (currently, we use sysfs for manually switching to different<br>
offload approach).<br>
<p>
2. About the DMA performance: The results were pretty size-dependent - smaller<br>
folios don't see much benefit (for medium size folios, in some cases, multiple<br>
channels compensated DMA overheads to give gains) but the large 2MB folios<br>
show really nice performance gains over CPU migrations.<br>
<p>
Latest RFC V2:<br>
<a href="https://lore.kernel.org/linux-mm/20250319192211.10092-1-shivankg@amd.com/">https://lore.kernel.org/linux-mm/20250319192211.10092-1-s...</a><br>
<p>
I also wanted to mention that the slide deck is available online which<br>
might benefit the readers:<br>
<a href="https://docs.google.com/presentation/d/1mjl5-jiz-TMVRK9bQcQ_IsSXrIP82CqWS8Q6em3mJi0/edit?usp=sharing">https://docs.google.com/presentation/d/1mjl5-jiz-TMVRK9bQ...</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1016150/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor1017736"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Should long-running DMA to movable pages use shadow buffers?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 16, 2025 18:42 UTC (Wed)
                               by <b>DemiMarie</b> (subscriber, #164188)
                              [<a href="/Articles/1017736/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The obvious solution to long-running DMA operations blocking page migration is to simply not allow such operations.   Can they be made to use shadow buffers instead?  That means an extra memory copy, but the performance cost might be acceptable.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1017736/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2025, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
