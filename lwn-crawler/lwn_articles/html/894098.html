        <!DOCTYPE html>
        <html lang="en">
        <head><title>Dealing with negative dentries [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/894098/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/894038/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/894098/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Dealing with negative dentries</h1>
</div>
<div class="ArticleText">
<div class="FeatureByline">
           By <b>Jake Edge</b><br>May 9, 2022</br>
           <hr>
<a href="/Articles/lsfmm2022/">LSFMM</a>
</div>
<p>
The problem of negative dentries accumulating in the dentry cache in an
unbounded manner, as we <a href="/Articles/890025/">looked at</a> back in
April, came up at the
<a
href="https://events.linuxfoundation.org/lsfmm/">2022 Linux Storage,
Filesystem, Memory-management and BPF Summit</a> (LSFMM).
Negative dentries reflect failed file-name lookups, which are then cached,
saving an expensive operation if the file name in question is looked up
again.  There is no mechanism to proactively prune back those cache
entries, however, so the cache keeps growing until memory pressure finally
causes the system to forcibly evict some of them, which can make the system
unresponsive for a long time or even cause a soft lockup.
</p>

<h4>The problem</h4>

<a href="/Articles/894380/">
<img src="https://static.lwn.net/images/2022/lsfmm-brennan-sm.png" border=0 hspace=5
align="right" alt="[Stephen Brennan]" title="Stephen Brennan" width=200
height=300>
</a>

<p>
Stephen Brennan led the session; he had posted a <a
href="/ml/linux-kernel/20220331190827.48241-1-stephen.s.brennan@oracle.com/">patch
set</a>, with a new approach to the problem, during the discussion in
March.  The problem that he is seeing is on big servers with lots of
memory, where part of the workload is looking up unique IDs in some
directory a few times per second—which goes on for months or years.  Each lookup
creates a negative dentry in the cache, resulting in a cache full of
these entries that have never been used after they were created.
</p>

<p>
Since there is no memory pressure, because the system has lots more memory than is
needed by the workload, there is no clean up. That can lead to soft lockups
when iterating through the children of a dentry because of the amount of
time it takes to do so.  It also leads to slab
fragmentation; if the system has 500 million negative dentries and then a
directory containing some of them is deleted, there will be an enormous
number of partially filled slab pages.
</p>

<p><blockquote class="ad">
<b><tt>$ sudo subscribe today</tt></b>
<p>
Subscribe today and elevate your LWN privileges. You’ll have
access to all of LWN’s high-quality articles as soon as they’re
published, and help support LWN in the process.  <a href="https://lwn.net/Promo/nst-sudo/claim">Act now</a> and you can start with a free trial subscription.
</blockquote>
<p>
His goal is to have some kind of generic system for managing all of the
various least-recently-used (LRU) lists in the page-cache and filesystem
code.
Currently, negative dentries are not moved to the head of the LRU when
  they are referenced; instead, they are simply marked and left in place
  until the shrinker runs.  <a href="/Articles/550463/">Shrinkers</a> are the mechanism that the
  memory-management subsystem uses to request cache entries be freed.
  They only run
when there is memory pressure, but at that point a dentry might have been
marked as referenced a year ago, so that dentry is not useful anymore—if it ever was.  When that
happens, the shrinkers have to 
do a lot of work just to move entries to the end of the list before they
can even be reclaimed.
</p>

<p>
In the mailing list discussion, Dave Chinner <a
href="/ml/linux-mm/20220322222114.GE1609613@dread.disaster.area/">wanted to
see</a> a generic solution for various caches that all use the
<tt>list_lru</tt> mechanism.  Brennan (and others) have been thinking about
that.  For example, every time something gets added to these caches, the
list could be rotated to move those with fewer references to the back of
the list.  At that point, perhaps some aging rules could be applied to
negative dentries.  Another thing that could be done is to track the number
of entries in these caches, and their types, so that decisions could be
made based on the numbers of dentries, negative dentries, or some
calculation using
those numbers.
</p>

<p>
James Bottomley said that the problem is that the number of negative
dentries is completely unbounded, so  he wondered if the focus of the work should be on
dealing with that. The number of positive dentries is bounded by
the number of files in a directory, but there is a nearly infinite number
of file names that are <i>not</i> present.  Brennan agreed, noting that on
the systems he has looked at, 99% of the cached dentries are of the
negative variety, so that is the source of the underlying problem.  But he
thinks the fix can be made using the existing <tt>lru_list</tt> and
shrinker frameworks.
</p>

<p>
While Oracle's main concern is with negative dentries, Matthew Wilcox said,
there are other caches that have similar problems.  For example, under
certain workloads, the inode cache can similarly end up with many entries
that will never be used again.  That cache is bounded by the number of
files in the filesystem, but it is still a "used once" problem as with
negative dentries in the problem cases.
</p>

<h4>Not really LRU</h4>

<p>
This is a "classic LRU problem", Kent Overstreet said.  Brennan agreed with
that, noting that these LRUs are not really being treated as "least
recently used".  There are, instead, used-once entries scattered throughout
the list.  Under memory pressure, those entries are the ones that should be
cleaned up;  if they were organized better, so that all of
those that were not recently used were together, the cost of scanning the whole
list for them could be reduced.
But there is still the problem of workloads that create "stupid
amounts" of negative dentries that will never be used again.  There is no
good reason to cache those at all. 
</p>

<p>
Josef Bacik said that he had solved a similar problem around five years ago
by not marking entries as referenced until they are used for the second
time.  Prior to that, the list was being scanned to clear the referenced bits for
entries that had been referenced once, but
that scan took a long time.  He chose to wait for the second use, instead
of changing the LRU to be a real LRU, because he found that constantly
shuffling things to the back of the list was "not excellent" for the
workload he was looking at. 

</p>

<p>
Brennan said that it is not excellent for a lot of workloads because it
leads to
a lot of contention on the spinlocks.  He loves the idea of waiting until
the entry is used again, but it leads to another problem: "how much is too
much?"  Memory pressure provides a good signal to indicate that entries
need to be pruned, but the soft lockups he mentioned can occur starting
around&nbsp;100 million negative dentries in a single directory.  He would
rather not use some kind of "magic threshold", but there needs to be some
mechanism to start shrinking the one-use items, at least.  
</p>

<h4>Other possibilities</h4>

<p>
Bottomley suggested that the bounded positive dentry cache size for a
directory be the
limit on how large the negative-dentry cache could grow.  Brennan thought
that was an interesting idea.  Ted Ts'o pointed out that negative dentries
have no references to other data structures in the system, so they are easy
to get rid of, or simply to move to another page.  He wondered if simply
getting rid of the negative dentries blocking the freeing of a page might
be a reasonable tradeoff, even if those entries might actually be used
again.  There may be good reasons to give negative dentries special
treatment, he said.
</p>

<p>
Bacik said that the negative-dentry problem can be solved in a fairly
straightforward way, but that if Brennan wanted to solve the more general
problem, there was a lot of work that would be needed.  There was some
discussion of using a mechanism like the  <a href="/Articles/495543/">page
cache "refault" tracking</a>, 
that was added by  Johannes Weiner quite a ways back; it would allow the system to know that
something it had evicted returned to the cache, so it should probably stick
around longer.
</p>

<p>
Overstreet wondered if there was a way to detect workloads that are
scanning and creating lots of negative dentries, then stopping the creation
of those entries.  That could be tracked per process ID and limits could be
placed on how many negative dentries could be created.  Michal Hocko said
it sounded like a similar problem to that of throttling the creation of
dirty pages; when the rate of their creation gets too high, a process is
throttled to slow down their creation.
</p>

<p>
Brennan said that the problem is not necessarily that the entries are
created at a high rate of hundreds or thousands per second; it could be a
slow trickle of them over a long period of time.  It can add up to hundreds
of millions over, say, a year's time.  There are some workloads that simply
do lookups, which create a negative dentry when the file is not
found, but others may be creating lots of temporary files and then deleting
them, which also leaves negative dentries behind.
</p>

<p>
John Hubbard said that part of the problem is that Linux wants to use all
of the available memory if possible, because it generally leads to better
performance, but there is a cost to getting that memory back when it is
needed elsewhere.  Making any kind of improvement on the reclaim side would
really help, Brennan said.
</p>

<p>
As time for the session wound down, Bacik asked Brennan what it is he would
like the filesystems and memory-management developers to do to help.
Brennan said that there were a lot of good ideas raised in the session and
he hopes that those who care about the specific problem for negative
dentries and the more general problem of finding better ways to reclaim
memory from these caches would provide more eyeballs on the patches he
would be posting.
</p>

<p>
Weiner asked if a way to sidestep the problem would be to put the negative
dentries on a separate shrinker list.  There are some shrinkers that are
called more aggressively and there is no need to protect specific entries; a more
wholesale freeing would probably work just fine.  Brennan agreed that might be a way
forward.  The possibility of making changes that were specific to negative
dentries was his favorite part of the discussion, he said.
</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Dentry_cache">Dentry cache</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Storage_Filesystem_Memory-Management_and_BPF_Summit-2022">Storage, Filesystem, Memory-Management and BPF Summit/2022</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/894098/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor894432"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Dealing with negative dentries</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 10, 2022 6:20 UTC (Tue)
                               by <b>nickodell</b> (subscriber, #125165)
                              [<a href="/Articles/894432/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
In one of the threads discussing this patch, there&#x27;s an example of how dentry bloat can happen on non-crazy systems: <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1720479">https://bugzilla.redhat.com/show_bug.cgi?id=1720479</a> I thought it was interesting, so I dug through the bug tracker and associated source code to understand the rationale behind *why* it was making so many dentries.<br>
<p>
Here&#x27;s a short summary of why it happened:<br>
<p>
1. In the linked bug, curl is being used as a Docker healthcheck for Elasticsearch. It&#x27;s getting run every second and creating ~20,000 negative dentries each time.<br>
2. NSS is a library for loading and validating SSL certificates. It&#x27;s used in curl and Firefox. It can load a set of certificate authorities from the filesystem.<br>
3. But loading these is slow, so it builds an indexed SQLite database of SSL certs so that cert lookup is fast.<br>
4. The location that the database is being built on could be a network filesystem, so if that happens, the database should be built up in memory, *then* written to disk in one go, for speed reasons.<br>
5. But how can it detect if it&#x27;s a slow network FS or a fast disk FS? It measures it using stat(). But if it stats a file which exists, the file could be in the dentry cache already, which would throw off the measurement. So it measures the stat() time of a nonexistant file with a random number in the filename.<br>
6. It repeats that measurement 10,000 files, or for 33ms, whichever comes first. Also, it measures both /tmp and the directory it loads the certificates from.<br>
<p>
There are a couple of contributing factors to the problem:<br>
<p>
1. The developers of NSS, Mozilla, mostly care about performance for Firefox. In Firefox, NSS is only loaded once per process. curl also loads NSS once per process, but each process much shorter lived.<br>
2. Firefox is used on desktop systems, which get rebooted more often.<br>
3. AFAIK, there&#x27;s no good cross-platform way to determine if a path is on a network filesystem.<br>
4. Elasticsearch gets run on systems with gobs and gobs of memory, and it&#x27;s not rebooted for a really long time.<br>
<p>
The story does have a happy ending, though. These days, NSS will make a temporary dir, look up its 10000 non-existant files in that directory, and deletes the temporary dir. As I understand it, that cleans up all but one negative dentry.<br>
<a href="https://github.com/nss-dev/nss/blob/18668d2e34500a6f14b68ece3686d21a4525a42f/lib/softoken/sdb.c#L396">https://github.com/nss-dev/nss/blob/18668d2e34500a6f14b68...</a><br>
<p>
But it&#x27;s easy to see why the NSS developers started looking up nonexistent files - it solved a pressing performance problem in a cross-platform way that looked to be nearly free. It seems like negative dentries are something of an attractive nuisance - easy to misuse without knowing the performance costs.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/894432/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor894575"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Dealing with negative dentries</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 10, 2022 17:26 UTC (Tue)
                               by <b>brenns10</b> (subscriber, #112114)
                              [<a href="/Articles/894575/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I remember reading this bug report and thinking that this was one of the crazier systems. I don&#x27;t love the idea of timing operations to determine whether something is local or remote: ideally we should provide an API to provide the required info and then try to make every operation fast enough to appear as if it&#x27;s local :P .  But I suppose craziness is in the eye of the beholder :)<br>
<p>
<font class="QuotedText">&gt; But it&#x27;s easy to see why the NSS developers started looking up nonexistent files - it solved a pressing performance problem in a cross-platform way that looked to be nearly free. It seems like negative dentries are something of an attractive nuisance - easy to misuse without knowing the performance costs.</font><br>
<p>
You&#x27;re 100% right though. Userspace shouldn&#x27;t need to know or care what a dentry is, or worry about the cache pollution they cause. The kernel needs to be smart enough to weed out these useless negative dentries.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/894575/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor894586"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Dealing with negative dentries</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 10, 2022 18:57 UTC (Tue)
                               by <b>nickodell</b> (subscriber, #125165)
                              [<a href="/Articles/894586/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt;I don&#x27;t love the idea of timing operations to determine whether something is local or remote: ideally we should provide an API to provide the required info and then try to make every operation fast enough to appear as if it&#x27;s local :P</font><br>
<p>
They don&#x27;t care about whether the directory is local or remote, exactly - they care about whether it&#x27;s fast or slow. In principle, you could have a really fast network filesystem, and then NSS wouldn&#x27;t bother with the workaround.<br>
<p>
<font class="QuotedText">&gt;But I suppose craziness is in the eye of the beholder :)</font><br>
<p>
Haha, exactly.<br>
<p>
-----<br>
<p>
By the way, thanks for hosting this session, and posting the initial patch. I thought it was a really smart and fast heuristic.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/894586/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor894672"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Dealing with negative dentries</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 11, 2022 7:37 UTC (Wed)
                               by <b>jengelh</b> (subscriber, #33263)
                              [<a href="/Articles/894672/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt;3. AFAIK, there&#x27;s no good cross-platform way to determine if a path is on a network filesystem.</font><br>
<p>
At what point does certain storage become &quot;network&quot;? Media conversion to fiber? Cabling distance to the array &gt;1000m? What would you do if the &quot;network&quot;ed mount were still to be the faster choice over a local disk?<br>
Such checking attempts can only end in vain, even before having to consider the difference in OS APIs.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/894672/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor894455"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Dealing with negative dentries</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 10, 2022 8:33 UTC (Tue)
                               by <b>NYKevin</b> (subscriber, #129325)
                              [<a href="/Articles/894455/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This is probably a stupid question but... why can&#x27;t you just put a (per-directory) hard cap on the number of dentries at some arbitrary number (say, 1000)? Are there really applications out there that need (for performance reasons) more than 1000 negative dentries in a single directory? Why aren&#x27;t those applications using something like SQLite instead of raw filesystem lookups?<br>
<p>
Yes, I&#x27;m sure there&#x27;s some weird application that builds huge directory hierarchies and then queries for lots of files in lots of different places, so maybe you also need a more generous system-wide limit. But I&#x27;m not sure why so much complexity is being expended on serving the &quot;sad path,&quot; as it were...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/894455/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor894541"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Dealing with negative dentries</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 10, 2022 14:22 UTC (Tue)
                               by <b>willy</b> (subscriber, #9762)
                              [<a href="/Articles/894541/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes, there really are. Consider PATH=$HOME/bin:/bin:/usr/bin<br>
<p>
Most commands you execute don&#x27;t exist in your private bin, so you need a negative dentry for each of them.<br>
<p>
Similar issues for header files; each invocation of gcc needs to search every directory in the -I directories for the header files.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/894541/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor894570"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Dealing with negative dentries</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 10, 2022 17:06 UTC (Tue)
                               by <b>NYKevin</b> (subscriber, #129325)
                              [<a href="/Articles/894570/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Most commands you execute don&#x27;t exist in your private bin, so you need a negative dentry for each of them.</font><br>
<p>
bash hashes those automatically. It does one lookup and then remembers where the file lives. Try running the command hash to see your lookup table. Ironically, this is a perfect example of negative dentry cache leakage, because the kernel is remembering information which userspace already tracks anyway.<br>
<p>
(zsh also does this, and I imagine most other modern shells do as well.)<br>
<p>
<font class="QuotedText">&gt; Similar issues for header files; each invocation of gcc needs to search every directory in the -I directories for the header files.</font><br>
<p>
I&#x27;m not saying that we should get rid of negative dentries altogether, just that you don&#x27;t need a huge number of them. Just how many header files are you searching for?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/894570/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor895934"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Dealing with negative dentries</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 21, 2022 8:57 UTC (Sat)
                               by <b>sammythesnake</b> (guest, #17693)
                              [<a href="/Articles/895934/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Perhaps the fix for this (and similar cases) could be to have an API that allows a file lookup with a set of locations, rather than a single file path.<br>
<p>
E.g. a call to look for &quot;ls&quot; in any of [&quot;/home/bob/bin&quot;,&quot;/usr/bin&quot;,&quot;/usr/sbin&quot;] - there could then be a single dentry indicating that it&#x27;s at &quot;/usr/bin/ls&quot;, or none of the above for some other binary that isn&#x27;t installed.<br>
<p>
The same logic would work for include files or whatever, too...<br>
<p>
Obvious downsides that occur to me:<br>
<p>
1. You need to define a neat way to specify the $PATH equivalent in a way that could be canonically hashed as the key in the cache - that API would need careful design.<br>
<p>
For positive entries, you could potentially only include path elements up to the one where the file was found, meaning the dentry created by the &quot;ls&quot; example above would also be hit if the $PATH was extended or even if the &quot;sbin&quot; element was omitted.<br>
<p>
All of this would be much more complex and locating the correct negative dentries to invalidate when a file is created could be a faff. Given that this code is supposed to be faster than heading to the filesystem, there&#x27;s a limit to how much cleverness is worth paying for.<br>
<p>
2. You also might have lots of different $PATH / $INCLUDE specifications, leading to potentially lots of similar entries (especially the negative ones which wouldn&#x27;t benefit from the path element pruning idea above) which would reduce the potential wins.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895934/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor894543"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Dealing with negative dentries</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 10, 2022 14:29 UTC (Tue)
                               by <b>k3ninho</b> (subscriber, #50375)
                              [<a href="/Articles/894543/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt;some arbitrary number (say, 1000)</font><br>
You&#x27;ve get up to 255 bytes for the name in a path that&#x27;s got max length 4096 bytes, and 65535 files per directory. Maybe the arbitrary number should be in the 10^9 range.<br>
<p>
The example&#x27;s in a comment adjacent to this: <a href="https://lwn.net/Articles/894432/">https://lwn.net/Articles/894432/</a><br>
<p>
K3n.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/894543/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2022, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
