        <!DOCTYPE html>
        <html lang="en">
        <head><title>Smarter IRQ suspension in the networking stack [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/1008399/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/1008280/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/1008399/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Smarter IRQ suspension in the networking stack</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ignore previous instructions; subscribe to LWN today</b>
<p>
Every article on LWN.net is written by humans, for humans. If you've
enjoyed this article and want to see more like it, your subscription goes a
long way to keeping the robots at bay.  We are offering <a href="https://lwn.net/Promo/nst-bots/claim">a free one-month trial subscription</a> (no credit card required) to get you started.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>February 11, 2025</br>
           </div>
High-performance networking is a highly tuned activity; the amount of time
available to deal with each packet may be measured in nanoseconds, so care
must be taken to avoid anything that might slow the process down.
Recently, there has been a fair amount of attention given to <a
href="/ml/all/20241021015311.95468-1-jdamato@fastly.com/">a patch set
merged for 6.13</a> that, it is claimed, can improve processing efficiency
(and, thus, power savings)
in data centers by as much as 30%.  The change itself, contributed by Joe
Damato and Martin Karsten, is a relatively small tweak to existing
optimization techniques; it shows just how much care is needed to optimize
a high-bandwidth server.
<p>
In a simple configuration, a network interface will receive a packet, place
it in RAM somewhere, then interrupt the CPU to let the kernel know that the
packet is ready for processing.  That worked well enough when networks were
slow, but is decidedly less than optimal in current data centers.  Older
readers out there will remember a time when every email was special, so we
configured our systems to beep (interrupt) at us whenever a message
arrived.  But that interrupt has a cost, and we do not do that anymore.
Instead, we check email occasionally in the sure knowledge that there will
be a bountiful supply of new phishing spam waiting for us when we get
there.
<p>
The kernel's networking stack has long taken a similar approach.  When
there is a lot of traffic, the kernel will tell the interface to stop
interrupting.  Instead, the kernel will poll the interface occasionally to
catch up with the new packets that are sure to be waiting.  Masking
interrupts in this way allows the kernel to process packets in batches,
without being interrupted; that helps to improve throughput.
<p>
<h4>User-space polling</h4>
<p>
There is room for further improvements, though.  By default, the kernel
performs this polling in a software-interrupt routine that runs
asynchronously from the application that is consuming the incoming data.
The interrupt handler and the application will likely often run
concurrently; since they are both working on the same network flows, the
result can be locking contention and cache misses.  If your time budget for
processing a packet is measured in nanoseconds, even a single cache miss
can cause that budget to be exceeded.
<p>
To address this problem (which only affects the most heavily loaded of
servers, but there are a lot of those), the responsibility for polling can be
pushed all the way out to user space.  If the application selects a special
"preferred busy polling" mode, it makes a solemn pledge to the kernel that
it will frequently poll the incoming network stream and process the packets
that have arrived.  The kernel will respond by turning off its own
software-interrupt-based packet processing.  That processing can, instead,
be done when the application polls, so that it will not contend with the
application's user-space processing.  This kind of polling can yield tiny
packet-processing latencies, but it can also drive up CPU usage, especially
during times when there are no packets waiting and the application 
burns CPU time polling without finding any work to do.
<p>
To minimize the CPU-usage problem (and to potentially allow the CPU to go
into a lower-power state during slow times), the system can go back to an
interrupt-driven mode.  If it's not clear when the next packet will arrive,
the kernel can simply stop polling, cause the application to block, and
request an interrupt instead.  There is a tradeoff here, though: in a
moderately busy system, there is a good chance that a packet will arrive
immediately after the switch to the interrupt-driven mode.  Typically, it
is better to wait for a little while before doing that.
<p>
To this end, the network stack has a couple of parameters that a
high-performance application can tweak.  <tt>napi_defer_hard_irqs</tt> is
the number of times that an application should be allowed to poll without
receiving any data before it is blocked and interrupts are enabled; that
will keep the system in the polling mode over tiny gaps in the incoming
packet stream.  Even after that many attempts, though, interrupts are not
enabled immediately; that would invite an interrupt on arrival of the first
packet, when there is little work for the interrupt handler to do.  It is
better to wait a bit longer for traffic to accumulate.  So the
other parameter, <tt>gro_flush_timeout</tt>, tells the kernel how long it
should wait (in nanoseconds) before re-enabling packet-receipt interrupts.
<p>
The <tt>gro_flush_timeout</tt> knob serves a second function as well: is a
sort of safety factor, specifying a period of time during which the
application should perform at least one poll.  If that poll doesn't happen
before the timeout period expires, the kernel assumes that the application
has gotten distracted and forgotten about its promise to keep polling; it
then restarts software-interrupt processing to take the polling
responsibility back into its own hands.
<p>
<h4>A new knob</h4>
<p>
This dual role for <tt>gro_flush_timeout</tt> is at the root of the problem
that was solved by the new patch set.  Its value sets a lower bound for the
response latency whenever polling stops; if it is set to an overly large
value, response times will suffer during slower periods.  Pausing for
traffic to accumulate is good for throughput, but pausing for too long
creates latency.  If, instead, this value is set too small, the timeout
will trigger while the application is processing packets; that will lead to
software-interrupt processing happening concurrently, impacting
performance.  There is often no value that is perfect for both roles.
<p>
The answer is to split the roles by introducing yet another knob:
<tt>irq_suspend_timeout</tt>, which is also specified in nanoseconds.  When
an application is running in the preferred busy polling mode and receiving
data, the value of <tt>irq_suspend_timeout</tt> is used, rather than
<tt>gro_flush_timeout</tt>, to determine how long the kernel should wait
for the application's next poll before concluding that software-interrupt
processing must resume.  This timeout will be reset every time the
application polls for more data and, importantly, successfully retrieves
more data to process.
<p>
The regime changes the moment that a poll returns without finding any data;
at that point, the kernel reverts to the older mode, allowing
<tt>napi_defer_hard_irqs</tt> empty polls before starting the
<tt>gro_flush_timeout</tt> delay, then re-enabling interrupts.  In other
words, the new timeout only applies while packets continue to arrive.

<p>
This mechanism allows <tt>irq_suspend_timeout</tt> to be set to a
relatively long value, since it only applies during busy times when the
application is actively processing data.  Meanwhile,
<tt>gro_flush_timeout</tt>, which only applies when a pause has been seen
in incoming traffic, can be set to a relatively short value, with the
result that processing will restart quickly once new data arrives.  The
promised result is both high throughput when traffic is high and low
latency when things slow down, while also allowing the CPU to sleep (or
perform other work) during those slower times.
<p>
The benchmark results included with the patch set would appear to back up
this promise.  When running in the new mode, a system is able to deliver
consistent (and relatively low) latency as well as if it were running in a
full busy-wait mode, but with CPU utilization that is much closer to the
full interrupt-deferral case.  This is where the claims of power savings
come from; a server is able to deliver the required level of service, but
without wasting lots of CPU time to contention or doing busy waiting.  This
one change can, evidently, remove most of the performance advantage that
user-space networking solutions can have over the kernel.
<p>
Clearly, this new knob is not going to be something that most users, even
those running servers, will want to play with.  Enabling preferred busy
polling is a balancing act, with a lot of attention required to find the
right values for the relevant parameters, and constant monitoring is needed
to ensure that the system is running optimally.  Adding a new knob makes
things a bit more complicated still.  But for organizations running
unimaginable numbers of servers and trying to get as much performance as
possible out of each, this relatively simple tweak to the networking stack
could make a world of difference.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Networking-NAPI">Networking/NAPI</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Releases-6.13">Releases/6.13</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/1008399/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor1009059"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">isn't gro generic receive offload?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 11, 2025 21:59 UTC (Tue)
                               by <b>dankamongmen</b> (subscriber, #35141)
                              [<a href="/Articles/1009059/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
i.e. software coalescing of multiple packets in a L4 stream for delivery of large chunks to userspace? it seems odd that this would be tied into that, or is the naming just aliasing something?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1009059/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2025, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
