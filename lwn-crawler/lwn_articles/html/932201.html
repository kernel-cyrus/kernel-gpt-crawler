        <!DOCTYPE html>
        <html lang="en">
        <head><title>A slab allocator (removal) update [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/932201/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/932267/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/932201/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>A slab allocator (removal) update</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ready to give LWN a try?</b>
<p>
With a subscription to LWN, you can stay current with what is happening in the Linux and free-software community and take advantage of subscriber-only site features.  We are pleased to offer you <b><a href="https://lwn.net/Promo/nst-trial/claim">a free trial subscription</a></b>, no credit card required, so that you can see for yourself.  Please, join us!
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>May 22, 2023</br>
           <hr>
<a href="/Articles/lsfmmbpf2023">LSFMM+BPF</a>
</div>
The kernel developers try hard to avoid duplicating functionality in the
kernel, which is enough of a challenge to maintain as it is.  So it has
often seemed out of character for the kernel to support three different
slab allocators (called SLAB, SLOB, and SLUB), all of which handle the
management of small memory allocations in similar ways.  At the <a
href="/Articles/lsfmmbpf2023">2023 Linux Storage, Filesystem,
Memory-Management and BPF Summit</a>, slab maintainer Vlastimil Babka
updated the group on progress toward the goal of reducing the number of
slab allocators in the kernel and gave an overview of what to expect in
that area.
<p>
Babka started by saying that <a
href="/ml/linux-mm/4b9fc9c6-b48c-198f-5f80-811a44737e5f@suse.cz/">his
original proposal</a> for the session mentioned the SLOB allocator in the
title.  This allocator, which was optimized for memory-limited systems, <a
href="/Articles/918344/">has been on the chopping block</a> for a while
now.  That removal, he announced to applause, happened during the 6.4 merge
window.  There is a set of configuration options that can be selected to
make the SLUB allocator more suitable for small-memory systems.  It is now
possible to call <tt>kfree()</tt> on all slab-allocated objects â€” something
that SLOB never supported.
<p>
The next step, he said, might be to remove SLAB.  That would solve one of
his biggest problems: he never figured out how to pronounce SLAB and SLUB
so that others could hear the difference.  SLAB contains 4,000 lines of
code, he said, not all of which is regularly or well tested.  He has found
parts of the SLAB allocator that have been broken for years.  Keeping SLAB
around means maintaining a common-code layer used also by SLUB, which
complicates maintenance.  It also requires reimplementing features; both
allocators have implementations of memory control groups, for example, while
realtime preemption is only supported by SLUB.
<p>

<a href="/Articles/932206/"><img
src="https://static.lwn.net/images/conf/2023/lsfmm/VlastimilBabka-sm.png" alt="[Vlastimil Babka]"
title="Vlastimil Babka" class="lthumb"></a>


This is not the first time somebody has suggested removing SLAB; he found
at least three other times that the idea has come up. Each time the idea is
raised, somebody complains about performance regressions when using SLUB.
He wanted to know if the same objections would be raised this time.
<p>
David Rientjes is one of the developers who has objected to the removal of
SLAB in the past.  Speaking from a Google perspective, he said that things
have come a long way since then.  Per-cpu partial slabs help a lot.  He has
been looking at the benchmark results, and has concluded that, at this
point, they can go either way depending on the workload.  He did complain
that SLUB can have a higher memory overhead; partial slabs make it better,
and further progress can be made on that front.  At this point, he
concluded, he would not object to removing SLAB.
<p>
Michal Hocko said that SUSE has been using SLUB for some time; it works
better in some cases, and worse in others.  The biggest reason to make the
change, he said, was that SLUB makes debugging problems easier; he
suggested just removing SLAB and fixing any remaining problems afterward.
Matthew Wilcox said that, in the past, SLUB performed worse with certain
database benchmarks, but that problem has since gone away.
<p>
Another attendee asked about SLUB's extra memory overhead; is it something
structural, or is it something that can be chipped away at.  Babka answered
that he was surprised to hear objections about memory overhead.  SLUB, it
seems, uses about 30% more memory than SLAB to keep track of the memory it
manages; he asked whether that translated to significant amount of
memory when viewed as an absolute number.
<p>
Much of SLUB's additional overhead, he said, could be seen as a structural
problem; SLUB gets its performance by using a lot of per-CPU caches.  When
Christoph Lameter <a href="/Articles/229984/">introduced SLUB</a> in 2007,
one of his justifications for the addition of another allocator was that
SLAB used too much memory for caches.  But, Babka said, things have shifted
over time.  Addressing this memory use would require coming up with another
way to get similar performance.
<p>
Pasha Tatashin asked whether per-CPU caching still makes sense in systems
with hundreds of cores.  Babka answered that some per-CPU caching is needed
for scalability, but that there might be ways to make it more effective.
<p>
Concerns about memory usage notwithstanding,
the conclusion from the session was that nobody objects to the removal of
the SLAB allocator at this point; Babka plans to post a proposal to the
mailing lists and see what kind of reaction it gets.  Anybody who objects,
he said, should be prepared to show a use case or benchmark that regresses
with SLUB so that any remaining problems can be addressed.  But this
removal should not be held back for the sake of a microbenchmark; if there
are concrete problems, the community can discuss how to fix them.
<p>
Once that task is complete, he said, it's time to think about what is next.
API improvements will become easier once there is only one allocator to
change.  One idea he had was opt-in, per-CPU caching of array objects
which, he said, could improve performance while simultaneously reducing
overhead.  The ability to allocate in non-maskable interrupt (NMI) context
using a per-CPU cache was another idea; there would still be no guarantees
that an allocation would succeed, though.  That would allow the removal of
a BPF-specific allocator.
<p>
Perhaps, he said, the allocator could offer guaranteed allocations with
some sort of upper bound, much like mempools do now.  That could be useful
for tasks like the allocation of <a href="/Articles/845507/">maple-tree</a>
nodes.  More generally, he concluded, he would like to find ways to end the
reinvention of memory-management functionality outside of the
memory-management layer.  There are a lot of things being done now that
would be better handled in the core memory-management code.
<p>
Wilcox had one problem he would like to see a solution for that he called
"dcache poisoning".  On a system with a lot of memory and little memory
pressure, the directory entry (dentry) cache can grow without bound.  This
can be an especially big problem with workloads creating a lot of <a
href="/Articles/890025/">negative dentries</a>.  The kernel will only run
the shrinker when there is memory pressure; by the time that happens,
cleaning out the dentry cache can take a long time.  Andrew Morton
described this as a "dentry cache policy decision", but Babka said that the
allocator might be a useful part of a solution to this problem.
<p>
Babka closed the session by thanking the attendees and asking them to wish
him luck as he proceeds with the SLAB removal.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Slab_allocators">Memory management/Slab allocators</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Storage_Filesystem_Memory-Management_and_BPF_Summit-2023">Storage, Filesystem, Memory-Management and BPF Summit/2023</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/932201/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor932639"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A slab allocator (removal) update</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 22, 2023 18:08 UTC (Mon)
                               by <b>koverstreet</b> (subscriber, #4296)
                              [<a href="/Articles/932639/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
What exactly is the dcache problem?<br>
<p>
As long as running time of the dcache shrinker is linear in the amount of memory being freed, I don't see how runtime would strictly be a problem - if you're allocating a lot of memory, you're going to have to pay to reclaim a lot of memory, this is typical steady state behavior.<br>
<p>
Or is this more of a fragmentation problem, since with a large dcache the shrinker isn't likely to be reclaiming objects from the same slabs? That's a trickier problem...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/932639/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor932644"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A slab allocator (removal) update</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 22, 2023 18:47 UTC (Mon)
                               by <b>Paf</b> (subscriber, #91811)
                              [<a href="/Articles/932644/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Well, one reason might be that the shrinker can often be run synchronously as part of a memory allocation rather than separately through a thread.  Though in that case I believe they just request whatâ€™s needed, so I donâ€™t know why it would take a long time to get it just because the cache is large.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/932644/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor932662"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A slab allocator (removal) update</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 23, 2023 0:46 UTC (Tue)
                               by <b>brenns10</b> (subscriber, #112114)
                              [<a href="/Articles/932662/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
One issue with dentries is that even if the shrinker runtime is linear, the coefficient can still be pretty large. Any dentry that is in-use (typically open files as well as any dentry with a child, and several other cases) can't be freed, so you need to find a page full of unreferenced dentries. But the shrinker is (a very fuzzy approximation of) LRU, so it runs dentry by dentry until by chance, it has freed enough dentries to free a page. Since dentries are 192 bytes, it takes a while to clear out 21 dentries from the same page by chance.<br>
<p>
Thankfully, in the "silly" examples of bad workloads, all 21 dentries were created by the same application looking up non-existent files, and they all got added to the LRU at the same time. But if the workload looks at all more complicated with mixed-lifetime objects, it can get ugly.<br>
<p>
That said, it may not be that different from other caches, I haven't looked at a lot of others.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/932662/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor932667"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A slab allocator (removal) update</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 23, 2023 5:34 UTC (Tue)
                               by <b>mokki</b> (subscriber, #33200)
                              [<a href="/Articles/932667/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I've maintained CI machines that have 50% of 384 GiB memory in negative dentries.<br>
Often, when the kernel tried to free some more memory, the result was soft lockups of over 1 minute in dmesg.<br>
Flushing manually the dentry cache regularly helped. This was ~6 years ago and hopefully there are now better limits to the max amount of negative dentries.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/932667/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor932739"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A slab allocator (removal) update</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 23, 2023 18:03 UTC (Tue)
                               by <b>WolfWings</b> (subscriber, #56790)
                              [<a href="/Articles/932739/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Still no maximum limits for negative dentries at all in any LTS kernels I'm aware of, and they get intermixed entirely with 'positive' dentries.<br>
<p>
There's been numerous attempts to improve the situation over the years, LWN articles about it even, but it never makes progress since it's a relatively niche situation without enough visibility to most kernel devs to maintain momentum to improve the situation. I'm not even sure there's any mechanism to stop the dentry cache purge when memory-pressure triggers it... it may literally scan ALL of cache and purge what it can instead of freeing say a few MB and stopping, I haven't checked the code in depth but that's the general behavior I've seen in the past.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/932739/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2023, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
