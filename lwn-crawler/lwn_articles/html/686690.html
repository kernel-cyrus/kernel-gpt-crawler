        <!DOCTYPE html>
        <html lang="en">
        <head><title>Transparent huge pages in the page cache [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/686690/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/686393/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/686690/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Transparent huge pages in the page cache</h1>
</div>
<div class="ArticleText">
<div class="GAByline">
           <p>May 11, 2016</p>
           <p>This article was contributed by Neil&nbsp;Brown</p>
           </div>
<p>As <a href="https://lwn.net/Articles/684300/">was discussed</a> at the
recent <a href="/Articles/lsfmm2016/">Linux Storage, Filesystem, and
Memory-Management Summit</a>, there is interest in adding <a
href="https://lwn.net/Articles/423584/">transparent huge page</a> (THP)
support to filesystems, particularly tmpfs but ultimately others as well.
Huge pages are important when mapping large files into a process's virtual
memory as they reduce the per-access overhead.  Supporting huge pages
transparently is essential as the tradeoffs between huge and non-huge
pages depend on system-level parameters such as the amount of free memory
and its level of fragmentation.  Individual applications are not able to
assess these parameters and so cannot be expected to make appropriate
decisions.
<p><blockquote class="ad">
<b><tt>$ sudo subscribe today</tt></b>
<p>
Subscribe today and elevate your LWN privileges. You’ll have
access to all of LWN’s high-quality articles as soon as they’re
published, and help support LWN in the process.  <a href="https://lwn.net/Promo/nst-sudo/claim">Act now</a> and you can start with a free trial subscription.
</blockquote>
<p>
The level of interest in THP for filesystems is such that two competing
patch sets have 
emerged that provide similar functionality with quite different approaches.
The discussions at the summit were largely about engineering
issues, including amount of testing, general maintainability, and level of
intrusiveness into other parts of the kernel.  While these are appropriate
for that forum, they can leave the technically minded wondering what the
deep technical differences are, what these new &quot;team
pages&quot; are, and whether they are — or are not — a good idea.</p>

<p>Before delving into those differences, it will be useful to understand
how the requirements for THP support in filesystems differ from those for the
existing THP support for anonymous memory.  The different requirements
primarily come from the fact that files can be accessed concurrently
and in different sized units, and particularly how this can cause the
file to grow.</p>

<p>Anonymous memory is only accessed by memory mapping (i.e. with
<tt>mmap()</tt>) and the size of this mapping is usually fixed on allocation.
Sharing between processes only happens as the result of a <tt>fork()</tt>
call and, for the 
process-private mappings that support THP, huge pages will only remain shared as
long as they are unchanged.  So every mapping of an anonymous transparent
huge page will be the same size.</p>

<p>Memory used for file-backed data can be accessed by direct reads and
writes and can be mapped concurrently by multiple processes, which may
request differently sized mappings.  Preventing one process from getting
a huge mapping because some other process has only mapped one or two (small)
pages is not nearly so acceptable as it might be with anonymous memory.  For
this reason, THP for filesystems must be able to support
concurrent mapping as both huge and non-huge pages.</p>

<p>Unlike anonymous memory, space in files isn't allocated by mapping it:
that happens as the result of <tt>write()</tt> or <tt>fallocate()</tt>
calls.  The allocated size may not be a multiple of the huge-page
size, and the space allocated may not even be contiguous if holes are
left.  If huge pages were only used once a file was large enough to
completely fill them, then a file that was not initially allocated to its
final size would need to be migrated from individual pages to huge
pages before a huge-page mapping would be possible.  This would often
be unnecessary work.  So THP for files must allocate huge pages before
the file is known to be big enough to fully utilize them.</p>

<p>Finally, a file may be used without being mapped into process memory at
all, while anonymous memory is always mapped.  So any changes to a
filesystem to support transparent huge page mapping must not negatively
impact normal read/write performance on an unmapped file.</p>

<p>The two patch sets approach these challenges from two different
directions.  One seems to say &quot;we know how to do filesystems, let's
build on that to enable huge mappings&quot;.  The other starts with &quot;we
know how to do huge mappings&quot; and proceeds to &quot;how can we adjust those
to work with filesystems?"  Both patch sets support only tmpfs.
This allows for valuable simplifications but means they cannot easily
be assessed as fully general solutions.</p>

<h4>Page teams: extending filesystems toward huge pages</h4>

<p>The <a href="/Articles/682623/">first patch set</a> is in use at Google
and is being championed by Hugh Dickins.  It starts with current
filesystem use of the page cache and asks &quot;how can we encourage
huge page mappings?&quot;.  This involves allocating a &quot;high
order&quot; physically contiguous set of pages when possible, annotating
them so that the memory-management code can easily detect that a huge-page
mapping will work, and allowing the set to be broken into individual pages
when, but only when, necessary.</p>

<p>The allocation step is relatively straightforward: when allocating
memory in the page cache, if there are not currently any allocated
pages in the region that a huge page would fill, request a huge page.
If that works, good.  If not, just fall back to individual small
pages.</p>

<p>The annotation step is where the term &quot;team pages&quot; comes in;
the large allocation is referred to as a "team" or "team of pages."
The first page of the
high-order set of pages, and every page in that set that has been
instantiated in the file, gets a new page flag: <tt>PG_team</tt>.  This
makes it easy, when looking at a page, to know if it is part of a larger
team allocation.  By itself this is not quite enough to allow a huge page
to be mapped since, when that mapping happens, any &quot;holes&quot; within
that page must be instantiated as they could be written to.  So every small
page must get <tt>PG_team</tt> set.  This instantiation happens the first
time that a huge mapping is attempted, and an extra page flag —
<tt>PG_checked</tt> — is set on the head page.  From then on, a huge mapping
can be created after just checking for <tt>PG_team</tt> and
<tt>PG_checked</tt>.</p>

<p>

Finally, it must be possible to break up the team when free memory is
short. There are two sides to this. If a team has never been mapped as a
huge page, it may have some unallocated pages (<tt>PG_team</tt> not set)
that are invisible to memory management (as they are not part of the file),
but must be made visible so they can be released when memory pressure is
high.  Pages in the team that <i>are</i> part of the file will be tracked
on an LRU (least recently used) list so that the oldest pages can be
written out to swap should that become necessary. Either of these will
require disbanding the team before individual pages are written or freed.


<p>Unallocated pages are marked in the file's <a href="/Articles/175432/">radix
tree</a> using a tag, <tt>SHMEM_TAG_HUGEHOLE</tt>, which reuses the
<tt>PAGECACHE_TAG_DIRTY</tt> tag used by normal filesystems.  All files
with &quot;huge holes&quot; are kept in a new LRU list that is scanned by
a shrinker when memory reclaim tries to recover memory.  The
basic approach of this shrinker is, <a
href="http://mid.gmane.org/alpine.LSU.2.11.1604051417530.5965@eggly.anvils">quoting
Dickins</a>, to "<q>find [the] least occupied huge page in [the] older
half of shrinklist, and 
migrate its cachepages into the most occupied huge page with enough
space to fit, again chosen from [the] older half of shrinklist.</q>"
<p>

Rather than just freeing some scattered pages, it attempts to free a
whole huge page.  This generally helps reduce fragmentation of free
space, so there are more likely to be huge pages free the next time one is
needed.

<p>When dismantling a team of pages that has no holes, it is necessary to
get a page lock on the head page first in order to avoid racing with an
attempt to map the whole team into an address space.  Consequently,
attempting to 
disband a team when a tail page has reached the top of the LRU list is
problematic since the reclaim process is not a good time to lock some other
page. The page-teams patch set addresses this by refusing to write a
tail page to swap before the head page has been written.  When the
head page is processed, it disbands the team, writes out that head,
and thus frees all the tail pages to be written when their time comes.
As pages tend to be written out in the same order as in the file, this
usually works quite well.</p>

<p>When it doesn't work, though, the very large number of pages that refuse
to be 
evicted (up to 511 for every 512) can distort the active and inactive page
counts that are used to guide page eviction.   To address this,
slightly creative accounting is used to not count the tail pages, but
instead to count the head pages as though they were multiple pages.
This means that, as long as the head page is active, the whole team is
accounted as active, and the memory reclaim code will be keen to
transition more pages from active to inactive so they can then be
freed.</p>

<p>While this approach seems to have minimal impact on filesystems by
allowing them to continue to use pages in the page cache much as they
already do, there are problems.  As already noted, the
<tt>PAGECACHE_TAG_DIRTY</tt> tag is being reused to record where in the
radix tree there are holes that can be reclaimed.  This is not a problem
for tmpfs as its pages don't have a distinction between
&quot;clean&quot; and &quot;dirty&quot;.  Anything that is in memory can be
written to swap and then removed from memory, it need never be marked
&quot;clean&quot;.  It is a problem for most other filesystems, though, so some
other way of finding &quot;huge holes&quot; would need to be found.</p>

<p>Another conflict is that, to achieve the creative accounting mentioned,
the head page holds a count of the number of allocated tail pages.
This number is stored in the same place in the page description
structure that most filesystems use to store a pointer to their own private
data. 
This is not a problem for tmpfs, which doesn't use the <tt>private</tt> field,
but would be for other filesystems.  And then there is that fact that
the head page of a team imposes a particular meaning on the
<tt>PG_checked</tt> flag, which would interfere with file systems that use
that flag themselves.</p>

<p>It is quite possible that these issues can all be addressed with
sufficient ingenuity.  The patch set is deliberately aimed at
supporting only tmpfs, not on general filesystem support, to keep the
complexity manageable.  But they are issues to keep in mind when
considering the long term future of THP support in the page cache.</p>

<h4>THP-enabled tmpfs using compound pages</h4>

<p>The <a
href="/Articles/684087/">second
patch set</a> under consideration comes from Kirill Shutemov.  It starts
with the premise that the memory-management code already knows how to map
<a href="/Articles/619514/">compound pages</a> into a process's address space,
because they are used for anonymous THP and for files in the <a
href="/Articles/374424/">hugetlbfs filesystem</a>.  It tries to make such
compound pages (collections of pages that largely behave like a single
page) usable by a filesystem, particularly tmpfs.</p>

<p>Having individual compound pages, rather than teams of small pages, means
that the active/inactive LRUs just see the one page rather than multiple
related pages on different LRUs, so the creative accounting needed for page
teams is irrelevant here.  However, when memory is mapped with
<tt>MAP_LOCKED</tt>, it must be accounted as &quot;unevictable&quot; rather
than active or inactive.  If just part of a compound page is mapped and
locked, some <a
href="http://mid.gmane.org/1460766240-84565-2-git-send-email-kirill.shutemov@linux.intel.com">extra
care</a> is needed, once again, to get that accounting right.</p>

<p>Unlike the page team approach, compound pages provide no obvious
mechanism for keeping track of the free space that might be at the end
of a compound page after the end of the file.  The current patch set
doesn't address this at all, treating that space as in-use until the
compound page is disbanded for some other reason, typically to write
it out to swap.  There are suggestions that this will be addressed in
a future patch set.  Similarly this patch set makes no effort to
support page-sized holes within a compound page.</p>

<p>Processes expect to be able to map individual small pages.  If the
region they want to map is within a compound page, this becomes more
complex: it is necessary to find the compound page that contains the
target region and then map part of that.  The current approach for
finding that compound page stores all the small pages within the
compound page in the page-cache radix tree.  This is similar to how
page teams operate, but doesn't make best use of having a single compound
page.  This solution is expected only to be interim.  Matthew Wilcox,
one of the DAX developers, has <a href="/Articles/684864/">some patches</a>
that enhance the radix 
tree to be able to store a single entry covering a large range of
addresses.  This 
will help with DAX, which uses huge, and even larger, pages and would
help with mapping compound pages too.</p>

<p>Allowing, eventually, only one radix tree entry per huge page is a real
benefit, and there are other related benefits.  Any operation that works a
page at a time could fairly easily operate on a huge page at a time, thus
reducing per-page overhead.  Andrea Arcangeli, architect of the original
huge-page support in Linux, sees this as a key issue, <a
href="http://mid.gmane.org/20160419165024.GB24312@redhat.com">noting
that</a>:</p>

<p>
<div class=BigQuote>
My view is that in terms of long-lived computation from userland point
of view, both models are malleable enough and could achieve everything
we need in the end, but as far as the overall kernel efficiency is
concerned the compound model will always retain a slight advantage in
performance by leveraging a native THP compound refcounting that
requires just one atomic_inc/dec per THP mapcount instead of 512 of
them.
</div>

<p>In terms of compatibility with other filesystems, it is quite clear
that a traditional filesystem would need a lot of change to work with
compound pages.  A filesystem will typically attach some private data
to each page, possibly a list of <tt>buffer_head</tt>s  describing the
filesystem blocks in that page.  With compound pages that private data
structure will now have to describe a much larger range of blocks.  A
<a
href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/tree/fs/buffer.c?id=b562e44f507e863c6792946e4e1b1449fbbac85d#n218">linear
search</a> as currently used would no longer be appropriate.  On
the positive side, at least there is somewhere to store that private
data, which is not currently the case with team pages.</p>

<h4>Six of one, half a dozen of the other</h4>

<p>The two approaches are clearly different and they both have costs
and benefits.  Probably the two key questions are: which provides the
lowest overheads for large scale operations, and which integrates more
easily with other filesystems.  Neither patch set is really
sufficiently mature to provide answers to those questions and it wouldn't
be at all surprising if each question is answered best by a different
approach.  Continuing on without a clear decision does not seem
likely to be in the best interests of Linux in the short term, but
making one now does not seem at all easy.  I'm certainly glad that it
isn't my responsibility to make that call.</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Huge_pages">Huge pages</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Huge_pages">Memory management/Huge pages</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Brown_Neil">Brown, Neil</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/686690/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor687120"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Transparent huge pages in the page cache</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 12, 2016 7:17 UTC (Thu)
                               by <b>matthias</b> (subscriber, #94967)
                              [<a href="/Articles/687120/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; This is not a problem for tmpfs as its pages don't have a distinction between "clean" and "dirty". Anything that is in memory can be written to swap and then removed from memory, it need never be marked "clean".</font><br>
<p>
Why doesn't tmpfs distinguish between clean and dirty? Is it not possible that a file written to swap previously is just loaded back to memory for reading? In this case its pages should be clean. It should be possible to remove the pages from memory without another writeback.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/687120/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor687129"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Transparent huge pages in the page cache</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 12, 2016 9:32 UTC (Thu)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/687129/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
What an excellent question - thanks!  I'm not very familiar with those sorts of details of tmpfs and I glossed over them a bit in the article.<br>
<p>
I've had a look at the code and while I agree that tmpfs *could* distinguish between clean and dirty, it doesn't.<br>
For anonymous memory there is a thing called the "Swap cache".  Data read back from swap is recorded in there until the page is dirtied so if it needs to be "Swaped out" again it is already known where on the swap device it is and no write-out is needed.<br>
This doesn't seem to apply to tmpfs.<br>
<p>
When shmem_getpage_gfp() loads a page in from swap, it immediately calls delete_from_swap_cache(page) and set_page_dirty(page).  So the page is immediately marked as 'dirty'.<br>
<p>
I don't know why this is, but I suspect there is a good reason..... unless it is an historical accident :-)<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/687129/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor687193"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Transparent huge pages in the page cache</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 12, 2016 14:37 UTC (Thu)
                               by <b>riel</b> (subscriber, #3142)
                              [<a href="/Articles/687193/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I believe the reason is that a page can only be part of one page cache mapping at a time.<br>
<p>
Either the page is in the swap cache mapping, or it is in the file mapping.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/687193/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2016, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
