        <!DOCTYPE html>
        <html lang="en">
        <head><title>Bus1: a new Linux interprocess communication proposal [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/697191/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/697029/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/697191/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Bus1: a new Linux interprocess communication proposal</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ready to give LWN a try?</b>
<p>
With a subscription to LWN, you can stay current with what is happening in the Linux and free-software community and take advantage of subscriber-only site features.  We are pleased to offer you <b><a href="https://lwn.net/Promo/nst-trial/claim">a free trial subscription</a></b>, no credit card required, so that you can see for yourself.  Please, join us!
</blockquote>
<div class="GAByline">
           <p>August 17, 2016</p>
           <p>This article was contributed by Neil&nbsp;Brown</p>
           </div>
<p>Anyone who has been paying attention to Linux kernel development in
recent years would be aware that IPC — interprocess communication — is not
a solved problem.  There are certainly many partial solutions, from pipes
and signals, through sockets and shared memory, to more special-purpose
solutions like <a href="https://lwn.net/Articles/466304/">Cross Memory
Attach  and Android's binder</a>.  But it seems there
are still some use cases that aren't fully addressed by current solutions,
leading to new solutions being occasionally proposed to try to meet those needs.
The latest proposal is called &quot;bus1&quot;.  While that isn't a
particularly interesting name, it could be much worse: it could have been
named after a town in Massachusetts like <a
href="https://en.wikipedia.org/wiki/Wayland_(display_server_protocol)">Wayland</a>,
<a href="https://en.wikipedia.org/wiki/Dracut_(software)">Dracut</a>, <a
href="https://en.wikipedia.org/wiki/Plymouth_(software)">Plymouth</a>, and
others.</p>

<p>The focus for bus1 is much the same as that for <a
href="https://lwn.net/Articles/580194/">recent &quot;kdbus&quot;
proposals</a> — to provide kernel support for D-Bus — and the
implementation has strong similarities with binder, which occupies a
similar place in the IPC space.  The primary concerns seem to be
low-overhead message passing between established peers and multicast,
which are useful for remote procedure calls and distributing status
updates, respectively.</p>

<p>David Herrmann <a
href="https://lists.linuxfoundation.org/pipermail/ksummit-discuss/2016-July/003047.html">announced
bus1</a> on the kernel-summit mailing list with the goal of having a
session for discussing the new functionality at the upcoming summit in
November.  The announcement was accompanied by <a
href="https://github.com/bus1">a link to the 
current code and documentation</a>, which is pleasingly well organized and
thorough.  Any imperfections are easily explained by the fact that bus1 is
under active development and did not interfere with my ability to form the following
picture of the structure, strengths, and, occasionally, weaknesses of
bus1.</p>

<h4>Peers, nodes, and handles</h4>


<p>

All communication mediated by bus1 travels between "peers", where a peer is
a kernel abstraction somewhat like a socket.  A process accesses a peer
through a file descriptor which, in the current implementation, is obtained
by opening the character special device <tt>/dev/bus1</tt>.  Tom Gundersen,
one of the authors, <a
href="https://lists.linuxfoundation.org/pipermail/ksummit-discuss/2016-July/003152.html">acknowledged</a>
that having a dedicated system call to create a peer, and to perform the
various other operations that currently use <tt>ioctl()</tt>, might make
more sense for eventual upstream submission.  Devices and <tt>ioctl()</tt>
have been used so far because they make out-of-tree development easier.

<p>A peer is not directly addressable, but it can hold an arbitrary
number of addressable objects known as &quot;nodes&quot;.  Bus1 maintains
minimal state about a node beyond a reference counter and linkage into
other data structures; it serves only as a rendezvous point.  When a
message is sent to a node, it is delivered to the peer that owns the node,
and the peer is told &quot;this message was sent to that node&quot;.  The
application managing the node can interpret that as a particular object, or 
as a particular service, or whatever is appropriate.</p>

<p>Nodes themselves do not have externally visible names, but are
identified by &quot;handles&quot; that are a little bit like file
descriptors, a little bit like the &quot;watch descriptors&quot; used by
inotify, and a lot like the object descriptors used by binder.  As such, a
handle acts like a &quot;capability&quot;.
If a peer holds a handle that identifies a particular node, then it has
implicit permission to send messages to that node, and hence whatever object
some application associates with that node.
If, instead, it doesn't have a handle for a particular
node, the only way get one is to ask another node to provide it, and that
is where permission checking will happen.</p>

<p>A handle is a 64-bit number (allocated by bus1) that only has
meaning in the context of a particular peer, in the same way that a file
descriptor only has meaning the context of the process that owns it.  A
handle refers to a node that belongs to some peer; it might be the same
peer that owns the handle, or it might be a different peer.  In the latter
case, the handle effectively acts as a link between two peers, though
neither can directly determine any details of the other.</p>

<p>

To create a new node, an application performs any of the various
<tt>ioctl()</tt> operations that accept a handle, passing the special
reserved handle number of "3".  This causes a new node to be allocated; the
handle number for that node will replace the reserved number in the
argument to <tt>ioctl()</tt>.

<p>When a peer is created by opening <tt>/dev/bus1</tt>, it has no nodes
and no handles.  Nodes local to the peer can be created on demand as
described above, but an extra step is required to get a handle for a node
in another peer.  The <tt>BUS1_CMD_HANDLE_TRANSFER</tt> <tt>ioctl()</tt>
can be used for this.

This <tt>ioctl()</tt> is called on the file
descriptor for one peer and is given the file descriptor for the
destination peer along with the handle to transfer.  A new handle will be
created for the second peer referring to the node pointed to by the
original handle.
<p>
The question of how to arrange for a process to have two different
peer-descriptors so it can call <tt>BUS1_CMD_HANDLE_TRANSFER</tt> is not
addressed by bus1.  One option would be to have a daemon listening on a
Unix-domain socket.  An application that wants to communicate on that
daemon's bus would open <tt>/dev/bus1</tt> and send the resulting file descriptor
over a socket to the daemon.  The daemon would then perform the handle
transfer and tell the application what the new handle is.

<p>This mechanism could be repeated to give the first peer a handle that
can be used to reach the second, but once there is this one point of
communication, it is possibly easier to use the more general approach of
message passing.</p>

<h4>Messages, queues, and pools</h4>

<p>
The core functionality of any IPC mechanism is to pass messages.  Bus1
allows a message to be sent via a peer to a list of nodes by specifying a
list of destination handles.  This message has three
application-controlled segments and a fourth segment that is imposed by
bus1.


<p>The three application-controlled segments all contain resources to be
passed to the message recipient(s).  They are: a block of uninterpreted
data that can be assembled from multiple locations as is done by <a
href="http://man7.org/linux/man-pages/man2/readv.2.html"><tt>writev(2)</tt></a>,
a list of handles, and a list of file descriptors.  The handles and file
descriptors are mapped to references to internal data structures when a
message is sent, and mapped back to handles and descriptors relevant to the receiver
when it is received.  In order to give an application control over its open files, the
receiving application can request that files not be mapped to local
    file descriptors.  This is particularly useful when combined with
    the "peek" version of message reception which reports the content of
    the message without removing it from the incoming queue.

<p>If a peer is sent a handle for a node that it already has a handle for,
then the handle it is given will be exactly the same as the handle it
already has.  This means that handles can be compared for equality by just
comparing the 64-bit values.  This contrasts with file descriptors in that
when a file descriptor is received, a new local descriptor is allocated
even if the process already has the same file open on a different
descriptor.</p>

<p>The fourth segment of a message identifies the sender of the message; it
contains the sender's process, thread, user, and group IDs.  Each of these numbers
is mapped appropriately if the message travels between namespaces.  These
details are similar to those contained in the <tt>SCM_CREDENTIALS</tt>
message that can be passed over a Unix-domain
socket, but with an important difference:  when using
<tt>SCM_CREDENTIALS</tt>, the sending process provides the credentials
and the kernel validates them; with bus1, instead, the sending process has no
control at all.  This means that if the sending process is running a
setuid program and has different real and effective user IDs, it cannot
choose which one to send.  Bus1 currently insists on always sending the
real user and group IDs.</p>

<p>Note that the identification of the sender does not include a handle by
which a reply might be sent.  If the sender wants a reply, it must
explicitly pass a handle as part of the message; there is no implicit
return path.</p>

<p>As mentioned, a list of recipient handles can be given, and the message
will be delivered to all of the recipients, if possible.  This provides a
form of multicast, though there is no native support for a
publish/subscribe multicast arrangement where multicast messages are sent
to a well-known address and recipients can indicate which addresses they
are listening on.  If publish/subscribe is needed, it would have to be
layered on top with some application maintaining subscription lists and
sending messages to those lists as required.</p>

<p>Each peer has a &quot;pool&quot; of memory, currently limited to 256MB,
in which incoming messages are placed.  When a message is sent to a
particular peer, space is allocated in that peer's pool and the data
segment of the message is copied directly from the sender's memory into the
recipient's pool.  The recipient can map that pool into virtual memory and
will get read-only access to the data.  When it has finished with
the data it can tell bus1 that section (or &quot;slice&quot;) of the pool
is free for reuse.</p>

<p>The message-transfer process copies the data to the pool, reserves a
little extra space in the pool to store the translated handles and file
descriptors, and adds a fixed-sized structure with other message details to
a per-peer queue.  Once there is a message on the queue, the peer's file
descriptor will report to <tt>poll()</tt> or <tt>select()</tt> that
it is readable; an <tt>ioctl()</tt> request can then be made to find out
where in the pool the message is and to collect other details like the sender's
credentials.  It is only when this request is made that the handles and
file descriptors are translated and their details added to the pool.</p>

<p>In order to avoid denial-of-service attacks, each user has quotas limiting
the amount of space they can consume in pools by sending messages and the
number of handles and file descriptors they can have sent that haven't
been processed yet.  The default quota on space is 256MB in a total of at
most 16,383 messages.  As soon as the receiving application accepts the
message, whether it releases the pool space or not, the charge against the
sender is removed.</p>

<h4>Total message ordering</h4>

<p>An important property that the bus1 developers put some effort into
providing is a global ordering of messages.  This doesn't mean that every
message has a unique sequence number, but instead provides semantics that
are just as good for practical purposes, without needing any global
synchronization.</p>

<p>The particular properties that are ensured are &quot;consistency&quot;
(if two peers receive the same two messages, they will both see them
in the same order), and &quot;causality&quot; (if there is any chance
of causality between two messages, then the message relating to the cause
will be certain to arrive before the message relating to the result).  This
is achieved using local clocks at each peer that are synchronized in a
manner similar to that used for <a
href="https://en.wikipedia.org/wiki/Logical_clock">Lamport clocks</a>.  For
the fine details it is best to read the <a
href="https://github.com/bus1/bus1/wiki/Message-ordering">documentation
section on message ordering</a>.</p>

<h4>Like binder, only better?</h4>

<p>As I absorbed all the details about bus1, I was struck by its
similarities to Android's binder.  The message structure is similar, the handles are
similar, and the use of a pool to receive messages is similar.  Though I
haven't covered them here, bus1 delivers node destruction messages when a
node is destroyed in a similar manner to binder.  Given this, a useful
perspective might be provided by looking for differences.</p>

<p>The most obvious difference is that binder strongly unifies the concept
of a peer with that of a process.  In binder, the message-receipt pool is
reserved in one process's address space, and each object ID, the equivalent
of a bus1 handle, is a per-process identifier.  Having all these concepts
connected with a file descriptor in bus1, instead of with a process, is a
clear improvement in flexibility and simplicity.</p>

<p>Binder has an internal distinction between requests and replies, and a
dedicated send/wait/receive operation so that a complete remote procedure
call can be effected in a single system call. Bus1 doesn't have this and so
would require separate send, wait, and receive steps.  This may seem like a
minor optimization, but there is an important underlying benefit that this
brings to binder.</p>

<p>Unifying all the steps into a single operation provides binder with the
concept of a transaction; the message and reply can be closely associated
into a single abstraction.  If the recipient of the message needs to
perform other IPC calls as part of handling the message, binder can see
those as part of the same transaction, which will continue until the reply
comes back to the originating process.  Since all of this can be identified as
a single transaction, binder is able to temporarily elevate the priority of
every process involved to match the priority of the calling process,
effectively allowing priority inheritance across IPC calls.  The
introduction to bus1 that was posted to the kernel-summit list identified
priority inheritance as an important requirement for an IPC system, but the
current code and documentation don't give any hint about how that will be
implemented.  Until we can see the design for priority inheritance, we
cannot know if discarding the transaction concept of binder is a good
simplification, or a bad loss of functionality.</p>

<p>Any IPC mechanism requires some sort of shared namespace for actors to
find each other.  Both binder and bus1 largely leave this to other layers,
though in slightly different ways.  In binder there is a single well-known
object ID — the number &quot;0&quot;.  Only a single privileged process can
receive messages sent to &quot;0&quot;.  An obvious use of this would be to
support registration and lookup in a global namespace.  The process
listening on ID&nbsp;0 would be a location broker that checked the privileges of
any processes registering a name, and then would direct any request for
that name to the associated object.
Bus1 doesn't even have this "ID&nbsp;0".  Whatever handshake is used to
allow <tt>BUS1_CMD_HANDLE_TRANSFER</tt> to be called must also make sure that
each new client knows how to contact any broker that it might need.

<p>
Finally, binder has nothing like the global message-ordering guarantees
that bus1 provides, but bus1 has nothing like the thread-pool management
that is built into binder.  The importance of either of these cannot be
known without considerable experience working in this space, so it might be
a worthy topic to explore at the Kernel Summit.  These differences,
together with the lack of a request/reply distinction in bus1, are probably
enough that it would be unwise to hope that bus1 might eventually replace
binder in the kernel.


<h4>Summary</h4>

<p>It is early days yet for bus1.  Though it has been under development for
a least eight months (based on Git history) and is based on even older
ideas, there has been little public discussion.  The follow-up comments on
the kernel-summit email thread primarily involved people indicating their
interest rather than commenting on the design.  From my limited perspective,
though, it is looking positive.  The quality of the code and documentation
is excellent.  The design takes the best of binder, which is a practical
success as a core part of the Android platform, and improves on it.  And
the development team appears to be motivated towards healthy informed
community discussion prior to any acceptance.  The tea-leaves tell me there
are good things in store for bus1.</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#bus1">bus1</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#kdbus">kdbus</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Message_passing">Message passing</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Brown_Neil">Brown, Neil</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/697191/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor697473"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 17, 2016 20:24 UTC (Wed)
                               by <b>cruff</b> (subscriber, #7201)
                              [<a href="/Articles/697473/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Hopefully it will be documented better than netlink sockets, especially rtnetlink.  That was really painful to work through.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697473/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697487"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">bus1 v binder</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 0:13 UTC (Thu)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697487/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
One important distinction between bus1 and binder is that binder does not do multicast. That explains why binder does not need to care about message ordering. Moreover, the priority inheritance scheme is a more natural fit when everything is unicast only.<br>
<p>
There is no intrinsic reason why some more of the binder features could not be added to bus1. One could for instance imagine (suitably restricted) "reply-handles" that imply priority inheritance. The send/wait/receive ioctl is also a natural extension (even if all it does is optimize away some ioctl calls).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697487/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor697489"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Discoverability</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 0:19 UTC (Thu)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697489/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
As the article says, one way to have some global broker, would be through a UDS socket where bus1 fds could be passed back and forth to query the required handles.<br>
<p>
Another approach that we played around with would be to have a service manager pass in a pre-initialized bus1 fd when it spawns a service, containing handles to all its dependencies. This would require something like dependencies being declared in a manifest installed with each service and have nodes created and handles distributed accordingly.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697489/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor698199"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Discoverability</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 25, 2016 6:32 UTC (Thu)
                               by <b>HelloWorld</b> (guest, #56129)
                              [<a href="/Articles/698199/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The latter sounds a lot like CloudABI, have you given that a look?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/698199/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor697498"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 5:32 UTC (Thu)
                               by <b>Cyberax</b> (<b>&#x272D; supporter &#x272D;</b>, #52523)
                              [<a href="/Articles/697498/">Link</a>] (21 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It would have been nice if they used file descriptors instead of handles.<br>
<p>
I know that FDs are a very scarce resource that is expensive to create (due to its dense address space), but perhaps this should be fixed by itself.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697498/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697521"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 11:21 UTC (Thu)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697521/">Link</a>] (20 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I don't think that would be workable, but ignoring that, care to elaborate on the benefit you think that would have?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697521/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697524"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 11:39 UTC (Thu)
                               by <b>HenrikH</b> (subscriber, #31152)
                              [<a href="/Articles/697524/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
To be able to add support for select(), poll() and epoll() ?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697524/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697530"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 12:55 UTC (Thu)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697530/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
But this would be orthogonal to the actual IPC mechanism, right? So regular FD passing should cover that just fine? Or did you mean somehow poll()ing on IPC operations?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697530/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697576"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 16:44 UTC (Thu)
                               by <b>pbonzini</b> (subscriber, #60935)
                              [<a href="/Articles/697576/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes, that's how I read it as well. On the other hand it seems like /dev/bus1 is pollable ("once there is a message on the queue, the peer's file descriptor will report to poll() or select() that it is readable").<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697576/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697577"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 16:52 UTC (Thu)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697577/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Correct /dev/bus1 is pollable.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697577/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor697566"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 15:20 UTC (Thu)
                               by <b>drag</b> (guest, #31333)
                              [<a href="/Articles/697566/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I would guess that it would make things slightly easier to deal with. <br>
<p>
<font class="QuotedText">&gt; Nodes themselves do not have externally visible names, but are identified by "handles" that are a little bit like file descriptors, a little bit like the "watch descriptors" used by inotify, and a lot like the object descriptors used by binder.</font><br>
<p>
Instead a 'little bit' like file descriptors maybe they can be a 'whole lot like' file descriptors that people can use inotify to monitor? <br>
<p>
DRI3 itself uses file descriptors as references generated textures and passing FDs around instead of textures seemed like a big win for that.  Maybe dbus lib could be reworked so that when programs launch and register themselves with the dbus daemon the dbus daemon obtains a bus1 FD, registers it, and passes that onto the libdbus client.  That way programs don't need to communicate directly with the daemon anymore. FDs can be passed into sandboxes and if dbus syncs it's view of the world to storage dbus could survive dbus crashes and restarts.   It may also greatly simplify people that want to do 'direct access' to these sorts of busses without pulling in a lot of dependencies. <br>
<p>
Maybe it will make it easier to get dus1 compatible APIs into other Unix kernels as well.  As a propaganda win it will fit in with the 'everything is a file' model. <br>
<p>
I donno. I don't really understand low-level OS programming that very well, so forgive my ignorance.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697566/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697579"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 17:10 UTC (Thu)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697579/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Instead a 'little bit' like file descriptors maybe they can be a 'whole lot like' file descriptors that people can use inotify to monitor? </font><br>
<p>
You mean poll() I guess? At any rate, the way it works now is that you poll() on the /dev/bus1 fd and that will tell you when there are messages to be read destined for any node.<br>
<p>
You cannot currently poll on just one node, as messages are ordered per-peer that does not really make sense. But if that was desirable, it could be done without actually replacing handles with fds altogether.<br>
<p>
One could imagine an ioctl acting like poll on a single node or a set of nodes, or one could imagine an ioctl creating a fd representing a single node or a set of nodes, which can then be polled() on. I'd be interested in first seeing what in particular this would be used for though.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697579/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697590"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 19:30 UTC (Thu)
                               by <b>excors</b> (subscriber, #95769)
                              [<a href="/Articles/697590/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; One could imagine an ioctl acting like poll on a single node or a set of nodes</font><br>
<p>
I think that would be a non-ideal design - it's often useful to wait on multiple different types of object (e.g. an event loop that listens to IPC channels, and network sockets, and an eventfd or pipe to get woken up by other threads), but that's only possible if everything is an fd, not if each type of object has its own poll-like API.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697590/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor697582"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 17:25 UTC (Thu)
                               by <b>Cyberax</b> (<b>&#x272D; supporter &#x272D;</b>, #52523)
                              [<a href="/Articles/697582/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I think that it will be workable, file structures are not that heavyweight if we forgo the dense address space.<br>
<p>
Advantages are several - we already have quite a lot of infrastructure to deal with files, like suspend/resume and /proc interface that is useful for debugging. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697582/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor697602"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 22:04 UTC (Thu)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/697602/">Link</a>] (11 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I've publicly stated an opinion like this before in the context of binder, so I'll have a go at elaborating my perspective, which may or may not match that of Cyberax.  Though I'll start by re-iterating my positive impression of bus1 - I'm not at all attacking, just drawing a picture to provide contrast and perspective.<br>
<p>
My starting point is the "full exploitation" pattern that was mentioned in the first paper published about Unix and which I discussed here some time ago: <a href="https://lwn.net/Articles/411845/">https://lwn.net/Articles/411845/</a>.  "Full exploitation" prefers to build on (and exploit) what you have instead of building something new.<br>
<p>
Applying that pattern to the ideas in bus1, I see a "peer" being a socket with a new address-family: AF_BUS1.  This allows sendto/recvfrom to be used rather than new ioctls which have a very similar argument structure.<br>
<p>
The required property for addresses in the address family is that they be unfakeable, so they can be used as capabilities.  There is also a desire to be able to listen for, and send to, multiple addresses at once.  This leads to "list of file descriptors" as an obvious choice.  Here I mean *any* file descriptor.  bus1 would internally use the "struct file" pointer for rendezvous and possibly not touch the struct-file itself.  A bus1 socket would bind() to a list of file descriptors, could pass those to other processes either via fork, or UDS, or BUS1, and could send to a list of file-descriptors to achieve multicast.<br>
<p>
bus1 adds more than just capability-based addressing, and I think it could be valuable to ask if that "more" might be useful for other services in the kernel: can we fully-exploit those improvements?<br>
The mappable receive pool that bus1 uses: might it be just as useful for UDS, or pipes ... or even TCP/UDP??<br>
The priority inheritance mechanism you will eventually provide: could it be useful with AF_NETLINK messages, or maybe could sending a signal also send a priority boost (yeah.... maybe not that last one).<br>
<p>
<p>
Part of the reason I don't push this sort of picture more is that there are serious difficulties.  Layering on top of existing code is likely to either require changes to that code which might be hard to justify, or to require compromises in performance/functionality which could be similarly unpopular.<br>
A particular issue is the fact that bus1 allows bit-wise equality comparison of handles.  This means that when a message arrives, each node must be mapped to a handle for the receiver.  In the AF_BUS1 model, it would need to map a 'struct file *' to a file descriptor.  There is no infrastructure support for that, you we'd either need to suffer linear searches, or add a per-process reverse-lookup data structure.  Neither of these would have an easy path into the kernel.<br>
But then... I start to wonder why easy equality tests are important.  <br>
There are two sorts of handles.  "My" handles (which this peer receives messages for) and other handles.<br>
Recognizing my handles is important.  Recognizing when other handles match doesn't seem so important.<br>
All of "my" handles were, in the AF_BUS1 model, passed to bind() in a simple array, so they have a sequence number.  file descriptors in an incoming message could be reported as either "my handle[N]" or "new other file descriptor". <br>
That would seem to remove the need for generic lookup of fd by struct-file, but might have other problems.<br>
<p>
As Cyberax suggested, using file descriptors might hit against problems with the cost of file descriptors.  They are a limited resource, in part because they hold a struct-file active, and struct-file is not light-weight.<br>
<p>
If we wanted to, we could reduce the burden.  I think we could make a file-descriptor point to a structure that was just a refcount and an operations pointer (i.e. pointer a struct full of function pointers).  This would be embedded in a 'struct file' for normal use, but the AF_BUS1 implementation might provide a way to create a file descriptor which pointed to a different, much lighter weight, structure.<br>
I personally think this would be an excellent idea, but I doubt it would really be worth the trouble that I expect it would be trying to convince multiple parties that we should add it to the kernel.<br>
<p>
So as I said, I don't really think bus1 should be changed to this model, but I thought it might provide a helpful perspective on what some people might mean they they bang on the door with their pitchforks screaming "give us our file-descriptors".<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697602/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697621"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 0:26 UTC (Fri)
                               by <b>Cyberax</b> (<b>&#x272D; supporter &#x272D;</b>, #52523)
                              [<a href="/Articles/697621/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
We can carve out a range of FDs (with the highest order bit set, for example) that will forgo the dense encoding requirement. It will allow lots of neat tricks to speed up their creation and we'll be able to provide canonic mappings making bitwise comparisons possible, for example.<br>
<p>
What is going to break in this case?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697621/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697710"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 15:11 UTC (Fri)
                               by <b>dtlin</b> (subscriber, #36537)
                              [<a href="/Articles/697710/">Link</a>] 
      </p>
      
      </div>
      </summary>
      File descriptors are nonnegative int so I can imagine unhappiness with the highest order bit set (<code>if (open() &lt; 0) abort();</code>). Second-highest order bit might be okay.
      
          <div class="CommentReplyButton">
            <form action="/Articles/697710/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor697625"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 0:54 UTC (Fri)
                               by <b>Cyberax</b> (<b>&#x272D; supporter &#x272D;</b>, #52523)
                              [<a href="/Articles/697625/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
BTW, my main reason for wanting FDs is Linux's miserable epoll() interface. It's not possible to wait on multiple object types (unlike in BSDs with kqueue). So everything pretty much must have an FD interface. And this is needed pretty much always in async applications that need to wait on multiple event sources.<br>
<p>
We're pretty much at this point right now with timerfd(), signalfd() and almost here with process handles. I find it counterproductive that we're adding new non-FD stuff.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697625/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697627"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 1:02 UTC (Fri)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/697627/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt;  I find it counterproductive that we're adding new non-FD stuff.</font><br>
<p>
The "non-FD stuff" is stuff that it doesn't make any sense to wait for.  They don't have events.  They are almost purely opaque rendezvous points.<br>
"almost" because when they are destroyed, a destruction message gets sent, so they conceptually have some state.  But those messages, and all messages sent to the handle, come through the peer fd in an orderly manner.  And you can certainly 'poll' on the peer fd.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697627/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor697632"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 1:36 UTC (Fri)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697632/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thanks for the perspective (and the excellent article!), much appreciated.<br>
<p>
I agree with the big picture, this would be nice. But I'm afraid that, as you allude to, when you get down to the details it is not really feasible (nor acceptable upstream).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697632/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor698235"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 25, 2016 14:16 UTC (Thu)
                               by <b>dvdhrm</b> (guest, #85474)
                              [<a href="/Articles/698235/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If you receive multiple handles to the same node, you really want them to compare equal. First of all, you want that to better manage resource restrictions. That is, holding 10k refs to the same handle is free, but not if they're not merged. But more importantly, you want authentication to work: A 3rd party should be able to authenticate you based on a handle you pass, by simply comparing it to a stored handle. Further use-cases are easy to imagine. I would even say this is a major feature, rather than a neat side-effect.<br>
<p>
Sure, you could implement an equality-check as method call on each node, and pass the to-be-compared handle. That, however, would mean granting the handle to the remote peer, which is probably not what you want. Besides, it would be a separate roundtrip for each comparison.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/698235/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor698239"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 25, 2016 14:31 UTC (Thu)
                               by <b>heftig</b> (subscriber, #73632)
                              [<a href="/Articles/698239/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If a handle can represent a capability other than addressing a node, does this mean you can revoke that implied capability by destroying the node?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/698239/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor698255"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 25, 2016 16:06 UTC (Thu)
                               by <b>dvdhrm</b> (guest, #85474)
                              [<a href="/Articles/698255/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes. If a node is destroyed, handles to that node cannot be transmitted anymore (fully ordered against node destruction; replaced with an invalid handle). Furthermore, anyone else holding a handle will be aware that the node is destroyed (through notifications).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/698255/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor698372"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 27, 2016 9:09 UTC (Sat)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/698372/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; That is, holding 10k refs to the same handle is free</font><br>
<p>
Can you describe a use-case that might cause an application to hold 10K handles which aren't necessarily all the same, but might often be in practice, often enough that this would be a useful optimization? (Genuinely curious)<br>
<p>
<font class="QuotedText">&gt; A 3rd party should be able to authenticate you based on a handle you pass,</font><br>
<p>
Interesting - handles are not just capabilities, but are also authentication tokens.  I guess there is a lot of similarity there, but they are different.  I wonder if it would be cleaner for auth tokens to be handled like capabilities (as you suggest), or like other auth tokens (uid, gid, pid).  I don't (yet) have an opinion on that.<br>
<p>
Thanks!<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/698372/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor700052"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 9, 2016 9:53 UTC (Fri)
                               by <b>dvdhrm</b> (guest, #85474)
                              [<a href="/Articles/700052/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt;&gt; That is, holding 10k refs to the same handle is free</font><br>
<font class="QuotedText">&gt; Can you describe a use-case that might cause an application to hold 10K handles which aren't necessarily all the same, but might often be in practice, often enough that this would be a useful optimization? (Genuinely curious)</font><br>
<p>
Use-cases with 10k non-equal handles exist even with DBus right now, for instance related to 10k connected hard discs. Imagine a manager of those discs that enumerates the devices via the bus, and retrieves information on each device, caching it locally. If those information sets include, for instance, a driver handle, those might very reasonably be the same for a large part of devices. Hence, you end up with a dozen driver handles, or 10k driver handles, depending on whether they're merged or not.<br>
<p>
Granted, this example only reduces the handle count linearly (the dominating number of handles is still the same order of magnitude, given the 10k devices). But I think it is reason enough to support merged handles.<br>
<p>
<font class="QuotedText">&gt;&gt; A 3rd party should be able to authenticate you based on a handle you pass,</font><br>
<font class="QuotedText">&gt; Interesting - handles are not just capabilities, but are also authentication tokens. I guess there is a lot of similarity there, but they are different. I wonder if it would be cleaner for auth tokens to be handled like capabilities (as you suggest), or like other auth tokens (uid, gid, pid). I don't (yet) have an opinion on that.</font><br>
<p>
You assume an explicit authentication scheme, but this is not necessary for capability-based systems, where authentication can be implicit by simple handle ownership. I rather meant setups where you talk about objects without passing messages through the object-provider, like this:<br>
<p>
You have 3 programs, one of them is the display manager that provides direct framebuffer access to your graphics devices, another one is the window manager, and the third one is a regular window-client. Whenever the window-manager makes a client full-screen, it can pass its handle of the window-client to the display-manager. A window-client can now instruct the display-manager to render full-screen without compositing, bypassing the hop that is the window-manager. The client can pass a handle to itself as authorization, and the display-manager can compare it to the handle that was retrieved from the window-manager, and make sure it really is the current full-screen window.<br>
This also makes use of ordering: the window-manager can asynchronously queue its notifications when another window becomes full-screen, and it is guaranteed that any racing rendering request to the display-manager is properly ordered.<br>
<p>
The authorization scheme here relies on the window-client handle to be merged in the display-manager. Note that the alternative solution would be to temporarily create nodes in the display-manager and pass it to the window-client. When switching between full-screen windows, the window-manager would instruct a destruction of that node and create a new one. But this requires a round-trip for node-retrieval, while the former does not.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/700052/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor786584"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 24, 2019 10:54 UTC (Wed)
                               by <b>jkowalski</b> (guest, #131304)
                              [<a href="/Articles/786584/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This is doable with file descriptors as well, you can use kcmp(2) to compare the struct file pointer (and I assume that is compatible with the transitive authentication scheme handles allow for) because struct file ptr is only same across dup or fd-passing over UDS. It wouldn't be too hard to coalesce the handle into one that already exists into the receiving process's fd table, such that when it receives the message the integer of the fd is equal to one it already has, which just means you can save a system call and do equality checks in any process sharing the fd table with you. This might be useful for Unix sockets, to avoid closing duplicate file descriptors, as a socket option.<br>
<p>
The overhead of struct file isn't as problematic then, as multiple processes share the same reference, and just have different pointers to the same underlying reference in their fd table. Revokability is easy with two ended communication streams, you close your end and create a new reference for clients joining the system thereafter, rendering previous ones useless.<br>
<p>
If you have some way to expose this named hierarchy in the filesystem, you can also avoid just giving handles at startup, the process can acquire them lazily by opening what it wants to talk to. The superblock can take uid= gid= parameters to make it easy to give a view of this filesystem as a private mount in the process's namespace, at some point you could even implement a proxy scheme by bind mounting some part of some other hierarchy over this. The filesystem namespace is very flexible for that sort of stuff.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/786584/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor697592"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 18, 2016 19:32 UTC (Thu)
                               by <b>smcv</b> (subscriber, #53363)
                              [<a href="/Articles/697592/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I must say I'm disappointed to have read about this for the first time on LWN, and not on the D-Bus mailing list.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697592/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697630"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 1:28 UTC (Fri)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697630/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Once the code and the documentation is more complete and ready for an RFC we will advertise this more widely, including to the DBus mailinglist.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697630/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor697636"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 2:14 UTC (Fri)
                               by <b>samroberts</b> (subscriber, #46749)
                              [<a href="/Articles/697636/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It looks to me like Send/Receive/Reply has similar effects to the global message order delivery, I'm not sure what the global message delivery would bring to binder, so its not clear that its lack is a negative.<br>
<p>
Since bus1 doesn't have have that, it uses the global instead. I like the global message ordering, sounds robust and helpful, and should lead to more predictable message delivery, and decrease odd race condition bugs.<br>
<p>
However, send/receive/reply is an incredibly powerful way of structuring IPC, it's the like coroutines for the IPC world, any idea why it got dropped?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697636/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697667"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 9:17 UTC (Fri)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697667/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
As binder doesn't do multicast, the order of messages is not a problem. Moreover, binder has one global lock, so only one message transaction can take place at any given time anyway.<br>
<p>
We saw send/receive/reply as a possible future addition, rather than something basic, so we did not include it for now.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697667/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor697674"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 11:26 UTC (Fri)
                               by <b>tdz</b> (subscriber, #58733)
                              [<a href="/Articles/697674/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
AFAICT kdbus was not merged because there was so much overhead in the DBus userspace that this should be fixed first. [1] Does bus1 somehow address this?<br>
<p>
Also, IIRC microkernels had bad performance because of the excessive IPC and the book-keeping required by fancy features (multicast). Why does bus1 not repeat these mistakes? Was this problem meanwhile solved?<br>
<p>
[1] <a href="http://lkml.iu.edu/hypermail/linux/kernel/1506.2/05492.html">http://lkml.iu.edu/hypermail/linux/kernel/1506.2/05492.html</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697674/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697681"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 13:23 UTC (Fri)
                               by <b>micka</b> (subscriber, #38720)
                              [<a href="/Articles/697681/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; there was so much overhead in the DBus userspace that this should be fixed first</font><br>
<p>
Maybe Bus1 doesn't position itself as a kernel space reimplementation of d-bus so it doesn't have to address that.<br>
I mean, if it is more general and has *other* use cases.<br>
<p>
<font class="QuotedText">&gt; Why does bus1 not repeat these mistakes?</font><br>
<p>
I won't pretend to know much on this subject, but if the problem of microkernels was that because everything was userspace, communicating via IPC, things didn't scale, then Bus1 doesn't fit this pattern because it doesn't add userspace processes. All that's userspace stays in userspace, all that's kernel stays kernel, the only thing that changes is that messages are mediated by the kernel. So it shouldn't change the amount of messages.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697681/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor697683"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 19, 2016 14:03 UTC (Fri)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697683/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Well, that was not really the reason for kdbus not to be merged. The argument Linus made was that comparing the performance of kdbus with the performance of the DBus daemon was not really a fair comparison as the DBus daemon was not really optimized for speed. However, had kdbus gone into the kernel the DBus daemon itself would (and any suboptimal performance) would anyway go away, so that itself was not a blocker.<br>
<p>
Like kdbus, bus1 would similarly allow processes to communicate directly without going through a userspace broker.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697683/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor697840"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 21, 2016 4:08 UTC (Sun)
                               by <b>alison</b> (subscriber, #63752)
                              [<a href="/Articles/697840/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thanks for another great explanation, neilbrown.   The famous inefficiency of D-Bus stems both from the many context switches and associated data copies.  The article clearly explains how context switches can be reduced by establishing peer-to-peer communication subsequent to a first in-kernel capability check.  What's less clear on reading the article is whether large data structures can be passed by reference into the memory space of a pool, a la dmabuf.   What guarantee have we, tomegund, that the passing of large messages will be more efficient than in the current D-Bus implementation?   I guess you could suggest to tokenize messages rather than pass large ones, but the kernel doesn't implement userspace, it just tries to make userspace work.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697840/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697841"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 21, 2016 4:22 UTC (Sun)
                               by <b>heftig</b> (subscriber, #73632)
                              [<a href="/Articles/697841/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Since you can pass FDs, you can also pass DMABUF and memfds. So this can be solved on a layer above bus1.<br>
<p>
kdbus also had special support for passing sealed memfds. IIRC the problem with that was that you had to munmap a memfd in order to seal it, and munmap was/is slowass.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697841/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor697849"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 21, 2016 10:03 UTC (Sun)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/697849/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yeah, exactly. Though there was nothing kdbus-specific about sealed fds. They can be used with bus1 (or UDS) just as well.<br>
<p>
So for "small" messages they can be sent by copying them precisely once (straight from the sender to the receiver), and for "large" messages one can do zero-copy by sending a sealed memfd (the reason for not always doing zero-copy is that the fixed overhead is pretty high).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/697849/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor698353"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 26, 2016 22:21 UTC (Fri)
                               by <b>imMute</b> (guest, #96323)
                              [<a href="/Articles/698353/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt;Since you can pass FDs, you can also pass DMABUF and memfds. So this can be solved on a layer above bus1.</font><br>
<p>
I was about to post a question asking why the bus1 protocol included the "message pools" when fd passing was already included.  Creating a memfd, sealing it, then sending the fd through bus1 seems like it would be more performant because there is no copying of the data once it's put into the memfd buffer.<br>
<p>
<font class="QuotedText">&gt;kdbus also had special support for passing sealed memfds. IIRC the problem with that was that you had to munmap a memfd in order to seal it, and munmap was/is slowass.</font><br>
<p>
The article on LWN about sealing &amp; memfd_create (<a href="https://lwn.net/Articles/591108/">https://lwn.net/Articles/591108/</a>) says that the seal is applied with a fcntl() call.  Scratch that, another article (<a href="https://lwn.net/Articles/593918/">https://lwn.net/Articles/593918/</a>) agrees with what you've stated (that munmap() has to be called before applying any seals).  Given that seals can only be removed under *exclusive* ownership, it's likely that any IPC mechanism using this wouldn't reuse memfd buffers.  That implies that memfd's have to be created, sealed, and destroyed very efficiently for it to have more performance than copying buffers through the kernel.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/698353/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor698431"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 28, 2016 23:55 UTC (Sun)
                               by <b>tomegun</b> (subscriber, #56697)
                              [<a href="/Articles/698431/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
You basically got it right. Zero-copy using memfd only has a performance benefit if the payload is sufficiently large (forgot the precise size). For most use-cases the one-copy the pools give is faster than zero-copy.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/698431/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor699480"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bus1: a new Linux interprocess communication proposal</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 5, 2016 14:39 UTC (Mon)
                               by <b>Shugyousha</b> (subscriber, #93672)
                              [<a href="/Articles/699480/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
According to this LWN article <a href="https://lwn.net/Articles/580194/">https://lwn.net/Articles/580194/</a> copying is faster until you reach 512KB. Then memory mapping starts to win out.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/699480/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2016, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
