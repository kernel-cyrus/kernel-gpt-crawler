        <!DOCTYPE html>
        <html lang="en">
        <head><title>Compcache: in-memory compressed swapping [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/334649/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/334068/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/334649/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Compcache: in-memory compressed swapping</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Please consider subscribing to LWN</b>
<p>
Subscriptions are the lifeblood of LWN.net.  If you appreciate this
content and would like to see more of it, your subscription will
help to ensure that LWN continues to thrive.  Please visit
<a href="/Promo/nst-nag1/subscribe">this page</a> to join up and keep LWN on
the net.
</blockquote>
<div class="GAByline">
           <p>May 26, 2009</p>
           <p>This article was contributed by Nitin Gupta</p>
           </div>
<p>
The idea of memory compression&mdash;compress relatively unused pages and
store them in memory
itself&mdash;is simple and has been around for a long
time.  Compression, through the elimination of expensive disk I/O, is far
faster than swapping those pages to secondary storage.
When a page is needed again, it is decompressed and given back, which
is, again, much faster than going to swap.
 
<p>
An implementation of this idea on Linux is currently under development
as the <a href="http://code.google.com/p/compcache/">compcache</a>
project. It creates a virtual block device (called ramzswap) which acts
as a swap disk. Pages swapped to this disk are compressed and stored in
memory itself. The project home contains use cases, performance
numbers, and other related bits. The whole aim of the project is not
just performance &mdash; on swapless setups, it allows running applications
that would otherwise simply fail due to lack of memory. For example,
Edubuntu <a href="https://wiki.edubuntu.org/Compcache">included</a>
compcache to lower the RAM requirements of its installer.
 
<p>
The <a href="http://code.google.com/p/compcache/wiki/Performance">performance
page</a> on the project wiki shows numbers for configurations that
closely match netbooks, thin clients, and embedded devices. These
initial results look promising. For example, in the benchmark for thin
clients, ramzswap gives nearly the same effect as doubling the memory.
Another <a href="http://code.google.com/p/compcache/wiki/Performance/SwapDiskVsRamz">benchmark</a>
shows that average time required to complete swap requests is
reduced drastically with ramzswap. With a swap partition located on
a 10000 RPM disk, average time required for swap read and write
requests was found to be 168ms and 355ms, respectively. While with
ramzswap, corresponding numbers were mere 12&micro;s and 7&micro;s, respectively &mdash;
this includes time for checking zero-filled pages and
compressing/decompressing all non-zero pages.

<p>
The approach of using a virtual block device is a major simplification
over earlier attempts. The previous implementation required changes to the
swap write path, page 
fault handler, and page cache lookup functions (<tt>find_get_page()</tt> and
friends). Those patches did not gain widespread acceptance due to their
intrusive nature.  The new approach is far less intrusive, but at a cost:
compcache has lost the ability to 
compress page cache (filesystem backed) pages. It 
can now compress swap cache (anonymous) pages only. At the same time,
this simplicity and non-intrusiveness got it included in <a href="https://wiki.ubuntu.com/Compcache">Ubuntu</a>, ALT
Linux, <a href="http://www.ltsp.org/twiki/bin/view/Ltsp/AltLinux">LTSP</a>
(Linux Terminal Server Project) and maybe other places as well.

<p>
It should be noted that, when used at the hypervisor level, compcache
can compress any part of the guest memory and for any kind of guest OS
(Linux, Windows etc) &mdash; this should allow running more virtual
machines for
a given amount of total host memory. For example, in KVM the
guest physical memory is simply anonymous memory for the host (Linux
kernel in this case). Also, with the recent <a
href="http://lwn.net/Articles/266320/">MMU notifier</a> support 
included in the Linux kernel, nearly the entire <a
href="http://compcache.googlecode.com/svn/wiki/files/documents/KvmForum2008_kdf2008_15.pdf">guest 
physical memory is now swappable [PDF]</a>.

<p>
<h4>Implementation</h4>
<p>
All of the individual components are separate kernel modules:
<ul><li>LZO compressor: lzo_compress.ko, lzo_decompress.ko (already in
mainline)</li><li>xvMalloc memory allocator: xvmalloc.ko</li><li>compcache block device driver: ramzswap.ko</li></ul>
Once these modules are loaded, one can just enable the ramzswap swap device:
<pre>
    swapon /dev/ramzswap0
</pre>
Note that ramzswap cannot be used as a generic block device. It can
only handle page-aligned I/O, which is sufficient for use as a swap
device. No use case has yet come to light that would justify the effort
to make it a generic compressed read-write block device. Also, to
minimize block layer overhead, ramzswap uses the &quot;no queue&quot; mode of
operation. Thus, it accepts requests directly from the block layer and
avoids all overhead due to request queue logic.

<p>
The ramzswap module accepts parameters for "disk" size, memory limit, and
backing swap partition. The optional backing swap partition parameter
is the physical disk swap partition where ramzswap will forward
read/write requests for pages that compress to a size larger than
<tt>PAGE_SIZE/2</tt> &mdash; so we keep only highly compressible pages in
memory. 
Additionally, purely zero filled pages are checked and no memory is
allocated for such pages. For &quot;generic&quot; desktop workloads (Firefox,
email client, editor, media player etc.), we typically see 4000-5000
zero filled pages.

<p>
<h4>Memory management</h4>
<p>
One of the biggest challenges in this project is to manage variable
sized compressed chunks. For this, ramzswap uses memory allocator
called <a href="http://code.google.com/p/compcache/wiki/xvMalloc">xvmalloc</a>
developed specifically for this project. It has O(1) malloc/free, <a href="http://code.google.com/p/compcache/wiki/xvMallocPerformance">very
low fragmentation</a> (within 10% of ideal in all tests), and can use
highmem (useful on 32-bit systems with &gt;1G memory). It exports a
<i>non-standard</i> allocator interface: 
<pre>
    struct xv_pool *xv_create_pool(void);
    void xv_destroy_pool(struct xv_pool *pool);

    int xv_malloc(struct xv_pool *pool, u32 size, u32 *pagenum, u32 *offset, gfp_t flags);
    void xv_free(struct xv_pool *pool, u32 pagenum, u32 offset);
</pre>

<p> <tt>xv_malloc()</tt> returns a <tt>&lt;pagenum, offset&gt;</tt>
pair. It is then up to the caller to map this page (with <tt>kmap()</tt>)
to get a valid kernel-space pointer.

<p>
The justification for the use of a custom memory allocator was provided when the
compcache <a href="http://lkml.org/lkml/2009/3/30/182">patches</a>
were posted to linux-kernel. Both the SLOB and SLUB allocators were found to
be unsuitable for use in this project. SLOB targets embedded devices and <a href="http://lwn.net/Articles/157944/">claims</a>
to have good space efficiency. However, it was found to have some major
problems: It has O(n) alloc/free behavior and can lead to large amounts of wasted
space as 
detailed in <a href="http://lkml.org/lkml/2009/3/18/210">this LKML post</a>.

<p>
On the other hand, SLUB has different set of problems.
The first is the usual fragmentation issue. The data presented <a
href="http://code.google.com/p/compcache/wiki/AllocatorsComparison">here</a> 
shows that kmalloc uses ~43% more memory than xvmalloc. Another problem is
that it depends 
on allocating higher order pages to reduce fragmentation. This is not
acceptable for ramzswap as it is used in tight-memory situations, so higher
order allocations are almost guaranteed to fail.
The xvmalloc allocator, on the other hand, always allocates zero-order
pages when it needs to expand a memory pool.

<p>
Also, both SLUB and SLOB are limited to allocating from
<i>low memory</i>. This
particular limitation is applicable only for 32-bit system with more
than 1G of memory. On such systems, neither allocator is able to
allocate from the high memory zone. This restriction is not acceptable for
the compcache project. Users with such configurations reported memory
allocation failures from ramzswap (before xvmalloc was developed) even
when plenty of high-memory was available. The xvmalloc allocator,
on the other hand, is able to allocate from the high memory region.

<p>
Considering above points, xvmalloc could potentially replace the
SLOB allocator. However, this would involve lot of additional work as
xvmalloc provides a non-standard
malloc/free interface. Also, xvmalloc is <a href="http://code.google.com/p/compcache/issues/detail?id=24">not
scalable</a> in its current state (neither is SLOB) and hence cannot be
considered as a replacement for SLUB.

<p>
The memory needed for compressed pages is not pre-allocated; it grows
and shrinks on demand. On initialization, ramzswap creates an xvmalloc
memory pool. When the pool does not have enough memory to satisfy an
allocation request, it grows by allocating single (0-order) pages from
kernel page allocator. When an object is freed, xvmalloc merges it with
adjacent free blocks in the same page. If the resulting free block size
is equal to <tt>PAGE_SIZE</tt>, i.e. the page no longer contains any object; we
release the page back to the kernel.

<p>
This allocation and freeing of objects can lead to fragmentation of the
ramzswap memory. Consider the case where a lot of objects are freed
in a short period of time and, subsequently, there are very few swap
write requests. In that case, the xvmalloc pool can end up with a lot of
partially filled pages, each containing 
only a small number of live
objects. To handle this case, some sort of xvmalloc memory defragmentation
scheme would need to be implemented; this could be done by
relocating objects from almost-empty pages to other pages in the xvmalloc
pool. However, it should be noted that, practically, after months of
use on several desktop machines, waste due to xvmalloc memory
fragmentation never exceeded 7%.

<p>
<h4>Swap limitations and and tools</h4>

Being a block device, ramzswap can never know when a compressed page is no
longer required &mdash; say, when the owning process has exited. Such stale
(compressed) pages simply waste memory. But with recent &quot;<a href="http://lwn.net/Articles/297695/">swap discard</a>&quot; support,
this is no longer as much of a problem.  Swap discard sends BIO_RW_DISCARD bio request when it
finds a free swap cluster during swap
allocation.  Although compcache does not get the callback
immediately after a page becomes stale, it is still better than just
keeping those pages in memory until they are overwritten by another
page. Support for the swap discard mechanism was added in compcache-0.5.

<p>
In general, the discard request comes
a long time after a page has become stale. Consider a case where
a memory-intensive workload terminates and there is no further
swapping activity. In those cases, ramzswap will end up having lots of
stale pages. No discard requests will come to ramzswap since no further
swap allocations are being done. Once swapping activity starts
again, it is expected that discard requests will be received for some of these
stale pages. So, to make ramzswap more effective, changes are
required in the kernel (not yet done) to scan the swap bitmap more
aggressively to find any
freed swap clusters &mdash; at least in the case of RAM backed swap devices.
Also, an adaptive compressed cache resizing policy would be useful
&mdash; monitor accesses to the compressed cache and move relatively unused
pages to a physical swap device. Currently, ramzswap can simply
forward uncompressible pages to a backing swap disk, but it cannot swap out
memory allocated by xvmalloc.

<p>
Another interesting sub-project is the <a
href="http://code.google.com/p/compcache/wiki/SwapReplay">SwapReplay</a> 
infrastructure. This tool is meant to easily test memory allocator behavior under
actual swapping conditions. It is a kernel module and a set of
userspace tools to replay swap events in userspace. The kernel module
stacks a pseudo block device (/dev/sr_relay) over a physical swap device.
When kernel swaps over this pseudo device, it dumps a &lt;sector number, R/W
bit, compress length&gt; tuple to userspace and then 
forwards the I/O request to the backing swap device (provided as a
swap_replay module parameter). This data can then be parsed using a
parser library which provides a callback interface for
swap events. Clients using this library can provide any action for
these events &mdash; show compressed length histograms, simulate ramzswap
behavior etc. No kernel patching is required for this functionality. 

<p>
The swap replay infrastructure has been very useful throughout
ramzswap development. The ability to replay swap traces allows for easy and
consistent simulation of any workload without the need to set it up and run it
again and again. So, if a user is suffering from high memory
fragmentation under some workloads, he could simply send me swap trace
for his workload and I have all the data needed to reproduce the
condition on my side &mdash; without the need to set up the same workload.

<p>
Clients for the parser library were written to simulate ramzswap behavior
over traces from a variety of workloads leading to easier evaluation of
different memory allocators and, ultimately, development and enhancement
of the xvmalloc allocator. In the future, it will also help testing variety
of eviction policies to support adaptive compressed cache resizing.

<p>
<h4>Conclusion</h4>
<p>
The compcache project is currently under active development; some of the
additional features planned are: adaptive compression cache
resizing, allow swapping of xvmalloc memory to physical swap disk,
memory defragmentation by relocating compressed chunks within memory
and compressed swapping to disk (4-5 pages swapped out with single disk
I/O). Later, it might be extended to compress page-cache pages too
(as
earlier patches did) &mdash; for now, it just includes the ramzswap component to
handle anonymous memory compression.

<p>
Last time the ramzswap patches were submitted for review, only LTSP
performance data was provided as a justification for this feature.
Andrew Morton was <a href="http://lkml.org/lkml/2009/4/1/514">not
satisfied</a> with this data. However, now there is a lot more data
uploaded to the performance page on the project wiki that shows
performance improvements with ramzswap. Andrew also pointed out lack
of data for cases where ramzswap can cause performance <i>loss</i>:
<div class="BigQuote">We would also be
interested in seeing the performance _loss_ from these
patches. There must be some cost somewhere. Find a worstish-case test
case and run it and include its results in the changelog too, so we
better understand the tradeoffs involved here.
</div>
<p>
The project still lacks data for such cases. However, it should
be available by the 2.6.32 time frame, when these patches will be posted
again for possible inclusion in mainline.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Swapping">Memory management/Swapping</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Gupta_Nitin">Gupta, Nitin</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/334649/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor334732"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 26, 2009 20:15 UTC (Tue)
                               by <b>JoeF</b> (guest, #4486)
                              [<a href="/Articles/334732/">Link</a>] (16 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I have noticed compcache on my Ubuntu-based EasyPeasy installation on my EeePC, which loads it by default.<br>
I had some issues with it wrt hibernation, though. When I tried to hibernate, the system would complain about not enough swap space being available, even though the disk-based swap is big enough. I "fixed" that for now with swapoff /dev/ramzswap.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/334732/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor334734"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 26, 2009 20:17 UTC (Tue)
                               by <b>BrucePerens</b> (guest, #2510)
                              [<a href="/Articles/334734/">Link</a>] (15 responses)
      </p>
      
      </div>
      </summary>
      Oops. You need disk-based backing store to hibernate. Not yet a feature?
      
          <div class="CommentReplyButton">
            <form action="/Articles/334734/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor334736"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 26, 2009 20:21 UTC (Tue)
                               by <b>BrucePerens</b> (guest, #2510)
                              [<a href="/Articles/334736/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      I see it <i>is</i> a feature. Maybe it's not configured correctly? Also, the code would have to be hibernation-aware, because it has to push its entire RAM out to backing store before hibernating.
      
          <div class="CommentReplyButton">
            <form action="/Articles/334736/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor334738"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 26, 2009 20:29 UTC (Tue)
                               by <b>JoeF</b> (guest, #4486)
                              [<a href="/Articles/334738/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
"Maybe it's not configured correctly?"<br>
<p>
Could be. I haven't checked with the EasyPeasy people yet. I am using all defaults, though.<br>
I did notice that the priority of /dev/ramzswap is being set to 100. I tried setting the priority of the on-disk swap space higher than that, but it didn't help with hibernation.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/334738/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor334735"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 26, 2009 20:23 UTC (Tue)
                               by <b>JoeF</b> (guest, #4486)
                              [<a href="/Articles/334735/">Link</a>] (12 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
For hibernate, the ram-based swap of course should be bypassed.<br>
But I guess the hibernate code just takes the first swap device and goes with that, assuming that all swap space is disk-based.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/334735/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor334739"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 26, 2009 20:29 UTC (Tue)
                               by <b>BrucePerens</b> (guest, #2510)
                              [<a href="/Articles/334739/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <blockquote>For hibernate, the ram-based swap of course should be bypassed.</blockquote>
It's worse than that. Memory belonging to the ram-based swap medium would be marked as not itself swappable. Otherwise, you would get in a loop. So, it has to back itself up to its private backing store device before hibernating, and restore itself before the OS is allowed to resume. It can't just stand by and passively allow another swap device to take care of its pages.
      
          <div class="CommentReplyButton">
            <form action="/Articles/334739/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor334767"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 27, 2009 1:44 UTC (Wed)
                               by <b>nitingupta</b> (guest, #53817)
                              [<a href="/Articles/334767/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes, true. Currently, swapping compressed memory to private swap disk is under development. It can be made hibernation aware once this is done.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/334767/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor334783"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 27, 2009 6:17 UTC (Wed)
                               by <b>avik</b> (guest, #704)
                              [<a href="/Articles/334783/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
swapoff /dev/ramzswap<br>
<p>
Should allow hibernation.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/334783/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor334831"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 27, 2009 13:41 UTC (Wed)
                               by <b>JoeF</b> (guest, #4486)
                              [<a href="/Articles/334831/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yup. That's what I do right now.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/334831/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor334792"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Could compcache improve restore after STD responsiveness?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 27, 2009 6:50 UTC (Wed)
                               by <b>rvfh</b> (guest, #31018)
                              [<a href="/Articles/334792/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Interestingly, storing compressed memory to swap to hibernate reminds me a lot of TuxOnIce (and maybe now uswsusp, but that needs user space magic), which could save much more than the default swsup thanks to compression...<br>
<p>
Could ramzswap help have a more responsive system after restore too? Maybe with a little tweaking?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/334792/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor383460"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Could compcache improve restore after STD responsiveness?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 15, 2010 10:13 UTC (Thu)
                               by <b>dgm</b> (subscriber, #49227)
                              [<a href="/Articles/383460/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Also, apparently compression would add vert little overhead to the swap-to-disk case, allowing for faster i/o and better use of swap space. <br>
<p>
Maybe it should be considered to add this feature to the generic swap code?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/383460/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor334795"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 27, 2009 7:23 UTC (Wed)
                               by <b>macc</b> (guest, #510)
                              [<a href="/Articles/334795/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Shoudn't that be layered?<br>
<p>
mem -&gt; compressed swap|blockdev --&gt; to disk<br>
<p>
snitching on disk IO should work for hibernation too<br>
as long as compression is faster than diskaccess ( true )<br>
<p>
MACC<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/334795/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor335016"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 28, 2009 10:24 UTC (Thu)
                               by <b>rvfh</b> (guest, #31018)
                              [<a href="/Articles/335016/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Maybe the swap partition should be compressed too, so we don't<br>
<p>
mem -&gt; compressed swap -&gt; uncompressed swap on disk<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/335016/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor335161"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 29, 2009 4:15 UTC (Fri)
                               by <b>nitingupta</b> (guest, #53817)
                              [<a href="/Articles/335161/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Maybe the swap partition should be compressed too, so we don't</font><br>
<font class="QuotedText">&gt; mem -&gt; compressed swap -&gt; uncompressed swap on disk</font><br>
<p>
This is the idea I'm working on. Swap-out entire xvmalloc pages -- each containing multiple compressed pages -- to swap disk. The aim here is not to save disk space but to improve performance.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/335161/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor336481"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Would xvmalloc and swap readahead play nice?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 6, 2009 7:37 UTC (Sat)
                               by <b>gmatht</b> (subscriber, #58961)
                              [<a href="/Articles/336481/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Wouldn't swapping out xvmalloc pages prevent swap readahead from being of any use, given that adjacent pages are unlikely to be allocated in adjacent positions by xvmalloc? On a conventional HDD, reading an uncompressed page should take only ~0.1ms while seeking to the page should take ~10ms. My concern is that optimizing the 0.1ms while forcing a 10ms seek for every page would be a big performance loss.<br>
<p>
There seems to be a big difference between the optimal layout for a memory allocator where seek is not a problem and the optimal layout on a conventional hard disk were seek times dwarf virtually everything else.<br>
<p>
If, OTOH, adjacent pages were written out in adjacent positions on disk this could *halve* the cost of swap readahead; both halving the time required to read in the extra pages and also halving the memory used by pages that where read from disk but not used.<br>
<p>
(I can see just swapping out xvmalloc pages being a win for SSD, where seek is not a problem for random reads. Also clearly if you are writing out an xvmalloc page there should be very little overhead, and you know you will get 4k of real memory back for each page swapped out. Even so, wouldn't you still have to read in the entire 4K xvmalloc page just to access one of the compress pages stored on that page?)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/336481/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor336560"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Would xvmalloc and swap readahead play nice?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 7, 2009 5:22 UTC (Sun)
                               by <b>nitingupta</b> (guest, #53817)
                              [<a href="/Articles/336560/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Wouldn't swapping out xvmalloc pages prevent swap readahead from being of any use, given that adjacent pages are unlikely to be allocated in adjacent positions by xvmalloc? On a conventional HDD, reading an uncompressed page should take only ~0.1ms while seeking to the page should take ~10ms. My concern is that optimizing the 0.1ms while forcing a 10ms seek for every page would be a big performance loss.</font><br>
<p>
With compressed swapping to disk, the seek times will also reduce as pages will be spread over a smaller area on disk. Still, in general swapping out xvmalloc pages is expected to incur higher swap read overhead due to more no. of seeks involved -  an xvmalloc page contains almost unrelated pages.<br>
<p>
<font class="QuotedText">&gt; There seems to be a big difference between the optimal layout for a memory allocator where seek is not a problem and the optimal layout on a conventional hard disk were seek times dwarf virtually everything else.</font><br>
<p>
Yes, this the whole problem. Theoretically, this problem could be solved by first collecting together physically contiguous pages (w.r.t disk sectors) in a single memory page and then swap this page to disk. However, when pages are swapped out this way, we are not guaranteed that we will be able to free even a single page. Also, this will increase in-memory fragmentation as these pages will be taken out from random xvmalloc pages. So, after lots of such pages are swapped out, we have to do some in-memory defragmentation (not yet implemented) to bring down fragmentation and free pages.<br>
<p>
<font class="QuotedText">&gt; If, OTOH, adjacent pages were written out in adjacent positions on disk this could *halve* the cost of swap readahead; both halving the time required to read in the extra pages and also halving the memory used by pages that where read from disk but not used.</font><br>
<p>
In general, swap readahead in its present state is almost meaningless in case most of the pages are in (compressed) memory. Decompressing pages is almost instant. Instead, more useful will be to implement some sort of prefetch ioctl for ramzswap so its prefetches pages from backing swap and keeps them compressed in memory. But which pages to prefectch? This will need more study and experimentation.<br>
<p>
<font class="QuotedText">&gt; (I can see just swapping out xvmalloc pages being a win for SSD, where seek is not a problem for random reads. Also clearly if you are writing out an xvmalloc page there should be very little overhead, and you know you will get 4k of real memory back for each page swapped out. Even so, wouldn't you still have to read in the entire 4K xvmalloc page just to access one of the compress pages stored on that page?)</font><br>
<p>
Yes, reading in single xvmalloc page will bring in bunch of unrelated pages to memory. These additional pages may be kept/discarded based on configurable/hardcoded policy in ramzswap.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/336560/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor335166"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 29, 2009 5:57 UTC (Fri)
                               by <b>zmi</b> (guest, #4829)
                              [<a href="/Articles/335166/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; mem -&gt; compressed swap -&gt; uncompressed swap on disk</font><br>
<font class="QuotedText">&gt; [and from the article:]</font><br>
<font class="QuotedText">&gt; allow swapping of xvmalloc memory to physical swap disk</font><br>
<p>
That was my immediate idea when reading the article. I'd love it to be a<br>
layer inserted just before normal swap disks, absolutely transparent. Like<br>
this, (compressed) pages not used for a long time can be put to disk swap<br>
at low I/O rates (or low I/O times, if that's easily measurable). And when<br>
too much real mem is used, ramzswap can move pages to disk swap (maybe just<br>
as a last resort to recover before OOM conditions).<br>
<p>
The disk swap should support compressed pages directly, and you can also<br>
drop (or at least increase) the "if not enough compression gain, store<br>
uncompressed to disk" rule, and just store pages that are not good<br>
compressed to disk swap, but in it's compressed state. That should help<br>
lower I/O, which is never a failure :-)<br>
<p>
If this feature arrives, the vm.swappiness can be increased to more quickly<br>
swap. Currently I lower it to 10 on my desktop (8GB RAM) because the disk<br>
swapping in the morning after nightly backup used to be a nightmare with<br>
the default value, the system very much unresponsive for quite a long time<br>
(at least it feels like before the first coffee *g*). And that's already on<br>
a 10krpm VelociRaptor drive.<br>
<p>
I wonder if ramzswap will help on my 8GB desktop, and want to test it.<br>
(already running now)<br>
<p>
BTW: shouldn't there be a compressed name also? Like zap or just zp ;-)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/335166/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor335005"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 28, 2009 8:23 UTC (Thu)
                               by <b>jimparis</b> (guest, #38647)
                              [<a href="/Articles/335005/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
How does compcache differ in concept from, say:<br>
- use mtdram driver to make a MTD device out of ram<br>
- use jffs2 with compression enabled on the new mtd device<br>
- put a swapfile on that filesystem and swap to it<br>
Is there a fundamental reason that this wouldn't work and compcache is needed, or is compcache just trying to remove some of those layers?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/335005/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor335006"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 28, 2009 8:45 UTC (Thu)
                               by <b>amikins</b> (guest, #451)
                              [<a href="/Articles/335006/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
More layers of indirection will result in notably more processing per action. Making a specialty 'device' with fewer features and simpler assumptions about usage allows you to cut a lot of significant corners.<br>
<p>
I'd be -very- interested in some measurements of the difference between the 'existing possible' approach and compcache..<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/335006/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor335162"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 29, 2009 4:29 UTC (Fri)
                               by <b>nitingupta</b> (guest, #53817)
                              [<a href="/Articles/335162/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
How does compcache differ in concept from, say:<br>
<p>
<font class="QuotedText">&gt; - use mtdram driver to make a MTD device out of ram</font><br>
<p>
mtdram driver simply simulates MTD device in ram - no compression and no memory management (it simply preallocates all the memory). Also, there are unnecessary overheads involved -- simulate erasing eraseblock and such.<br>
<p>
<font class="QuotedText">&gt; - use jffs2 with compression enabled on the new mtd device</font><br>
<font class="QuotedText">&gt; - put a swapfile on that filesystem and swap to it</font><br>
<p>
Base for this indirection hierarchy is the in-ram mtd device which has problems mentioned above. Also, as amikims pointed out, additional levels of indirection means more overhead.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/335162/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor337294"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 12, 2009 19:10 UTC (Fri)
                               by <b>bluefoxicy</b> (guest, #25366)
                              [<a href="/Articles/337294/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I've tried using the device mapper.  It tends to deadlock if you try to device map a file on a tmpfs and create swap partitions on it.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/337294/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor336529"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">compcache and vm_deadlock for thin client stability</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 6, 2009 19:19 UTC (Sat)
                               by <b>gvy</b> (guest, #11981)
                              [<a href="/Articles/336529/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thanks for both this article and compcache of course!<br>
<p>
It (and vm_deadlock patches by Peter Zijlstra) saved me and colleagues quite a lot of frustration while eatin' our own dog food, that is working on thin clients with 64M RAM.<br>
<p>
Hope #ltsp folks did get around to integration on TCs (the article mentions installer but the culprit with school terminal networks is usually the client not the server), at least we did "sell" both patches to them back then. :)<br>
<p>
So thanks again, it was nice to communicate with you and it is nice to read up on current developments either.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/336529/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor336577"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 7, 2009 12:41 UTC (Sun)
                               by <b>seeg</b> (guest, #58966)
                              [<a href="/Articles/336577/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Does this mean that Windows would run faster because of more memory under Linux hypervising?<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/336577/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor337386"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 14, 2009 20:04 UTC (Sun)
                               by <b>alankila</b> (guest, #47141)
                              [<a href="/Articles/337386/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
An amazing piece of technology. This makes my 128 MB laptop suddenly usable for more than single task at a time. Kudos.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/337386/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor338633"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Compcache: in-memory compressed swapping</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2009 11:38 UTC (Thu)
                               by <b>phil42</b> (guest, #5175)
                              [<a href="/Articles/338633/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Do you get a free memory test as part of the compression/decompression process?<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/338633/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2009, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
