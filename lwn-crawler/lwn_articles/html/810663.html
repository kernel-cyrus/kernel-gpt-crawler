        <!DOCTYPE html>
        <html lang="en">
        <head><title>Accelerating netfilter with hardware offload, part 2 [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/810663/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/811045/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/810663/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Accelerating netfilter with hardware offload, part 2</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>We're bad at marketing</b>
<p>
We can admit it, marketing is not our strong suit. Our strength is
writing the kind of articles that developers, administrators, and
free-software supporters depend on to know what is going on in the
Linux world. Please <a href="/Promo/nsn-bad/subscribe">subscribe today</a> to help us keep doing that, and so
we don’t have to get good at marketing.
</blockquote>
<div class="GAByline">
           <p>January 31, 2020</p>
           <p>This article was contributed by Marta Rybczyńska</p>
           </div>
<p>As network interfaces get faster, the amount of CPU time available to
process each packet becomes correspondingly smaller.  The good news is that
many tasks, including packet filtering, can be offloaded to the hardware
itself. The bad news is that the Linux kernel required quite a bit of work to be
able to take advantage of that capability.  The <a
href="/Articles/809333/">first article</a> in this series provided an
overview of how hardware-based packet filtering can work and the support
for this feature that already existed
in the kernel. This series now concludes with a detailed look at how
offloaded packet filtering works in the netfilter subsystem and how
administrators can make use of it.</p>

<p>The offload capability was added by <a
href="/ml/netdev/20190709205550.3160-1-pablo%40netfilter.org/">a
patch set</a> from Pablo Neira Ayuso, merged in the kernel 5.3 release
and updated thereafter. The goal of the patch set was to add
support for offloading a subset of the netfilter rules in a typical
configuration, thus bypassing the kernel's generic packet-handling code for
packets filtered 
by the offloaded rules. It is not currently possible to offload all of the rules,
as that would require additional support from the underlying hardware and in the
netfilter code. The use case and some of the internals are mentioned
in Neira's <a
href="https://linuxplumbersconf.org/event/4/contributions/463/attachments/286/485/2019-plumbers-lisboa.pdf">slides
[PDF]</a> from the 2019 Linux Plumbers Conference.

<h4>Background work</h4>

<p>The bulk of the patch set is the refactoring needed to allow the
netfilter  offload mechanism to reuse the infrastructure that was
directly tied to the traffic-control (tc) subsystem before. The refactoring
effort was able to take advantage of an existing driver callback.
Some modules, which were only used by the tc subsystem before have become more
generic.</p>

<p>The first new subsystem, the "flow block" infrastructure, <a
href="https://lore.kernel.org/netdev/20171012171823.1431-1-jiri@resnulli.us/">was introduced</a> in 2017
to allow the sharing of filtering rules and to optimize the use of <a
href="https://en.wikipedia.org/wiki/Content-addressable_memory">ternary
content-addressable memory (TCAM)</a> entries. It allows a set of
rules to be shared by two (or more) network interfaces, which reduces
the hardware
resources needed by rule offloading; this is because the network cards with
multiple physical interfaces usually share the TCAM entries between
those interfaces. This optimization, in the case of switches, allows the
administrator to define common blocks of filtering rules that can be
assigned to multiple interfaces. When a shared block is in place, any
changes will apply to  all interfaces that the block is assigned to. The
netfilter offload patch extends the use of flow blocks beyond the
tc subsystem, making it available for all subsystems that
need
to offload packet-filtering tasks.</p>

<p>A flow block is, at its core, a list of driver callbacks invoked when
the rules programmed into the hardware are changed.  There is usually
one entry per device
(for typical network cards); in the case of switches there is one
callback for all the interfaces in the switch.  For a
configuration with two network interfaces that share the same rules,
the flow-block list contains two callbacks (one for each interface).
The flow-block infrastructure does not limit the number of filtering
rules.</p>

<p>Another important part of the patch set modifies a callback provided by
network card device drivers. Those callbacks are kept in the <tt><a
href="https://elixir.bootlin.com/linux/latest/source/include/linux/netdevice.h#L1257">struct  
net_device_ops</a></tt> structure. The netfilter offload patch set reuses
the <tt>ndo_setup_tc()</tt> callback, which was initially added to
configure schedulers, classifiers, and actions for the tc subsystem;
it has the following prototype:</p>
<pre>
    int (*ndo_setup_tc)(struct net_device *dev, enum tc_setup_type type,
                        void *type_data);
</pre>

<p>It takes the network device <tt>dev</tt>, the type of the
configuration to apply (defined in the <tt>enum tc_setup_type</tt>) and
an opaque data value. The enum defines different action types; 
netfilter does not define its own type, instead it uses the
one defined by the flower classifier (<tt>TC_SETUP_CLSFLOWER</tt>). This is
expected to change in the future, when drivers will start supporting
tc and netfilter offloading at the same time.</p>

<p>Finally, the flow-rule API <a
href="/ml/netdev/20190202115054.4880-1-pablo@netfilter.org/">was
introduced</a> in February 2019 (there is a longer cover letter in <a
href="/Articles/775046/">version 6 of the flow-rule  
patch set</a>). It implements an intermediate representation for the
flow-filtering rules, allowing the separation of the driver-specific
implementation from the details of the subsystem calling it. In
particular, it enabled a single code path to be used by drivers to
support access-control-list offloads configured by either <tt>ethtool</tt> or the
flower classifier.</p>

<p>In the flow-rule API, each <a
href="https://elixir.bootlin.com/linux/latest/source/include/net/flow_offload.h#L243"><tt>flow_rule</tt></a>  
object represents a filtering rule. It consists of the match condition of the
rule (<a href="https://elixir.bootlin.com/linux/latest/source/include/net/flow_offload.h#L9"><tt>struct
flow_match</tt></a>) and the actions to be performed (<a
href="https://elixir.bootlin.com/linux/latest/source/include/net/flow_offload.h#L219"><tt>struct
flow_action</tt></a>).

In the netfilter code, each <tt>flow_rule</tt> represents a rule to be
offloaded to the hardware; it is kept in the flow-block list. When
netfilter offloads a 
rule to hardware, it iterates over the callback list in the flow
block,  invoking each callback 
and passing in the rules, so that they can be handled by the
driver.</p>

<h4>Driver API changes</h4>

<p>As the tc-specific code was made more generic, several types and
definitions were renamed or reorganized. A new
type, <tt>flow_block_command</tt>, that defines the commands for the
driver's flow-block setup function was added. It includes two
definitions, <tt>TC_BLOCK_BIND</tt> and <tt>TC_BLOCK_UNBIND</tt>, that
were renamed to <tt>FLOW_BLOCK_BIND</tt> and
<tt>FLOW_BLOCK_UNBIND</tt>, respectively. Those allow the kernel to bind and
unbind a flow block to an interface. In the same way,
<tt>flow_block_binder_type</tt>, which defines the type of the offload
(ingress for input and egress for output), had seen its members
renamed from <tt>TCF_BLOCK_BINDER_TYPE_*</tt> to
<tt>FLOW_BLOCK_BINDER_TYPE_*</tt></p>

<p>The existing drivers were all setting up tc offloading in a very similar way, so
Neira added a helper function that can be used by all of them:</p>
<pre>
    int flow_block_cb_setup_simple(struct flow_block_offload *f,
        			   struct list_head *driver_block_list,
        			   flow_setup_cb_t *cb, void *cb_ident,
				   void *cb_priv, bool ingress_only);
</pre>
<p>
where <tt>f</tt> is the offload context, <tt>driver_block_list</tt> is
the list of flow blocks for the specific driver, <tt>cb</tt> is the
driver's <tt>ndo_setup_tc()</tt> callback, 
<tt>cb_ident</tt> is the identification of the context,
<tt>cb_priv</tt> is the context to be passed to <tt>cb</tt> (in most cases
<tt>cb_ident</tt> and <tt>cb_priv</tt> are identical), and
<tt>ingress_only</tt> is true if the offload should be set up for
the ingress (receive) side only (this was the case for all the drivers
right until 5.4, in 5.5 the <tt>cxgb4</tt> driver supports both
directions). <tt>flow_block_cb_setup_simple()</tt> registers one
callback per network device, which is exactly what most of the drivers
need.

<p>Each driver is expected to keep a list of flow blocks with their
callbacks: that is the <tt>driver_block_list</tt> argument of
<tt>flow_block_cb_setup_simple()</tt>. This list is necessary if the
driver needs more than one callback, for example one for the ingress
and the other for the egress rules.</p>

<p>The callback implemented by the drivers, of type
<tt>flow_setup_cb_t</tt> has the following definition:</p>
<pre>
    typedef int flow_setup_cb_t(enum tc_setup_type type, void *type_data,
        			void *cb_priv);
</pre>
<p>Its implementation in the driver sets up the hardware filtering
using the provided configuration. The argument <tt>type</tt> defines
the classifier to use, <tt>type_data</tt> is the data specific to the
classifier (and is usually a pointer to a <tt>flow_rule</tt> structure)
and <tt>cb_priv</tt> is the callback private data.</p>

<p>If the driver needs to go beyond the functionality of
<tt>flow_block_cb_setup_simple()</tt> (which usually means
it is part of a switch), it needs to use the part of the API that allocates
the flow blocks directly. These blocks are allocated and freed by two
helpers: <tt>flow_block_cb_alloc()</tt> and
<tt>flow_block_cb_free()</tt> with the following prototypes:
<p>
<pre>
    struct flow_block_cb *flow_block_cb_alloc(flow_setup_cb_t *cb,
                                              void *cb_ident, void *cb_priv,
                                              void (*release)(void *cb_priv));
    void flow_block_cb_free(struct flow_block_cb *block_cb);
</pre>

<p>The callbacks are defined by the drivers and passed to netfilter
by the flow-block infrastructure. Netfilter maintains the list of
callbacks that are attached to each given rule.</p>

<p>Each of the flow blocks contains a list of driver offload callbacks. The drivers
can add and remove themselves from the list contained in the flow-block
list using <tt>flow_block_cb_add()</tt> and
<tt>flow_block_cb_remove()</tt> with the following prototypes:</p>
<pre>
    void flow_block_cb_add(struct flow_block_cb *block_cb,
                           struct flow_block_offload *offload);
    void flow_block_cb_remove(struct flow_block_cb *block_cb,
                              struct flow_block_offload *offload);
</pre>

<p>The driver can look up for a specific callback using
<tt>flow_block_cb_lookup()</tt> defined as follows:</p>
<pre>
    struct flow_block_cb *flow_block_cb_lookup(struct flow_block *block,
        				       flow_setup_cb_t *cb, void *cb_ident);
</pre>

<p>This function searches for the flow-block callbacks on the list in
the <tt>block</tt> context; if both the <tt>cb</tt> callback and the
<tt>cb_ident</tt> value match, it returns the associated flow-block callback
structure. It is used by switch drivers to check if a given callback is
already installed (again, switches use one callback for all of their
interfaces). The setup of the first interface allocates and registers the
callback when 
<tt>flow_block_cb_lookup()</tt> returns NULL. Subsequently, other interfaces get a
non-NULL return and reuse the callback in place,  only increasing the
reference count (see below). When unregistering a callback,
<tt>flow_block_cb_lookup()</tt> also returns  non-NULL if other users exist
and the driver just
decrements the reference count.</p>

<p>The operations for the flow-block reference counts are
<tt>flow_block_cb_incref()</tt> and <tt>flow_block_cb_decref()</tt>;
they are defined as follows:
<pre>
    void flow_block_cb_incref(struct flow_block_cb *block_cb);
    unsigned int flow_block_cb_decref(struct flow_block_cb *block_cb);
</pre>
<p>The value returned by <tt>flow_block_cb_decref</tt> is the value of the
reference count after the operation.</p>

<p>Another function, <tt>flow_block_cb_priv()</tt>, allows the driver
to access its private data. It has the following, simple,
prototype:</p>
<pre>
    void *flow_block_cb_priv(struct flow_block_cb *block_cb);
</pre>

<p>Finally, the drivers can use <tt>flow_block_is_busy()</tt> to check
if the callback is already in use (added to the lists and active). The
function has the following prototype:</p>
<pre>
    bool flow_block_cb_is_busy(flow_setup_cb_t *cb, void *cb_ident,
                               struct list_head *driver_block_list);
</pre>
<p>It returns <tt>true</tt> if it finds an entry with both <tt>cb</tt>
and <tt>cb_ident</tt> on the <tt>driver_block_list</tt>. Its use is in
the code setting up the offloads to avoid setting up tc and
netfilter callbacks at the same time. This check is expected to be removed
from drivers that are able to support both at the same time
in their hardware, once that support gets implemented.</p>

<p>The internals of the traffic classifier were modified to apply the
filtering stored in the flow-block API; this is done in a new function <tt><a
href="https://elixir.bootlin.com/linux/latest/source/net/sched/cls_api.c#L1537">tcf_block_setup()</a></tt>.  

<h4>Callback list</h4>

<p>The drivers set up the flow-block object (<tt>flow_block_cb</tt>)
and add their callbacks to their list. Each driver then passes this list
to the core networking code, which does the registration (in
tc and netfilter) and calls the driver callback
to do the actual hardware setup. This
callback uses the classifier-specific data it receives in the parameters,
including the type of the operation (for example to add or remove an
offload).</p>

<p>Edward Cree <a
href="https://lwn.net/ml/netdev/75eec70e-60de-e33b-aea0-be595ca625f4@solarflare.com/">asked</a>
why there is a single list per driver, and not per device, for
example:</p>

<p>
<div class="BigQuote">
        Pablo, can you explain (because this commit message doesn't) why
        these per-driver lists are needed, and what the information/state
        is that has module (rather than, say, netdevice) scope?
</div>
<p>

<p>The drivers only supported one single flow block, Neira <a
href="/ml/netdev/20190813195126.ilwtoljk2csco73m@salvia/">explained</a>,  
and the idea was to extend that support to one for each subsystem (ethtool,
tc, and so on). This is for two reasons: the first is that the current
drivers can only support one subsystem; when that restriction is lifted, the other
limitation is that the sharing support would require the same
configuration of all the subsystems. This means that, for example, the
same configuration would be required for both <tt>eth0</tt> and
<tt>eth1</tt> for tc, and also there would also have to be a shared 
configuration for netfilter. Neira assumes this is almost never going
to be the case.</p>

<h4>The netfilter offload itself</h4>

<p><a href="https://lwn.net/ml/netdev/20190709205550.3160-13-pablo@netfilter.org/">The
last patch in the series</a> introduces the hardware offloading of
netfilter itself. Currently the support is basic and only handles
the ingress chain. The rule must perform an
exact match on the five elements identifying the flow: the protocol,
the source and destination addresses, and the source and destination ports.</p>

<p>An example of the offload is given in the series:</p>
<pre>
    table netdev filter {
        chain ingress {
            type filter hook ingress device eth0 priority 0; flags offload;
            ip daddr 192.168.0.10 tcp dport 22 drop
        }
    }
</pre>
<p>It drops all TCP packets to the destination address
<tt>192.168.0.10</tt>, port&nbsp;22 (typically used by SSH). The only
difference from the non-offloaded rules is the addition of the
<tt>flags&nbsp;offload</tt> option.</p>

<p>Since the control of offloading is given to the administrator, there
might be misconfigurations. For example, when the offload flag is set
for a rule that cannot be offloaded, the error code will be <tt>EOPNOTSUPP</tt>.
If the driver cannot handle the command, for example when the TCAM is
full, the result will be a driver-specific error code.</p>

<p>The interface gives a lot of power to the system administrator, but
also makes them responsible for figuring out which rules will benefit the
most from offloading. It seems that knowledge of the system
configuration and the traffic it handles will be necessary to derive the
most benefit from this new feature. At the time of writing this article, no
benchmark or best-practices documents are available. It also
remains to be seen where the limitations of the offload feature will be &mdash; for
example, how easy it will be to diagnose failures in the user
configuration coming from the driver callbacks.</p>

<h4>Summary</h4>

<p>The netfilter classification offloading feature allows the activation of
hardware offloading, which can provide important performance gains for certain use
cases. This work resulted in useful refactoring of existing code
blocks and opens a way for other offloading users. However, 
drivers need to be modified to take full advantage of this capability and
the API itself 
is quite complex with a number of levels of callbacks. The
administrators gain a powerful tool, but it will be up to them to use
it correctly. There is definitely more work to be done in this area.

<p>[The author would like to thank Pablo Neira Ayuso for helpful comments]</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Device_drivers-Network_drivers">Device drivers/Network drivers</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Networking-Packet_filtering">Networking/Packet filtering</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Packet_filtering">Packet filtering</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Rybczynska_Marta">Rybczynska, Marta</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/810663/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor811227"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Accelerating netfilter with hardware offload, part 2</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 31, 2020 20:53 UTC (Fri)
                               by <b>johill</b> (subscriber, #25196)
                              [<a href="/Articles/811227/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I don't see it in the code on a cursory look, but I guess they should use netlink extended ACK by passing down the "extack" pointer, so that an error string can be returned to the user in addition to the cryptic "-EOPNOTSUPP", or "-ENOSPC" or whatever happens.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/811227/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor811289"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Accelerating netfilter with hardware offload, part 2</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 2, 2020 4:14 UTC (Sun)
                               by <b>pabs</b> (subscriber, #43278)
                              [<a href="/Articles/811289/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Does the offload support trust the offload hardware or does it also re-apply the netfilter rules after the filtering done by the offload hardware?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/811289/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2020, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
