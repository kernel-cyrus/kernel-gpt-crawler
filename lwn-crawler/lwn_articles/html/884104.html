        <!DOCTYPE html>
        <html lang="en">
        <head><title>Going big with TCP packets [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/884104/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/884383/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/884104/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Going big with TCP packets</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>This article brought to you by LWN subscribers</b>
<p>
Subscribers to LWN.net made this article &mdash; and everything that
       surrounds it &mdash; possible.  If you appreciate our content, please
       <a href="/Promo/nst-nag3/subscribe">buy a subscription</a> and make the next
       set of articles possible.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>February 14, 2022</br>
           </div>
Like most components in the computing landscape, networking hardware has
grown steadily faster over time.  Indeed, today's high-end network
interfaces can often move data more quickly than the systems they are
attached to can handle.  The networking developers have been working for
years to increase the scalability of their subsystem; one of the current
projects is <a
href="/ml/netdev/20220203015140.3022854-1-eric.dumazet@gmail.com/">the
BIG TCP patch set</a> from Eric Dumazet and Coco Li.  BIG TCP isn't for
everybody, but it has the potential to significantly improve networking
performance in some settings.

<p>
Imagine, for a second, that you are trying to keep up with a 100Gb/s
network adapter.  As networking developer Jesper Brouer <a
href="/Articles/629155/">described</a> back in 2015, if one is using the longstanding
maximum packet size of 1,538 bytes, running the interface at full speed
means coping with over eight-million packets per second.  At that rate, CPU
has all of about 120ns to do whatever is required to handle each packet,
which is not a lot of time; a single cache miss can ruin
the entire processing-time budget.
<p>
The situation gets better, though, if the number of packets is reduced, and
that can be achieved by making packets larger.  So it is unsurprising that
high-performance networking installations, especially local-area networks
where everything is managed as a single unit, use larger packet sizes.
With proper 
configuration, packet sizes up to 64KB can be used, improving the situation
considerably.  But, in settings where data is being moved in units of
megabytes or gigabytes (or more — cat videos are getting larger all the
time), that still leaves the system with a lot of packets to handle.
<p>
Packet counts hurt in a number of ways.  There is a significant fixed
overhead associated with every packet transiting a system.  Each packet
must find its way through the network stack, from the upper protocol layers
down to the device driver for the interface (or back).  More packets means more
interrupts from the network adapter.  The <tt>sk_buff</tt>
structure ("SKB") used to represent packets within the kernel is a large
beast, since it must be able to support just about any networking feature that 
may be in use; that leads to significant per-packet
memory use and memory-management costs.  So there are good reasons to wish
for the ability to move data in fewer, larger packets, at least for
some types of applications.
<p>
The length of an IP packet is stored in the IP header; for both IPv4 and
IPv6, that length lives in a 16-bit field, limiting the maximum
packet size to 64KB.  At the time these protocols were designed, a 64KB
packet could take multiple seconds to transmit on the backbone Internet
links that were available, so it must have seemed like a wildly large number;
surely 64KB would be more than anybody would ever rationally want to put into
a single packet.  But times change, and 64KB can now seem like a
cripplingly low limit.
<p>
Awareness of this problem is not especially recent: there is a solution
(for IPv6, at least) to be found in <a
href="https://datatracker.ietf.org/doc/html/rfc2675">RFC&nbsp;2675</a>,
which was adopted in 1999.  The IPv6 specification allows the placement of
<a
href="https://en.wikipedia.org/wiki/IPv6_packet#Hop-by-hop_options_and_destination_options">"hop-by-hop"
headers</a> with additional information; as the name suggests, a hop-by-hop
header is used to communicate options between two directly connected
systems.  RFC&nbsp;2675 enables larger packets with a couple of tweaks to
the protocol.  To send a "jumbo" packet, a system must set the (16-bit) IP
payload length field to zero and add a hop-by-hop header containing the
real payload length.  The length field in that header is 32&nbsp;bits,
meaning that jumbo packets can contain up to 4GB of data; that should
surely be enough for everybody.
<p>
The BIG TCP patch set adds the logic necessary to generate and accept jumbo
packets when the maximum transmission unit (MTU) of a connection is set
sufficiently high.  Unsurprisingly, there were a number of details to
manage to make this actually work.  One of the more significant issues is
that packets of any size are rarely stored in physically contiguous memory,
which tends to be hard to come by in general.  For zero-copy operations,
where the buffers live in user space, packets are guaranteed to be
scattered through physical memory.  So packets are represented
as a set of "fragments", which can be as short as one (4KB) page each;
network interfaces handle the task of assembling packets from fragments on
transmission (or fragmenting them on receipt).
<p>

Current kernels limit the number of fragments stored in an SKB to&nbsp;17,
which is sufficient to store a 64KB packet in single-page chunks.  That
limit will clearly interfere with the creation of larger packets, so the
patch set raises the maximum number of fragments (to&nbsp;45).  But, as
Alexander Duyck <a
href="/ml/netdev/ee1fedeb33cd989379b72faac0fd6a366966f032.camel@gmail.com/">pointed
out</a>, many interface drivers encode assumptions about the maximum number
of fragments that a packet may be split into.  Increasing that limit
without fixing the drivers could lead to performance regressions or even
locked-up hardware, he said.
<p>
After some discussion, Dumazet <a
href="/ml/netdev/CANn89iKMa5fT3HhKdO2K=WFxwBsRBr_HN=sxPDqX-MJvWyoz5Q@mail.gmail.com/">proposed</a>
working around the problem by adding a configuration option controlling the
maximum number of allowed fragments for any given packet.  That is fine for
sites that build their own kernels, which  prospective users of 
this feature are relatively likely to do.  It offers little help for
distributors, though, who must pick a value for this option for all of
their users.
<p>
In any case, many drivers will need to be updated to handle jumbo packets.
Modern network interfaces perform segmentation offloading, meaning that
much of the work of creating individual packets is done within the
interface itself.  Making segmentation offloading work with jumbo packets
tends to involve a small number of tweaks; a few drivers are updated in the
patch set.
<p>
One other minor problem has to do with the placement of the RFC 2675
hop-by-hop header.  These headers, per the IPv6 standard, are placed
immediately after the IP header; that can confuse software that "knows"
that the TCP header can be found immediately after the IP header in a
packet.  The <tt>tcpdump</tt> utility has some problems in this regard; it
also seems that there are a fair number of BPF programs in the wild that
contain this assumption.  For this reason, jumbo-packet handling is
disabled by default, even if the underlying hardware and link could handle
those packets.
<p>
Dumazet included some brief benchmark results with the patch posting.
Enabling a packet size of 185,000 bytes increased network throughput by
nearly 50% while also reducing round-trip latency significantly.  So BIG
TCP seems like an option worth having, at least in the sort of environments
(data centers, for example) that use high-speed links and can reliably
deliver large packets.  If tomorrow's cat videos arrive a little more
quickly, BIG TCP may be part of the reason.
<p>
See <a href="https://netdevconf.info/0x15/session.html?BIG-TCP">Dumazet's
2021 Netdev talk</a> on this topic for more details.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Networking-IPv6">Networking/IPv6</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/884104/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor884783"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 14, 2022 21:39 UTC (Mon)
                               by <b>dcg</b> (subscriber, #9198)
                              [<a href="/Articles/884783/">Link</a>] (12 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This is not too different from the problems that modern file systems have using the full bandwidth of modern storage. Isn&#x27;t the root problem the same? CPUs are not getting faster, but other hardware pieces are, so abstraction layers have to do as little as possible and algorithms have to be extremely efficient. Very interesting times for operating system development.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884783/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor884791"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 2:19 UTC (Tue)
                               by <b>NYKevin</b> (subscriber, #129325)
                              [<a href="/Articles/884791/">Link</a>] (11 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
HDD I/O speeds are not getting significantly faster, either. It&#x27;s actually starting to become a bit of a problem, because the ratio of storage space to I/O bandwidth has gotten extremely biased in favor of the former as HDDs get bigger but not faster, so a large fleet of HDDs doesn&#x27;t have enough overall bandwidth to be useful at scale. You could work around this by buying a lot of small HDDs, but that&#x27;s so expensive (per gigabyte) that you&#x27;re probably better off just buying SSDs instead. As a result, we&#x27;re starting to see increased use of SSDs even in domains where HDD seek time would otherwise be acceptable, and HDDs are sometimes getting relegated to &quot;cool&quot; storage and batch processing.<br>
<p>
(The above describes my experience with extremely large-scale services. For &quot;normal-sized&quot; services, you&#x27;re probably fine with an HDD or ten, but if you&#x27;ve suddenly decided to build your own private YouTube, you should at least run the numbers, just in case.)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884791/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor884795"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 5:21 UTC (Tue)
                               by <b>zdzichu</b> (subscriber, #17118)
                              [<a href="/Articles/884795/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I believe &quot;modern storage&quot; in 2022 are NVMe drives capable of 5 million IOPS each.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884795/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor884802"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 10:36 UTC (Tue)
                               by <b>mageta</b> (subscriber, #89696)
                              [<a href="/Articles/884802/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
For many use-cases thats still just way too expensive (for the moment); and there is plenty of development still happening in HDDs (even tapes). For example, some vendors starting to deploy multi-actuator HDDs (we recently got support for that in Linux), so you can have multiple reads/writes concurrently - obviously that&#x27;s still slower than flash.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884802/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor884830"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 14:44 UTC (Tue)
                               by <b>HenrikH</b> (subscriber, #31152)
                              [<a href="/Articles/884830/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Well so are 100Gb/s NICs and switches so neither one is consumer level driven at the moment.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884830/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor884831"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 14:59 UTC (Tue)
                               by <b>Wol</b> (subscriber, #4433)
                              [<a href="/Articles/884831/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Well, admittedly my home system isn&#x27;t configured like a lot of them ...<br>
<p>
But I reorganised (as in archived last year&#x27;s) loads of mailing lists, and it was noticeable that even after Thunderbird came back and said &quot;finished&quot;, that the disk subsystem - a raid-5 array - was desperately struggling to catch up. With 32GB of ram, provided it caches everything fine I&#x27;m not worried, but it&#x27;s still a little scary knowing there&#x27;s loads of stuff in the disk queue flushing as fast as possible ...<br>
<p>
Cheers,<br>
Wol<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884831/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor903511"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 1, 2022 23:28 UTC (Mon)
                               by <b>WolfWings</b> (subscriber, #56790)
                              [<a href="/Articles/903511/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
That&#x27;s a large reason my home NAS is a lot of smaller spindles when I built it last, using 2.5&quot; 2TB HDD drives currently. Yeah there&#x27;s single 3.5&quot; drives in the next year or two that can approach the capacity of the array, but the throughput craters in that case especially for random I/O in comparison, and if I lose a 2TB drive it&#x27;s a bit under 4 hours for a rebuild not days.<br>
<p>
Since that&#x27;s limited entirely by the write speed of the 2TB drive I&#x27;ve been thinking about adding a single NVMe exclusively as a hot-spare just to reduce that time down to about 30 minutes TBH.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/903511/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor903512"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 1, 2022 23:39 UTC (Mon)
                               by <b>Wol</b> (subscriber, #4433)
                              [<a href="/Articles/903512/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
What raid level?<br>
<p>
A four or five drive raid-6 reduces the danger of a disk failure. An NVMe cache will speed up write time. And the more spindles you have, the faster your reads, regardless of array size.<br>
<p>
Cheers,<br>
Wol<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/903512/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor903600"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 2, 2022 21:13 UTC (Tue)
                               by <b>bartoc</b> (guest, #124262)
                              [<a href="/Articles/903600/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Once the drives get big enough it makes sense to just use something like btrfs raid10, instead of something like raid6, rebuilds still take a long time but don&#x27;t have to read all of every drive anymore. There are also fewer balancing issues if you add more drives. Actually, even with raid6 you should probably use something like btrfs or zfs (zfs can have some creeping performance problems, and is harder to expand/contract, but is better tested). Btrfs raid6 is said to be &quot;unsafe&quot; but in reality, it is probably safer than mdraid raid6 or a raid controller&#x27;s raid6.<br>
<p>
Not to mention the additional cost of the bigger drives (per TB) is offset by needing less &quot;other crap&quot; to drive them. You need smaller RAID enclosures, fewer controllers/expanders/etc, less space, and so on.<br>
<p>
A four drive raid6 is pretty pointless, you get the write hole and the write amplification for a total of .... zero additional space efficiency. Just use a check summing raid10 type filesystem. IMHO 8-12 disks is the sweet spot for raid6.<br>
<p>
fun quote from the parity delustering paper, published 1992:<br>
<font class="QuotedText">&gt; Since the time necessary to reconstruct the contents of a failed disk is certainly minutes and possibly hours, we focus this paper on the performance of a continuous-operation storage subsystem during on-line failure recovery.</font><br>
<p>
My last raid rebuild was I think 5 full days long, using a small array of 18 TB disks.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/903600/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor903603"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 2, 2022 23:01 UTC (Tue)
                               by <b>Wol</b> (subscriber, #4433)
                              [<a href="/Articles/903603/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; A four drive raid6 is pretty pointless, you get the write hole and the write amplification for a total of .... zero additional space efficiency. Just use a check summing raid10 type filesystem. IMHO 8-12 disks is the sweet spot for raid6.</font><br>
<p>
But a four-drive raid-10 is actually far more dangerous to your data ... A raid 6 will survive a double disk failure. A double failure on a raid 10 has - if I&#x27;ve got my maths right - a 30% chance of trashing your array.<br>
<p>
md-raid-6 doesn&#x27;t (if configured that way) have a write hole any more.<br>
<p>
<font class="QuotedText">&gt; Btrfs raid6 is said to be &quot;unsafe&quot; but in reality, it is probably safer than mdraid raid6 or a raid controller&#x27;s raid6.</font><br>
<p>
I hate to say it, but I happen to KNOW that btrfs raid6 *IS* unsafe. A lot LESS safe than md-raid-6. It&#x27;ll find problems better, but it&#x27;s far more likely that those problems will have trashed your data. Trust me on that ...<br>
<p>
At the end of the day, different raids have different properties. And most of them have their flaws. Unfortunately, at the moment btrfs parity raid is more flaw and promise than reality.<br>
<p>
Oh - and my setup - which I admit chews up disk - is 3-disk raid-5 with spare, over dm-integrity and under lvm. Okay, it&#x27;ll only survive one disk failure, but it will also survive corruption, just like btrfs. But each level of protection has its own dedicated layer - the Unix &quot;do one thing and do it well&quot;. Btrfs tries to do everything - which does have many advantages - but unfortunately it&#x27;s a &quot;jack of all trades, crap at some of them&quot;, one of which unfortunately is parity raid ...<br>
<p>
And while I don&#x27;t know whether my layers support trim, if they do, btrfs has no advantage over me on time taken to rebuild/recover an array. Btrfs knows what part of the disk is use, but so does any logical/physical device that supports trim ...<br>
<p>
Cheers,<br>
Wol<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/903603/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor884803"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 10:35 UTC (Tue)
                               by <b>Sesse</b> (subscriber, #53779)
                              [<a href="/Articles/884803/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This was a problem even when I started in Google in 2007; disks were getting so large that anything like recovery or the likes was getting problematic. So the problem has been there all along, it&#x27;s just moving slowly into more “normal” problem domains as the problem gets worse and worse.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884803/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor884856"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 17:45 UTC (Tue)
                               by <b>rgmoore</b> (<b>&#x272D; supporter &#x272D;</b>, #75)
                              [<a href="/Articles/884856/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <p>I assume that with something like YouTube, the final solution involves multiple levels of caching with different tradeoffs between latency and cost.  With a site that is accessed mostly by browsing, you can get advance notice of what items are likely to be looked at soon based on what's on the users' screens and can pre-populate the cache accordingly.  I'm sure there are engineers whose whole job is to optimize this behavior.  It also makes me wonder if some of the dreaded YouTube algorithm isn't built around trying to steer viewers into stuff that's popular right now because it's sure to be available in cache.


      
          <div class="CommentReplyButton">
            <form action="/Articles/884856/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor884915"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 16, 2022 10:13 UTC (Wed)
                               by <b>NYKevin</b> (subscriber, #129325)
                              [<a href="/Articles/884915/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Speaking with my Google hat on: Saying that the final solution involves &quot;multiple levels of caching&quot; is like saying that a game of Magic: The Gathering involves multiple rules.[1] Beyond that I&#x27;m not really at liberty to comment, but I can point you at [2] for the official company line on how the recommendation system works.[3]<br>
<p>
[1] See <a href="https://media.wizards.com/2022/downloads/MagicCompRules%2020220218.txt">https://media.wizards.com/2022/downloads/MagicCompRules%2...</a> for the MTG rules. But don&#x27;t actually try to read them, because they&#x27;re intended to be used for resolving specific issues, not as a &quot;here&#x27;s how to play the game&quot; starting point.<br>
[2]: <a href="https://blog.youtube/inside-youtube/on-youtubes-recommendation-system/">https://blog.youtube/inside-youtube/on-youtubes-recommend...</a><br>
[3]: The linked blog post is Google/YouTube&#x27;s official position on the matter, and may not be reflective of my own personal views (which I have no interest in discussing). It&#x27;s also from September 2021, so things may have changed since then.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884915/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor884794"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 5:20 UTC (Tue)
                               by <b>alison</b> (subscriber, #63752)
                              [<a href="/Articles/884794/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Enabling a packet size of 185,000 bytes increased network throughput by nearly 50%</font><br>
<p>
Presumably &quot;throughput&quot; involves getting the BIG TCP packet off the NIC via DMA, probably of the scatter-gather variety for so much data.   It&#x27;s remarkable that the speed of these transfers is sufficient for a 50% speed-up.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884794/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor884801"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 10:28 UTC (Tue)
                               by <b>mageta</b> (subscriber, #89696)
                              [<a href="/Articles/884801/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Current kernels limit the number of fragments stored in an SKB to 17, which is</font><br>
<font class="QuotedText">&gt; sufficient to store a 64KB packet in single-page chunks. That limit will</font><br>
<font class="QuotedText">&gt; clearly interfere with the creation of larger packets, so the patch set raises</font><br>
<font class="QuotedText">&gt; the maximum number of fragments (to 45). But, as Alexander Duyck pointed out,</font><br>
<font class="QuotedText">&gt; many interface drivers encode assumptions about the maximum number of fragments</font><br>
<font class="QuotedText">&gt; that a packet may be split into. Increasing that limit without fixing the</font><br>
<font class="QuotedText">&gt; drivers could lead to performance regressions or even locked-up hardware, he</font><br>
<font class="QuotedText">&gt; said.</font><br>
<font class="QuotedText">&gt; </font><br>
<font class="QuotedText">&gt; After some discussion, Dumazet proposed working around the problem by adding a</font><br>
<font class="QuotedText">&gt; configuration option controlling the maximum number of allowed fragments for</font><br>
<font class="QuotedText">&gt; any given packet. That is fine for sites that build their own kernels, which</font><br>
<font class="QuotedText">&gt; prospective users of this feature are relatively likely to do. It offers little</font><br>
<font class="QuotedText">&gt; help for distributors, though, who must pick a value for this option for all of</font><br>
<font class="QuotedText">&gt; their users. </font><br>
<p>
Hmm, sounds a lot like what we have in the block layer with &quot;block queue limits&quot;; where each low level driver that implements an interface to the block layer also provides a set of limits for this specific queue, also - among other things - including how the scatter-gather list of this queue must look like so the underlying device can actually deal with it. For example some devices can&#x27;t deal with multi-page scatter-elements, while other can; some have a upper limit of scatter-elements in a single list, and so on. This way there doesn&#x27;t have to be a single config switch and/or a kernel wide knob.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884801/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor884808"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 13:46 UTC (Tue)
                               by <b>taladar</b> (subscriber, #68407)
                              [<a href="/Articles/884808/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; software that &quot;knows&quot; that the TCP header can be found immediately after the IP header in a packet.</font><br>
<p>
This could also affect iptables rules using the u32 match.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884808/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor884853"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2022 16:45 UTC (Tue)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/884853/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I hereby confirm that 64KB packets seemed insanely large to me in the 1980s.  ;-)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884853/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor884913"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 16, 2022 9:34 UTC (Wed)
                               by <b>geert</b> (subscriber, #98403)
                              [<a href="/Articles/884913/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
However, Commodore managed to send more than 10 million ;-)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884913/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor884933"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 16, 2022 14:17 UTC (Wed)
                               by <b>xxiao</b> (guest, #9631)
                              [<a href="/Articles/884933/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
RFC2675 adds 32bit field for 4GB packets in IPv6, what about IPv4, how can IPv4 ever do more that 16-bit length of packages? I still don&#x27;t understand how that can work.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884933/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor884936"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 16, 2022 14:33 UTC (Wed)
                               by <b>farnz</b> (subscriber, #17727)
                              [<a href="/Articles/884936/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>Legacy technology can't do more than 16 bit packet lengths; you will have to upgrade to IPv6 if you need jumbo packets on the wire.


      
          <div class="CommentReplyButton">
            <form action="/Articles/884936/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor884932"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 16, 2022 14:24 UTC (Wed)
                               by <b>jhhaller</b> (guest, #56103)
                              [<a href="/Articles/884932/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
One of the problems with implementing changes like this is the use of global settings which control too much for one setting. Take, for example, the problem of increasing MTU. It&#x27;s hard to change the MTU because it&#x27;s used both to control receive packet size and transmit packet size. Everyone on a LAN segment has to agree on the MTU because switches don&#x27;t operate in the ICMP or (for IPv4) fragmentation domain. So, if one&#x27;s corporate backbone has evolved to significantly higher bandwidth, but still drops a small fraction of packets, TCP flow control algorithms limit transmission based on latency. Larger MTUs would help, but implementing that requires a flag day in every subnet participating in a conversation. If one could change systems to accept larger MTUs, but not send larger MTUs, a flag day isn&#x27;t required, as every system can be configured to accept larger MTUs, but not transmit them. Once every system has been changed, then the router port and endpoint systems can be changed to larger MTUs.<br>
<p>
I hope that BIG TCP does something similar, that one can first configure systems to accept BIG TCP before they are sent, which would avoid flag-day requirements to implement it. Except for point-to-point communication, it will be years before every system can operate with BIG TCP. Ideally, it could be implemented on a connection-pair basis rather than switch-controlled Ethernet frame size limitations.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/884932/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor885108"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 17, 2022 13:37 UTC (Thu)
                               by <b>kleptog</b> (subscriber, #1183)
                              [<a href="/Articles/885108/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It would be nice if Path MTU discovery actually worked reliably everywhere. Nowadays with layers and layers of tunnelling and encapsulation being fairly normal, reducing MTUs on interfaces to make things reliable is still required far too often.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/885108/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor885251"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 18, 2022 10:10 UTC (Fri)
                               by <b>geert</b> (subscriber, #98403)
                              [<a href="/Articles/885251/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I used to be &quot;blessed&quot; with a work laptop with Windows and VPN software. When using the VPN from home, the network stopped working very soon.<br>
Turned out that the VPN software enabled a firewall rule to block all incoming ICMP traffic.  This included the &quot;fragmentation needed&quot; messages sent from my OpenWRT router, which strictly obeyed the 576-byte MTU supplied by my ISP&#x27;s DHCP server.<br>
<p>
Of course I was the only one having that problem, as off-the-shelf consumer grade router software just ignored any MTU values, and 1500-byte packets worked fine regardless.  Interestingly, we had to fix Path MTU Discovery in one of our embedded products a few weeks before...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/885251/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor903035"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jul 31, 2022 23:07 UTC (Sun)
                               by <b>fest3er</b> (guest, #60379)
                              [<a href="/Articles/903035/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
You weren&#x27;t the only one. I dutifully obeyed Comcast&#x27;s MTU size. And things broke. I eventually chose to ignore that incorrect, erroneous setting. That &#x27;handwave&#x27; solved the problem. For me.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/903035/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor885256"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 18, 2022 10:54 UTC (Fri)
                               by <b>farnz</b> (subscriber, #17727)
                              [<a href="/Articles/885256/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>In large part, we have the problems we have with MTU because most of our link layers now simulate a 1980s 10BASE5 network, just at very high speeds. A switched 100GBASE-LR4 network is designed to present the appearance of a single 10BASE5 segment (via switch behaviour); an 802.11 network tunnels 10BASE5 compatible networking over an RF link layer where the "true" packet size (via aggregation) is variable but can go as high as 1 MiB.
<p>As a result, we have point to point links at the L1 level (in both WiFi and wired Ethernet), which are used to emulate a bus network topology at L2. If we'd done things very differently, we'd be presenting those P2P links directly to the L3 system, and the "switch" or "AP" equivalent would be able to offer different MTUs to different clients, and send PMTU discovery messages back instantly if you're going to a lower MTU path attached to the same switch.
<p>It's worth noting that IPv6 (a late 1980s/early 1990s design) has vestigial support for this; a router can indicate that no other hosts are on-link, and thus force you to send everything via the router. If you're directly attached via P2P links to an IPv6 router, you could thus have different MTUs on all the P2P links, and the router would be able to control path MTU as appropriate.


      
          <div class="CommentReplyButton">
            <form action="/Articles/885256/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor885237"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 18, 2022 3:59 UTC (Fri)
                               by <b>developer122</b> (guest, #152928)
                              [<a href="/Articles/885237/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Why in the world is it called &quot;big TCP&quot; when it&#x27;s the IP packet that&#x27;s bigger, not the TCP bit riding along inside it?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/885237/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor885250"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 18, 2022 9:57 UTC (Fri)
                               by <b>geert</b> (subscriber, #98403)
                              [<a href="/Articles/885250/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Because &quot;Big IP&quot; would attract too many investors? ;-)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/885250/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor885238"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 18, 2022 4:02 UTC (Fri)
                               by <b>developer122</b> (guest, #152928)
                              [<a href="/Articles/885238/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; The sk_buff structure (&quot;SKB&quot;) used to represent packets within the kernel is a large beast, since it must be able to support just about any networking feature that may be in use; that leads to significant per-packet memory use and memory-management costs.</font><br>
<p>
There seem to be a lot of old, very overloaded structures in the kernel with different bits used in different contexts. It makes me wonder if one could work up a way of generically breaking these optional bits out into sub-structures and leave the main structure mostly a table of references. One would need to macro-ify the copying and other handling of them though. Or maybe this is just making things even more complicated. :P<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/885238/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor885245"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 18, 2022 9:02 UTC (Fri)
                               by <b>laarmen</b> (subscriber, #63948)
                              [<a href="/Articles/885245/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
One thing to consider is that not having these extra bits in the skb means another memory load, which might not be affordable in the per-packet CPU budget.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/885245/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor903478"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 1, 2022 16:02 UTC (Mon)
                               by <b>jhoblitt</b> (subscriber, #77733)
                              [<a href="/Articles/903478/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Does anyone know what layer2 hardware is being used to test this work on?  I don&#x27;t believe I&#x27;ve ever seen an Ethernet NIC that supports an MTU &gt; 16KiB.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/903478/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor929991"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Going big with TCP packets</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 24, 2023 14:31 UTC (Mon)
                               by <b>edeloget</b> (subscriber, #88392)
                              [<a href="/Articles/929991/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Looking at the patches, I would give a look to Mellanox NICs :)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/929991/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2022, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
