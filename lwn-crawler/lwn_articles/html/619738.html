        <!DOCTYPE html>
        <html lang="en">
        <head><title>Transparent huge page reference counting [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/619738/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/619333/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/619738/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Transparent huge page reference counting</h1>
</div>
<div class="ArticleText">
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>November 11, 2014</br>
           </div>
While most architectures supported by Linux use a 4KB page size, most of
them also are able to work with much larger pages, varying from 2MB to 1GB
in size.  These "huge pages" offer significant performance advantages for
many workloads, the biggest of which is usually the reduction of pressure
on the translation lookaside buffer which short-circuits the process
of turning a virtual address into a physical address.  The kernel's <a
href="/Articles/423584/">transparent huge pages</a> (THP) feature enables
the use of huge pages without the need for any sort of developer or user
intervention.  THP suffers from some limitations that prevent it from being
used as fully as one might like, though; a <a
href="/Articles/619191/">patch set</a> from Kirill A. Shutemov aims to
reduce those limitations, at the cost of making changes to some fairly
complex code.
<p>
<h4>Transparent huge pages</h4>
<p>
THP works by quietly substituting huge pages into a process's address space
when (1)&nbsp;those page are available and (2)&nbsp;it appears that the
process would benefit from the change.  When Andrea Arcangeli first added
this feature to the 2.6.38 kernel, he had a formidable problem to face: there were
many places in the kernel's memory-management code that were not prepared
to cope with huge pages scattered randomly in a process's address space.
Andrea dealt with some of those problems by avoiding them entirely; that is
why, for example, page-cache pages (those backed by files on disk) cannot
be huge pages 
in current kernels.  
<p>
In many other situations, Andrea placed a call to
<tt>split_huge_page()</tt>, a function which breaks a huge page down into
its component small pages.  Whenever he encountered code that could not
cope with a huge page, and that he wasn't able to fix at the time, he put
in a <tt>split_huge_page()</tt> call to simply make the huge page go away.
These calls have a clear performance cost, since they undo the work that
put the huge page into place to begin with.  But they reduced the problem
to something more tractable; <tt>split_huge_page()</tt> can thus be thought
of as a crutch similar to the big kernel lock.  It is almost never the
optimal solution to the problem, but it is a solution that can be made to
work now, deferring a hard problem for a later time.
<p><blockquote class="ad">
<b><tt>$ sudo subscribe today</tt></b>
<p>
Subscribe today and elevate your LWN privileges. You’ll have
access to all of LWN’s high-quality articles as soon as they’re
published, and help support LWN in the process.  <a href="https://lwn.net/Promo/nst-sudo/claim">Act now</a> and you can start with a free trial subscription.
</blockquote>
<p>
Over time, some of the <tt>split_huge_page()</tt> calls in the kernel have
been replaced with code that can handle huge pages.  But they still exist 
in the page migration code,
in the implementation of <a href="/Articles/330589/">kernel samepage
merging</a> (KSM),
in the <a href="/Articles/348886/">bad-memory poisoning code</a>,
in the implementation of <tt>mprotect()</tt> and <tt>mlock()</tt>,
and in the swap code, among other places.  Some of these cases are
unlikely to change; KSM will probably never be able to merge duplicate
pages if it cannot split them out of huge pages.  Others might seem just as
resistant to change; what does it mean to change the protection of, say,
half of a huge page with <tt>mprotect()</tt>?  It turns out that this
latter case can be optimized, though, as part of a bigger effort to rework
and simplify how the management of transparent huge pages and their
references counts is done.
<p>
<h4>PMD- and PTE-level mappings</h4>
<p>
To understand Kirill's patch set, it is good to remember that huge pages
are represented in the kernel as compound pages.  Readers who are
unfamiliar with how compound pages work may want to take a look at <a
href="/Articles/619514/">this article</a> for some basic background and
terminology.
<p>
Kirill's ultimate goal is to enable the use of transparent huge pages with
the page cache.  Currently, only anonymous pages can be replaced with huge
pages, limiting their use to only a fraction of total memory.  That is an
ambitious goal, and the current patch set does not even try to approach
it.  Instead, Kirill has worked to simplify the management of transparent
huge pages and make them more flexible.
<p>
In particular, he has eliminated the hard separation between normal and
huge pages in the system.  In current kernels, a specific 4KB page can be
treated as an individual page, or it can be part of a huge page, but not
both.  If a huge page must be split into individual pages, it is split
completely for all users, the compound page structure is torn down, and the
huge page no longer exists.  The 
fundamental change in Kirill's patch set is to allow a huge page to be
split in one process's address space, while remaining a huge page in any
other address space where it is found.
<p>
Time for a quick reminder of how page tables are structured on Linux
systems; this diagram was taken from <a href="/Articles/117749/">this 2005
LWN article</a> on the subject:
<p>
<blockquote>
<img src="https://static.lwn.net/images/ns/kernel/four-level-pt.png" alt="[Page tables]"
width=661 height=402>
</blockquote>
<p>

A huge page is represented in a process's page table with a single entry at
the page middle directory (PMD) level.  Individual pages,
instead, have entries at the bottom page-table entry (PTE) level, as shown
in the diagram.  But
there is nothing that says that the same memory must be mapped in the same
way in all processes; it is perfectly legitimate for one process to see a
2MB range as a single huge page while another has it mapped as 512
individual PTEs.  If this type of different mapping were supported, one
process could call <tt>mprotect()</tt> to change the protections on a
portion of a huge page (causing the mapping to be split in that process's
address space) while not disturbing the huge page mapping in other
processes, which are not affected by the protection change.
<p>
In other words, if <tt>split_huge_page()</tt> could be replaced by a new
function, call it <tt>split_huge_pmd()</tt>, that would only split up a
single process's mapping of a huge page, code needing to deal with
individual pages could often be accommodated while preserving the benefits
of the huge page for other processes.
But, as noted above, the kernel currently does not support different
mappings of huge 
pages; all processes must map the memory in the same way.  This restriction
comes down to how various parameters — reference counts in particular — are
represented in huge pages.
<p>
<h4>Huge-page reference counting</h4>
<p>
A reference count tracks the number of users an object (such as a page in
memory) has, allowing the
kernel to determine when the object is free and can be deleted.
There are actually two types of reference counts for a normal page.  The first,
stored in the <tt>_count</tt> field of <tt>struct page</tt>, is the total
number of references held 
to the page.  
The second, kept in <tt>_mapcount</tt>, is the number of page
table entries referring to this page.  A page-table mapping is a reference,
so every such reference counted in
<tt>_mapcount</tt> is also tracked in <tt>_count</tt>;  the latter should thus
always be greater than or equal to the former.  Situations where
<tt>_count</tt> can exceed <tt>_mapcount</tt> include pages mapped for DMA
and pages mapped into the kernel's address space with a function like
<tt>get_user_pages()</tt>.  Locking a page into memory with
<tt>mlock()</tt> will also increase <tt>_count</tt>.
The relative value of these two counters is
important; if <tt>_count</tt> equals <tt>_mapcount</tt>, the page can be
reclaimed by locating and removing all of the page table entries.  But if
<tt>_count</tt> is greater than <tt>_mapcount</tt>, the page is "pinned"
and cannot be reclaimed until the extra references are removed.
<p>
The reference count rules change with compound pages, though.  In that
case, the value of <tt>_count</tt> is held at zero for all tail pages to
avoid confusing other parts of the memory management code.  Reference
counts are, as a rule, tracked in the head page for the compound page as a
whole, but it is still necessary to track references on individual (small)
pages within the compound page.  Imagine a situation where part of such a
page is used for an I/O operation, for example.  The trick that is used is
to keep that reference in <tt>_mapcount</tt> instead and to have the
various helper functions that access reference counts pick the right field
depending on whether a given page is a tail page or not.
<p>
This trick works because huge pages are mapped and unmapped as a unit, so
there is no need to track the mapping of tail pages separately.  If,
however, one wants to allow the mapping of individual pages within a huge
page, things fall apart, because it will become necessary to track the
mappings to those individual pages.  So this trick must go; it must be
replaced by a scheme that can track both the mappings to the huge page as a
whole and the individual pages that make up that huge page.
<p>
The first part, tracking mappings to the huge page as a whole, is done with
another 
increasingly familiar (to those who read the article on compound pages)
trick: this count is placed into the 
<tt>mapping</tt> field of the first <i>tail</i> page in the huge page.
This field is normally used to track the file that has been mapped into
this page of 
memory; since huge pages are not used in the page cache, there is no
file mapping and this space is available for other uses.  The
count is an <tt>atomic_t</tt>, while <tt>mapping</tt> is a pointer to
<tt>struct address_space</tt>, so yet another cast is used.  One might
argue that another union field should be added to make the overloading
explicit, but that was not done here.
<p>
There is still the matter of tracking non-mapping reference counts to tail
pages — the reason <tt>_mapcount</tt> was used in those pages to begin
with.  This tracking is done so that, should the huge page be split, the
individual pages with elevated reference counts can be properly marked.
Kirill's approach is to give up on that objective and, in the process,
change how  non-mapping references to tail pages are tracked.  Instead, a
call to <tt>get_page()</tt> on a tail page will increment the reference
count on the <i>head</i> page.  So the knowledge that a specific tail page
is pinned is replaced with the knowledge that some page, somewhere within
the compound page, is pinned.
<p>
That, naturally, will destroy the ability to mark individual pages as being
pinned if the huge page is split.  Kirill's answer to that is to simply
cause <tt>split_huge_page()</tt> to fail if any pages within the huge page are
pinned.  Note that it will <i>not</i> cause <tt>split_huge_pmd()</tt>,
which just splits the mapping for one process, to fail.  So most cases that
formerly had to call <tt>split_huge_page()</tt> will still work since the
huge page is no longer truly being split.  The cases where a split is
absolutely necessary will simply fail, but, Kirill says, the code is
prepared for that eventuality in all cases.
<p>
Removing tail page reference counting enables the removal of a surprising
amount of special-case code.  It also frees up <tt>_mapcount</tt> for its
original purpose: to track the number of page-table mappings to the page.
At that point, it becomes possible for one process to map a huge page as a
single page, while another maps it as a set of individual pages.
<p>
Kirill claims that the simplification of the code yields performance
improvements on their own, though no benchmark results have been posted.
Allowing some processes to retain a huge-page mapping when others need a
split view should also make things go faster in cases where memory is
shared.  This feature should make a bigger difference, though, in the
future when THP can be used with the page cache, where sharing of pages
happens rather more often.  That day will not come soon, though; first this
set of patches must find its way into the mainline.  Given that the work is
being done in low-level memory-management code, and given that Kirill
thinks there are probably a few surprises (code that doesn't expect an
individual page to be a tail page, for example) yet to be found, that
probably is not going to happen in the immediate future.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Huge_pages">Huge pages</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Huge_pages">Memory management/Huge pages</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/619738/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2014, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
