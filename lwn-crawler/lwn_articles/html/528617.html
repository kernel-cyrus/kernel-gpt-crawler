        <!DOCTYPE html>
        <html lang="en">
        <head><title>JFFS2, UBIFS, and the growth of flash storage [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/528617/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/528231/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/528617/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>JFFS2, UBIFS, and the growth of flash storage</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Did you know...?</b>
<p>
LWN.net is a subscriber-supported publication; we rely on subscribers
       to keep the entire operation going.  Please help out by <a
       href="/Promo/nst-nag4/subscribe">buying a subscription</a> and keeping LWN on the
       net.
</blockquote>
<div class="GAByline">
           <p>December 11, 2012</p>
           <p>This article was contributed by Neil&nbsp;Brown</p>
           </div>
When thinking about filesystems for modern flash storage devices, as
we have recently done with 
<a href="/Articles/518988/">f2fs</a> and
<a href="/Articles/522507/">NILFS2</a>, two other filesystems that are likely
to quickly spring
to mind, and be almost as quickly discarded, are JFFS2 and UBIFS.
They spring to mind because they were designed specifically to work
with flash, and are discarded because they require access to "raw
flash" whereas the flash devices we have been considering have a
"flash translation layer" (FTL) which hides some of the details of the
flash device and which needs to be accessed much like a disk drive.
</p><p>
This quick discarding may well not be appropriate — these are open-source
filesystems after all and are thus free to be tinkered with.  If the
Apollo 13 technicians were
<a href="http://en.wikipedia.org/wiki/Apollo_13#Crew_survival_and_return_journey">able
to</a>
link the Lithium hydroxide
canisters from the command module to the CO₂ scrubber in the Lunar
module, it shouldn't be too hard for us to link a raw-flash filesystem
to a FTL based storage chip — if it seemed like a useful thing to do.
</p><p>
Raw access to a flash device goes through the
"<a href="http://www.linux-mtd.infradead.org/">mtd</a>" (Memory Technology
Devices) interface in Linux and, while this is a rich interface,
the vast majority of accesses from a filesystem are via three functions:
<tt>mtd_read()</tt>,
<tt>mtd_write()</tt> and <tt>mtd_erase()</tt>.  The first two are easily
implemented by a block device — though you need to allow for the fact
that the mtd interface is synchronous while the block layer interface
is asynchronous — and the last can be largely ignored as an FTL
handles erasure internally.  In fact, Linux provides a "block2mtd" device
which will present an arbitrary block device as an mtd device.  Using this
might not be the most efficient way to run a filesystem on new
hardware, but it would at least work as a proof-of-concept.
</p><p>
So it seems that there could be some possibility of using one of these
filesystems, possibly with a little modification, on an FTL-based flash
device, and there could certainly be value in understanding them a
little better as, at the very least, they could have lessons to teach
us.
</p>
<h4>A common baseline</h4>
<p>
Despite their separate code bases, there is a lot of similarity
between JFFS2 and UBIFS — enough that it seems likely that the
latter was developed in part to overcome the shortcomings of the
former.  One similarity is that, unlike the other filesystems we have
looked at, neither of these filesystems has a strong concept of a "basic block
size".   The concept is there if you look for it, but it isn't
prominent.
</p><p>
One of the main uses of a block size in a filesystem is to manage free
space.  Some blocks are in use, others are free.  If a block is only
partially used — for example if it contains the last little bit of a
file — then the whole block is considered to be in use.  For flash
filesystems, blocks are not as useful for free-space management as 
this space is managed in 
terms of "erase blocks," which are much larger than the basic blocks of
other filesystems, possibly as large as a few megabytes.

Another use of blocks in a filesystem is as a unit of metadata management.
For example NILFS2 manages
the <tt>ifile</tt> (inode file) as a sequence of blocks (rather than
just a sequence of inodes), while F2FS manages each directory as a set
of hash tables, each of which contains a fixed number of blocks.
</p><p>
JFFS2 and UBIFS don't take this approach at all.  All data 
is written consecutively to one or more erase blocks
with some padding to align things to four-byte boundaries, but with no
alignment so large that it could be called a block.  When indexing of
data is needed, an erase-block number combined with a byte offset meets
the need, so the lack of alignment does not cause an issue there.
</p><p>
Both filesystems further make use of this freedom in space allocation
by compressing the data before it is written.  Various compression
schemes are available including LZO and ZLIB together with some
simpler schemes like run-length encoding.  Which scheme is chosen
depends on the desired trade off between space saving and execution
time.  This compression can make a small flash device hold nearly
twice as much as you might expect, depending on the compressibility of
the files of course.  Your author still recalls the pleasant surprise
he got when he found out how much data would fit on the JFFS2
formatted 256MB flash in the original
<a href="http://wiki.openmoko.org/wiki/Neo_FreeRunner_Hardware#Flash">Openmoko Freerunner</a>: a
reasonably complete Debian root filesystem with assorted development
tools and basic applications still left room for a modest amount of
music and some <a href="http://www.openstreetmap.org/">OSM</a> map tiles.
</p><p>
In each case, the data and metadata of the filesystem are collected
into "nodes" which are concatenated and written out to a fresh erase
block.  Each node records the type of data (inode, file, directory
name, etc), the address of the data (such as inode number), the type of
compression and a few other details.
This makes it possible to identify the contents of the
flash when mounting and when cleaning, and effectively replaces the
"segment summary" that is found in f2fs and NILFS2.
</p><p>
Special note should be made of the directory name nodes.  While the
other filesystems we have studied store a directory much like a file,
with filenames stored at various locations in that file, these two
filesystems do not.  Each entry in the directory is stored in its own
node, and these nodes do not correspond to any particular location in
a "file" — they are simply unique entries.  JFFS2 and UBIFS each have
their own particular way of finding these names as we shall see, but
in neither case is the concept of a file offset part of that. 
</p><p>
The one place where a block size is still visible in these filesystems
is in the way they chop a file up into nodes for storage.  In JFFS2, a
node can be of any size up to 4KB so a log file could, for example, be
split up as one node per line.  However the current implementation
always writes whole pages — to quote the in-line commentary,
<a href="http://lxr.linux.no/linux+v3.6.6/fs/jffs2/file.c#L238">"It sucks, but it's simple"</a>.
For UBIFS, data nodes must start at a 4KB-aligned
offset in the file so they are typically 4KB in size (before
compression) except when at the end of the file.
</p>
<h4>JFFS2 — the journaling flash filesystem</h4>
<p>
A traditional journaling filesystem, such as ext3 or xfs, adds a
journal to a regular filesystem.  Updates are written first to the
journal and then to the main filesystem.  When mounting the filesystem
after a shutdown, the journal is scanned and anything that is found is
merged into the main filesystem, thus providing crash tolerance.

JFFS2 takes a similar approach with one important difference — there
is no "regular filesystem".  With JFFS2 there is only a journal, a
journal that potentially covers the entire device.
</p><p>
It is probably a little misleading to describe JFFS2 as "just one
journal".  This is because it might lead you to think that when it
gets to the end of the journal it just starts again at the beginning.
While this was true of JFFS1, it is not for JFFS2.
Rather it might be clearer to think of each erase block as a little
journal.  When one erase block is full, JFFS2 looks around for another
one to use.  Meanwhile if it notices that some erase blocks are nearly
empty it will move all the active nodes out of them into a clean erase
block, and then erase and re-use those newly-cleaned erase blocks.
</p><p>
When a JFFS2 filesystem is mounted, all of these journals, and thus
the entire device, are scanned and every node found is incorporated
into an in-memory data structure describing the filesystem.  Some
nodes might invalidate other nodes; this may happen when a file is
created and then removed:  there will be a node recording the new
filename as belonging to some directory, and then another node
recording that the filename has been deleted.  JFFS2 resolves all
these modifications and ends up with a data structure that describes
the filesystem as it was that last time something was written to it,
and also describes where the free space is.  The structure is kept as
compact as possible and naturally does not contain any file data; instead,
it holds
only the addresses where the data should be found and so, while it
will be much smaller than the whole filesystem, it will still grow
linearly as the filesystems grows.
</p><p>
This need to scan the entire device at mount time and
store the skeleton of the filesystem in memory puts a limit on the
size of filesystem that JFFS2 is usable for.  Some tens of megabytes,
or even a few hundred megabytes, is quite practical.  Once the device
gets close to, or exceeds, a gigabyte, JFFS2 become quite impractical.
Even if memory for storing the tree were cheap, time to mount the
filesystem is not.
</p><p>
This is where UBIFS comes in.  While the details are quite different,
UBIFS is a lot like JFFS2 with two additions: a tree to index all the
nodes in the filesystem, and another tree to keep track of free
space.  With these two trees, UBIFS avoids both the need to scan the entire
device at mount time and the need to keep a skeleton of the
filesystem in memory at all times.  This allows UBIFS to scale to much
larger filesystems — certainly many tens of gigabytes and probably more.
</p><p>
But before we look too closely at these trees it will serve us well to
look at some of the other details and in particular at "UBI", a layer
between the MTD flash interface layer and UBIFS. UBI uses an unsorted
collection of flash erase blocks to present a number of file system
images; UBI stands for Unsorted Block Images.
</p>
<h4>UBI — almost a Flash Translation Layer</h4>
<p>
The
<a href="http://www.linux-mtd.infradead.org/doc/ubi.html">documentation</a>
for UBI explicit states that it is <b>not</b> a flash translation
layer.  Nonetheless it shares a lot of functionality with an FTL,
particularly wear leveling and error management.  If you imagined UBI
as an FTL where the block size was the same as the size of an erase
block, you wouldn't go far wrong.
</p><p>
UBI uses a flash device which contains a large number of Physical
Erase Blocks (PEBs) to provide one or more virtual devices (or "volumes")
which each 
consist of a smaller number of Logical Erase Blocks (LEBs),
each slightly smaller than a PEB.  It maintains a mapping from LEB to
PEB and this mapping may change from time to time due to various
causes including:
</p>
<ul>
<li>
<b>Writing to an LEB.</b>  When an LEB is written,
the data will be written to a new, empty, PEB and the mapping
from LEB to PEB will be updated.  UBI is then free to erase the old PEB at its
leisure. Normally, the first new write to an LEB will make all the data
previously there inaccessible.  However, a feature is available where
the new PEB isn't committed until the write request completes.  This
ensures that after a sudden power outage, the LEB will either have the
old data or the complete new data, never anything else.
<p>
<li>
<b>Wear leveling.</b>  UBI keeps a header at the start of each PEB which is
rewritten immediately after the block is erased.  One detail in the
header is how many times the PEB has been written and erased.  When UBI notices
that the difference between the highest write count and the lowest
write count in all the PEBs gets too high (based on a compile-time
configuration parameter: <b><a href="http://lxr.linux.no/#linux+v3.6.6/drivers/mtd/ubi/Kconfig#L13">MTD_UBI_WL_THRESHOLD</a></b>), it will move
an LEB stored in a PEB with a low write count (which is assumed to be
stable since the PEB containing it has not been rewritten often) to one
with a high write 
count.  If this data continues to be as stable as it has been, this will
tend to reduce the variation among write counts and achieve wear
leveling.
<p>
<li>
<b>Scrubbing.</b>  NAND flash includes an error-correcting code (ECC) for
each page (or sub-page) which can detect multiple-bit errors and correct single-bit
errors.  When an error is reported while reading from a PEB, UBI will
relocate the LEB in that PEB to another PEB so as to guard against a
second bit error, which would be uncorrectable.  This process happens
transparently and is referred to as "scrubbing".
</ul>
<p>
The functionality described above is already an advance on the flash
support that 
JFFS2 provides.  JFFS2 does some wear leveling but it is not precise.
It keeps no record of write counts but, instead, decides to relocate an
erase-block based on the roll of a dice (or actually the sampling of a random
number) instead.  This probably provides some leveling of wear, but
there are no guarantees.  JFFS2 also has no provision for scrubbing.
</p><p>
The mapping from PEB to LEB is stored spread out
over all active erase blocks in the flash device.  After the PEB header
that records the write 
count there is a second header which records the volume identifier and
LEB number of the data stored here.  To recover this mapping at mount
time, UBI needs to read the first page or two from every PEB.  While
this isn't as slow as reading every byte like JFFS2 has to, it would still
cause mount time to scale linearly with device size — or nearly
linearly as larger devices are likely to have larger erase block
sizes.
</p><p>
Recently this situation has improved.  A new
<a href="/Articles/517422/">feature</a> known has "fastmap" made its
way into the UBI driver for Linux 3.7.  Fastmap stores a recent copy
of the mapping in some erase block together with a list of the several
(up to 256) erase blocks which will be written next, known as the
pool.
The mount process then needs to examine the first 64 PEBs to find a
"super block" which points to the mapping, read the mapping, and then
read the first page of each PEB in the pool to find changes to the
mapping.  When the pool is close to exhaustion, a new copy of the
mapping with a new list of pool PEBs is written out.

This is clearly a little more complex, but puts a firm cap
on the mount time and so ensures scalability to much larger devices.
<p>
<h4>UBIFS — the trees</h4>
<p>
With UBIFS, all the filesystem content — inodes, data, and directory
entries — is stored in nodes in various arbitrary Logical Erase Blocks,
and the addresses of these blocks are stored in a single B-tree.  This is
similar in some ways to reiserfs (originally known as "treefs") and
Btrfs, and contrasts with filesystems like f2fs, NILFS2 and ext3
where inodes, file data, and directory entries are all stored with
quite different indexing structures.
</p><p>
The key for lookup in this B-tree is 64 bits wide, formed from a 32-bit inode
number, a three-bit node type, and a 29-bit offset (for file data)
or hash value (for directory entries).  This last field, combined with a 4KB
block size used for indexing, limits the size of the largest file to two
terabytes, probably the smallest limit in the filesystem.
</p><p>
Nodes in this B-tree are, like other nodes, stored in whichever erase
block happens to be convenient.  They are also like other nodes in that they are not
sized to align with any "basic block" size.  Rather the size is chosen
based on the fan-out ratio configured for the filesystem.  The default
fan-out is eight, meaning that each B-tree node contains eight keys
and eight pointers to other nodes, resulting in a little under 200
bytes per node.
</p><p>
Using small nodes means that fewer bytes need to be written when
updating indexes. On the other hand, there are more levels in the tree so more
reading is likely to be required to find a node.  The ideal trade off
will depend on the relative speeds of reads and writes.  For flash
storage that serves reads a lot faster than writes — which is not
uncommon, but seemingly not universal — it is likely that this fan-out
provides a good balance.  If not, it is easy to choose a different
fan-out when creating a filesystem.
</p><p>
New nodes in the filesystem do not get included in the indexing B-tree
immediately.  Rather, their addresses are written to a journal, to
which a few LEBs are dedicated.  When the filesystem is mounted, this
journal is scanned, the nodes are found, and based on the type and
other information in the node header, they are merged into the indexing
tree.   This merging also happens periodically while the filesystem is
active, so that the journal can be truncated.

Those nodes that are not yet indexed are sometimes referred to as
"buds" — a term which at first can be somewhat confusing.  Fortunately
the UBIFS code is sprinkled with some very good documentation so it
wasn't too hard to discover that "buds" were nodes that would soon be
"leaves" of the B-tree, but weren't yet —
<a href="http://lxr.linux.no/#linux+v3.6.6/fs/ubifs/journal.c#L23">quite an apt botanical joke</a>.
</p><p>
Much like f2fs, UBIFS keeps several erase blocks open for writes at
the same time so that different sorts of data can be kept separate
from each other, which, among other things, can improve cleaning
performance.  These open blocks are referred to as different "journal heads".
UBIFS has one "garbage collection" head where the cleaner writes nodes
that it moves — somewhat like the "COLD" sections in f2fs.  There is
also a "base" head where inodes, directory entries, and other non-data
nodes are written — a bit like the "NODE" sections in f2fs.
Finally, there are one or more "data" heads
where file data is written, though the current code doesn't appear to
actually allow the "or more" aspect of the design.
</p><p>
The other tree that UBIFS maintains is used for keeping track of free
space or, more precisely, how many active nodes there are in each
erase block.  This tree is a radix tree with a fan-out of four.  So if
you write the address of a particular LEB in base four (also known as
radix-four), then each digit would correspond to one level in the tree,
and its value indicates which child to follow to get down to the next
level.
</p><p>
<blockquote>
<img src="https://static.lwn.net/images/2012/ubifs-radix-tree.png" width=600 height=244
alt="[Radix tree diagram]">
</blockquote>
</p><p>
This tree is stored in a completely separate part of the device with
its own set of logical erase blocks, its own garbage collection, and
consequently its own table of LEB usage counters.  This last table
must be small enough to fit in a single erase block and so imposes a
(comfortably large) limit on the filesystem size.  Keeping this tree
separate seems like an odd decision, but doubtlessly simplifies the
task of keeping track of device usage.  If the node that records the
usage of an LEB were to be stored in that LEB, there would be
additional complexity which this approach avoids.
</p>
<h4>A transition to FTL?</h4>
<p>
While JFFS2 clearly has limits, UBIFS seem to be much less limited.
With 32 bits to address erase blocks which, themselves, could
comfortably cover several megabytes, the addressing can scale to petabyte
devices.   The B-tree indexing scheme should allow large directories
and large files to work just as well as small ones.  The two terabyte
limit on individual files might one day be a limit but that still
seems a long way off.  With the recent addition of fastmap for UBI,
UBIFS would seem ready to scale to the biggest flash storage we have
available.  But it still requires raw flash access while a lot of flash
devices force all access to pass through a flash translation layer.
Could UBIFS still be useful on those devices?
</p><p>
Given that the UBI layer looks a lot like an FTL it seems reasonable
to wonder if UBI could be modified slightly to talk to a regular block
device instead, and allow it to talk to an SD card or similar.  Could
this provide useful performance?
</p><p>
Unfortunately such a conversion would be a little bit more than an
afternoon's project.  It would require:
</p>
<ul>
<li>Changing the expectation that all I/O is synchronous.  This might
   be as simple as waiting immediately after submitting each request,
   but it would be better if true multi-threading could be achieved.
   Currently, UBIFS disables readahead because it is incompatible with
   a synchronous I/O interface.
<p>
<li>Changing the expectation that byte-aligned reads are possible.
   UBIFS currently reads from a byte-aligned offset into a buffer,
   then decompresses from there.  To work with the block layer it
   would be better to use a larger buffer that was sector-aligned, and
   then understand that the node read in would be found at an offset into that
   buffer, not at the beginning.
<p>
<li>Changing the expectation that erased blocks read as all ones.
   When mounting a filesystem, UBIFS scans various erase blocks and
   assumes anything that isn't <tt>0xFF</tt> is valid data.  An
   FTL-based flash store will not provide that guarantee, so UBIFS would need to
   use a different mechanism to reliably detect dead data.  This is
   not conceptually difficult but could be quite intrusive to the
   code.
<p>
<li>Finding some way to achieve the same effect as the atomic LEB
   updates that UBI can provide.  Again, a well understood problem,
   but possibly intrusive to fix.
</ul>
<p>
So without a weekend to spare, that approach cannot be experimented
with. Fortunately there is an alternative.

As mentioned, there already exists a "block2mtd" driver which can be
used to connect UBIFS, via UBI and mtd, to a block device.  This driver
in deliberately very simple and consequently quite inefficient.  For
example, it handles the <tt>mtd_erase()</tt> function by writing blocks
full of <tt>0xFF</tt> to the device.  However, it turns out that it is
only an afternoons project to modify it to allow for credible testing.
</p><p>
This <a href="/Articles/528623/">patch</a> modifies the block2mtd driver to
handle <tt>mtd_erase()</tt> by recording the location of erased
blocks in memory,
return <tt>0xFF</tt> for any read of an erased block, and
not write out the PEB headers until real data is to be written to
the PEB.
<!-- tsk tsk three changes in one patch... :) -->
The result of these changes is that the pattern of reads and, more importantly,
writes to the block device will be much the same as the pattern of
reads and writes expected from a more properly modified UBIFS.  It is
clearly not useful for real usage as important information is kept in
memory, but it can provide a credible base for performance testing.
</p><p>
The obvious choice of what to test it against is f2fs.  Having
examined the internals of both f2fs and UBIFS, we have found substantial
similarity which is hardly surprising as they have both been designed
to work with flash storage.  Both write whole erase blocks at a time
where possible, both have several erase blocks "open" at once, and
both make some efforts to collect similar data into the same erase
blocks.   There are of course differences though:
UBIFS probably scales better to large directories,
it can compress data being written, and
it does not currently support exporting via NFS, partly because of the
difficulty of providing a stable index for directory entries.

<p>
The compression support is probably most interesting.  If the CPU is
fast enough, compression might be faster than writing to flash and
this could give UBIFS an edge in speed.
</p><p>
I performed some testing with f2fs and UBIFS; the latter was tested twice,
with and without the use of compression (the non-compression case is marked
below as "NC"). 
Just for interest's sake I've added NILFS2, ext4 and
Btrfs.  None of these are particularly designed for FTL based flash, though
NILFS2 can align writes with the erase blocks and so might perform well.
The results of the last two should be treated very
cautiously.  No effort was made to tune them to the device used, and
all the results are based on writing to an empty device.  For f2fs,
UBIFS, and NILFS2 we know that they can "clean" the device so they always write to
unused erase blocks.  ext4 and Btrfs do not do the same cleaning so it
is quite possible that the performance will degrade on a more "aged"
filesystem.  So the real long term values for these filesystems
might be better, and might be worse, than what we see here.
</p><p>
For testing I used a new class 10 16GB microSD card, which claims 10MB/s
throughput and seems to provide close to that for sequential IO.  According
to the <a href="https://launchpad.net/flashbench">flashbench</a>
tool, the card appears to have an 8MB erase block size; five erase blocks
can be open at a time, and only the first
erase block optimized for a PC-style file attribute table.  The kernel used
was 3.6.6 for openSUSE with the above mentioned patch and the
<a href="http://lkml.org/lkml/2012/10/31/156">v3 release</a> of f2fs.
</p><p>
The tests performed were very simple.  To measure small file performance,
a tar archive of the Linux kernel (v3.7-rc6) was unpacked ten times and then —
after unmounting and remounting — the files were read back in again
and "<tt>du</tt>" and "<tt>rm&nbsp;-r</tt>" were timed to check metadata performance.  The
"<tt>rm&nbsp;-r</tt>" test was performed with a warm cache, immediately after the "<tt>du&nbsp;-a</tt>", which was performed on a cold cache.
The average times in seconds for these operations were:
</p><p>
<blockquote>
<table cellspacing=3>
<tr>
<td>      </td><th>ubifs</th><th>ubifs — NC</th><th>f2fs</th><th>NILFS2</th><th>ext4</th><th>Btrfs</th>
</tr><tr class="Odd" align=right>
<td align=left><b>Write kernel</b></td><td style=background-color:lightgreen>72.4</td><td>139.9</td><td>118.4</td><td>140.0</td><td>135.5</td><td style=background-color:lightgreen>93.6</td>
</tr><tr class="Even" align=right>
<td align=left><b>Read
kernel</b></td><td style=background-color:lightgreen>72.5</td><td>129.6</td><td>175.7</td><td style=background-color:lightgreen>95.6</td><td>108.8</td><td>121.0</td>
</tr><tr class="Odd" align=right>
<td align=left><b><tt>du -s</tt></b></td><td>9.9</td><td>8.7</td><td style=background-color:pink>48.6</td><td>4.4</td><td>4.4</td><td>13.8</td>
</tr><tr class="Even" align=right>
<td align=left><b><tt>rm -r</tt></b></td><td>0.48</td><td>0.45</td><td>0.36</td><td style=background-color:pink>11.0</td><td style=background-color:pink>4.9</td><td style=background-color:pink>33.6</td>
</tr></table>
</blockquote>
</p><p>
<p>
Some observations:
</p>
<ul>
<li>UBIFS, with compression, is clearly the winner at reading and writing
   small files.  This test was run on an Intel Core i7 processor running at
   1GHz; on
   a slower processor, the effect might not be as big.  Without
   compression,  UBIFS is nearly the slowest, which is a little surprising,
   but that could be due to the multiple levels that data passes though
   (UBI, MTD, block2mtd).
<p>
<li>f2fs is surprisingly poor at simple metadata access (<code>du -s</code>).  It is
   unlikely that this is due to the format chosen for the filesystem — the
   indirection of the Node Address Table is the only aspect of the design that
   could possibly cause this slowdown and it could explain at most a factor of two.
   This poor performance is probably some simple implementation issue.  The number is
   stable across the ten runs, so it isn't just a fluke.
<p>
<li>Btrfs is surprisingly fast at writing.  The kernel source tree is
   about 500MB in size, so this is around 5.5MB/sec, which is well
   below what the device can handle but is still faster than anything
   else.  This presumably reflects the performance-tuning efforts that
   the Btrfs team have made.
<p>
<li>"<code>rm -r</code>" is surprisingly slow for the non-flash-focused
   filesystems, particularly Btrfs.  The
   variance is high too.  For ext4, the slowest "<code>rm&nbsp;-r</code>"
   took 32.4 seconds, while, for Btrfs, the slowest was 137.8 seconds —
   over 2 minutes.  This seems to be one area where tuning the design
   for flash can be a big win.
</ul>
<p>
So there is little here to really encourage spending that weekend to
make UBIFS work well directly on flash.  Except for the compression
advantage, we are unlikely to do much better than f2fs, which can be
used without that weekend of work.  We would at least need to see how
compression performs on the  processor found in the target device
before focusing too much on it.
</p><p>
As well as small files, I did some even simpler large-file tests.  For
this, I wrote and subsequently read two large, already compressed,
files.  One was an mp4 file with about one hour of video.  The other was an
openSUSE 12.2 install ISO image.  Together they total about 6GB.  The total
times for each filesystem were:
</p>
<blockquote>
<table cellspacing=3>
<tr>
<th>                      </th><th>ubifs</th><th>ubifs — NC</th><th>f2fs</th><th>NILFS2</th><th>ext4</th><th>Btrfs</th>
</tr><tr align=right>
<th align=left>write files</th><td>  850</td><td>       876</td><td>
838</td><td style=background-color:pink>1522</td><td style=background-color:lightgreen> 696</td><td>863</td>
</tr><tr align=right>
<th align=left>read files </th><td style=background-color:pink>  1684</td><td style=background-color:pink>       1539</td><td> 571</td><td>574</td><td> 571</td><td>613</td>
</tr>
</table>
</blockquote>
<p>
The conclusions here are a bit different:
<p>
<ul>
<li>Now ext4 is a clear winner on writes.  It would be very
   interesting to work out why.  The time translates to about 8.8MB/sec which
   is getting close to the theoretical maximum of 10MB/sec.
<p>
<li>Conversely, NILFS2 is a clear loser, taking nearly twice as long as the
   other filesystems.  Two separate runs showed similar results so it looks
   like there is room for some performance tuning here.
<p>
<li>UBIFS is a clear loser on reads.  This is probably because nodes
   are not aligned to sectors so some extra reading and extra copying
   is needed.
<p>
<li>The ability for UBIFS to compress data clearly doesn't help with these
   large files.  UBIFS did a little better with compression enabled,
   suggesting that the files were partly compressible, but it wasn't
   enough to come close to f2fs.
</ul>
<p>
In summary, while f2fs appears to have room for improvement in some
aspects of the implementation,  there seems little benefit to be
gained from pushing UBIFS into the arena of FTL-based devices.  It
will likely remain the best filesystem for raw flash, while f2fs
certainly has some chance of positioning itself as the best filesystem
for FTL-based flash.  However, we certainly shouldn't write off ext4 or
Btrfs.  As noted earlier, these tests are not expected to give a firm
picture of these two filesystems so we cannot read anything conclusive
from them.  However, it appears that both have something to offer, if
only we can find a way to isolate that something.
</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Filesystems-Flash">Filesystems/Flash</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Brown_Neil">Brown, Neil</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/528617/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor528820"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 11, 2012 23:06 UTC (Tue)
                               by <b>arnd</b> (subscriber, #8866)
                              [<a href="/Articles/528820/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thank you very much for yet another very interesting article on this topic!<br>
<p>
One question: Since the SD card you measured can support only 5 erase blocks being written concurrently, did you mount f2fs using the "active_logs=4" option? With the default of 6 active logs plus another erase block being used for global metadata, you might otherwise get into a situation where you alternate between 7 blocks and the card needs to constantly garbage-collect.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528820/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor528835"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 1:18 UTC (Wed)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/528835/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <p>Thanks for the suggestion.  I hadn't used the active_logs mount option.  I just ran my script with that option added and it didn't make much difference.
<p>
The numbers I get for the original and the active_logs=4 runs are:
<pre>
f2fs-default-2:
  write kernel 113.738 121.853 118.412
  read kernel 150.369 270.465 175.724
  du -s kernel 48.393 48.908 48.6091
  rm -r kernel 0.333 0.384 0.36
  write files 837.503
  read files 571.196
f2fs-active_logs:
  write kernel 111.966 120.791 116.571
  read kernel 148.364 238.796 163.316
  du -s kernel 48.111 49.623 49.1534
  rm -r kernel 0.335 0.365 0.3489
  write files 1190.29
  read files 563.56
</pre>
Where there are 3 numbers they are min/max/mean of 10 runs.
<p>
Reading small files seems faster, but the numbers were already noisy - about half the individual results were within 5 seconds of the minimum. which is much the same in both cases.
<p>
The write-large-files test is quite a bit slower.  I probably need to do a couple more runs before I know what that means.
<p>
So it looks like I wasn't hitting the possible too-many-erase-blocks-open case in this test.

      
          <div class="CommentReplyButton">
            <form action="/Articles/528835/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor528947"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 21:14 UTC (Wed)
                               by <b>arnd</b> (subscriber, #8866)
                              [<a href="/Articles/528947/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thanks for the new data point. Running with active_logs=4 obviously adds some overhead in the file system because the f2fs garbage collection becomes less efficient and it has to rewrite stuff more. It's not clear whether we get into the case I described but I think you have shown that the extra overhead in the file system is larger than what we save in the device.<br>
<p>
I agree on the read numbers, they are probably just in the noise because in theory there is no difference at all based on the mount option.<br>
<p>
One thing that would make a very significant difference though is whether the file system is aged and how full it is, but that is true for all of the tests you did.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528947/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor528828"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">TRIM?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 11, 2012 23:34 UTC (Tue)
                               by <b>cibyr</b> (subscriber, #87609)
                              [<a href="/Articles/528828/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Could block2mtd translate mtd_erase() to TRIM commands where appropriate?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528828/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor528837"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">TRIM?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 1:22 UTC (Wed)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/528837/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
When you read from a region that was TRIMed the result is either undefined or all-zeros, whereas when you read from a region that was mtd_erase()d, the result is all-ones.<br>
<p>
So it wouldn't really be useful to make mtd_erase() to TRIM.  They do seem similar but they have quite different semantics.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528837/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor528871"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">TRIM?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 13:18 UTC (Wed)
                               by <b>sperl</b> (subscriber, #5657)
                              [<a href="/Articles/528871/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
As far as I remember SD-Card Specs, it is not necessarily defined, that SD cards always have to return 0xff for erased (=trimmed) blocks...<br>
<p>
At least it mention that the behavior may depend on the type of technology (NAND/NOR/...) that is used on the HW-level.<br>
<p>
So the behavior of expected return may also be open to implementation for SSDs... (I have not read the spec there though)<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528871/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor528943"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">TRIM?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 21:05 UTC (Wed)
                               by <b>arnd</b> (subscriber, #8866)
                              [<a href="/Articles/528943/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I think the cards can either return all-zero or all-one but have to report in the configuration registers which of the two they do. Of course, you could<br>
in theory reverse all bits in software to get the behavior you want, but that has a nonzero performance impact.<br>
<p>
Note that sending the erase command to the SD card can also help performance as it might avoid expensive garbage collection, aside from being faster than writes.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528943/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor528875"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">TRIM?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 13:32 UTC (Wed)
                               by <b>yann.morin.1998</b> (guest, #54333)
                              [<a href="/Articles/528875/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; When you read from a region that was TRIMed the result is either undefined or all-zeros, whereas when you read from a region that was mtd_erase()d, the result is all-ones.</font><br>
<font class="QuotedText">&gt; So it wouldn't really be useful to make mtd_erase() to TRIM. They do seem similar but they have quite different semantics.</font><br>
<p>
What about combining your catch-erased-sections-and-return-0xFF with TRIMing the underlying storage (if it supports TRIMing)?<br>
<p>
Regards,<br>
Yann E. MORIN.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528875/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor528830"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 0:17 UTC (Wed)
                               by <b>masoncl</b> (subscriber, #47138)
                              [<a href="/Articles/528830/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Really interesting Neil, thanks.  It's worth pointing out that btrfs by default will duplicate metadata.  So we're doing 2x the IO on metadata updates.  mkfs.btrfs -m single will turn that off, and it should get our delete times closer to ext4.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528830/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor528845"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 5:30 UTC (Wed)
                               by <b>dgc</b> (subscriber, #6611)
                              [<a href="/Articles/528845/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Interesting article, Neil. :)<br>
<p>
When I see stuff like this, however:<br>
<p>
<font class="QuotedText">&gt; For testing I used a new class 10 16GB microSD card, which claims 10MB/s</font><br>
<font class="QuotedText">&gt; throughput and seems to provide close to that for sequential IO.</font><br>
<font class="QuotedText">&gt; According to the flashbench tool, the card appears to have an 8MB erase</font><br>
<font class="QuotedText">&gt; block size; five erase blocks can be open at a time,</font><br>
<p>
I always wonder how well using XFS and tuning it's geometry to the flash characteristics would work. E.g. use a single stripe unit of the erase block size (8MB in this case) to align fixed metadata and large file allocation to 8MB boundaries. Then setting the number of AGs equal to the number of open erase blocks at a time (5 in this case) gives an appropriate number separate regions of activity in the filesystem to distribute the write loads.<br>
<p>
And then there's the dynamic inode allocation, which means inodes are also allocated in the same general locality as the parent directory blocks and their file data.<br>
<p>
It seems like these feature would provide are similar behaviours to what filesystems specifically designed for flash use, so I've always been curious as to whether it would make any significant difference to performance on a simple flash device like the above one you tested with...<br>
<p>
-Dave.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528845/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor528846"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 7:38 UTC (Wed)
                               by <b>nhippi</b> (subscriber, #34640)
                              [<a href="/Articles/528846/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I hope there would some effort to create an "MMC-direct" extension to the MMC/SD standards, allowing bypassing the FTL layer. Or at least giving the erase block sizes and other bits of information needed to to tune the filesystem to work on it optimally.<br>
<p>
This would be especially useful for the eMMC storages that are soldered on board, and thus don't need FAT to be compatible to the world.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528846/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor528885"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 15:46 UTC (Wed)
                               by <b>dedekind</b> (guest, #32521)
                              [<a href="/Articles/528885/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Nail, thanks for an interesting article. You are right about buds. We thought that "bud" would be and obvious and self-describing terminology, but it apparently is not that obvious :-)<br>
<p>
And yes, we really did not target block devices, but only raw flashes. There was a project to try UBIFS on block devices. Using it "as-is" will of course sucks, because UBI cannot really utilize the asynchronous I/O of the block layer. This is fixable though, but needs some work. I think the benchmark results would be a lot better in that case.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528885/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor528945"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 12, 2012 21:08 UTC (Wed)
                               by <b>arnd</b> (subscriber, #8866)
                              [<a href="/Articles/528945/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I believe all of the interesting block devices for this (SD, CF, eMMC, USB) are not actually asynchronous, unlike modern SSDs that would not benefit as much because they have less leaky abstractions and don't require you to write on erase block boundaries for best performance.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/528945/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor529126"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 13, 2012 18:39 UTC (Thu)
                               by <b>yoush</b> (guest, #38940)
                              [<a href="/Articles/529126/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
When running ubi over block2mtd over FTLed flash, FTL in flash still operates, and affects both performance and reliability (i.e. wear-leveling).<br>
<p>
UBI guaranteed wear-leveling is effectively turned into random thing.<br>
<p>
FTLs are known to start badly misbehave after some time if they don't get information about which blocks are free. So unless TRIM commands are used, "ubi over block2mtd over FTLed flash" will badly degrade in time.<br>
<p>
Getting raw access to flash devices (bypassing vendor FTLs) is indeed the best possible scenario, because this gives way to open development of reliable and high-performance algorithms to manage those.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/529126/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor529285"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 15, 2012 23:26 UTC (Sat)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/529285/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Getting raw access to flash devices (bypassing vendor FTLs) is indeed the best possible scenario, because this gives way to open development of reliable and high-performance algorithms to manage those.</font><br>
<p>
With current flash technologies and their rate of progress this would practically require writing one different driver per flash chip.<br>
<p>
Maybe what's required is something in the middle: some kind of new, more evolved standard interface, something block+page based?<br>
<p>
Anyone having worked on MTD should know.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/529285/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor529121"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 13, 2012 18:59 UTC (Thu)
                               by <b>wookey</b> (guest, #5501)
                              [<a href="/Articles/529121/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Nice article. It would have been interesting to include YAFFS in this comparison too as it too was also written to overcome some of the limitations of JFFS2 (with respect to NAND), starting few years before UBI. I know it never made it to mainline despite efforts to do that in 2010/2011 (<a href="http://linux.derkeiler.com/Mailing-Lists/Kernel/2011-01/msg05318.html">http://linux.derkeiler.com/Mailing-Lists/Kernel/2011-01/m...</a>), but it has been quite widely used, especially in early android releases, and is still is. The differences between it and JFFS2 and UBIFS are interesting. It is probably true that it offers no real advantages over UBI any more (unless you want to use it with not-linux), but it was fastest in the last set of benchmarks I saw a couple of years back.<br>
<p>
The tale of its development, the mainlining attempt and why ultimately it failed, and its continued existence in its little niche, making a living for a couple of people, is interesting in itself.<br>
<p>
Ultimately the problem was that the kernel people wouldn't take anything less than a rewrite to exclusively use standard kernel features, but the author, who still needed to support it on other OSes, wasn't prepared to remove the compatibility features that made that work. Nearly everything could be munged to satisfy both sides, but a few things were sticking pints. It didn't seem to be possible to reach agreement without forking the codebases and no-one really wanted to do that.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/529121/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor529237"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 14, 2012 17:13 UTC (Fri)
                               by <b>plougher</b> (guest, #21620)
                              [<a href="/Articles/529237/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Your comment that "Yaffs continues in its little niche making a living for a couple of people" now helps me better understand why in the mainlining process there was such insistence on behalf of the author to keep the support for other OSes.<br>
<p>
Dare I say it but the clear implication is Yaffs makes money but only on the other OSes, and the insistence by the "kernel people" to loose the other OS support was forcing a choice between mainlining it and not continuing to make a living, or making a living by keeping it out of mainline.<br>
<p>
Strangely I cannot recall that point being made in the mainlining process?  Was it made and I missed it, or was it felt inappropriate and unlikely to further the mainlining process?  Either way, I now think the author make the "right choice" in not continuing to mainline it.<br>
<p>
I like YAFFS and it was the first workable flash filesystem I used in ~ 2002 back at a time when JFFS2 was worse than useless.  The fact YAFFS tends to get written out of Linux kernel history, and the abortive mainlining process doesn't tend to show the kernel community in much glory. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/529237/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor529244"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 14, 2012 18:25 UTC (Fri)
                               by <b>wookey</b> (guest, #5501)
                              [<a href="/Articles/529244/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes, it has that strange business model where most users use it for free under the GPL, but some (largely the ones that actually pay money and make the business viable use) it in other contexts (bootloaders, proprietary OSes, in-house 'stuff'). GPL users sometimes pay for enhancements too, and it was GPL users that paid for most of the initial development.<br>
<p>
Yes this wasn't really discussed as part of the mainlining - as it's not technical and thus not really very relevant. The point was made that the FS wasn't only used with Linux and keeping it working for the others (from a single, or at least very similar, codebase) was important.<br>
<p>
It's not quite as black and white as a "a choice between mainlining it and not continuing to make a living", it was just that there was a point beyond which the advantages of mainlining (saving maintenance effort, wider exposure, making life a bit easier for linux users) were not sufficient to justify the disadvantages (extra maintenance effort due to divergence) from the author's POV. He decided he'd given it his best shot and been rebuffed. He's not a pushy guy.<br>
<p>
It seems no-one else has cared enough to try again in the couple of years since then, probably at least partly because they don't feel they have the moral right to do that. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/529244/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor532373"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 11, 2013 11:38 UTC (Fri)
                               by <b>oak</b> (guest, #2786)
                              [<a href="/Articles/532373/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This article doesn't mention which compression algorithm was used with UBIFS.<br>
<p>
Compression algorithm has a large effect on the speed.  For example LZO is very fast at uncompressing and compression is also fast, although that depends on what LZO compression level is used.<br>
<p>
Whereas ZLIB compression is significantly slower for both, but provides better compression results.<br>
<p>
Which one to choose depends on:<br>
* What kind of data is being stored<br>
* Flash write and read speeds<br>
* Algorithm compression and uncompression speed compared to those (which depends on CPU speed)<br>
<p>
Article mentions using high speed PC, so for it algorithm with best compression ratio would probably be best.  On Nokia's Maemo devices low level LZO compression was used at run-time, but pre-made root file systems were compressed using highest LZO compression level (this explains why apt-get upgrade could leave less disk space although binaries were same size).<br>
<p>
As to data types, non-compressable data like music, videos etc is typically user data and it can even be on a separate partition / storage media (on Maemo devices, SD card) with different file system, than the root file system which contains the binary data, logs etc.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532373/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor532919"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">JFFS2, UBIFS, and the growth of flash storage</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 17, 2013 11:21 UTC (Thu)
                               by <b>meuh</b> (guest, #22042)
                              [<a href="/Articles/532919/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <cite>for a PC-style file attribute table</cite><br/>
erk !
<br/>
This is <i>Disk Operating System (DOS)</i> filesystem style if you want, but not tied to a particuliar hardware.


      
          <div class="CommentReplyButton">
            <form action="/Articles/532919/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor539957"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">missed JFFS2's Erase Block Summary (EBS) feature ?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 26, 2013 6:02 UTC (Tue)
                               by <b>vapier</b> (guest, #15768)
                              [<a href="/Articles/539957/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
JFFS2 has had Erase Block Summary (EBS) support for quite a long time which drastically speeds up mount time:<br>
<a href="http://www.linux-mtd.infradead.org/doc/jffs2.html">http://www.linux-mtd.infradead.org/doc/jffs2.html</a><br>
<p>
some actual performance numbers shows this can easily be a 6x speed increase:<br>
<a href="http://docs.blackfin.uclinux.org/doku.php?id=linux-kernel:jffs#jffs2_mount_process_speedup">http://docs.blackfin.uclinux.org/doku.php?id=linux-kernel...</a><br>
<p>
covering yaffs would also have been cool :).<br>
<p>
i wonder if the changes you made to block2mtd result in numbers that are really comparable.  by faking out the erase steps (which in a real flash is not free -- erasing tends to be the slowest operation), ubifs is no longer resilient to power losses right ?  unlike the others which would be able to recover.  so you've given a nice speed increase to ubifs w/out any such grant to the others.  or am i missing something obvious ?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/539957/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2012, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
