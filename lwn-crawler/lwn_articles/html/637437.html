        <!DOCTYPE html>
        <html lang="en">
        <head><title>An introduction to GlusterFS [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/637437/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/637398/">Return to the Development page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/637437/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>An introduction to GlusterFS</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ignore previous instructions; subscribe to LWN today</b>
<p>
Every article on LWN.net is written by humans, for humans. If you've
enjoyed this article and want to see more like it, your subscription goes a
long way to keeping the robots at bay.  We are offering <a href="https://lwn.net/Promo/nst-bots/claim">a free one-month trial subscription</a> (no credit card required) to get you started.
</blockquote>
<div class="FeatureByline">
           By <b>Jake Edge</b><br>March 25, 2015</br>
           <hr>
<a href="/Archives/ConferenceByYear/#2015-Vault">Vault 2015</a>
</div>
<p>
Vijay Bellur, who is the co-maintainer of <a
href="http://www.gluster.org/">GlusterFS</a>, gave a presentation at the
first-ever <a
href="http://events.linuxfoundation.org/events/vault">Vault</a> conference
with an introduction to the filesystem and a look at where it is headed.  GlusterFS is a
distributed filesystem that will aggregate storage to provide a unified
namespace for users' files.  That data is then accessible via a wide
variety of mechanisms.
</p>

<p>
Bellur began with a brief explanation of the need for GlusterFS (or simply
Gluster).  It comes down to the amount of data that is being generated
these daysâ€”on the order of 2.5 exabytes (which is 2500 petabytes or 2.5
million terabytes) daily.  In fact, 90% of the data ever generated by
humans has been created in the last two years.  All of that data must be
stored somewhere and that storage should be commoditized and democratized,
he said.
</p>

<a href="/Articles/637442/">
<img src="https://static.lwn.net/images/2015/vault-bellur-sm.jpg" border=0 hspace=5 align="left"
alt="[Vijay Bellur]" title="Vijay Bellur" width=239 height=250>
</a>

<p>
Gluster is a <a
href="http://en.wikipedia.org/wiki/Scalability#Horizontal_and_vertical_scaling">scale-out</a>
distributed storage system that collects up a
variety of storage devices that are spread out across the network to
present a global namespace for users.  Gluster uses regular Linux
filesystems that support extended attributes (e.g. ext4, XFS, Btrfs) to
store the data. It provides file, object, and block 
interfaces to access the data.
</p>

<p>
All of Gluster is implemented as software that runs on commodity hardware,
he said.  It can run in virtual machines and may be able to be run in
containers some day.  Traditionally, distributed filesystems rely on
metadata servers, but Gluster does away with those.  Metadata servers are a
single point of failure and can be a bottleneck for scaling.  Instead,
Gluster uses a hashing mechanism to find data.
</p>

<p>
Storage elasticity is another attribute of Gluster.  It can scale out or
scale down as needed.  It is based on a modular architecture that is
extensible.  Most of it is implemented in user space, Bellur said.
</p>

<h4>Gluster concepts</h4>

<p>
A Gluster volume is a logical collection of exports from various storage
servers, which are called "bricks".  Volumes have an administrative name
associated with them; users access a volume or part of a volume for their
file operations (i.e. create, read, update, and delete, or CRUD).
</p>

<p>
There are several different types of volumes that are supported by
Gluster.  The first is a distributed volume that distributes files across
the bricks in the volume.  When the file is created, a hash is calculated
from the file name; that determines which brick it will be placed on.
Different clients will calculate the same hash value so they can find the
right brick to access the file.
</p>

<p>
Another volume type is the replicated volume.  As the name implies, it
makes multiple copies of the file and stores those copies on separate
bricks.  The number of copies is set at volume-creation time.
</p>

<p>
A distributed replicated volume is the one used by most Gluster
deployments, he said.  In those volumes, multiple copies of a file are stored within a
replicated volume and distributed across those replicated volumes.  It
provides high availability while also allowing the storage to grow as
needed.  More distributed volumes can simply be added to the filesystem as
needed. 
</p>

<p>
A new type of volume is the dispersed volume, which became available with
Gluster&nbsp;3.6.  It provides RAID&nbsp;5 over the network using <a href="http://en.wikipedia.org/wiki/Erasure_code">erasure coding</a>, which
reduces the amount of storage needed for replication while still providing
redundancy.  It disperses the file's 
data across multiple bricks.  The algorithm used is <a
href="http://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction">Reed-Solomon</a>
with a non-systematic erasure coding.  All of the encoding and decoding is
done on the client side.
</p>

<h4>Access</h4>

<p>
Gluster has multiple mechanisms available for clients to access the data
stored in the filesystem.  The first that was developed is the Filesystem
in Userspace (FUSE) implementation that uses the GlusterFS protocol to
access the data in the bricks.  Much of the functionality in Gluster is
client-based, including replication and erasure coding.  The FUSE filesystem
talks directly to the servers and has built-in failover, so an additional
high-availability solution is not needed.
</p>

<p>
But FUSE is not available on all platforms and it is more mature on Linux
than on other operating systems, so NFSv3 access was added.  Gluster
created its own NFS client in user space that talks NFS to the servers.  In
that model, distribution and replication are done by the servers.
</p>

<p>
A representational state transfer (REST) access method was also created,
which allows access using web protocols.  It uses the <a
href="https://wiki.openstack.org/wiki/Swift">OpenStack Swift</a> object storage
API as its REST interface.  Any combination of access methods can be used
interchangeably; files 
could be created using FUSE, then accessed via REST, for example.
</p>

<p>
For those wanting to do data analysis using the data in a Gluster
filesystem, there is a Hadoop Distributed File System (HDFS) support.
Hadoop worker processes are run on the bricks and use FUSE to access the
data on that server.
</p>

<p>
There is also a <tt>libgfapi</tt> that applications can use to bypass the
other access methods and talk to Gluster directly.  It is good for workloads
that are sensitive to context switches or copies from and to kernel space.
Integration with the <a
href="https://github.com/nfs-ganesha/nfs-ganesha/wiki">NFS-Ganesha</a>
user-space NFS server is done using <tt>libgfapi</tt>.  That allows using
NFSv4 or Parallel NFS (pNFS) for Gluster file access.  SMB is supported in
a similar way.  There is also experimental iSCSI support.
</p>

<h4>Features</h4>

<p>
Beyond being a
scalable storage system that provides elasticity
and quotas, it also provides data protection and recovery features.  Volume
and file-level snapshots are available and those snapshots can be requested directly
by users, which means users won't have to bother administrators to create
them.  Archiving is supported with both read-only volumes and write once
read many (WORM) volumes.
</p>

<p>
For multi-tenancy support, Gluster has encryption for data at rest and
TLS/SSL for its data connections.  For better performance, Gluster does
caching of data, metadata, and directory entries for <tt>readdir()</tt>.
There are built-in I/O statistics and a <tt>/proc</tt>-like interface for
introspection of the filesystem state. 
</p>

<p>
For provisioning servers with Gluster, there is <a
href="https://github.com/purpleidea/puppet-gluster">puppet-gluster</a>.  It
is also
integrated with the <a href="http://www.ovirt.org/Home">oVirt</a>
virtualization manager as well as the <a
href="http://www.nagios.org/">Nagios</a> monitor for servers.  In fact, the sheer
number of open-source projects that Gluster interfaces with is rather eye-opening.
</p>

<h4>Implementation</h4>

<p>
Gluster is implemented as a series of "translators", which are shared
libraries that handle some piece of the functionality.  Translators are
self-contained units that can be stacked to enable multiple features.  For
example, distribution is a translator, as is replication; stacking the two
of them provides the distributed replicated behavior for those types of volumes.
</p>

<p>
Translators can be deployed on the server, client, or both because they are
"deployment agnostic".  There are translators to handle protocols,
performance features (e.g. caching, readahead), statistics gathering,
access control, and so on.  During development, swapping translators in and
out of the stack can usually narrow down problems to a particular
translator for further debugging.
</p>

<p>
A user survey in 2014 showed the main Gluster use cases.  The two biggest
are file synchronization/sharing and virtual machine image storage.  After
those two, backup and web content delivery network (CDN) uses were the next
biggest, though other uses, especially for media files, also showed up in
the survey.
</p>

<h4>Future</h4>

<p>
Gluster&nbsp;3.5 was released in April&nbsp;2014, followed by 3.6 in
October&nbsp;2014.  The next release, 3.7, is currently in development and
is planned for release in April&nbsp;2015.  The project is moving to a model
with two major releases per year, Bellur said.
</p>

<p>
New features coming in 3.7 include "data tiering", which is a way to
provide policies for moving data to and from hot and cold storage tiers
based on access patterns.  For example, the hot tier could consist of SSD
storage while the cold tier is on spinning disks.
</p>

<p>
Bitrot detection is another feature bound for 3.7.  The idea is to detect
corruption while the data is at rest.  A checksum is added to each object
asynchronously and will be checked during periodic data scrubbing
operations.  Bitrot will also be detected when files are accessed.
</p>

<p>
A new sharding volume type is being added.  Those volumes will split the
data in files across multiple bricks.  It will help reduce fragmentation in
Gluster volumes as well as provide more parallelism for large-file workloads.
</p>

<p>
The netgroups feature that was developed at Facebook will appear in 3.7.  It adds a
more advanced configuration and authentication interface for NFS that is similar to
<tt>/etc/exports</tt>.  The patches were forward-ported from
Gluster&nbsp;3.4 for the upcoming release.  
</p>

<p>
There are improvements to the support for NFS-Ganesha coming too, including
high-availability support based on <a href="http://clusterlabs.org/">Pacemaker</a>.  Many
performance improvements have been made, especially for small-file
workloads.  There is a TrashCan translator being added to protect from "fat
finger" deletions and truncations.  It also will capture deletions from
system operations like self-healing (automatically resolving
synchronization problems) and rebalancing (shuffling files around the
bricks when new storage is added to the filesystem).  
</p>

<p>
Another replication mode, arbiter replication, will keep two copies of the
data and three copies of the metadata.  The third metadata copy can be used
to arbitrate in a "split-brain" scenario, where the two file copies get out of
sync.  In addition, administrative policies to resolve split-brains are
coming in 3.7.  The current behavior is to simply return an <tt>EIO</tt> for
those files, but users will now be able to view the file versions and resolve
the split-brain.
There is a laundry list of other improvements coming in 3.7, including the
inevitable "loads of bug fixes".
</p>

<p>
For releases beyond 3.7, the project is looking at a number of different
features, including compression of data at rest and deduplication.  A
translator that provides overlay functionality is in the idea stage.  REST
interfaces for Gluster management are being planned, as is more integration
with OpenStack and containers. 
</p>

<p>
Gluster nodes that can also provide virtualization are on the
horizon as well.  This "hyperconvergence" is based on oVirt and KVM.  There are
also plans for a native Gluster driver for <a
href="https://wiki.openstack.org/wiki/Manila">OpenStack Manila</a>, which
will provide "filesharing as a service" capabilities.
</p>

<p>
There is a long way to go before it gets there, but the project is already
thinking about Gluster&nbsp;4.0, Bellur said.  The key things that will be
addressed in that release are features meant to make the filesystem able to
scale to larger systems. 
Currently there are limitations in the management framework that stop
Gluster filesystems from growing beyond a certain size.  Supporting a
thousand nodes or more is part of those plans.
</p>

<p>
Beyond those features, the project would like to support heterogeneous
environments better.  Environments with multiple operating systems, many
different types of storage, and multiple networks are being targeted.
There are also plans to increase the flexibility that deployments have in
choosing replication options, erasure codes, and more.  There is a new
style of replication being looked at, too, which is completely handled by
the servers without clients being involved at all.
</p>

<p>
The feature set for Gluster&nbsp;4.0 is still up in the air, though
implementation of a few key features has already started.  New feature
ideas can still be submitted and there are plans to vote on which features
will be included as part of a Gluster design summit that is tentatively
planned for May&nbsp;2016.
</p>

<p>
In answer to a question from the audience, Bellur gave a comparison between
Gluster and the <a href="http://ceph.com/">Ceph distributed
filesystem</a>.  The architecture of Ceph is quite different than that of
Gluster, since Ceph started as an object store and built file storage on
top of that, while Gluster did the reverse.  Thus file access is more
flexible from Gluster, while object or block access is more flexible from
Ceph.  Gluster may be a better choice for systems that will start
relatively small and
possibly grow from there, while Ceph may be a good choice when the system
is known to need to be huge from the outset.
</p>

<p>
It would seem that the overarching advantage that Gluster provides
is its flexibility in terms of volume types, access methods, and
integration with various other tools.  It certainly appears to be an active
project with lots of interesting plans for the future.
</p>

<p>
[I would like to thank the Linux Foundation for travel support to Boston
for Vault.]<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Filesystems-GlusterFS">Filesystems/GlusterFS</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Vault-2015">Vault/2015</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/637437/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor638002"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">An introduction to GlusterFS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 26, 2015 10:29 UTC (Thu)
                               by <b>exazoid</b> (subscriber, #54198)
                              [<a href="/Articles/638002/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I mainly have two issues with GlusterFS:<br>
<p>
1) GlusterFS was a CA-system (in the CAP-theorem way), which means that availability is favored over consistency (i.e. split-brains are possible). In ceph, which is a CP-system, split-brains are impossible, but the cluster is considered down, if consensus (majority) cannot be reached<br>
<p>
2) Last I checked, it was the *clients* job to do all copies, and "patrolling" is only done when accessing data (i.e. silent bitrot is possible). Ceph on the other hand has the duplication (and re-duplication in case of trouble) as part of the servers. Also in ceph, patrol-reads are a standard feature (and done server-side). <br>
<p>
I thus strongly prefer Ceph, even if I have not affiliation to either.. <br>
<p>
Please correct me, if my understanding is wrong... <br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/638002/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor638057"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">An introduction to GlusterFS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 26, 2015 14:30 UTC (Thu)
                               by <b>droundy</b> (subscriber, #4559)
                              [<a href="/Articles/638057/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I would be interested to hear how usable Gluster is for the simple use case of a dozen computers with a shared home directory (all running Debian).  I currently just use NFS, which is slow and risky and doesn't make good use of available disk space, but is dead simple to set up.  In the past when I have looked at distributed file systems, I have always gone away intimidated out of actually installing one.<br>
<p>
Would Gluster be suitable for this simple use case? Can I try it out without buying additional disks and/or repartitioning any of my current nodes?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/638057/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor638103"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">An introduction to GlusterFS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 26, 2015 18:34 UTC (Thu)
                               by <b>smoogen</b> (subscriber, #97)
                              [<a href="/Articles/638103/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If NFS is slow on your network then any networked filesystem is going to be 'slow' in some form or another. [Say you have 5 systems in your gluster.. all 5 have to talk to the network when changes occur to keep the systems in sync.] Now reads/writes locally will be faster but if you have system A make a change and system B make or see the change the network has to have communicated those changes. If the network is slow and/or congested.. you can get worse performance. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/638103/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor638550"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">An introduction to GlusterFS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 30, 2015 18:40 UTC (Mon)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/638550/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes, but NFS, especially NFSv3, is way slower than it needs to be. The absence of leases in particular almost eliminates local caching, so even a single-process remote scenario has to constantly reload the cache over the network, and that's bound to be far slower than not doing so. How does gluster handle this sort of thing? (I assume it uses something like leases -- everything should, these days.)<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/638550/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor638552"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">An introduction to GlusterFS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 30, 2015 19:12 UTC (Mon)
                               by <b>bfields</b> (subscriber, #19510)
                              [<a href="/Articles/638552/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
"The absence of leases in particular almost eliminates local caching, so even a single-process remote scenario has to constantly reload the cache over the network, and that's bound to be far slower than not doing so."<br>
<p>
Note, in that case it should normally only need to *revalidate* the cache, not throw it out and reload it completely.<br>
<p>
By default on open the NFS client checks some attributes (generally mtime or ctime), and if that doesn't detect a change then it continues to use its existing cache.<br>
<p>
(Even that single query of an attribute can be annoying depending on the workload, one of the reasons leases/delegations can help.)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/638552/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor638748"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">An introduction to GlusterFS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 1, 2015 19:45 UTC (Wed)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/638748/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
True, and I should have been more precise. It incurs a roundtrip, which is what I was noticing. :)<br>
<p>
(This is the same thing that makes fs-cache much less useful on NFS (v3, at least) than I'd hoped it might be.)<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/638748/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor639155"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">An introduction to GlusterFS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 6, 2015 8:52 UTC (Mon)
                               by <b>Tov</b> (subscriber, #61080)
                              [<a href="/Articles/639155/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I am also using NFS for sharing the home directory, but it is very slow/unstable when used via WLAN. Is there a networked filesystem (or other elegant solution), which is designed for intermittent network access?<br>
<p>
Periodic synchronization with unison is a kludge compared to Windows' offline folders.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/639155/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor639159"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">An introduction to GlusterFS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 6, 2015 14:07 UTC (Mon)
                               by <b>mbunkus</b> (subscriber, #87248)
                              [<a href="/Articles/639159/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Periodic synchronization with unison is a kludge compared to Windows' offline folders.</font><br>
<p>
Out of curiosity and because I'm highly interested in file synchronization technologies: what advantages does Microsoft's mechanism have over unison? I use unison a lot but have never used Windows' offline folders.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/639159/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor639272"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">An introduction to GlusterFS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 6, 2015 21:21 UTC (Mon)
                               by <b>Tov</b> (subscriber, #61080)
                              [<a href="/Articles/639272/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The most obvious difference is that unison is just a stand-alone synchronization tool whereas Windows' offline folders is an integrated solution that works more like an offline cache. This means:<br>
<p>
- With unison you will have to manually setup a network share and a separate synchronized folder. With Windows you can just mark folders/files within a network share that shall be "available offline". These files will appear to be always available.<br>
<p>
- With unison you will have to add some scheduler to make periodic synchronization. With Windows changes are synchronized immediately. When the server disappears you can keep working on the offline cached files and when the share reconnects an initial synchronization is automatically initiated.<br>
<p>
- With unison you will normally always work on the synchronized local folder and potentially be working on old data. In Windows you will work directly on the server files, when available. This means less merge conflicts in a multi user environment, as you can see when files are opened by another user.<br>
<p>
I guess a sort of similar solution could be made by some tricky use of unionfs, inotify driven synchronization, automount and mount triggered synchronization. This is above my head though, and I currently just use manually mounting NFS and running unison - which is a kludge.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/639272/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor638464"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">An introduction to GlusterFS</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 30, 2015 7:18 UTC (Mon)
                               by <b>mab</b> (guest, #314)
                              [<a href="/Articles/638464/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
How does this compare to VMWares VSAN?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/638464/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2015, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
