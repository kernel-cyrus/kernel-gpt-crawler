        <!DOCTYPE html>
        <html lang="en">
        <head><title>Sleepable RCU [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/202847/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/203087/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/202847/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Sleepable RCU</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Please consider subscribing to LWN</b>
<p>
Subscriptions are the lifeblood of LWN.net.  If you appreciate this
content and would like to see more of it, your subscription will
help to ensure that LWN continues to thrive.  Please visit
<a href="/Promo/nst-nag1/subscribe">this page</a> to join up and keep LWN on
the net.
</blockquote>
<div class="GAByline">
           <p>October 9, 2006</p>
           <p>This article was contributed by Paul McKenney</p>
           </div>
Classic RCU requires that read-side critical sections obey the same rules
obeyed by the critical sections of pure spinlocks: blocking or sleeping
of any sort is strictly prohibited.
This has frequently been an obstacle to the use of RCU, and
I have received numerous requests for a ``sleepable RCU'' (SRCU) that
permits arbitrary sleeping (or blocking) within RCU read-side critical
sections.
I had previously rejected all such requests as unworkable, since arbitrary
sleeping in RCU read-side could indefinitely extend grace periods, which
in turn could result in arbitrarily large amounts of memory awaiting the
end of a grace period, which finally would result in system hangs due
to memory exhaustion.
After all, any concurrency-control primitive that could result in
system hangs -- even when used correctly - does not deserve to exist.

<P>
However, the realtime kernels that require spinlock critical sections
be preemptible&nbsp;[3] also require that RCU read-side critical
sections be preemptible&nbsp;[2].
Preemptible critical sections in turn require that lock-acquisition
primitives block in order to avoid deadlock,
which in turns means that both RCU's and spinlocks'
critical sections be able to block awaiting a lock.
However, these two forms of sleeping have the special property that
priority boosting and priority inheritance may be used to awaken
the sleeping tasks in short order.

<P>
Nevertheless,
use of RCU in realtime kernels was the first crack in the tablets
of stone on which were inscribed ``RCU read-side critical sections can never
sleep''.
That said, indefinite sleeping, such as blocking waiting for an
incoming TCP connection, is strictly verboten even in realtime kernels.

<P>
<b>Quick Quiz 1</b>: Why is sleeping prohibited within Classic RCU read-side
critical sections?

<P>
<b>Quick Quiz 2</b>:
Why not permit sleeping in Classic RCU read-side critical sections
by eliminating context switch as a quiescent state, leaving user-mode
execution and idle loop as the remaining quiescent states?

<p>
<h2>SRCU Implementation Strategy</h2>

<P>
The primary challenge in designing an SRCU
is to prevent any given task sleeping in an RCU read-side
critical section from preventing an unbounded number of RCU callbacks.
SRCU uses two strategies to achieve this goal:

<OL>
<LI>refusing to provide asynchronous grace-period interfaces,
	such as the Classic RCU's <TT>call_rcu()</TT> API, and
</LI>
<LI>isolating grace-period detection within each subsystem using SRCU.
</LI>
</OL>
The rationale for these strategies are discussed in the following sections.

<p>
<h3>Abolish Asynchronous Grace-Period APIs</h3>

<P>
The problem with the <TT>call_rcu()</TT> API is that a single thread can
generate an arbitrarily large number of blocks of memory awaiting a
grace period, as illustrated by the following:

<P>
<PRE>
    1 while (p = kmalloc(sizeof(*p), GFP_ATOMIC))
    2     call_rcu(&amp;p-&gt;rcu, f);
</PRE>
<P>
In contrast, the analogous code using <TT>synchronize_rcu()</TT> can
have at most a single block of memory per thread awaiting a grace period:

<P>
<PRE>
    1 while (p = kmalloc(sizeof(*p),
    2                    GFP_ATOMIC)) {
    3    synchronize_rcu();
    4    kfree(&amp;p-&gt;rcu, f);
    5 }
</PRE>
<P>
Therefore, SRCU provides an equivalent to <TT>synchronize_rcu()</TT>, but not
to <TT>call_rcu()</TT>.
<p>
<h3>Isolate Grace-Period Detection</h3>

<P>
In Classic RCU, a single read-side critical section could indefinitely
delay <I>all</I> RCU callbacks, for example, as follows:

<P>
<PRE>
    1 /* BUGGY: Do not use!!! */
    2 rcu_read_lock();
    3 schedule_timeout_interruptible(longdelay);
    4 rcu_read_unlock();
</PRE>
<P>
This sort of behavior might be tolerated if RCU were used only within
a single subsystem that was carefully designed to withstand long-term
delay of grace periods.
It is the fact that a single RCU read-side bug in one isolated subsystem can
delay <I>all</I> users of RCU that forced these long-term RCU read-side
delays to be abolished.

<P>
One way around this issue is for grace-period detection to be performed
on a subsystem-by-subsystem basis, so that a lethargic RCU reader will
delay grace periods only within that reader's subsystem.
Since each subsystem can have only a bounded number of memory blocks
awaiting a grace period, and since the number of subsystems is also
presumably bounded, the total amount of memory awaiting a grace period
will also be bounded.
The designer of a given subsystem is responsible for: (1) ensuring that
SRCU read-side sleeping is bounded and (2) limiting the amount of memory
waiting for <TT>synchronize_srcu()</TT>.&nbsp;[1]

<P>
This is precisely the approach that SRCU takes, as described in the
following section.

<p>
<h2>SRCU API and Usage</h2>

<P>
The SRCU API is shown in below.
The following sections describe how to use it.

<P>
<pre>
    int init_srcu_struct(struct srcu_struct *sp);
    void cleanup_srcu_struct(struct srcu_struct *sp)
    int srcu_read_lock(struct srcu_struct *sp);
    void srcu_read_unlock(struct srcu_struct *sp, int idx);
    void synchronize_srcu(struct srcu_struct *sp);
    long srcu_batches_completed(struct srcu_struct *sp);
</pre>


<p>
<h3>Initialization and Cleanup</h3>

<P>
Each subsystem using SRCU must create an
<TT>struct</TT> <TT>srcu_struct</TT>,
either by declaring a variable of this type or by
dynamically allocating the memory, for example, via <TT>kmalloc()</TT>.
Once this structure is in place, it must be initialized via
<TT>init_srcu_struct()</TT>, which returns zero for success or an error
code for failure (for example, upon memory exhaustion).

<P>
If the <TT>struct</TT> <TT>srcu_struct</TT> is dynamically allocated, then
<TT>cleanup_srcu_struct()</TT> must be called before it is freed.
Similarly, if the <TT>struct</TT> <TT>srcu_struct</TT> is a variable declared within
a Linux kernel module, then <TT>cleanup_srcu_struct()</TT> must be called
before the module is unloaded.
Either way, the caller must take care to ensure that all SRCU read-side
critical sections have completed (and that no more will commence) before
calling <TT>cleanup_srcu_struct()</TT>.
One way to accomplish this is described below.


<p>
<h3>Read-Side Primitives</h3>

<P>
The read-side <TT>srcu_read_lock()</TT> and <TT>srcu_read_unlock()</TT> primitives
are used as shown:

<P>
<PRE>
    1 idx = srcu_read_lock(&amp;ss);
    2 /* read-side critical section. */
    3 srcu_read_unlock(&amp;ss, idx);
</PRE>
<P>
The <TT>ss</TT> variable is the <TT>struct</TT> <TT>srcu_struct</TT> whose initialization
was described above,
and the <TT>idx</TT> variable is an integer that in effect tells
<TT>srcu_read_unlock()</TT> the grace period during which the corresponding
<TT>srcu_read_lock()</TT> started.

<P>
This carrying of an index is a departure from the RCU API, which,
when required, stores the equivalent information in the task structure.
However, since a given task could potentially occupy an arbitrarily large
number of nested SRCU read-side critical sections, SRCU cannot
reasonably store this index in the task structure.



<p>
<h3>Update-Side Primitives</h3>

<P>
The <TT>synchronize_srcu()</TT> primitives may be used as shown below:

<P>
<PRE>
    1 list_del_rcu(p);
    2 synchronize_srcu(&amp;ss);
    3 kfree(p);
</PRE>
<P>
As one might expect by analogy with Classic RCU, this primitive blocks
until until after the completion of all SRCU read-side critical sections
that started before the <TT>synchronize_srcu()</TT> started, as shown
in Table&nbsp;1.

<P>
<TABLE>
<tr class="Even"><th></th><th>CPU 0</th><th>CPU 1</th><th>CPU 2</th><th>CPU 3</th></tr>
<tr class="Odd"><td>1</td>
    <td><tt>i0=srcu_read_lock(&amp;s1);</tt></td>
    <td></td>
    <td></td>
    <td><tt>i3=srcu_read_lock(&amp;s2);</tt></td></tr>
<tr class="Even"><td>2</td>
    <td></td>
    <td><tt>synchronize_srcu(&amp;s1);</tt> [enter]</td>
    <td></td>
    <td></td></tr>
<tr class="Odd"><td>3</td>
    <td></td>
    <td></td>
    <td><tt>i3=srcu_read_lock(&amp;s1);</tt></td>
    <td></td></tr>
<tr class="Even"><td>4</td>
    <td><tt>srcu_read_unlock(&amp;s1,i0);</tt></td>
    <td></td>
    <td></td>
    <td></td></tr>
<tr class="Odd"><td>5</td>
    <td></td>
    <td><tt>synchronize_srcu(&amp;s1);</tt> [exit]</td>
    <td></td>
    <td></td></tr>
<tr class="Even"><td>6</td>
    <td></td>
    <td></td>
    <td><tt>srcu_read_unlock(&amp;s1,i2);</tt></td>
    <td></td></tr>
<CAPTION><STRONG>Table 1:</STRONG>
SRCU Update and Read-Side Critical Sections</CAPTION>

</table>
<p>
Here, CPU&nbsp;1 need only wait for the completion of CPU&nbsp;0's SRCU read-side
critical section.
It need not wait for the completion of CPU&nbsp;2's SRCU read-side critical
section, because CPU&nbsp;2 did not start this critical section until <I>after</I>
CPU&nbsp;1 began executing <TT>synchronize_srcu()</TT>.
Finally, CPU&nbsp;1's <TT>synchronize_srcu()</TT> need not wait for CPU&nbsp;3's
SRCU read-side critical section, because CPU&nbsp;3 is using <TT>s2</TT> rather
than <TT>s1</TT> as its <TT>struct</TT> <TT>srcu_struct</TT>.
CPU&nbsp;3's SRCU read-side critical section is thus related to a different
set of grace periods than those of CPUs&nbsp;0 and 2.


<P>
The <TT>srcu_batches_completed()</TT> primitive may be used to
monitor the progress of a given <TT>struct</TT> <TT>srcu_struct</TT>'s
grace periods.
This primitive is used in ``torture tests'' that validate SRCU's operation.

<P>



<p>
<h3>Cleaning Up Safely</h3>

<P>
Cleaning up SRCU safely can be a challenge, but fortunately many
uses need not do so.
For example, uses in operating-system kernels that are initialized at
boot time need not be cleaned up.
However, uses within loadable modules must clean up if the corresponding
module is to be safely unloaded.

<P>
In some cases, such as the RCU torture module,
only a small known set of threads are using the
SRCU read-side primitives against a particular <TT>struct</TT> <TT>srcu_struct</TT>.
In these cases, the module-exit code need only kill that set of threads,
wait for them to exit, and then clean up.

<P>
In other cases, for example, for device drivers, any thread in the
system might be using the SRCU read-side primitives.
Although one could apply the method of the previous paragraph, this
ends up being equivalent to a full reboot, which can be unattractive.
The example below shows one way that cleanup
could be accomplished without a reboot.

<P>

<pre>
    1  int readside(void) {
    2      int idx;
    3      rcu_read_lock();
    4	   if (nomoresrcu) {
    5          rcu_read_unlock();
    6	       return -EINVAL;
    7      }
    8	   idx = srcu_read_lock(&amp;ss);
    9	   rcu_read_unlock();
    10	   /* SRCU read-side critical section. */
    11	   srcu_read_unlock(&amp;ss, idx);
    12	   return 0;
    13 }
    14
    15 void cleanup(void)
    16 {
    17     nomoresrcu = 1;
    18     synchronize_rcu();
    19     synchronize_srcu(&amp;ss);
    20     cleanup_srcu_struct(&amp;ss);
    21 }
</pre>



<P>
The <TT>readside()</TT> function overlaps an RCU and an SRCU read-side
critical section, with the former running from lines&nbsp;8-7 and the
latter running from lines 6-9.
The RCU read-side critical section uses pure RCU
to guard the
value of the <TT>nomoresrcu</TT> variable.
If this variable is set, we are cleaning up, and therefore must not enter
the SRCU read-side critical section, so we return <TT>-EINVAL</TT> instead.
On the other hand, if we are not yet cleaning up, we proceed into the
SRCU read-side critical section.

<P>
The <TT>cleanup()</TT> function first sets the <TT>nomoresrcu</TT> variable
on line&nbsp;17, but then must wait for all currently executing RCU read-side
critical sections to complete via the <TT>synchronize_rcu()</TT> primitive
on line&nbsp;19.
Once the <TT>cleanup()</TT> function reaches line&nbsp;19, all calls to
<TT>readside()</TT> that could possibly have seen <TT>nomorersrcu</TT> equal
to zero must have already reached line&nbsp;8, and therefore already must
have entered their SRCU read-side critical section.
All other calls to <TT>readside()</TT> will exit via line&nbsp;6, and will thus
refrain from entering the read-side critical section.

<P>
Therefore, once <TT>cleanup()</TT> completes its call to
<TT>synchronize_srcu()</TT> on line&nbsp;19, all SRCU read-side critical sections
will have completed, and no new ones will be able to start.
It is therefore safe on line&nbsp;20 to call <TT>cleanup_srcu_struct()</TT>to clean up.

<P>


<h2>Implementation</h2>

<P>
This section describes SRCU's data structures, initialization and 
cleanup primitives, read-side primitives, and update-side primitives.

<P>

<h3>Data Structures</h3>

<P>
SRCU's data structures are shown below in source and schematic form.
The <TT>completed</TT> field is a count of the number of grace periods
since the <TT>struct</TT> <TT>srcu</TT> was initialized, and as shown in the
diagram, its low-order bit is used to index the
<TT>struct</TT> <TT>srcu_struct_array</TT>.
The <TT>per_cpu_ref</TT> field points to the array, and the
<TT>mutex</TT> field is used to permit but one <TT>synchronize_srcu()</TT> at
a time to proceed.

<P>

<table>
<tr><td valign="top">
<pre>
 1 struct srcu_struct_array {
 2     int c[2];
 3 };
 4 struct srcu_struct {
 5     int completed;
 6     struct srcu_struct_array *per_cpu_ref;
 7     struct mutex mutex;
 8 };
</pre></td>
<td valign="top">
<img  src="https://static.lwn.net/images/ns/kernel/srcu/img4.png" width=245 height=241>
</td></tr></table>
<P>


<h3>Initialization Implementation</h3>

<P>
SRCU's initialization function, <TT>init_srcu_struct()</TT>, is shown below.
This function simply initializes the fields in the
<TT>struct</TT> <TT>srcu_struct</TT>, returning zero if initialization succeeds
or <TT>-ENOMEM</TT> otherwise.

<P>
<pre>
    1 int init_srcu_struct(struct srcu_struct *sp)
    2 {
    3     sp-&gt;completed = 0;
    4     mutex_init(&amp;sp-&gt;mutex);
    5     sp-&gt;per_cpu_ref =
    6         alloc_percpu(struct srcu_struct_array);
    7     return (sp-&gt;per_cpu_ref ? 0 : -ENOMEM);
    8 }
</pre>


<P>
SRCU's cleanup functions are shown below.
<pre>
    1  int srcu_readers_active_idx(struct srcu_struct *sp,
    2         int idx)
    3  {
    4      int cpu;
    5	   int sum;
    6
    7      sum = 0;
    8	   for_each_possible_cpu(cpu)
    9	       sum += per_cpu_ptr(sp-&gt;per_cpu_ref, cpu)-&gt;c[idx];
    10     return sum;
    11 }
    12
    13 int srcu_readers_active(struct srcu_struct *sp)
    14 {
    15     return srcu_readers_active_idx(sp, 0) +
    16                 srcu_readers_active_idx(sp, 1);
    17 }
    18
    19 void cleanup_srcu_struct(struct srcu_struct *sp)
    20 {
    21     int sum;
    22
    23     sum = srcu_readers_active(sp);
    24	   WARN_ON(sum);
    25	   if (sum != 0)
    26	       return;
    27     free_percpu(sp-&gt;per_cpu_ref);
    28     sp->per_cpu_ref = NULL;
    29 }
</pre>


The main cleanup function, <TT>cleanup_srcu_struct()</TT> is shown
on lines&nbsp;19-29 of this figure, however, it immediately invokes
<TT>srcu_readers_active()</TT>, shown on lines&nbsp;13-17 of this figure,
to verify that there are no readers currently using this
<TT>struct</TT> <TT>srcu_struct</TT>.

<P>
The <TT>srcu_readers_active()</TT> function simply returns the sum of
<TT>srcu_readers_active_idx()</TT> on both possible indexes,
while <TT>srcu_readers_active_idx()</TT>, as shown on lines&nbsp;1-11,
sums up the per-CPU counters corresponding to the specified index,
returning the result.

<P>
If the value returned from <TT>srcu_readers_active()</TT> is non-zero,
then <TT>cleanup_srcu_struct()</TT> issues a warning on line&nbsp;24 and
simply returns on lines&nbsp;25 and 26, declining to destroy a
<TT>struct</TT> <TT>srcu_struct</TT> that is still in use.
Such a warning always indicates a bug, and given that the bug
has been reported, it is better to allow the system to continue
with a modest memory leak than to introduce possible memory corruption.

<P>
Otherwise, <TT>cleanup_srcu_struct()</TT> frees the array of per-CPU
counters and <TT>NULL</TT>s the pointer on lines&nbsp;27 and 28.

<P>


<h3>Read-Side Implementation</h3>

<P>
The code implementing <TT>srcu_read_lock()</TT> is:
<p>
<pre>
    1  int srcu_read_lock(struct srcu_struct *sp)
    2  {
    3      int idx;
    4
    5      preempt_disable();
    6	   idx = sp-&gt;completed &amp; 0x1;
    7	   barrier();
    8	   per_cpu_ptr(sp-&gt;per_cpu_ref,
    9	   smp_processor_id())-&gt;c[idx]++;
    10	   srcu_barrier();
    11	   preempt_enable();
    12	   return idx;
    13 }
</pre>
<p>
This function has been carefully constructed to avoid the
need for memory barriers and atomic instructions.

<P>
Lines&nbsp;5 and 11 disable and re-enable preemption, in order to force
the sequence of code to execute unpreempted on a single CPU.
Line&nbsp;6 picks up the bottom bit of the grace-period counter, which will
be used to select which rank of per-CPU counters is to be used for this
SRCU read-side critical section.
The <TT>barrier()</TT> call on line&nbsp;7 is a directive to the compiler
that ensures that the index is
fetched but once, so that the index used on line&nbsp;9 is the same
one returned on line&nbsp;12.
Lines&nbsp;8-9 increment the selected counter for the current CPU.
Line&nbsp;10 forces subsequent execution to occur <I>after</I>
lines&nbsp;8-9, in order to prevent to misordering of any code
in a non-<TT>CONFIG_PREEMPT</TT> build, but only
from the perspective of an intervening interrupt handler.
However, in a <TT>CONFIG_PREEMPT</TT> kernel, the required
<TT>barrier()</TT> call is embedded in the <TT>preempt_enable()</TT> on line&nbsp;11, so the
<TT>srcu_barrier()</TT> is a no-op in that case.
Finally, line&nbsp;12 returns the index so that it may be passed in to the
corresponding <TT>srcu_read_unlock()</TT>.


<P>
The code for <TT>srcu_read_unlock()</TT> is:
<p>
<pre>
    1 void srcu_read_unlock(struct srcu_struct *sp, int idx)
    2 {
    3     preempt_disable();
    4	  srcu_barrier();
    5	  per_cpu_ptr(sp->per_cpu_ref,
    6                 smp_processor_id())->c[idx]--;
    7     preempt_enable();
    8 }
</pre>
<p>


Again, lines&nbsp;3 and 7 disable and re-enable preemption so that the
whole code sequence executes unpreempted on a single CPU.
In <TT>CONFIG_PREEMPT</TT> kernels, the <TT>preempt_disable()</TT> on line&nbsp;3
contains a <TT>barrier()</TT> primitive, otherwise, the <TT>barrier()</TT>is supplied by line&nbsp;4.
Again, this directive forces the subsequent code to execute after
the critical section from the perspective of intervening
interrupt handlers.
Lines&nbsp;5 and 6 decrement the counter for this CPU, but with the same
index as was used by the corresponding <TT>srcu_read_lock()</TT>.

<P>
The key point is that a given CPU's counters
can be observed by other CPUs only in
cooperation with that CPU's interrupt handlers.
These interrupt handlers are responsible for ensuring that any needed
memory barriers are executed prior to observing the counters.

<P>


<h3>Update-Side Implementation</h3>

<P>
The key point behind SRCU is that <TT>synchronize_sched()</TT> blocks until
all currently-executing preempt-disabled regions of 
code complete.
The <TT>synchronize_srcu()</TT> primitive makes heavy use of this effect,
as can be seen here:
<p>
<pre>
    1  void synchronize_srcu(struct srcu_struct *sp)
    2  {
    3      int idx;
    4
    5      idx = sp-&gt;completed;
    6	   mutex_lock(&amp;sp-&gt;mutex);
    7	   if ((sp-&gt;completed - idx) &gt;= 2) {
    8          mutex_unlock(&amp;sp-&gt;mutex);
    9	       return;
    10     }
    11     synchronize_sched();
    12	   idx = sp-&gt;completed &amp; 0x1;
    13	   sp-&gt;completed++;
    14	   synchronize_sched();
    15	   while (srcu_readers_active_idx(sp, idx))
    16         schedule_timeout_interruptible(1);
    17     synchronize_sched();
    18	   mutex_unlock(&amp;sp-&gt;mutex);
    19 }
</pre>




<P>
Line&nbsp;5 takes a snapshot of the grace-period counter.
Line&nbsp;6 acquires the mutex, and lines&nbsp;7-10 check to see whether
at least two grace periods have elapsed since the snapshot,
and, if so, releases the lock and returns -- in this case, someone
else has done our work for us.
Otherwise, line&nbsp;11 guarantees that any other CPU that sees the
incremented value of the grace period counter in <TT>srcu_read_lock()</TT>also sees any changes made by this CPU prior to entering
<TT>synchronize_srcu()</TT>.
This guarantee is required to make sure that any SRCU read-side
critical sections not blocking the next grace period have seen
any prior changes.

<P>
Line&nbsp;12 fetches the bottom bit of the grace-period counter for later
use as an index into the per-CPU counter arrays, and then line&nbsp;13
increments the grace-period counter.
Line&nbsp;14 then waits for any currently-executing <TT>srcu_read_lock()</TT>to complete, so that by the time that we reach line&nbsp;15, all
extant instances of <TT>srcu_read_lock()</TT> will be using the updated
value from <TT>sp-&gt;completed</TT>.
Therefore, the counters sampled in by <TT>srcu_readers_active_idx()</TT>on line&nbsp;15 are guaranteed to
be monotonically decreasing, so that once their sum reaches zero, it
is guaranteed to stay there.

<P>
However, there are no memory barriers in the <TT>srcu_read_unlock()</TT>primitive, so the CPU is within its rights to reorder the counter
decrement up into the SRCU critical section, so that references to
an SRCU-protected data structure could in effect ``bleed out'' of the
SRCU critical section.
This scenario is addressed by the <TT>synchronize_sched()</TT> on line&nbsp;17,
which blocks until all other CPUs executing in <TT>preempt_disable()</TT>code sequences (such as that in <TT>srcu_read_unlock()</TT>) complete these
sequences.
Because completion of a given <TT>preempt_disable()</TT> code sequence
is observed from the CPU executing that sequence, completion of the
sequence implies completion of any prior SRCU read-side critical section.
Any required memory barriers are supplied by the code making the
observation.

<P>
At this point, it is therefore safe to release the mutex as shown
on line&nbsp;18 and return to the caller, who can now be assured that
all SRCU read-side critical sections sharing the same
<TT>struct</TT> <TT>srcu_struct</TT>will observe any update made prior to the call to <TT>synchronize_srcu()</TT>.

<P>
<b>Quick Quiz 3</b>:Why is it OK to assume that updates separated by
	<TT>synchronize_sched()</TT> will be performed in order?

<P>
<b>Quick Quiz 4</b>: Why must line&nbsp;17 in <TT>synchronize_srcu()</TT>
	precede the release of the mutex on line&nbsp;18?
	What would have to change to permit these two lines to be
	interchanged?
	Would such a change be worthwhile?
	Why or why not?

<P>

<h2>SRCU Summary</h2>

<P>
SRCU provides an RCU-like set of primitives that permit general
sleeping in the SRCU read-side critical sections.
However, it is important to note that SRCU has been used only in
prototype code, though it has passed the RCU torture test.
It will be very interesting to see what use, if any, SRCU sees
in the future.


<h3>Quick Quiz answers</h3>

<b>Quick Quiz 1:</b> Why is sleeping prohibited within Classic RCU read-side
	      critical sections?
<p>
<b>Answer:</b>	      Because sleeping implies a context switch, which in
	      Classic RCU is a quiescent state, and RCU's grace-period
	      detection requires that quiescent states never appear in
	      RCU read-side critical sections.
<p>

<b>Quick Quiz 2:</b> Why not permit sleeping in Classic RCU read-side critical
	      sections by eliminating context switch as a quiescent state,
	      leaving user-mode execution and idle loop as the remaining
	      quiescent states?
<p>
<b>Answer:</b>	      This would mean that a system undergoing heavy kernel-mode
	      execution load (e.g., due to kernel threads) might never
	      complete a grace period, which would cause it to exhaust
	      memory sooner or later.
<p>
<b>Quick Quiz 3:</b> Why is it OK to assume that updates separated by
	      <tt>synchronize_sched()</tt> will be performed in order?
<p>
<b>Answer:</b>	      Because this property is required for the <tt>synchronize_sched()</tt>
	      aspect of RCU to work at all. For example, consider a
	      code sequence that removes an object from a list, invokes
	      <tt>synchronize_sched()</tt>, then frees the object. If this property
	      did not hold, then that object might appear to be freed
	      before it was removed from the list, which is precisely the
	      situation that synchronize_sched() is supposed to prevent!
<p>

<b>Quick Quiz 4</b>: Why must line&nbsp;17 in <TT>synchronize_srcu()</TT>
	precede the release of the mutex on line&nbsp;18?
	What would have to change to permit these two lines to be
	interchanged?
	Would such a change be worthwhile?
	Why or why not?
<p>
<b>Answer:</b>	      Suppose that the order was reversed, and that CPU 0 has just
	      reached line 13 of synchronize_srcu(), while both CPU 1
	      and CPU 2 start executing another synchronize_srcu() each,
	      and CPU 3 starts executing a <tt>srcu_read_lock()</tt>. Suppose that
	      CPU 1 reaches line 6 of <tt>synchronize_srcu()</tt> just before CPU 0
	      increments the counter on line 13. Most importantly, suppose
	      that CPU 3 executes <tt>srcu_read_lock()</tt> out of order with
	      the following SRCU read-side critical section, so that it
	      acquires a reference to some SRCU-protected data structure
	      before CPU 0 increments sp->completed, but executes the
	      <tt>srcu_read_lock()</tt> after CPU 0 does this increment.
<p>
	      Then CPU 0 will not wait for CPU 3 to complete its SRCU
	      read-side critical section before exiting the "while"
	      loop on lines 15-16 and releasing the mutex (remember,
	      the CPU could be reordering the code).
<p>
	      Now suppose that CPU 2 acquires the mutex next, and again
	      increments <tt>sp-&gt;completed</tt>. This CPU will then have to wait
	      for CPU 3 to exit its SRCU read-side critical section
	      before exiting the loop on lines 15-16 and releasing the
	      mutex. But suppose that CPU 3 again executes out of order,
	      completing the <tt>srcu_read_unlock()</tt> prior to executing a
	      final reference to the pointer it obtained when entering
	      the SRCU read-side critical section.
<p>
	      CPU 1 will then acquire the mutex, but see that the
	      <tt>sp-&gt;completed</tt> counter has incremented twice, and therefore
	      take the early exit. The caller might well free up the
	      element that CPU 3 is still referencing (due to CPU 3's
	      out-of-order execution).
<p>
	      To prevent this perhaps improbable, but entirely possible,
	      scenario, the final <tt>synchronize_sched()</tt> must precede
	      the mutex release in <tt>synchronize_srcu()</tt>.	Another
	      approach would be to change to comparison on line 7 of
	      <tt>synchronize_srcu()</tt> to check for at least three increments
	      of the counter. However, such a change would increase the
	      latency of a "bulk update" scenario, where a hash table
	      is being updated or unloaded using multiple threads. In
	      the current code, the latency of the resulting concurrent
	      <tt>synchronize_srcu()</tt> calls would take at most two SRCU grace
	      periods, while with this change, three would be required.
<p>
	      More experience will be required to determine which approach
	      is really better. For one thing, there must first be some
	      use of SRCU with multiple concurrent updaters.
<p>

<h3>Acknowledgements</h3>

<P>
I owe thanks to Oleg Nesterov and Alan Stern for discussions
that helped shape SRCU, and to Josh Triplett for a thorough
and careful review.
I am indebted to Daniel Frye for his support of this effort.

<p>
<h3>Bibliography</h3>

<ol>
<li> McKenney, P.&nbsp;E.
<EM>Exploiting Deferred Destruction: An Analysis of Read-Copy-Update
  Techniques in Operating System Kernels</EM>.
PhD thesis, OGI School of Science and Engineering at Oregon Health
  and Sciences University, 2004.
Available:
  <TT><A NAME="tex2html131"
  HREF="http://www.rdrop.com/users/paulmck/RCU/RCUdissertation.2004.07.14e1.pdf">http://www.rdrop.com/users/paulmck/RCU/RCUdissertation.2004.07.14e1.pdf</A></TT>  [Viewed October 15, 2004].

<p>
<li> McKenney, P.&nbsp;E., and Sarma, D.
Towards hard realtime response from the linux kernel on SMP
  hardware.
In <EM>linux.conf.au 2005</EM> (Canberra, Australia, April 2005).
Available:
  <TT><A NAME="tex2html132"
  HREF="http://www.rdrop.com/users/paulmck/RCU/realtimeRCU.2005.04.23a.pdf">http://www.rdrop.com/users/paulmck/RCU/realtimeRCU.2005.04.23a.pdf</A></TT>  [Viewed May 13, 2005].

<p>
<li> Molnar, I.
Index of /mingo/realtime-preempt.
Available: <TT><A NAME="tex2html133"
  HREF="http://people.redhat.com/mingo/realtime-preempt/">http://people.redhat.com/mingo/realtime-preempt/</A></TT>  [Viewed February 15, 2005], February 2005.
</ol><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Read-copy-update">Read-copy-update</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#McKenney_Paul_E.">McKenney, Paul E.</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/202847/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor204148"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Sleepable RCU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 12, 2006 19:00 UTC (Thu)
                               by <b>HappyCamp</b> (guest, #29230)
                              [<a href="/Articles/204148/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      Just a thought.  But wouldn't it be wise to define the acronyms that you use in the article.  It starts out talking about RCU but doesn't define the term.<br>
<p>
I figured out it stood for Read Copy Update.  Seems like it would have been easy enough to entitle the article: "Sleepable Read Copy Update" :)<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/204148/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor204191"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Definition of RCU needed</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 12, 2006 23:48 UTC (Thu)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/204191/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      Does "Read Copy Update" mean something to you?  I don't think it says any more than "RCU."  In fact, since I know what RCU is, I would have needed the text to explain that "Read Copy Update" means RCU.  A couple of sentences definining RCU are definitely called for, but the etymology of the acronym alone would be pretty useless.

      
          <div class="CommentReplyButton">
            <form action="/Articles/204191/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor204329"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Definition of RCU needed</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 14, 2006 14:45 UTC (Sat)
                               by <b>kevinbsmith</b> (guest, #4778)
                              [<a href="/Articles/204329/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      "Does 'Read Copy Update' mean something to you?"<br>
<p>
Yes. I have heard the term before, but didn't immediately think of it when I saw RCU. I had the same reaction as the parent poster ("What the #$#$ is RCU?". If the article had started "Classic RCU (Read-Copy-Update) requires that..." I would not have had that reaction.<br>
<p>
LWN is usually excellent about this. It's one of the few places where release announcements for software packages regularly include a brief summary of what the FooBar package actually does. That's one reason this RCU case really jumped out.<br>
<p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/204329/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor204355"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Definition of RCU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 14, 2006 22:03 UTC (Sat)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/204355/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      My apologies for leaving out this definition!!!
<P>
RCU does indeed stand for read-copy update.  The name comes from the fact that <B>readers</B> continue to freely access the data structures even while another thread is making and substituting a <B>copy</B> in order to <B>update</B>.  More information may be found at:
<UL>
<LI>  <A HREF="http://lwn.net/Articles/37889/">http://lwn.net/Articles/37889/</A> (though from 2003, guess I need to get Jon an update...) -- and Jon has written quite a bit about RCU, as you can see from Googling "read copy update site:lwn.net".
<LI>  <A HREF="http://en.wikipedia.org/wiki/RCU">http://en.wikipedia.org/wiki/RCU</A> (I update this, so please let me know if you find bugs.)
<LI>  <A HREF="http://www.rdrop.com/users/paulmck/RCU/">http://www.rdrop.com/users/paulmck/RCU/</A>
</UL>
      
          <div class="CommentReplyButton">
            <form action="/Articles/204355/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor204422"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Definition of RCU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 16, 2006 4:19 UTC (Mon)
                               by <b>xoddam</b> (guest, #2322)
                              [<a href="/Articles/204422/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <font class="QuotedText">&gt; <a href="http://en.wikipedia.org/wiki/RCU">http://en.wikipedia.org/wiki/RCU</a></font><br>
<font class="QuotedText">&gt; (I update this, so please let me know if you find bugs.) </font><br>
<p>
Presumably you update a copy whilst we read the previous version :-)<br>
<p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/204422/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor204432"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Updating wikipedia</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 16, 2006 13:12 UTC (Mon)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/204432/">Link</a>] 
      </p>
      
      </div>
      </summary>
      ;-)  ;-)  ;-)<br>
<p>
But as near as I can tell, that is exactly what happens.  Although I have no idea what algorithm wikis use to accomplish this.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/204432/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor208237"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Sleepable RCU - A further correction in Cleaning Up Safely Section:</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 8, 2006 6:09 UTC (Wed)
                               by <b>ds2horner</b> (subscriber, #13438)
                              [<a href="/Articles/208237/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      In the Cleaning Up Safely Section<br>
<p>
"The readside() function overlaps an RCU and an SRCU read-side critical section, with the former running from lines 8-7 and the latter running from lines 6-9."<br>
<p>
I believe references this code:<br>
    1  int readside(void) {<br>
    2      int idx;<br>
    3      rcu_read_lock();<br>
    4	   if (nomoresrcu) {<br>
    5          rcu_read_unlock();<br>
    6	       return -EINVAL;<br>
    7      }<br>
    8	   idx = srcu_read_lock(&amp;ss);<br>
    9	   rcu_read_unlock();<br>
    10	   /* SRCU read-side critical section. */<br>
    11	   srcu_read_unlock(&amp;ss, idx);<br>
    12	   return 0;<br>
    13 }<br>
<p>
I believe the correct references should be :<br>
<p>
"The readside() function overlaps an RCU and an SRCU read-side critical section, with the former running from lines 8-_11_ and the latter running from lines _5_-9."<br>
<p>
If I got this wrong, I _really_ am confused.<br>
<p>
Thanks for the wonderful artice, and the great work!<br>
<p>
<p>
 <br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/208237/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor220369"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Sleepable RCU - A further correction in Cleaning Up Safely Section:</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 2, 2007 18:40 UTC (Fri)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/220369/">Link</a>] 
      </p>
      
      </div>
      </summary>
      You are abolutely correct -- I guess I need to get my eyes checked!  :-/<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/220369/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor322345"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Sleepable RCU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 9, 2009 13:42 UTC (Mon)
                               by <b>dvyukov</b> (subscriber, #57055)
                              [<a href="/Articles/322345/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Hi Paul,<br>
<p>
I am curious as to why you allow only single outstanding SRCU callback per thread. The problem with RCU is that it allows basically unbounded number of outstanding callbacks, so why just not bound number of outstanding callbacks in SRCU? Memory blocks are frequently quite small, so that subsystem can tolerate up to let's say 1000 pending memory blocks. Restriction on single pending callback looks quite severe (may cause unnecessary blocking), why not provide:<br>
int init_srcu_struct(struct srcu_struct *sp, int limit_of_pending_callbacks);<br>
?<br>
While limit is not reached synchronize_srcu() is non blocking, otherwise it waits for grace period. I think in many situation it will make synchronize_srcu() practically non-blocking.<br>
Or it's just not worth doing (because of the additional implementation complexity)?<br>
<p>
<p>
One more question (it does not directly relates to SRCU, but I remember you were providing some computations regarding required number of grace periods somewhere, I hope I am not mixing up your reasoning now).<br>
You are removing all memory fences from reader side, including release fence in read_unlock(). In order to compensate this you are waiting for additional grace periods before executing callbacks. But on some architectures (IA-32, Intel 64, SPARC TSO) release fence is implied with every store, so isn't it possible to reduce the number of required grace periods before executing callbacks on these architectures?<br>
I.e. something like:<br>
#ifdef ACQUIRE_RELEASE_FENCES_ARE_IMPLIED_ON_ARCH // defined for x86 etc<br>
#define NUMBER_OF_GRACE_PERIODS_BEFORE_EXECUTING_CALLBACKS 2<br>
#else<br>
#define NUMBER_OF_GRACE_PERIODS_BEFORE_EXECUTING_CALLBACKS 4<br>
#endif<br>
Have you considered such variant? Is it worth doing?<br>
<p>
Thank you.<br>
<p>
--<br>
Dmitriy V'jukov<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/322345/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor337727"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Sleepable RCU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 17, 2009 17:37 UTC (Wed)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/337727/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Hello, Dmitriy!<br>
<p>
Sorry for the delay, but I don't receive email notification of new top-level comments, and so I just now saw your comment.<br>
<p>
Your suggestion is quite reasonable, and perhaps someday something similar will be implemented.  However, none of the people using or thinking of using SRCU (at least none that I am aware of) need more than one callback per thread.  One way that they can get the effect with the current API is to remove a number of items in one pass, use one synchronize_srcu() to wait, then free up the items.<br>
<p>
I did submit a patch in late 2006 that reduced the number of synchronize_sched() calls in synchronize_srcu() at the expense of barriers on the read side: <a href="http://lkml.org/lkml/2006/11/17/359">http://lkml.org/lkml/2006/11/17/359</a>, but the speedup was insufficient, so Oleg Nesterov did QRCU instead.  :-)<br>
<p>
I would expect that SRCU might get more attention as it becomes more heavily used, and people have additional things that they need it to do.  RCU has always been very usage-driven: <a href="http://doi.acm.org/10.1145/1400097.1400099">http://doi.acm.org/10.1145/1400097.1400099</a><br>
<p>
                                               Thanx, Paul<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/337727/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor616567"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Sleepable RCU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 17, 2014 5:30 UTC (Fri)
                               by <b>juihaochiang</b> (guest, #84945)
                              [<a href="/Articles/616567/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Hi, Paul:<br>
<p>
I am pretty new to RCU and have question about synchronize_srcu implementation.<br>
In line 11, the description says "line 11 guarantees that any other CPU that sees the incremented value of the grace period counter in srcu_read_lock() also sees any changes made by this CPU prior to entering synchronize_srcu(). This guarantee is required to make sure that any SRCU read-side critical sections not blocking the next grace period have seen any prior changes."<br>
<p>
[question] Assume the grace-period (gp) increments from 0 -&gt; 1, if the reader can see the incremented counter (gp = 1), it should already see any change prior to synchronize_srcu, e.g., item removed from list, then why do we need to call synchronize_sched to make sure about it? could you give an counter-example?<br>
<p>
Thanks,<br>
Jui-Hao<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/616567/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor647503"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Sleepable RCU</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 8, 2015 17:47 UTC (Mon)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/647503/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Hello, Jui-Hao,

<p>
Suppose we have the following sequence of events:

<ol>
<li> Task&nbsp;A does <code>srcu_read_lock()</code> and then picks up a pointer to an RCU -protected data element.
<li> Task&nbsp;B removes that same data element from the list.
<li> (Task&nbsp;B is supposed to do <code>synchronize_srcu()</code> here, but let's assume that it fails to do so.)
<li> Task&nbsp;B frees that data element&mdash;while Task&nbsp;A is still using it.  Chaos ensues.
</ol>

So that <code>synchronize_srcu()</code> really is needed!  Please do not leave it out.

<p>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Thanx, Paul
      
          <div class="CommentReplyButton">
            <form action="/Articles/647503/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2006, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
