        <!DOCTYPE html>
        <html lang="en">
        <head><title>The Linaro Connect scheduler minisummit [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/482344/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/481904/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/482344/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>The Linaro Connect scheduler minisummit</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>We're bad at marketing</b>
<p>
We can admit it, marketing is not our strong suit. Our strength is
writing the kind of articles that developers, administrators, and
free-software supporters depend on to know what is going on in the
Linux world. Please <a href="/Promo/nsn-bad/subscribe">subscribe today</a> to help us keep doing that, and so
we don’t have to get good at marketing.
</blockquote>
<div class="GAByline">
           <p>February 22, 2012</p>
           <p>This article was contributed by Paul McKenney</p>
           </div>
<p>I had the privilege of acting as moderator/secretary for the recent
Scheduler Mini-Summit at Linaro Connect, which was attended by
Peter Zijlstra (Red Hat),
Paul Turner (Google),
Suresh Siddha (Intel),
Venki Pallipadi (Google),
Robin Randhawa (ARM),
Rob Lee (Freescale assigned to Linaro),
Vincent Guittot (ST-Ericsson assigned to Linaro),
Kevin Hilman (TI),
Mike Turquette (TI assigned to Linaro),
Peter De Schrijver (Nvidia),
Paul Brett (Intel),
Steve Muckle (Qualcomm),
Sven-Thorsten Dietrich (Huawei),
and was ably organized by Amit Kucheria (Linaro).
Rough notes from the session can be found
<a href="https://wiki.linaro.org/WorkingGroups/PowerManagement/Doc/HMPscheduling">here</a>.

<p>The main goals of the mini-summit were as follows:

<ol>
<li>	Take first step towards planning any Linux-kernel scheduler
	changes that might be needed for ARM's
	upcoming
	<a
	href="http://www.arm.com/files/downloads/big.LITTLE_Final.pdf">big.LITTLE
	[PDF]</a> 
	systems to work well (see also
	<a href="http://lwn.net/Articles/481055/">Nicolas Pitre's
	LWN article</a>).
<p>
<li>	Create a power-aware infrastructure for scheduling and related
	Linux kernel subsystems.
	For example, integrate dyntick-idle,
	cpufreq, cpuidle, <a href="/Articles/474915/">sched_mc</a>, timers,
	thermal framework, pm_qos, 
	and the scheduler.
<p>
<li>	Provide a usable mechanism that reliably allows all work (present
	and future) to be moved off of a CPU so that said CPU can
	be powered off and back on under user-application control.
	CPU hotplug is used for this today, but has some serious side
	effects, so it would be good to either fix CPU hotplug or come
	up with a better mechanism&mdash;or, in the best Linux-kernel
	tradition, both.
	Such a mechanism might also be useful to the real-time people,
	who also need to clear <i>all</i> non-real-time activity from
	a given CPU.
</ol>

<p>How well did we meet these goals?
Read on and decide yourself!
To that end, the remainder of this article is organized as follows:

<ol>
<li>	<a href="#Overview of ARM big.LITTLE Systems">
	Overview of ARM big.LITTLE Systems</a>
<li>	<a href="#Major Issues Considered">
	Major Issues Considered</a>
<li>	<a href="#Future Work and Prospects">
	Future Work and Prospects</a>
<li>	<a href="#Conclusions">
	Conclusions</a>
</ol>

<p>Following this is the inevitable
<a href="#Answers to Quick Quizzes">Answers to Quick Quizzes</a>.
<p>

<h3><a name="Overview of ARM big.LITTLE Systems">
Overview of ARM big.LITTLE Systems</a></h3>

<p>ARM's big.LITTLE systems combine the
<a href="http://www.arm.com/products/processors/cortex-a/cortex-a7.php">Cortex-A7</a>
and
<a href="http://www.arm.com/products/processors/cortex-a/cortex-a15.php">Cortex-A15</a>
processors.
Both processors are implementations of the ARMv7
architecture and they execute the same code.
ARM stated the
little Cortex-A7 design was focused on energy efficiency at the expense of
performance. 
The bigger Cortex-A15 design was, instead, focused
on performance at some cost to energy efficiency.
In practice
this means the little core will be somewhat quicker and a lot
more power efficient than today's Cortex-A8: a multi-core
configuration of these little cores could run today's smartphones.
The big core will
significantly outperform Cortex-A9 within a similar power budget.

<p>

<div class="tlr"><a name="Quick Quiz 1"><b>Quick Quiz 1</b>:</a>
But what if there is a different number of Cortex-A7s than of Cortex-A15s?
<a href="#aqq1">Answer</a>
</div>

One way to use a big.LITTLE system is to have equal numbers of
Cortex-A7 and Cortex-A15 CPUs paired up, so that only one CPU
of a given pair is running at a time.
This pairing is &ldquo;a
continuation of dynamic voltage/frequency scaling by other
means&rdquo;.
To see this, imagine the Cortex-A15 initially running
at maximum clock frequency, with the voltage and frequency
decreasing until the performance is barely greater than that of
the Cortex-A7 CPU.
At this point, the firmware switches the
software context from the Cortex-A15 to the Cortex-A7, with the
Cortex-A7 initially running at its maximum clock frequency, but
at lower power than the Cortex-A15.

<div class="tlr"><a name="Quick Quiz 2"><b>Quick Quiz 2</b>:</a>
Why scale down?
Isn't it always better to run full out in order to race to idle?
<a href="#aqq2">Answer</a>
</div>

The voltage and frequency of
the Cortex-A7 can then be further decreased, in turn further
decreasing the power consumption.
<p>
For some implementations,
thermal limitations would require that the Cortex-A15 CPUs be
used only for short bursts at maximum frequency, as was discussed at
length at the summit.
However, I have since learned that many
other implementations are expected to be fully capable of running
the Cortex-A15 CPUs at maximum frequency indefinitely.

<p>The switch between the Cortex-A7 and Cortex-A15 CPUs is implemented
in firmware, but Grant Likely, Nicolas Pitre, and Dave Martin are
moving this functionality into the Linux kernel.

<p>In many big.LITTLE designs, it is also possible to run both the
Cortex-A7 and Cortex-A15 CPUs concurrently in an shared-memory configuration.
However, this means that the Linux kernel sees the big.LITTLE
architecture, which in turn raises the issues discussed in the
next section.

<h3><a name="Major Issues Considered">
Major Issues Considered</a></h3>

<p>Those of you who know the personalities in attendance will not be
surprised to hear that the discussions were both spirited and wide-ranging.
However, most of the discussion centered around the following four
major issues:

<ol>
<li>	<a href="#Benchmarks and Synthetic Workloads">
	Benchmarks and Synthetic Workloads</a>
<li>	<a href="#Parallel Hardware/Software Development">
	Parallel Hardware/Software Development</a>
<li>	<a href="#What Do You Do With a LITTLE CPU?">
	What Do You Do With a LITTLE CPU?</a>
<li>	<a href="#CPU Hotplug: Kill It or Cure It?">
	CPU Hotplug: Kill It or Cure It?</a>
</ol>

<p>Each of these issues is covered in one of the following sections:

<h4><a name="Benchmarks and Synthetic Workloads">
Benchmarks and Synthetic Workloads</a></h4>

<p>The biggest and most pressing issue facing SMP-style big.LITTLE
systems is the lack of packaged Linux-kernel-developer-friendly
benchmarks and synthetic workloads.
C&nbsp;programs and <code>sh</code>, <code>perl</code>, and <code>python</code>
scripts can be friendly to Linux-kernel developers, while benchmarks
requiring (for example) an Android SDK or a specific device
will likely be actively ignored.

<p>It is critically important for benchmarks to provide a useful
&ldquo;figure of merit&rdquo;, which should encompass both
user experience and estimated power consumption.
For example, a synthetic workload that models a user browsing the
web on a smartphone might have a smaller-is-better estimate of
average power consumption, but also have the constraint that
the system respond to emulated browser actions within (say)
500ms.
If the response time is within the 500ms constraint,
then the figure of merit is the estimated average power consumption,
but if that constraint is exceeded, the figure of merit is a
very large number.
The exact computation of the figure of merit will vary from
benchmark to benchmark.

<p>Currently, some rough and ready workloads are in use.
For example, Vincent Guittot used cyclic test in
<a href="https://wiki.linaro.org/WorkingGroups/PowerManagement/Doc/Hotplug">his work</a>.
While this did get the job done for Vincent, something more adapted
to embedded/mobile workloads instead of real-time computing would
be quite welcome.
Zach Pfeffer of Linaro will be doing some workload creation in his group,
however, given the wide variety of mobile and embedded workloads, additional
contributions would also be welcome.

<p>Finally, the scheduler maintains a great number of statistics and
tracepoints.
A &ldquo;schedtop&rdquo;-style tool that provides a mobile/embedded
view of this information would be very valuable.

<h4><a name="Parallel Hardware/Software Development">
Parallel Hardware/Software Development</a></h4>

<p>Even if you don't know exactly when a given piece of hardware will
be available, it is a good bet that it will become available too late
to get the needed software running on it.
It is therefore critically important to have some way to develop the
needed software <i>before</i> the hardware is available.
Thankfully, there are a number of ways to test big.LITTLE scheduler
features before big.LITTLE hardware becomes available.

<p>One crude but portable method is to create a <code>SCHED_FIFO</code>
thread on each LITTLE-designated CPU, and to have this thread spin,
burning CPU, for (say) one millisecond out of every two milliseconds.
This approach perturbs the scheduler's preemption points, particularly the
wake-up preemptions.
Nevertheless, this approach is likely to be quite useful.

<p>A less portable but more accurate approach is to constrain the
clock frequency of the CPUs so that the big-designated CPUs have a lower
bound on their frequency and the LITTLE-designated CPUs have an upper
bound on their frequency.
The way to do this is via the <code>sysfs</code> files in the
<code>/sys/devices/system/cpu/cpu*/cpufreq</code> directories,
the most pertinent of which are described below.
<p>
<div class="tlrw">
<a name="Quick Quiz 3"><b>Quick Quiz 3</b>:</a>
I typed the following commands:
<pre>
  cd /sys/devices/system/cpu/cpu1/cpufreq
  sudo echo 800000 &gt; scaling_max_freq
</pre>
Despite the <code>sudo</code>, I got &ldquo;Permission denied&rdquo;.
Why doesn't <code>sudo</code> give me sufficient permissions?
<a href="#aqq3">Answer</a>
</div>

Echoing a number into the <code>scaling_max_freq</code>
file will require that the corresponding CPU's frequency
be limited to the specified number in KHz.
Echoing a number into the
<code>scaling_min_freq</code>
file will require that the corresponding CPU's frequency
be at least the specified number in KHz.
Reading the
<code>scaling_available_frequencies</code>
file
will list out the frequencies (again in KHz) that the
corresponding CPU is capable of running at.
For example, the laptop I am typing on gives the following
list:
<pre>
    2534000 2533000 1600000 800000
</pre>
Reading the
<code>affected_cpus</code>
file lists the CPUs whose
core clock frequencies must move in lockstep with the
corresponding CPU.
On my laptop, each CPU's frequency may be varied independently,
but it is not unusual for a given &ldquo;clock domain&rdquo;
to contain multiple CPUs, which then must all run at the
same frequency, for example, on systems with hardware threads.
Reading the
<code>scaling_cur_freq</code>
file gives you the kernel's
opinion on what frequency the corresponding CPU is running at.
Reading the
<code>cpuinfo_cur_freq</code>
file, instead, gives you the hardware's
opinion on what frequency that the corresponding CPU is
running at,
which might or might not match the kernel's opinion, so
you should most definitely experiment to make sure that
all of this is doing what you want on your particular hardware
and kernel.

<p>For more information, see <code>Documentation/cpu-freq</code>
in the Linux kernel source directory.

<p>There was also some discussion of ways that the <code>linsched</code>
user-mode scheduler simulator might help with prototyping.

<p>Finally, it is possible to use T-states on Intel platforms to emulate
a big.LITTLE system.
According to Paul Brett:
<p>
<div class="BigQuote">
	Intel Architecture processors provide a clock modulation
	control exposed as the MSR_IA32_THERM_CONTROL MSR.
	This MSR can be used to reduce the effective clock
	frequency for each core independently in 12.5% increments
	from 100% down to 12.5%.  Under normal conditions,
	the least significant 5 bits of the MSR are cleared to
	indicate 100% performance.  To enable clock modulation,
	set bit 4 of this MSR to 1 and write a value from 1-7 in
	bits 1-3 (where 7 is 87.5% equivalent performance and 1
	is 12.5% equivalent performance).  More information on
	clock modulation can be found in volume 3 of the Intel
	IA64/IA32 Software Developers Manual, under Thermal
	Monitoring and Protection.  Please note that the effect
	of clock modulation approximates running the CPU at a
	lower frequency - in benchmarks we have noted up to a 5%
	variance in performance between clock modulation and
	running the same core at the equivalent frequency.
</div>
<p>
<div class="tlrw">
<p><a name="Quick Quiz 4"><b>Quick Quiz 4</b>:</a>
Why would anyone use an Intel system to test out an ARM capability?
<a href="#aqq4">Answer</a>
</div>

Although none of these approaches can be considered a perfect substitute
for running on the actual big.LITTLE hardware, they are all likely to be
very useful during the time until such hardware is actually available.

<h4><a name="What Do You Do With a LITTLE CPU?">
What Do You Do With a LITTLE CPU?</a></h4>

<p>If you have both big and LITTLE CPUs, how do you decide what tasks
will be banished to the slower LITTLE CPUs?
Similarly, if your workload is currently running all on LITTLE CPUs,
how do you decide when to take the step of starting up one of the
the power-hungry big CPUs?

<p>Right now for SMP-configured big.LITTLE systems, &ldquo;you&rdquo;
is the application developer, who can use
facilities such as CPU hotplug, affinity, cpusets, sched_mc, and so on
to manually direct the available work to the desired subsets of the CPUs.
These facilities constrain the scheduler in order to ensure that nothing
runs on CPUs that are to be powered down.

<p>Decisions on what CPUs to use should include a number of considerations.
First, if a LITTLE CPU is able to provide sufficient performance,
it provides better energy efficiency, at least in cases where
race to idle is inappropriate.
Second, because mobile platforms have no fans and are sometimes sealed,
some devices might not be able to run all the big CPUs at maximum
clock rate for very long without overheating.
Of course, such devices might also need to limit the heat produced
by analog electronics and GPUs as well (see Carroll's and Heiser's
2010 
<a
href="http://www.ssrg.nicta.com.au/publications/papers/Carroll_Heiser_10.pdf">USENIX
paper [PDF]</a>
and
<a
href="http://static.usenix.org/event/atc10/tech/slides/carroll.pdf">presentation
[PDF]</a>
for a power-consumption analysis of a ca.&nbsp;2008 smartphone).
Third, some workloads can adapt themselves to lower performance.
For example, some media applications can reduce performance
requirements by dropping frames and reducing resolution.
Fourth, there is more to performance than CPU clock speed: For example,
it is possible that a workload with high cache-miss rates can
run just as fast on a LITTLE CPU as it can on a big CPU.
Finally, many workloads will have preferred ways of using the CPUs,
for example, some mobile workloads might use the LITTLE CPUs
most of the time, but bring the big CPUs online for short bursts
of intense processing.

<p>Keeping track of all this can be challenging, which is one big reason
for thinking in terms of automated assistance from the scheduler.
Some of the proposed work towards this end is listed in the
<a href="#Future Work and Prospects">Future Work and Prospects</a>
section.
But first, let's take a closer look at CPU hotplug and its potential
replacements.

<h4><a name="CPU Hotplug: Kill It or Cure It?">
CPU Hotplug: Kill It or Cure It?</a></h4>

<p>Although CPU hotplug has a checkered reputation in many circles, it
is what almost all current multicore devices actually use to evacuate
work from a given CPU.
This is a bit surprising given that CPU hotplug was intended for
infrequently removing failing CPUs, not for quickly bringing perfectly
good CPUs into and out of service.
It is therefore well worth asking what CPU hotplug is providing that users
cannot get from other mechanisms:

<ul>
<li>	Migrating timers off of a given CPU.  This can likely be fixed,
	but a synchronous fix that prevents any further timers from being
	set may be more challenging.
<p>
<li>	Shutting off a CPU with a single simple action.
	This can likely be fixed, but requires coordinating interrupts,
	the scheduler, timers, kthreads, and so on.
<p>
<li>	Preventing all possible wakeup events from causing that
	CPU to power back on until the user explicitly permits
	it to power back on.
	(Some platforms may have wakeup events that cannot be shut off.)
<p>
<li>	Synchronous action, so that userspace can treat it atomically.
<p>
<li>	Coordinating user applications based on
	hotplug events.
	(However, there is no known embedded or mobile use of this
	feature, so if you need it, please let us know.
	Otherwise it will likely go away.)
</ul>

<p>These CPU-hotplug features are valuable outside of the mobile/embedded
space, for example, some real-time applications will take a CPU offline
and then immediately bring it back online to make it fully available
for the application&mdash;in particular, to clear timers off of the CPU.
Furthermore, people really do make use of CPU hotplug to offline failing
CPUs.

<p>But this brings up another question.
Given that CPU hotplug does all these useful things, what is not to like?
First, CPU-hotplug operations can take several seconds, as shown
<a href="https://wiki.linaro.org/WorkingGroups/PowerManagement/Doc/Hotplug">here</a>.
An ideal power-management mechanism would have latencies in the
5ms range.
It might be possible to make CPU hotplug run much faster.
Second, CPU-hotplug offline operations use the <tt>stop_machine()</tt> facility,
which interrupts each and every CPU for an extended time period.
This sort of behavior is not acceptable when certain types
of real-time or high-performance-computing (HPC) applications are running.
It might be possible to wean CPU hotplug from <tt>stop_machine()</tt>.

<p>Third, a given CPU's workqueues can contain large numbers of pending
items of work, and migrating all of these can be quite time
consuming, as can re-initializing all the workqueue kernel threads
when a given CPU comes online.
Other CPU-hotplug notifiers have similar problems, which can
hopefully be addressed by coming up with a good low-overhead
way to &ldquo;park&rdquo; and &ldquo;unpark&rdquo; kernel threads that are
associated with an offline CPU.

<div class="tlr">
<a name="Quick Quiz 5"><b>Quick Quiz 5</b>:</a>
Why not just use <code>SIGSTOP</code> to park per-CPU kthreads?
<a href="#aqq5">Answer</a>
</div>

<p>
Such a parking mechanism faces the following challenges:
<ul>
<li>	Many per-CPU kernel threads are (quite naturally) coded with
	the assumption
	that they will always run on the corresponding CPU.
<p>
<li>	If a kthread that has an affinity to a given CPU
	is awakened while that CPU is offline, the scheduler
	prints an error message and removes the affinity,
	so that the kthread will now be able to run on any CPU.
<p>
<li>	Wakeups can be delayed so that they do not arrive
	at the kthread until after the corresponding CPU
	has gone offline.
<p>
<li>	All kernel threads parked for a given offline CPU must sleep
	interruptibly, because otherwise the kernel will
	emit soft-lockup messages.
<p>
<li>	When a given CPU goes offline, any work pending for that
	CPU must either be completed immediately (thus delaying
	the offline operation), migrated to some other CPU
	(thus increasing complexity), or deferred until the
	CPU comes back online (which might be never).
</ul>
<p>
<div class="tlr">
<p><a name="Quick Quiz 6"><b>Quick Quiz 6</b>:</a>
What other mechanisms could be used to park per-CPU kthreads?
<a href="#aqq6">Answer</a>
</div>

There is some reason to believe that <i>any</i> mechanism that
evacuates all work from a CPU faces these same challenges.

<p>Finally, CPU-hotplug operations can destroy cpuset configuration,
so that cpusets need to be repaired when CPUs are brought
back online.
This topic is currently the subject of spirited discussions.
<p>Perhaps these CPU-hotplug shortcomings can be repaired.
But suppose that they cannot.
What should be done instead in order to evacuate all work from a given CPU?

<p>Tasks can be moved off of a given CPU by use of 
explicit per-task affinity, cgroups, or cpusets, although
interactions with other uses of these mechanisms need more
thought.
In addition, interactions among all of these mechanisms can have
unexpected results because of a strong desire that the scheduler
generally consume less CPU than the workload being scheduled.

<p>However, interrupts can still happen on a given CPU even after all
tasks have been evacuated.
Interrupts must be redirected separately using the
<code>/proc/irq</code> directory.
This directory in turn contains one directory
for each IRQ, and each IRQ directory contains a
<code>smp_affinity</code> file to which you can write a
hexadecimal mask to restrict delivery of the corresponding
interrupts.
You can then examine the <code>/proc/interrupts</code> file
to verify that interrupts really are no longer being
delivered to the CPUs in question.
See <code>Documentation/IRQ-affinity.txt</code> in the
kernel sources for more information.
One caution: that document notes that some irq controllers
do not support affinity, and for such controllers it is
not possible to direct irq delivery away from a given CPU.

<p>Finally, evacuating tasks and interrupts from a given CPU can still
leave timers running on that CPU.
As noted earlier, there is currently no mechanism other than
CPU hotplug to migrate timers off of a given CPU, but it should
be possible to create such a mechanism.
An asynchronous mechanism (which would allow each timer one final
ride on the outgoing CPU) is straightforward.
A synchronous mechanism would be more complex, but should be
doable.

<p>So, what should be done?
In the near term, the only sane approach is to attack on both fronts:
(1)&nbsp;attempt to cure CPU hotplug of its worst ills (especially
given that it will likely continue to be needed for removing failing
CPUs), and (2)&nbsp;attempt to improve the alternative mechanisms so
that they can do more of the work that can currently only be done
by CPU hotplug&mdash;hopefully avoiding at least some of the complexity
currently inherent to CPU hotplug.

<h3><a name="Future Work and Prospects">
Future Work and Prospects</a></h3>

<p>In the short term, the following actions need to be taken:

<ul>
<li>	Create an email list for the attendees and other interested parties.
	This is now available
	<a href="http://lists.linaro.org/mailman/listinfo/linaro-sched-sig">here</a>,
	courtesy of Amit Kucheria and Loic Minier.
<p>
<li>	Document best practices for using existing Linux kernel
	facilities (including CPU hotplug, cgroups, cpusets,
	affinity, and so on) to manage big.LITTLE systems in
	an SMP configuration.
	This documentation should include measurements of latencies 
	(keeping in mind the 5ms goal for evacuating work
	from a CPU and for restarting it) and power consumption.
	Vincent Guittot's
	<a href="https://wiki.linaro.org/WorkingGroups/PowerManagement/Doc/Hotplug">presentation</a>
	and <a href="http://git.linaro.org/gitweb?p=people/vingu/kernel.git">git tree</a>
	are a good start in this direction.
<p>
<li>	Create software to emulate big.LITTLE systems on current hardware,
	for example, using one or more of the approaches describe in the
	<a href="#Parallel Hardware/Software Development">
	Parallel Hardware/Software Development</a>
	section.
<p>
<li>	Produce Linux-kernel-developer-friendly synthetic workloads
	and benchmarks for mobile applications and use cases,
	as discussed in the
	<a href="#Benchmarks and Synthetic Workloads">Benchmarks and Synthetic Workloads</a>
	section.
	There will be some Linaro work in this direction, but additional
	workloads and benchmarks are welcome from any and all.
</ul>

In the medium term, the following additional actions are needed:

<ul>
<li>	Experiment with improving cpusets and cgroups as discussed
	in the
	<a href="#CPU Hotplug: Kill It or Cure It?">CPU Hotplug: Kill It or Cure It?</a>
	section.
<p>
<li>	Experiment with curing CPU hotplug, also discussed in the
	<a href="#CPU Hotplug: Kill It or Cure It?">CPU Hotplug: Kill It or Cure It?</a>
	section.
<p>
<li>	Accumulate a list of the attributes that system-on-a-chip
	(SoC) vendors believe to be important to scheduling and
	managing big.LITTLE systems.
	An initial list was accumulated during the scheduler summit:
	<p>
	<ul>
	<li>	Power-domain and clock-domain constraints.  For example,
		many ARM SoCs require that all CPUs in a cluster
		run at the same clock rate.
<p>
	<li>	Thermal tradeoffs.  For example, some SoCs might impose
		a tradeoff between the number of CPUs running at a
		given time and the frequency at which they are running
		if they are to avoid thermal throttling.
<p>
	<li>	Thermal feedback, e.g., temperature sensors.
<p>
	<li>	Process type, where the amount of leakage current can affect
		the optimal strategies for power-efficient operation.
<p>
	<li>	Relative benefit of reducing frequency of several CPUs
		as opposed to consolidating workload on a small number
		of CPUs.
<p>
	<li>	Instruction-per-clock (IPC) measurements and correlation
		between clock rate and useful forward progress.
	</ul>
<p>
<li>	Remove <code>sched_mc</code>.
</ul>

In the longer term, the following additional actions would be quite
helpful:

<ul>
<li>	Port Frederic Weisbecker's OS-jitter-reduction patchset to ARM.
	Geoff Levand of Huawei is leading up an effort along these lines.
<p>
<li>	Contact gaming companies (e.g., Epic) to see if their 3D gaming
	engines (which run on
	both iPhone and Android) can make good use of big.LITTLE,
	even in the presence of thermal throttling.
<p>
<li>	Investigate alternative scheduler disciplines.  For example,
	the prototype SCHED_EDF patchset would allow tasks to specify
	deadlines, which would allow the scheduler to better decide
	between race-to-idle and run-at-low-frequency.  Other related
	scheduler disciplines such as EVDF might be useful&mdash;there
	may be other real-time technologies that can be commandeered
	to energy-efficiency purposes.

	<p>If SCHED_EDF looks useful to mobile/embedded, someone needs
	to forward-port the patch and fix a number of issues in it.
	This is not a trivial project.  (Paul Turner is looking into
	bringing some Google resources to bear, and Juri Lelli has
	been doing some recent
	<a href="https://github.com/jlelli/">deadline-scheduler work</a>.)

	<p>One common mobile/embedded requirement is to consolidate the
	workload down to the minimum number of CPUs that can support
	acceptable user experience, then spread the load across that
	minimal set of CPUs.
<p>
<li>	Investigate modal scheduling.  Paul Turner gave the following
	list of modes as an example:
	<p>
	<ul>
	<li>	Low load of interactive, low-utilization tasks might
		favor race to idle.
		<p>
	<li>	Moderate load of periodic media-feeding tasks might
		lower frequency to the smallest value that allows
		the task to keep up with its hardware.
		<p>
	<li>	High load of CPU-bound tasks in the absence of thermal
		limitations might increase frequency.
	</ul>

	<p>Some hysteresis will be required.  It is usually OK to delay
	the decisions a bit, especially given that ARM provides relatively
	fast transitions between power states.

	Paul Turner posted a first step in this direction, with a
	<a href="https://lkml.org/lkml/2012/2/1/763">patch series</a>
	that improves the scheduler's ability to better estimate
	the effect of migration of each CPU's load.
	A more up-to-date series is maintained
	<a href="http://rs5.risingnet.net/~pjt/patches/load_avg/">here</a>.
</ul>

<h3><a name="Conclusions">
Conclusions</a></h3>

<p>The scheduler mini-summit at Linaro Connect was quite productive,
with work already in progress to implement some of the recommendations.
For example, some code and patches are in flight to reduce RCU's dependence on
<tt>stop_machine()</tt>, which is a first step towards weaning CPU hotplug from
<tt>stop_machine()</tt>.
For another example, Srivatsa Bhat is doing some good work on curing
CPU hotplug of some of its ills.

<p>So how did we do against the goals?
Let's check:

<ol>
<li>	Take first step towards planning any Linux-kernel scheduler
	changes that might be needed for ARM's
	upcoming big.LITTLE systems work well.

	<p>The most important actions toward this goal are the
	emulation of big.LITTLE systems, the mobile/embedded
	synthetic benchmarks/workloads, and the list of SoC attributes.
	This information will help work out which of the longer-term
	actions are most important.

	<p>
<li>	Create a power-aware infrastructure for scheduling and related
	Linux kernel subsystems.
	For example, integrate dyntick-idle,
	cpufreq, cpuidle, sched_mc, timers, thermal framework, pm_qos,
	and the scheduler.

	<p>The mobile/embedded synthetic benchmarks/workloads is the
	most important first step in this direction, as is the
	list of SoC attributes.
	The removal of <code>sched_mc</code> is a first implementation
	step, on the theory that one must tear down before one can
	build.

	<p>
<li>	Provide a usable mechanism that reliably allows all work (present
	and future) to be moved off of a CPU so that that CPU can
	be powered off and back on under user-application control.
	CPU hotplug is used for this today, but has some serious side
	effects, so it would be good to either fix CPU hotplug or come
	up with a better mechanism&mdash;or, in the best Linux-kernel
	tradition, both.
	Such a mechanism might also be useful to the real-time people,
	who also need to clear <i>all</i> non-real-time activity from
	a given CPU.

	<p>This goal received the most discussion, and the medium-term
	actions for curing CPU hotplug on the one hand or improving
	the alternatives to CPU hotplug on the other.
</ol>

<p>Work on these three goals has only just begun, but
with continued effort, we can make the Linux kernel work better for big.LITTLE
in particular and for mobile/embedded workloads on asymmetric
systems in general.

<h4><a name="Acknowledgments">
Acknowledgments</a></h4>

<p>I am grateful to the scheduler mini-summit attendees for many
useful and enlightening discussions, and especially to Amit Kucheria
for organizing the mini-summit.
We all owe thanks to Zach Pfeffer, Peter Zijlstra, Amit Kucheria,
Robin Randhawa, Jason Parker,
Rusty Russell, Vincent Guittot,
and Dave Rusling for helping make this article human readable.
I owe thanks to Dave Rusling and Jim Wasko for their support of this effort.

<p><h4><a name="Answers to Quick Quizzes">
Answers to Quick Quizzes</a></h4>

<a name="aqq1"></a>
<p><b>Quick Quiz 1</b>:
But what if there is a different number of Cortex-A7s than of Cortex-A15s?

</p><p><b>Answer</b>:
In that case, it is necessary to remove the excess CPUs from service,
for example, using CPU hotplug, before carrying out the switch.

</p><p><a href="#Quick%20Quiz%201"><b>Back to Quick Quiz 1</b>.</a>

<a name="aqq2"></a>
<p><b>Quick Quiz 2</b>:
Why scale down?
Isn't it always better to run full out in order to race to idle?

</p><p><b>Answer</b>:
Although it often is best to race to idle, there are some important
exceptions to this rule in certain mobile/embedded workloads.
For one example, imagine a codec that required the CPU to
occasionally do some work to provide the codec with data.
Because CPU power consumption often rises as the square of the
core clock frequency, you typically get the best battery life
by running the CPU at the lowest frequency that gets the work
done in time.
As always, use the right tool for the job!

</p><p><a href="#Quick%20Quiz%202"><b>Back to Quick Quiz 2</b>.</a>

<a name="aqq3"></a>
<p><b>Quick Quiz 3</b>:
I typed the following command:
<pre>
    sudo echo 800000 &gt; /sys/devices/system/cpu/cpu1/cpufreq/scaling_max_freq
</pre>
<p>Despite the <code>sudo</code>, I got &ldquo;Permission denied&rdquo;.
Why doesn't <code>sudo</code> give me sufficient permissions?

</p><p><b>Answer</b>:
Although that command does give <code>echo</code> sufficient
permissions, the actual redirection is carried out by the
parent shell process, which evidently does not have sufficient
permissions to open the file for writing.
One way to work around this is <code>sudo bash</code> followed
by the <code>echo</code>, or to do something like:
<p>
<pre>
    sudo sh -c 'echo 800000 &gt; /sys/devices/system/cpu/cpu1/cpufreq/scaling_max_freq'
</pre>
<p>
Another approach is to use <code>tee</code>, for example:
<p>
<pre>
    echo 800000 | sudo tee /sys/devices/system/cpu/cpu1/cpufreq/scaling_max_freq
</pre>

<p>Yet another approach uses <code>dd</code> as follows:

<pre>
    echo 800000 | sudo dd of=/sys/devices/system/cpu/cpu1/cpufreq/scaling_max_freq
</pre>

</p><p><a href="#Quick%20Quiz%203"><b>Back to Quick Quiz 3</b>.</a>

<a name="aqq4"></a>
<p><b>Quick Quiz 4</b>:
Why would anyone use an Intel system to test out an ARM capability?

</p><p><b>Answer</b>:
The scheduler is core code, and for the most part does not care
about which instruction-set architecture is running.
The important thing is not the ISA, but rather the performance
characteristics.

</p><p><a href="#Quick%20Quiz%204"><b>Back to Quick Quiz 4</b>.</a>

<a name="aqq5"></a>
<p><b>Quick Quiz 5</b>:
Why not just use <code>SIGSTOP</code> to park per-CPU kthreads?

</p><p><b>Answer</b>:
It might well work, at least given appropriate adjustments.
Please try it and let us know how it goes.

</p><p><a href="#Quick%20Quiz%205"><b>Back to Quick Quiz 5</b>.</a>

<a name="aqq6"></a>
<p><b>Quick Quiz 6</b>:
What other mechanisms could be used to park per-CPU kthreads?

</p><p><b>Answer</b>: Here are some possibilities:
<ul>
<li>	Kill the kthreads at CPU-offline time and recreate them at
	CPU-online time.
	This is used today, and is quite slow.
<p>
<li>	Kill the kthreads at CPU-offline time and recreate them at
	CPU-online time, as above, but create a separate <code>CLONE_</code>
	flag to prevent the parent from waiting until the child runs.
	This waiting behavior exists to work around an old <code>bash</code>
	bug, and is not needed for in-kernel kthreads.
<p>
<li>	Kill the kthreads at CPU-offline time, but don't recreate them
	until they are actually needed, perhaps using a separate high-priority
	kthread to allow the creation to be initiated from environments
	where blocking is prohibited.
	This might work well in some situations, but does increase the
	state space significantly.
<p>
<li>	Have the kthreads block while their CPU is offline.
	This approach faces some complications:
<p>
	<ul>
	<li>	Wake-ups can be delayed, so that a delayed wakeup might
		arrive at a kthread after the corresponding CPU has
		gone offline.
<p>
	<li>	If a task that has an affinity to a given CPU awakens while that
		CPU is offline, the scheduler prints a warning message
		and breaks affinity.
		This breaking of affinity can cause failures in kthreads
		written to assume that they only run on their CPU.
<p>
	<li>	Sleeping uninterruptibly while a CPU is offline can
		result in spurious soft-lockup warnings.
	</ul>
<p>
<li>	Use an explicit rendezvous to park each kthread, setting its
	affinity mask to cover all CPUs and informing it that it needs
	to remain quiescent.
	This operation would be reversed when the CPU comes back online.
	This works, but is often surprisingly difficult to get right,
	particularly on busy systems where wakeups can be delayed.
<p>
<li>	Your idea here.
</ul>

<p>It is quite likely that different approaches will be required in
different situations.

</p><p><a href="#Quick%20Quiz%206"><b>Back to Quick Quiz 6</b>.</a><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Scheduler">Scheduler</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#McKenney_Paul_E.">McKenney, Paul E.</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Linaro_Connect-2012.Q1">Linaro Connect/2012.Q1</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/482344/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor483179"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 23, 2012 7:15 UTC (Thu)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/483179/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
as I noted in the big.LITTLE topic, it's not just embedded/SoC systems that can use this sort of thing, current multicore monsters from Intel/AMD have some of the same design trade-offs (turbo mode where you shut some cores off to increase the speed of other cores while remaining within the same thermal envelope is one example)<br>
<p>
I am also very curious at how well the current scheduler works on a system with significantly different CPU speeds (ignoring the question of tuning cores on and off, how well does it spread the work?, what happens with a cpu hog thread? can it get stuck on a slow core?)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/483179/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor483291"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 23, 2012 16:11 UTC (Thu)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/483291/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Indeed, this should be of general interest.  If nothing else, the fact that several people outside of the ARM community showed up for the mini-summit should be strong evidence of that.  ;-)<br>
<p>
On your second question, I could give an opinion, but why not just try it on some of the current systems you mentioned?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/483291/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor483379"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 23, 2012 19:20 UTC (Thu)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/483379/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; On your second question, I could give an opinion, but why not just try it on some of the current systems you mentioned?</font><br>
<p>
simple, I don't happen to own any such systems :-) the ones I can freely tweak can't clock the different cores at different speeds.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/483379/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor483579"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 24, 2012 8:39 UTC (Fri)
                               by <b>rvfh</b> (guest, #31018)
                              [<a href="/Articles/483579/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; I am also very curious at how well the current scheduler works on a system with significantly different CPU speeds (ignoring the question of tuning cores on and off, how well does it spread the work?, what happens with a cpu hog thread? can it get stuck on a slow core?)</font><br>
<p>
I am no expert but recently had a look at the CFS (completely fair scheduler) code. The CFS only considers on core, and has a load balancing mechanism which is triggered when a core becomes idle.<br>
<p>
So if your big.LITTLE is fully busy, things will work although your high priority tasks might be on the 'wrong' core (the A7 i.o. the A15), and indeed a CPU hog thread could be stuck on the LITTLE when there is some idle time on the big.<br>
<p>
One solution could be to automatically evaluate the performance of each core (bogomips looks like a good enough measure to me) at startup, and then decide that a thread that is CPU-starved in the LITTLE shall be moved to the big. This means changing just the load balancer.<br>
<p>
Another approach is to assume that user-space knows better (which may well be true in some cases like video decoding and gaming) and have a daemon decide which CPU type which threads will be run on, and when to start/stop CPUs.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/483579/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor483586"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 24, 2012 8:53 UTC (Fri)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/483586/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
having userspace decide when to start/stop cores makes sense to me (but apparantly others disagree), but once userspace has made cores available to the system, having to have it evaluate which cores a process can run on continually seems like a bad idea.<br>
<p>
It's common for a process that's frequently a CPU hog to have times when it's not, and in any case, having a CPU hog not running because the 'fast' cores are all busy when a 'slow' core is idle is a bad idea.<br>
<p>
so 'fixing' this problem by relying on userspace to set/adjust affinity settings doesn't seem workable.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/483586/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor483691"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Different workloads will likely need different approaches</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 24, 2012 16:39 UTC (Fri)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/483691/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Indeed, I do not expect a one-size-fits-all solution to the general problem of scheduling on heterogeneous multiprocessors.  In some cases, userspace will know best, but in other cases the kernel's overall view of the activities of multiple independent applications will win the day.  Other cases will require cooperation between userspace and the kernel.<br>
<p>
I do expect no shortage of challenging and interesting problems to arise in this space!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/483691/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor483696"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 24, 2012 17:16 UTC (Fri)
                               by <b>charlesgt_arm</b> (guest, #83016)
                              [<a href="/Articles/483696/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Hi Paul<br>
<p>
Thanks for the great article. I was at the summit too, my first experience of this sort of thing as I am new to this world, and it was a great experience. I'd like to pick up on a few points though:<br>
<p>
<font class="QuotedText">&gt;&gt;”First, if a LITTLE CPU is able to provide sufficient performance, it provides better energy efficiency, at least in cases where race to idle is inappropriate.”</font><br>
<p>
I found this slightly misleading. Static leakage is also lower in the small cluster than in the big one, so even in race to idle cases, if LITTLE CPUs can supply adequate performance you’d in theory be better off using them. The balance here would be the states of other devices that are active during the use case, and the power states that can be entered. So if the super speed of the bigs is such that when you race to idle you turn lots of stuff off for a longer period of time than you would have if using the LITTLES (where your idle time would be less) then indeed you’d be better off in the big cores. But for situations where you are going to idle for significant periods of times (so LITTLES can still access aggressive retention modes) then due the lower static leakage you would always be better off on the LITTLES.<br>
<p>
<font class="QuotedText">&gt;&gt;”Coordinating user applications based on hotplug events. (However, there is no known embedded or mobile use of this feature, so if you need it, please let us know. Otherwise it will likely go away.)”</font><br>
<p>
Actually I raised this point at the summit. The reason I did is because I know of at least one system (Qt and in particular QtConcurrent) which creates thread pools as a multiple (in this case 1-1) of the amount of logical CPUs available. I believe Qt uses sysconf(_SC_NPROCESSORS_ONLN) when creating the thread pool, and that this would return the number of processors (or hyperthread sets) currently on line. I imagine there are other libraries which provide threadpool abstractions again based on the number of cores, but admit I have real knowledge here.<br>
So what I was actually worrying about was: what happens? And what should happen? I can imagine people in future coming up with requirements around wanting to know when the number of CPUs changes to scale up/down their thread pools. I think in theory it’s not really justifiable to have too much of a communication when scaling down. If performance monitoring code decides we are under using the CPU resources and to scale down, then clearly the threadpool is not using the cores too much so who cares. However if you were bringing more CPUs online and the threadpool is a big contributor to load, and has a 1-1 matching with number of CPUs, then growing the pool could make sense. Anyways it’s food for thought. <br>
<p>
<font class="QuotedText">&gt;&gt;”Wakeups can be delayed so that they do not arrive at the kthread until after the corresponding CPU has gone offline.”</font><br>
<p>
Did I misunderstand or should that have read “CPU has come  online”? I have probably misunderstood, but I thought that the idea is to postpone the wakeups until the CPUs for the targeted kthreads area available once again. I profess no knowledge here...<br>
<p>
There are some other notions of RACE to idle vs DVFS that are very focussed on schedule. But in reality device usage is going to be a key parameter in making that decision. I think more so than information that can be deduced from schedule. You allude to this in Quiz1. The classic example is mp3. You have a use case where CPU utilisation is low, periodic and bursty, and assuming good size buffers, gives you good idle time between bursts, however because you are using that audio hw/codec hw you cannot actually go into a very deep low power mode. So you are better off using DVFS rather than race to idle. A system that can represent available modes, given current device usage and latency constraints would be very useful here.<br>
<p>
Cheers<br>
<p>
Charles<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/483696/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor483708"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 24, 2012 18:47 UTC (Fri)
                               by <b>heechul</b> (guest, #79852)
                              [<a href="/Articles/483708/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Just like Qt, android dalvik also use sysconf(_SC_NPROCESSORS_ONLN) to report the number of available cpus to applications which then create the thread pools based on that information. Obviously, applications can suffer significant performance hit by dynamic hotplugging.<br>
<p>
The right solution should be using sysconf(_SC_NPROCESSORS_CONF) which, in theory, should return the total available cpus instead of online ones. <br>
<p>
The problem is that libc implementations, at least the android libc i used, do not distinguish the two and simply they are the same. i.e., report #of online cpus although _SC_NPROCESSORS_CONF is requested. They should be fixed as desired. <br>
<p>
Then a question would be whether kernel has standard interface to userspace to report #online cpus and #available cpus so that libc can properlly implement both _SC_NPROCESSORS_CONF and _SC_NPROCESSORS_CONF. <br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/483708/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor484524"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 29, 2012 19:45 UTC (Wed)
                               by <b>BenHutchings</b> (subscriber, #37955)
                              [<a href="/Articles/484524/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Last time I looked, glibc was using /proc/cpuinfo. I think it should be using /sys/devices/system/cpu/online and <br>
/sys/devices/system/cpu/possible, with a fallback to /proc/cpuinfo.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/484524/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor483723"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 24, 2012 19:11 UTC (Fri)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/483723/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Hello, Charles!<br>
<p>
Good point on the choice between big and LITTLE being far more nuanced than I could hope to fully capture in a one-sentence rule of thumb.  I do agree that the characteristics of a given device will often need to be taken into account.<br>
<p>
Please accept my apologies for losing your comment about thread pools.  I agree that having applications base their thread-pool sizes on the number of CPUs physically configured on the device will usually be a good place to start.<br>
<p>
I really did mean that wakeups can be delayed until a CPU has gone offline!  ;-)<br>
<p>
Here is what can happen (or at least did happen to me as of about a year ago): (1) A kthread bound to CPU 0 is awakened.  (2) Before the kthread can run, CPU 0 goes offline.  (3) The kthread actually tries to start running, and as a result has its binding to the now-offline CPU broken.  It is possible to handle this by careful use of preemption disabling and checks to see what CPU the kthread is actually running on.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/483723/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor484706"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 1, 2012 15:46 UTC (Thu)
                               by <b>tvld</b> (guest, #59052)
                              [<a href="/Articles/484706/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; I imagine there are other libraries which provide threadpool abstractions again based on the number of cores, but admit I have real knowledge here.</font><br>
<p>
Yes, I think that's fairly common.  (And not perfect.)<br>
<p>
<font class="QuotedText">&gt; So what I was actually worrying about was: what happens? And what should happen? I can imagine people in future coming up with requirements around wanting to know when the number of CPUs changes to scale up/down their thread pools.</font><br>
<p>
Thread pools could indeed benefit from adjustments at runtime. The underlying problem is that userspace is making resource-usage decisions.  In particular, parallelized programs do that to a larger extend than single-threaded ones because they have to decide how many threads they use.  For userspace, it's not clear whether none/few/many threads would yield optimal performance because the lower-level trade-offs (e.g., all that's discussed in the article) aren't known; likewise, the kernel can't optimize optimally either because it doesn't know about the program's utility function and because the userspace code that is run for single-thread vs. multi-thread is often different (e.g., due to differences in synchronization) and has different performance characteristics.<br>
<p>
<font class="QuotedText">&gt; I think in theory it’s not really justifiable to have too much of a communication when scaling down. If performance monitoring code decides we are under using the CPU resources and to scale down, then clearly the threadpool is not using the cores too much so who cares. However if you were bringing more CPUs online and the threadpool is a big contributor to load, and has a 1-1 matching with number of CPUs, then growing the pool could make sense.</font><br>
<p>
I agree that we shouldn't worry about having unused threads lying around.  However, if the kernel knows that there will only be one big core not occupied by other processes (and thus available to our program), for example, then the program can benefit from this because it knows it doesn't have to try hard to run stuff in parallel. The parallelization overheads of course vary depending on the parallelization approach that userspace follows and the actual application/workload (e.g., task-based parallelism together with work-stealing are more robust than other approaches in cases of load imbalance).<br>
<p>
Overall, I think we should work on getting userspace and kernel to try to optimize this jointly, because IMO this is an end-to-end optimization problem (program utility function down to HW performance characteristics) and because I doubt that we'll find a catch-all tuning policy that's feasible to add to the kernel.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/484706/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor483889"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Frequency vs. power consumption</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 26, 2012 5:03 UTC (Sun)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/483889/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <BLOCKQUOTE><I>Because CPU power consumption often rises as the square of the core clock frequency, you typically get the best battery life by running the CPU at the lowest frequency that gets the work done in time.</I></BLOCKQUOTE>
<P>If I'm not mistaken, dynamic power is <I>linearly</I> proportional to clock speed, holding all other things constant.  (Leakage power remains constant.)  Both dynamic and leakage power, though, tend to be proportional to the square of <I>voltage</I>.  (Power is V<sup>2</sup> / R.)  Now, if you need to increase voltage to get to a higher clock speed, then yes, the statement is true to an extent, but not all systems adjust voltage with clock frequency.</P>
<P>BTW, there's another reason running the CPU at a higher clock doesn't always help.  If you have a memory-bound workload, such that you spend most of your time in cache miss cycles, you're just going to burn a lot of clock power running the CPU faster, without speeding up the workload appreciably.  This is mentioned in the article as a possible reason to move a task from the A15 to the A7, but it's also just a more general argument for setting the "right" clock rate based on what you know of the task.</P>
      
          <div class="CommentReplyButton">
            <form action="/Articles/483889/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor484015"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Frequency vs. power consumption</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 27, 2012 20:08 UTC (Mon)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/484015/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Generally agreed on your point about voltage, frequency, and power, and hence the word "often" in my original.  ;-)<br>
<p>
Your point about a cache-missy workload being a good candidate for lower CPU frequency is a good one, depending of course on how much of the memory system is in the same clock domain.<br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/484015/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor484496"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Frequency vs. power consumption</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 29, 2012 18:05 UTC (Wed)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/484496/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <P>I just amused myself wondering what a good API would be for hinting to the OS about this... Maybe not<TT> madvise(MADV_CACHE_THRASHY)</TT> (for the simple reason that it's an attribute of the task, not an attribute of a memory page), but then what?</P>
<P>On a more serious note, I wonder if the OS could use hardware performance counters to auto-detect this sort of stuff.  If the ratio of stall to execute cycles is above a certain threshold, decrease the task's desired clock speed, and if it's above another threshold, increase it.  Hmmm....</P>
      
          <div class="CommentReplyButton">
            <form action="/Articles/484496/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor484500"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Frequency vs. power consumption</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 29, 2012 18:06 UTC (Wed)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/484500/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Errr...  that second statement should be <B>below</B>, not <B>above</B>.
      
          <div class="CommentReplyButton">
            <form action="/Articles/484500/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor488773"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Frequency vs. power consumption</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 27, 2012 12:51 UTC (Tue)
                               by <b>chrisr</b> (subscriber, #83108)
                              [<a href="/Articles/488773/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I don't believe it would be reasonable for the kernel to expect applications to tell it how cache-missy or otherwise they are. I would expect the cache miss ratio is likely to vary significantly across portions of an application and anyway cores often come with variable cache sizes. This makes it hard to determine what an application will perform like on any particular platform.<br>
<p>
For me, this means that the only reasonable way to know about a thread's optimal runtime performance requirement is therefore to measure it while its running and age older measurements as we do with load measurement.<br>
<p>
Whether it is possible to do this in a generic enough manner that it could be accepted into a mainline Linux Kernel is IMO a different matter to the technical problem of doing the measurement and using those indications for something useful, and probably will take longer too :)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/488773/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor488789"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Frequency vs. power consumption</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 27, 2012 14:06 UTC (Tue)
                               by <b>jzbiciak</b> (guest, #5246)
                              [<a href="/Articles/488789/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <P>Well, remember,<TT> madvise() </TT>is a hint.  I think you and I likely agree that the system should run reasonably if nobody ever calls it in a typical application.  It exists to help you take performance from "reasonable, if not quite optimal" to "stellar."  So, if you're<TT> bzip2 </TT>you might consider throwing that flag.  As you said, though, it's less clear if you're a web browser or office app.  (Although, I strongly suspect both are more cache thrashy than they'd like to be, even when idle.)</P>
<P>That said, my<TT> madvise() </TT>proposal above was partly tongue in cheek.  (It was also partly inspired by<TT> MADV_RANDOM</TT>.)  It would be interesting though, to try to characterize apps by their recent cache miss ratios and use that to make CPU affinity selections as well as operating frequency selections.</P>
<P>Actually, you need two ratios:  Hit/(hit+miss) and Stall/(stall+non-stall) cycles.  You could have a fairly high miss ratio with a low stall ratio.  A faster CPU still helps you.  The high miss ratio suggests streaming or a large working set, but there's enough prefetching and/or inherent parallelism the CPU can stay busy.  A high miss ratio with a high stall ratio suggests a more serial program that's staying memory bound.  Lower frequency or a slower CPU is unlikely to hurt the performance of the program.</P>
<P>Anyway... I've devolved into ramble-ville.</P>

      
          <div class="CommentReplyButton">
            <form action="/Articles/488789/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
<a name="CommAnchor485326"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The Linaro Connect scheduler minisummit</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 6, 2012 0:18 UTC (Tue)
                               by <b>landley</b> (guest, #6789)
                              [<a href="/Articles/485326/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I really, really hate the "quick quizzes", which completely disrupt the flow of the article to the point I stop reading. I find them so annoying that they completely spoil otherwise nice articles.<br>
<p>
If need to stop and think, I'm quite capable of doing so on my own. I don't need to be _prompted_ for it by some patronizing not-quite-textbook.<br>
<p>
If I don't retain the material on a first reading, this is what bookmarks (or google) are for. I don't need some professor to whap my knuckles for not "paying attention". Of COURSE I'm not paying full attention, reading this is competing for my attention with 15 other things. The time I can carve out that's uninterrupted and in large chunks is going to be spent _coding_ (either writing new stuff or reviewing other people's code), not trying to close browser tabs.<br>
<p>
There's probably a _reason_ nobody else writes articles this way...<br>
<p>
Rob<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/485326/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor485341"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Quick quizzes</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 6, 2012 1:10 UTC (Tue)
                               by <b>corbet</b> (editor, #1)
                              [<a href="/Articles/485341/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Sorry you don't like them.  They <i>are</i> deliberately rendered out of the text flow, so they shouldn't be that hard to ignore.
<p>
We recently had a comment from another reader asking for quizzes on more articles.  Sometimes we just can't win, I guess.
      
          <div class="CommentReplyButton">
            <form action="/Articles/485341/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2012, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
