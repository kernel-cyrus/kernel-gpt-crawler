        <!DOCTYPE html>
        <html lang="en">
        <head><title>The zswap compressed swap cache [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/537422/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/536768/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/537422/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>The zswap compressed swap cache</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Benefits for LWN subscribers</b>
<p>
The primary benefit from <a href="/Promo/nst-nag5/subscribe">subscribing to LWN</a>
       is helping to keep us publishing, but, beyond that, subscribers get
       immediate access to all site content and access to a number of extra
       site features.  Please sign up today!
</blockquote>
<div class="GAByline">
           <p>February 12, 2013</p>
           <p>This article was contributed by Seth Jennings</p>
           </div>
Swapping is one of the biggest threats to performance. The latency gap
between RAM and swap, even on a fast SSD, can be four orders of magnitude.  The
throughput gap is two orders of magnitude.  In addition to the speed gap,
storage on which a swap area resides is becoming more shared and
virtualized, which can cause additional I/O latency and nondeterministic
workload performance.  The zswap subsystem exists to mitigate these
undesirable effects of swapping through a reduction in I/O activity.
<p>
Zswap is a lightweight, write-behind compressed cache for swap pages.  It
takes pages that are in the process of being swapped out and attempts to
compress them into a dynamically allocated RAM-based memory pool.  If this
process is successful, the writeback to the swap device is deferred and, in
many cases, avoided completely.  This results in a significant I/O
reduction and performance gains for systems that are swapping. 
<p>
<h4>Zswap basics</h4>
<p>
Zswap intercepts pages in the middle of swap writeback and caches them
using the frontswap API.  Frontswap has been in the kernel since v3.5 and
has been <a
href="/Articles/386090/">covered by LWN</a> before.  It allows a
backend driver, like zswap, to intercept both swap page writeback and the
page faults for swapped out pages. Zswap also makes use of 
the "zsmalloc" allocator (discussed below) for compressed page storage.
<p>
Zswap seeks to be as simple as possible in its structure and operation.
There are two primary data structures.  The first is the <tt>zswap_entry</tt>
structure, which contains information about a single compressed page stored
in zswap:
<p>
<pre>
    struct zswap_entry {
	struct rb_node rbnode;
	int refcount;
	pgoff_t offset;
	unsigned long handle; /* zsmalloc allocation */
	unsigned int length;
	/* ... */
    };
</pre>
<p>
The second is the <tt>zswap_tree</tt> structure which contains a red-black tree of
zswap entries indexed by the <tt>offset</tt> value: 
<p>
<pre>
    struct zswap_tree {
	struct rb_root rbroot;
	struct list_head lru;
	spinlock_t lock;
	struct zs_pool *pool;
    };
</pre>
<p>
At the highest level, there is an array of <tt>zswap_tree</tt> structures indexed by
the swap device number. 
<p>

There is a single lock per <tt>zswap_tree</tT> to protect the tree
structure during lookups and modifications.  The higher-level swap code
provides certain protections that simplify the zswap implementation by not
having to design for concurrent store, load, and invalidate operations on
the same swap entry.  While this single-lock design might seem like a
likely source for contention, actual execution <a
href="https://lkml.org/lkml/2013/1/8/269/">demonstrates</a> that the swap
path is largely bottlenecked by other locks at higher levels, such as the
<tt>anon_vma</tt> mutex or <tt>swap_lock</tt>.  In comparison, the
<tt>zswap_tree</tt> lock 
is very lightly contended.  Writeback support, covered in the next section,
also led to this single-lock design.
<p>
For page compression, zswap uses compressor modules provided by the kernel's
cryptographic API.  This allows users to select the compressor dynamically
at boot time, and gives easy access to hardware compression accelerators or
any other future compression engines. 
<p>
A zswap store operation occurs when a page is selected for swapping by the
reclaim system and frontswap intercepts the page in
<tt>swap_writepage()</tt>.  The operation begins by compressing the page
into a per-CPU temporary buffer.  Compressing into the temporary buffer is
required because the compressed size, and thus the size of the permanent
allocation needed to hold it, isn't known until the compression is actually
done.  Once the compressed size is known, an object is allocated and the
temporary buffer is copied into the object.  Lastly, a <tt>zswap_entry</tt>
structure is allocated, populated, and inserted into the tree for that swap
device.
<p>
If the store fails for any reason, most likely because of an object
allocation failure, zswap returns an error which is propagated up through
frontswap into <tt>swap_writepage()</tt>. The page is then swapped out to
the swap device as usual.
<p>

A load operation occurs when a program page faults on a page table entry
(PTE) that contains a swap entry and is intercepted by frontswap in
<tt>swap_readpage()</tt>.  The swap entry contains the device and offset
information needed to look up the zswap entry in the appropriate tree.
Once the entry is located, the data is decompressed directly into the page
allocated by the page fault code.  The entry is not removed from the tree
during a load; it remains up-to-date until the entry is invalidated.
<p>
An invalidate operation occurs when the reference count for a
particular swap offset becomes zero in <tt>swap_entry_free()</tt>.  In this case,
the zswap entry is removed from the appropriate tree, and the entry and the
zsmalloc allocation that it references are freed. 
<p>
To be preemption-friendly, interrupts are never disabled.  Preemption is
only disabled during compression while accessing the per-cpu temporary
buffer page, and during decompression while accessing a mapped
zsmalloc allocation.
<p>
<h4>Zswap writeback</h4>
<p>
To operate optimally as a cache, zswap should hold the most recently used pages.  With
frontswap, there is, unfortunately, a real potential for an inverse least
recently used 
(LRU) condition in which the cache fills with older pages, and newer pages
are forced out to the slower swap device.  To address this, zswap is
designed with "resumed" writeback in mind. 
<p>
As background, the process for swapping pages follows these steps:
<p>
<ol>
<li> First, an anonymous memory page is selected for swapping and a slot is
     allocated in the swap device. 
<p>
<li> Next, the page is unmapped from all processes using that page.  The
PTEs referencing that page are filled with the swap entry that consists of
the swap type and offset where the page can be found.   
<p>
<li> Lastly, the page is scheduled for writeback to the swap device.
</ol>
<p>
When <tt>frontswap_store()</tt> in <tt>swap_writepage()</tt> is successful,
the writeback step is not performed.  However, the slot in the swap device has been
allocated and is still reserved for the page even though the page only
resides in the frontswap backend.  Resumed writeback in zswap forces pages
out of the compressed cache into their previously reserved swap slots in
the swap device.  Currently, the policy is basic and forces pages out from
the cache in two cases: (1)&nbsp;when the cache has reached its maximum size
according to the <tt>max_pool_percent</tt> sysfs tunable or, (2)&nbsp;when zswap is
unable to allocate new space for the compressed pool. 
<p>
During resumed writeback, zswap decompresses the page, adds it back to the
swap cache, and schedules writeback into the swap slot that was previously
reserved.  By splitting <tt>swap_writepage()</tt> into two functions after
<tt>frontswap_store()</tt> is called, zswap can resume writeback from the point
where the initial writeback terminated in frontswap.  The new function is
called <tt>__swap_writepage()</tt>.
<p>
Freeing zswap entries becomes more complex with writeback.  Without
writeback, pages would only be freed during invalidate operations
(<tt>zswap_frontswap_invalidate page()</tt>).  With writeback, pages can also be
freed in <tt>zswap_writeback_pages()</tt>.  These invalidate and writeback functions
can run concurrently for the same zswap entry.  To guarantee that entries
are not freed while being accessed by another thread, a reference count
field (called <tt>refcount</tt>) is used the zswap_entry structure. 
<p>
<h4>Zsmalloc rationale</h4>
<p>
One really can't talk about zswap without mentioning zsmalloc, the
allocator it uses for compressed page storage, which currently resides in
the Linux Staging tree.
<p>
Zsmalloc is a slab-based allocator used by zswap; it
provides more reliable allocation of large objects in a memory constrained
environment than does the kernel slab allocator.  Zsmalloc has already been
<a href="/Articles/477067/">discussed on LWN</a>, so this section will
focus more on the need for zsmalloc in the presence of the kernel slab
allocator. 
<p>
The objects that zswap stores are compressed pages.  The default compressor
is lzo1x-1, which is known for speed, but not so much for high compression.  As a
result, zswap objects can frequently be large relative to typical slab
objects (&gt;1/8th <tt>PAGE_SIZE</tt>).  This is
a problem for the kernel slab allocator under memory pressure.
<p>
The kernel slab allocator requires high-order page allocations to back
slabs for large objects.  For example, on a system with a 4K page size, the
<tt>kmalloc-512</tt> cache has slabs that are backed by two contiguous
pages. <tt>kmalloc-2048</tt> requires eight contiguous pages per slab.  These high-order
page allocations are very likely to fail when the system is under memory
pressure. 
<p>
Zsmalloc addresses this problem by allowing the pages backing a
slab (or “size class” in zsmalloc terms) to be both non-contiguous and
variable in number. They are variable in number because zsmalloc allows a
slab to be composed of less than the target number of backing pages.  A set
of non-contiguous pages backing a slab are stitched together using fields
of <tt>struct page</tt> to create a “zspage”.  This allows zsmalloc to service large
object allocations, up to <tt>PAGE_SIZE</tt>, without requiring high-order page
allocations. 
<p>
Additionally, the kernel slab allocator does not allow objects that are
less than a page in size to span a page boundary.  This means that if an
object is <tt>PAGE_SIZE/2&nbsp;+&nbsp;1</tt> bytes in size, it effectively uses an entire
page, resulting in ~50% waste.  Hence there are no <tt>kmalloc()</tt> cache sizes
between <tt>PAGE_SIZE/2</tt> and <tt>PAGE_SIZE</tt>.  Zswap frequently needs allocations in
this range, however.  Using the kernel slab allocator causes the memory
savings achieved through compression to be lost in fragmentation.
<p>
In order to satisfy these larger allocations while not wasting an entire
page, zsmalloc allows objects to span page boundaries at the
cost of having to map the allocations before accessing them.  This mapping
is needed because the object might be contained in two non-contiguous
pages.  For example, in a zsmalloc size class for objects that
are 2/3 of PAGE_SIZE, three objects could be stored in a zspage with two
non-contiguous backing pages with no waste.  The object stored in the
second of the three object positions in the zspage would be split between
two different pages.
<p>
Zsmalloc is a good fit for zswap.  Zswap was evaluated using the
kernel slab allocator and these issues did have a significant impact on
the <tt>frontswap_store()</tt> success rate.  This was due to <tt>kmalloc()</tt> allocation
failures and a need to reject pages  that compressed to sizes greater than
<tt>PAGE_SIZE/2</tt>.
<p>
<h4>Performance</h4>
<p>
In order to produce a performance comparison, kernel builds were
conducted with an increasing number of threads per run in a constant and
constrained amount of memory.  The results indicate a runtime reduction of
53% and an I/O reduction of 76% with zswap compared to normal swapping. 

The testing system was configured with:
<p>
<ul>
<li> Gentoo running v3.7-rc7
<li> Quad-core i5-2500 @ 3.3GHz
<li> 512MB DDR3 1600MHz (limited with mem=512m on boot)
<li> Filesystem and swap on 80GB HDD (about 58MB/s with hdparm -t)
</ul>
<p>
The table below summarizes the test runs.
<p>
<blockquote>
<table>
<tr><th></th><th colspan=4>Baseline</th><th colspan=4>zswap</th><th
colspan=2>Change</th></tr>
<tr><th>N</th><th>pswpin</th><th>pswpout</th><th>majflt</th><th>I/O
sum</th><th>pswpin</th><th>pswpout</th><th>majflt</th><th>I/O
sum</th><th>%I/O</th><th>MB</th></tr>
<tr class="Odd"><td align="right">8</td><td align="right">1</td><td
align="right">335</td><td align="right">291</td><td
align="right">627</td><td align="right">0</td><td align="right">0</td><td
align="right">249</td><td align="right">249</td><td
align="right">-60%</td><td align="right">1</td></tr>

<tr class="Even"><td align="right">12</td><td align="right">3688</td><td
align="right">14315</td><td align="right">5290</td><td
align="right">23293</td><td align="right">123</td><td
align="right">860</td><td align="right">5954</td><td
align="right">6937</td><td align="right">-70%</td><td
align="right">64</td></tr>

<tr class="Odd"><td align="right">16</td><td align="right">12711</td><td
align="right">46179</td><td align="right">16803</td><td
align="right">75693</td><td align="right">2936</td><td
align="right">7390</td><td align="right">46092</td><td
align="right">56418</td><td align="right">-25%</td><td
align="right">75</td></tr>

<tr class="Even"><td align="right">20</td><td align="right">42178</td><td
align="right">133781</td><td align="right">49898</td><td
align="right">225857</td><td align="right">9460</td><td
align="right">28382</td><td align="right">92951</td><td
align="right">130793</td><td align="right">-42%</td><td
align="right">371</td></tr>

<tr class="Odd"><td align="right">24</td><td align="right">96079</td><td
align="right">357280</td><td align="right">105242</td><td
align="right">558601</td><td align="right">7719</td><td
align="right">18484</td><td align="right">109309</td><td
align="right">135512</td><td align="right">-76%</td><td
align="right">1653</td></tr>
</table>
</blockquote>
<p>
  The 'N' column indicates the
maximum number of concurrent threads for the kernel build (<tt>make&nbsp;-jN</tt>) for
each run.  The next four columns are the statistics for the baseline run
without zswap, followed by the same for the zswap run.  The I/O sum column
for each run is a sum of pswpin (pages swapped in), pswpout (pages swapped
out), and majflt (major page faults).  The difference between the baseline
and zswap runs is shown both in relative terms, as a percentage of I/O
reduction, and in absolute terms, as a reduction of X megabytes of I/O
related to swapping activity. 
<p>
A compressed swap cache reduces the efficiency of the page reclaim process.
For any store operation, the cache may allocate some pages to store the
compressed page.  This results in an reduction of overall page reclaim
efficiency.  This reduction in efficiency results in additional shrinking
pressure on the page cache causing an increase in major page faults where
pages must be re-read from disk.  In order to have a complete picture of
the I/O impact, the major page faults must be considered in the sum of I/O.
<p>
The next table shows the total runtime of the kernel builds:
<p>
<blockquote>
<table>
<tr><th colspan=4>Runtime (in seconds)</th></tr>
<tr><th>N</th><th>base</th><th>zswap</th><th>%change</th></tr>
<tr class="Odd"><td align="right">8</td><td align="right">107</td><td
align="right">107</td><td align="right">0%</td></tr> 
<tr class="Even"><td align="right">12</td><td align="right">128</td><td
align="right">110</td><td align="right">-14%</td></tr> 

<tr class="Odd"><td align="right">16</td><td align="right">191</td><td
align="right">179</td><td align="right">-6%</td></tr> 

<tr class="Even"><td align="right">20</td><td align="right">371</td><td
align="right">240</td><td align="right">-35%</td></tr> 

<tr class="Odd"><td align="right">24</td><td align="right">570</td><td
align="right">267</td><td align="right">-53%</td></tr> 
</table>
</blockquote>
<p>
The runtime impact of swap
activity is decreased when comparing runs with the same number of threads.
The rate of degradation is reduced for increasingly constrained runs when
comparing baseline and zswap. 
<p>
The measurements of 
average CPU utilization during the builds are:
<p>
<blockquote>
<table>
<tr><th colspan=4>%CPU utilization (out of 400% on 4 cpus)</th></tr>
<tr><th>N</th><th>base</th><th>zswap</th><th>%change</th></tr>
<tr class="Odd"><td align="right">8</td><td align="right">317</td><td
align="right">319</td><td align="right">1%</td></tr> 

<tr class="Even"><td align="right">12</td><td align="right">267</td><td
align="right">311</td><td align="right">16%</td></tr> 

<tr class="Odd"><td align="right">16</td><td align="right">179</td><td
align="right">191</td><td align="right">7%</td></tr> 

<tr class="Even"><td align="right">20</td><td align="right">94</td><td
align="right">143</td><td align="right">52%</td></tr> 

<tr class="Odd"><td align="right">24</td><td align="right">60</td><td
align="right">128</td><td align="right">113%</td></tr> 
</table>
</blockquote>
<p>
The CPU utilization table shows that with zswap, the kernel build is able
to make more productive use of the CPUs, as is expected from the runtime
results. 
<p>
Additional performance testing was performed using SPECjbb.  Metrics
regarding the performance improvements and I/O reductions that can be
achieved using zswap on both x86 and Power7+ (with and without hardware
compression acceleration), can be found on <a
href="http://ibm.co/WUnOkG">this page</a>.
<p>
<h4>Conclusion</h4>
<p>
Zswap is a compressed swap cache, able to evict pages from the compressed
cache, on an LRU basis, to the backing swap device when the compressed pool
reaches it size limit or the pool is unable to obtain additional pages from
the buddy allocator.  Its approach trades CPU cycles for reduced swap I/O.
This trade-off can result in a significant performance improvement as reads
to and writes from to the compressed cache are almost always faster that reading
from a swap device which incurs the latency of an asynchronous block I/O
read.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Memory_management-Swapping">Memory management/Swapping</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Transcendent_memory">Transcendent memory</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#zswap">zswap</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Jennings_Seth">Jennings, Seth</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/537422/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor537986"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The zswap compressed swap cache</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 14, 2013 9:12 UTC (Thu)
                               by <b>iq-0</b> (subscriber, #36655)
                              [<a href="/Articles/537986/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Does anybody know if this plays nicely with unbalenced NUMA systems, like trying to use the memory of another numa node when the current node is under pressure?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/537986/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor538397"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The zswap compressed swap cache</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2013 15:52 UTC (Fri)
                               by <b>sjennings</b> (guest, #74813)
                              [<a href="/Articles/538397/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
zswap is not NUMA aware for the moment. The current behavior would depend on the default behavior of the buddy allocator when getting pages for zswap's compressed pool.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/538397/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor538356"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The zswap compressed swap cache</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2013 10:58 UTC (Fri)
                               by <b>geuder</b> (guest, #62854)
                              [<a href="/Articles/538356/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
So how does zswap relate to zcache? (<a href="https://lwn.net/Articles/537760/">https://lwn.net/Articles/537760/</a> , <a href="http://lwn.net/Articles/397574/">http://lwn.net/Articles/397574/</a>)  Different problem or different solution? Mutually exclusive or could be combined inside the same kernel? Found also <a href="http://lwn.net/Articles/528817/">http://lwn.net/Articles/528817/</a>, but still a bit confused...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/538356/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor538401"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The zswap compressed swap cache</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2013 16:58 UTC (Fri)
                               by <b>sjennings</b> (guest, #74813)
                              [<a href="/Articles/538401/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Both zcache and zswap do compressed swap page caching.  However, zcache uses the tmem API internally that creates an abstraction layer for doing a number of other things like compressed file page caching via cleancache and, more recently, remote RAM (RAMster).<br>
<p>
So same problem, different solution.  zswap focuses solely on compressed swap caching which removes the need for an abstraction layer, resulting in a smaller code base.<br>
<p>
Both can be built in the same kernel, but you would only enable one at a time.  Both zswap and zcache are enabled through a boot parameters for now.<br>
<p>
Neither is in mainline yet and discussions are (or will be) ongoing on LKML about what to do going forward.  There has been a LSF/MM topic suggested for this very discussion (<a href="http://marc.info/?l=linux-mm&amp;m=135923138220901">http://marc.info/?l=linux-mm&amp;m=135923138220901</a>)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/538401/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor538824"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The zswap compressed swap cache</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 18, 2013 17:21 UTC (Mon)
                               by <b>djm1021</b> (guest, #31130)
                              [<a href="/Articles/538824/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
As Seth responded, zcache is part of a larger portfolio of inter-related code and objectives, called Transcendent Memory (or "tmem"), supporting different kinds of "input" data (frontends) and different "data stores" (backends).  Tmem and its friends are described here: <a href="http://lwn.net/Articles/454795/">http://lwn.net/Articles/454795/</a> <br>
Avi Miller gave a talk on it at linux.conf.au last month and the recording of that talk can be found here: <a href="http://mirror.linux.org.au/linux.conf.au/2013/ogv/Transcendent_Memory_Not_Just_for_Virtualization_Anymore.ogv">http://mirror.linux.org.au/linux.conf.au/2013/ogv/Transce...</a><br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/538824/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor538541"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Specialised compression method from 1999 paper</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 16, 2013 7:50 UTC (Sat)
                               by <b>CChittleborough</b> (subscriber, #60775)
                              [<a href="/Articles/538541/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      Some academics tried this technique back in 1999 using three compression methods, including one designed for memory contents rather than file contents. See "The Case for Compressed Caching in Virtual Memory Systems" by Paul R. Wilson, Scott F. Kaplan, Yannis Smaragdakis, Proc. 1999 Usenix Annual Tech. Conf. (<a href="http://www.usenix.org/events/usenix01/cfp/wilson/wilson.pdf">PDF</a>, <a href="http://citeseerx.ist.psu.edu/viewdoc/similar?doi=10.1.1.26.7895&type=ab">CiteSeerX</a>), especially section 2.
<p>
It might be worth adding one of these word-orientated, recency-based compressors to the kernel and trying it with zswap. (One problem: Wilson's compressor design assumes a 32-bit machine.)

      
          <div class="CommentReplyButton">
            <form action="/Articles/538541/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor571898"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Specialised compression method from 1999 paper (WKdm et al.)</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Oct 28, 2013 6:56 UTC (Mon)
                               by <b>phil</b> (guest, #91719)
                              [<a href="/Articles/571898/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Actually, Wilson's algorithms don't assume 32 bits, and work even better on 64-bit machines.  That's one reason they're used in the new version of OSX ("Mavericks") now.<br>
<p>
They assume that most stuff is more or less aligned on AT LEAST 32 bit boundaries, or can be passably approximated that way.<br>
<p>
So for example, they'll notice if a 32 bit word is all zeroes, or if it's zeroes in the upper 22 bits;  many integers are.<br>
<p>
For a 64 bit int that's zeroes in all but the low 10 bits, what will happen is that the first 32 bits will be encoded as a big zero, in two bits, and second 32 bits will be encoded as an "almost zero," in 2 + 10 = 12  bits, so you get 64 bits crammed into 2 + 12 = 14 bits, for a compression ratio greater than 4.<br>
<p>
Similar things happen with 64-bit patterns that aren't mostly zeroes, but are similar to other 64-bit patterns nearby in memory, as happens with many integers and most pointers.  Often integers are numerically similar to other integers nearby (e.g., in arrays that represent discretized smooth functions) and pointers are similar to other pointers nearby (e.g., other pointers into the same few kilobytes, megabytes or gigabytes holding related elements of some data structure).<br>
<p>
When you have one of those similar-to-something-nearby matches, a 32 bit word gets compressed to 2 tag bits plus 4 selector bits saying which recently-seen pattern it's similar to, plus 10 lower bits it that differ somewhere.  For a 32-bit partial match, that gives you a compression ratio of 2.  (2 + 4 + 10 = 16 / 32)<br>
<p>
But if you're actually looking at 64 bit pointers or ints, you're likely to do much better in the case of partial all-but-low-bits matches like that---the upper 4 bytes will compress to 6 bits, and the lower 4 bytes will compress to 16, for a compression ratio of 64 / (6 + 16 = 20) or greater than 3.<br>
<p>
The short version is that if you guess 32-bit alignment, you get pretty good compression very, very fast on 32-bit machines, and even better compression "for free" on 64-bit machines---and a shade faster still---, because 64 bit ints and pointers typically have even less information in their upper bytes than 32-bit ints and pointers. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/571898/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor538618"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The zswap compressed swap cache</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 17, 2013 5:00 UTC (Sun)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/538618/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>
To operate optimally as a cache, zswap should hold the most recently used pages. 
</blockquote>
<p>
Actually, to operate optimally, it should hold the soonest reused pages.  Looking for the most recently used pages is just one cheap way to approximate that.  As we know from decades of research, there's usually a high correlation between the two properties, but there are notable cases where they are anti-correlated.

      
          <div class="CommentReplyButton">
            <form action="/Articles/538618/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor564192"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">swap required?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 21, 2013 12:34 UTC (Wed)
                               by <b>falstaff</b> (guest, #92469)
                              [<a href="/Articles/564192/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Is a real swap space required to make use of the zswap cache? Since it intercepts the swap_writepage call, it looks to me like a requirement. However, I'm completely unaware which code paths are called with/without swap...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/564192/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor565969"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Swapping out compressed data?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Sep 6, 2013 16:57 UTC (Fri)
                               by <b>monnier</b> (guest, #92728)
                              [<a href="/Articles/565969/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Your description gives me the impression that when the data needs to be swapped to the actual storage, it is done uncompressed (more precisely it's uncompressed and then written to backing store).  That seems obviously suboptimal.  Is it indeed the case, or can the compressed data be swapped out compressed?<br>
<p>
Regarding the measurements: doing the measurement on machine with a crippled memory but a fast CPU seems unfair.  A machine with 512MB of RAM is unlikely to have such a fast CPU, and a slower CPU makes compression less attractive since compression then takes more time.  IOW measurements on a real 512MB machine (with something like a 1GHz Pentium, or an Allwinner A10) would seem more realistic.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/565969/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor665884"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Memory allocation in zswap</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 26, 2015 17:36 UTC (Thu)
                               by <b>sbasu</b> (guest, #105518)
                              [<a href="/Articles/665884/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I have a question regarding allocation of pool in zswap. It seems that zswap allocates memory for caching on-the-fly whenever it needs to store new compressed pages. But swapping will happen and there will be a page_io request to zswap  only when physical memory is full. At that time if zswap is trying to allocate from physical memory (which is already full) will it not get a -ENOMEM error always? Also will it not create more pressure on physical memory  that is already trying to swap out pages?<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/665884/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor932086"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">zsawp front load freeentry</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 17, 2023 12:03 UTC (Wed)
                               by <b>xjtudso</b> (guest, #152064)
                              [<a href="/Articles/932086/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
“The entry is not removed from the tree during a load; it remains up-to-date until the entry is invalidated.”<br>
In my understanding, if zpool entry is not freed after a load, zpool will be used up quickly. As I checked in zswap code:<br>
freeentry:<br>
	spin_lock(&amp;tree-&gt;lock);<br>
        /*<br>
          this is a local refcnt put, zswap entry refcnt will be 1, after put. And it will not be freed here.<br>
        */<br>
	zswap_entry_put(tree, entry);<br>
	spin_unlock(&amp;tree-&gt;lock);<br>
<p>
	return ret;<br>
}<br>
So should zswap entry be freed here with an extra global entry_put just like zswap write back?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/932086/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2013, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
