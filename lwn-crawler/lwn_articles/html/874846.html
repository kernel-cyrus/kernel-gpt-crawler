        <!DOCTYPE html>
        <html lang="en">
        <head><title>Intel AMX support in 5.16 [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/874846/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/875076/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/874846/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Intel AMX support in 5.16</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>LWN.net needs you!</b>
<p>
Without subscribers, LWN would simply not exist.  Please consider
       <a href="/Promo/nst-nag2/subscribe">signing up for a subscription</a> and helping
       to keep LWN publishing.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>November 8, 2021</br>
           </div>
The x86 instruction set is large, but that doesn't mean it can't get bigger
yet.  Upcoming Intel processors will feature a new set of instructions
under the name of "Advanced Matrix Extensions" (AMX) that can be used to
operate on matrix data.  After a somewhat bumpy development
process, support for AMX has found its way into the upcoming 5.16 kernel.
Using it will, naturally, require some changes by application developers.
<p>
AMX (which is described in <a
href="https://software.intel.com/content/dam/develop/external/us/en/documents-tps/architecture-instruction-set-extensions-programming-reference.pdf">this
document</a>) is meant to be a general architecture for the acceleration of
matrix 
operations on x86 processors.  In its initial form, it implements a set of
up to eight "tiles", which are arrays of 16&nbsp;64-byte rows.
Programmers can store matrices in these tiles of any dimension that will
fit therein; a matrix of 16x16 32-bit floating-point values would work, but other
geometries are supported too.  The one supported operation currently will
multiply the matrices stored in two tiles, then add the result to a third tile.
By chaining these
operations, multiplication of matrices of any size can be implemented.  Evidently
other operations are meant to come in the future.
<p>
While AMX may seem like a feature aimed at numerical analysis, the real
target use case would appear to be machine-learning applications.  That
would explain why 16-bit floating-point arithmetic is supported, but 64-bit
is not.

<p>
The design of AMX gives the kernel control over whether these
features can be used by any given process.  There are a couple of reasons
for this, one being that AMX instructions, as one might imagine, use a lot
of processor resources.  A process doing heavy AMX work on a shared
computer may adversely affect other processes.  But AMX also cannot be
supported properly unless both the kernel and the user-space process are
ready for it.
<p>
<h4>Development process</h4>
<p>
Support for AMX was first <a
href="/ml/linux-kernel/20201001203913.9125-1-chang.seok.bae@intel.com/">posted</a>
by Chang Bae in October 2020, but got relatively few review comments.  By
the time <a
href="/ml/linux-kernel/20210221185637.19281-1-chang.seok.bae@intel.com/">version&nbsp;4</a>
came out in February, more developers were paying attention, and they were
not entirely pleased with how this feature was being integrated into the
kernel's existing floating-point unit (FPU) code.  Various versions
followed, with the frustration level seeming to increase; at the end of
September, Len Brown posted <a
href="/ml/linux-kernel/CAJvTdKkK=_pp1PrWdh1_GN73VifuAkivnErgK+bo2h34Vd_55w@mail.gmail.com/">minutes
from a conversation</a> that, seemingly, showed a path forward.
<p>

Unfortunately, <a
href="/ml/linux-kernel/20211001223728.9309-1-chang.seok.bae@intel.com/">version&nbsp;11</a>,
posted the very next day, seemed to ignore many of the decisions that had
been made.  This posting drew <a
href="/ml/linux-kernel/87k0iuhq8b.ffs@tglx/">a sharp rebuke</a> from Thomas
Gleixner, who felt that the feature was being shoved into the kernel
without listening to the complaints that were being raised.  Things weren't
looking great for AMX, but work was happening behind the scenes; in
mid-October, Gleixner posted <a
href="/ml/linux-kernel/20211011215813.558681373@linutronix.de/">a massive
reworking of the FPU code</a> meant to ease the task of supporting AMX.  <a
href="/ml/linux-kernel/20211021225527.10184-1-chang.seok.bae%40intel.com/">A
new AMX patch set</a> followed shortly thereafter, and that, more or less,
is what ended up in&nbsp;5.16.
<p>
Gleixner's <a
href="/ml/linux-kernel/163572865296.3357115.3707320162730818106.tglx%40xen13/">pull
request</a> for this code acknowledged its relatively unseasoned nature:
<p>
<blockquote class="bq">
	Note, this is relatively new code despite the fact that AMX support
   	is in the works for more than a year now.
<p>
   	The big refactoring of the FPU code, which allowed to do a proper
   	integration has been started exactly 3 weeks ago. Refactoring of
   	the existing FPU code and of the original AMX patches took a week
   	and has been subject to extensive review and testing. The only
   	fallout which has not been caught in review and testing right away
   	was restricted to AMX enabled systems, which is completely
   	irrelevant for anyone outside Intel and their early access
   	program. There might be dragons lurking as usual, but so far the
   	fine grained refactoring has held up and eventual yet undetected
   	fallout is bisectable and should be easily addressable before the
   	5.16 release. Famous last words...
</blockquote>
<p>
The FPU code is relatively tricky, low-level stuff, so it would indeed be
unsurprising to find a dragon or two lurking in the new work.
<p>
<h4>Using AMX</h4>
<p>
As noted above, the kernel is able to control which processes are able to
use the AMX instructions.  The first step for a user-space process would be
to use a new <a
href="https://man7.org/linux/man-pages/man2/arch_prctl.2.html"><tt>arch_prctl()</tt></a>
command (<tt>ARCH_GET_XCOMP_SUPP</tt>) to get a list of supported features; if
the appropriate bit is set in the result, AMX is available.  Then, another
<tt>arch_prctl()</tt> command (<tt>ARCH_REQ_XCOMP_PERM</tt>) can be used to
request permission to use AMX.  Some checks are made (one to be described
shortly), and there is an opportunity for security modules to express an
opinion as well.  Normally, though, the request will be granted.
Permissions apply to all threads in a process and are carried over a fork;
calling <tt>execve()</tt> will reset them, though.
<p>
One challenge presented by AMX is that processors can create a great deal
of internal state while the AMX instructions are running.  If the CPU is
interrupted in the middle of an operation, that state must be saved
somewhere or a lot of work could be lost.  So, if a process is using AMX,
the kernel must be prepared to save up to about 10KB of data in its
interrupt handlers before doing much of anything else.  This saving is done
using the <tt>XSAVE</tt> instruction.
<p>
The kernel allocates memory for each process that can be used for this
purpose.  Allocating 10KB for every process in the system would waste a lot
of memory, though; most processes will never use AMX instructions.
Happily, the processor can be configured to trap into the kernel the
first time any process executes an AMX instruction; the kernel can then
check whether permission to use those instructions has been granted and, if
so, allocate an appropriately sized buffer to hold the FPU state and allow
the operation to continue.
<p>
One potential problem has to do with the <a
href="https://man7.org/linux/man-pages/man2/sigaltstack.2.html"><tt>sigaltstack()</tt>
system call</a>, which allows a thread to establish a new stack for signal
handling.  That stack, too, must be large enough to hold the FPU state if
the process involved is using AMX.  For years, developers have been told to
use <tt>MINSIGSTKSZ</tt> as the minimum size for this stack; that size,
which is 2KB, is nowhere near large enough for AMX-using processes.
Indeed, it is not even large enough to use the <a
href="https://en.wikipedia.org/wiki/AVX-512">AVX-512 extensions</a>, a fact
that has caused some corrupted-stack problems in the past.
<p>
To avoid this problem for AMX, the kernel will check to ensure that all
signal stacks are sufficiently large.  This check is done at each call to
<tt>sigaltstack()</tt>, but a check of existing stacks is also done when a
process requests permission to use AMX in the first place.  Processes not
using AMX will not need the larger stack and, thus, will not be broken by
these checks.  Processes that <i>do</i> want to use AMX will not be allowed
to unless all of their signal stacks are big enough.
<p>
Once the infrastructure to perform these checks was put in place, the
kernel also gained the ability to ensure that processes using AVX-512 have
adequately sized signal stacks.  Enforcing that condition, though, has the
potential to 
break applications that seemingly work now, perhaps because their signal
handlers are never actually called.  To avoid this problem, there is a
kernel configuration option (<tt>STRICT_SIGALTSTACK_SIZE</tt>) and a
command-line option (<tt>strict_sas_size=</tt>), either of which can be
used to control 
whether the strict checks are carried out when AVX-512 is in use.
<p>
Assuming that all of the pieces hold together, this is the form that AMX
support will take in 5.16.  Those wanting more information can look at the
commits containing <a href="https://git.kernel.org/linus/6a3e0651b4a0">AMX
test cases</a> and <a href="https://git.kernel.org/linus/d7a9590f608d">some
documentation</a> on the <tt>arch_prctl()</tt> commands.  Meanwhile, keep
an eye out for dragons for the next nine weeks or so.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Architectures-x86">Architectures/x86</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Releases-5.16">Releases/5.16</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/874846/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor875436"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">packet processing</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 8, 2021 16:30 UTC (Mon)
                               by <b>mtaht</b> (subscriber, #11087)
                              [<a href="/Articles/875436/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
maybe I&#x27;m weird, but why aren&#x27;t we ever seeing any improvements for packet processing? For most workloads the SSE side of the chip is idle, and yet a few instructions (invsqrt for codel, all sorts of comparisons and masking stuff for ipv6 traffic) would probably help there.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/875436/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor875450"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">packet processing</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 8, 2021 18:33 UTC (Mon)
                               by <b>mebrown</b> (subscriber, #7960)
                              [<a href="/Articles/875450/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Last time I checked, the kernel code could not use FPU instructions, which includes SSE and all these newer instructions.<br>
<p>
... aaand after a quick google search: &quot;kernel_fpu_begin() / kernel_fpu_end()&quot;<br>
<p>
looks like they added a standardized way to do FPU/SSE/etc in the kernel. Likely the reason it&#x27;s not used in packet processing is that you&#x27;d have to call the above functions, and the speed increase would have to be worth the fpu state save/restore.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/875450/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor875477"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">packet processing</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 9, 2021 8:59 UTC (Tue)
                               by <b>Sesse</b> (subscriber, #53779)
                              [<a href="/Articles/875477/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
In addition to what mebrown said, there _is_ a fast instruction for inverse square root (rsqrtss).<br>
<p>
In general, packet processing is not dominated by a single operation; it&#x27;s more like various small tasks all over, so one specific instruction is unlikely to help a whole lot. But CPUs just getting generally faster helps, of course (even though there was a long time where progress was rather disappointing).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/875477/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor875557"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">packet processing</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 10, 2021 7:34 UTC (Wed)
                               by <b>flussence</b> (guest, #85566)
                              [<a href="/Articles/875557/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I imagine anyone with a workload where they need SIMD to keep up with line rate is already using a userspace thing like DPDK where they can use all the fancy instruction sets they want, along with heavily tuning scheduling, core isolation, PREEMPT_RT and the like (SSE, context switches, tolerable latency - pick 2)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/875557/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor875439"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Intel AMX support in 5.16</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 8, 2021 16:38 UTC (Mon)
                               by <b>ncm</b> (guest, #165)
                              [<a href="/Articles/875439/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Quality reporting like this keeps me subscribed to LWN.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/875439/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor875576"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Intel AMX support in 5.16</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 10, 2021 11:36 UTC (Wed)
                               by <b>epa</b> (subscriber, #39769)
                              [<a href="/Articles/875576/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I wondered whether this was the feature derided as a waste of silicon by Linus.  But no, that was AVX-512: <a href="https://www.realworldtech.com/forum/?threadid=193189&amp;curpostid=193190">https://www.realworldtech.com/forum/?threadid=193189&amp;...</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/875576/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor875716"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Intel AMX support in 5.16</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 10, 2021 18:40 UTC (Wed)
                               by <b>jak90</b> (subscriber, #123821)
                              [<a href="/Articles/875716/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
And just like that, AVX-512 is indeed kind of a waste of silicon on Alder Lake processors right now, since firmware if at all only allows the choice between AVX-512 support on performance cores and enabling efficiency cores, to avoid asymmetry entirely.<br>
For what dubious advantages it brings to the table, it would need a distinction from the OS to either declare that a task is planning to use AVX-512 instructions or to restrict it to performance cores on the first related illegal instruction encountered on an efficiency core.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/875716/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor875733"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Intel AMX support in 5.16</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 10, 2021 22:25 UTC (Wed)
                               by <b>bartoc</b> (guest, #124262)
                              [<a href="/Articles/875733/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
both options are kinda bad though, you don&#x27;t want just &quot;I&#x27;m going to use AVX-512 please pin me&quot; you also need to tell the scheduler when you&#x27;re done using it. Similarly if the kernel just pins on the first illegal instruction it would need to occasionally unpin if it wants to be able to do the non-avx512 things on the non-avx cores.<br>
<p>
Also, most apps using avx-512 are not doing it unconditionally, but rather call cpuid and check the results. Because cpuid completely serializes execution it&#x27;s very much not fast, and so apps tend to just call it once, in a static initializer or similar. calling it before each portion of code using AVX-512 is just not fast at all, so you&#x27;d want to make the &quot;can I do avx-512&quot; part of the per-thread state, and have the scheduler change it for you when it decided to schedule you on a CPU with different features.<br>
<p>
For AVX-512 on something like alder lake I think you&#x27;d need a system call that&#x27;s essentially &quot;do I have AVX-512&quot; and the kernel could say yes or no (even if there are some cores with AVX-512), but if it said yes then it would promise not to schedule you on any cores without AVX-512 until you were done. Hopefully this would be implementable without actually making a real transition to kernel mode by setting some per-thread flag the scheduler could look at when needed. Even this (pretty complicated) mechanism poses some problems, because apps might not tell the kernel when they are done, either because they forget, or because the kernel told them they could use the fancy instructions and they don&#x27;t want to give the core back. This would be a particular problem on laptops where I&#x27;d imagine the kernel might want to get everyone off the P cores so they could be completely powered off. Unfortunately once the app has started doing it&#x27;s fancy AVX-512 things the kernel can&#x27;t unilaterally decide to take back the permission to do AVX-512, as even if it handled the illegal instructions after moving the thread to an E core it can&#x27;t go back in time to have the process take the non-avx branch. So you might get situations (a little like with switchable graphics) where you have long running apps that ask for AVX-512, don&#x27;t tell the kernel when they are done with it, and then cause pretty dramatic reductions in battery life for no reason.<br>
<p>
I suppose the kernel _could_ forcibly reschedule the process by somehow implementing a software version of the AVX-512 instructions, that way you&#x27;d just get somewhat extreme slowness.<br>
<p>
Another option would be for intel themselves to implement such software versions of AVX-512 instructions, and use their execution as input into their new hardware scheduler thingy to indicate that maybe the thread should be scheduled on a P core.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/875733/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor875771"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Intel AMX support in 5.16</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 11, 2021 10:05 UTC (Thu)
                               by <b>wtarreau</b> (subscriber, #51152)
                              [<a href="/Articles/875771/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
No, the situation is much worse: applications are using it by accident during a memcpy() or such stuff that they most often do not even require the tiny savings brought by the instruction set, and such calls may happen way more often than one would accept to migrate the tasks, so the real result is that any task using a given libc would end up running exlusively on the avx-enabled core. What we really need is to turn such features into opt-in at the libc level so that we&#x27;re not inflicted that trouble without consent. And by the way there are plenty of cases where using this significantly lowers the CPU&#x27;s frequency and dramatically slows down the useful workload, which is another reason some people explicitly disable AVX512 on their machines.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/875771/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor875818"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Intel AMX support in 5.16</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 11, 2021 18:07 UTC (Thu)
                               by <b>anton</b> (subscriber, #25547)
                              [<a href="/Articles/875818/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      AVX slowdown and even AVX-512 slowdown <a href="https://travisdowns.github.io/blog/2020/08/19/icl-avx512-freq.html">does not seem to be bad</a> in recent Intel CPUs.

<p>I think that AVX-512 support on heterogeneous CPUs where some cores don't support AVX-512 is not a big problem.  There are several ways to deal with the situation. Sure you can come up with a scenario for every one of them where you would prefer a different result, but even in these scenarios the disadvantage of the not-preferred result is not that big, certainly not worse than outright disabling AVX-512 or outright disabling E-cores.

<p>E.g. if you automatically reduce the cpu-list of a thread to the P-cores once an AVX-512 instructions is used, the worst case is that the E-cores won't be used.  I guess many threads don't use AVX-512, so there is enough left for the E-cores; as for memcpy() and friends, the code for selecting the actual routine could be made more CPU-specific (rather than just checking the AVX-512 flags in cpuinfo).

<p>Alternatively, only report the AVX-512 flags on threads where the cpu-list is limited to the cores that have AVX-512.  So you won't get AVX-512 on ordinary threads.  Given that relatively few code actually makes significant use of AVX-512, it's not a big problem that the user then has to call such code with taskset or somesuch.

<p>In any case, in order to have such problems at all, we need CPUs that enable AVX-512 at the same time as E-cores.  From what I read, Intel wanted to give us no AVX-512 at all, and board manufacturers give us either AVX-512 or E-cores, but not both.






      
          <div class="CommentReplyButton">
            <form action="/Articles/875818/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor875859"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Intel AMX support in 5.16</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 12, 2021 11:44 UTC (Fri)
                               by <b>wtarreau</b> (subscriber, #51152)
                              [<a href="/Articles/875859/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I also noticed newer cores are less impacted by this, they&#x27;re making progress.<br>
<p>
For memcpy() ideally the solution would be to only consider features that intersect all CPUs the task may run on, and not just the starting one. It&#x27;s not much complicated after all, the most painful part is already done (except if it&#x27;s relying on a cpuid instruction).<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/875859/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor876539"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Intel AMX support in 5.16</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 19, 2021 17:48 UTC (Fri)
                               by <b>flussence</b> (guest, #85566)
                              [<a href="/Articles/876539/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Intel&#x27;s painted themselves into a corner with this design of putting exponentially-expanding vector instructions inline in the x86 ISA. Interestingly it looks like Apple are doing a thing similar to AMX, but they&#x27;ve put it in a separate part of the chip (and their users have to use an OpenCL-ish library to get at it). Higher overhead as a result but it also means they keep the performance/efficiency core arrangement without dealing with instruction set mismatches, or all of AVX512&#x27;s downclocking ballet, or humongous context switch overhead.<br>
<p>
I think with the way things are headed, other CPUs are going to follow the uncore design and AVX512 itself is going to get Itanium&#x27;d out of existence.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/876539/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor876545"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Intel AMX support in 5.16</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 20, 2021 13:12 UTC (Sat)
                               by <b>farnz</b> (subscriber, #17727)
                              [<a href="/Articles/876545/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <p>There is also the ARM SVE2 or <a href="https://github.com/riscv/riscv-v-spec/releases/tag/v1.0">RISC-V V extension</a> route to allowing for large vectors. In both designs, you have the same instructions used regardless of the number of elements in the vector, and the length of the vector is agreed between software and hardware at runtime. SVE2 allows for the vector to be up to 2048 bits long, while RISC-V V extension permits the vector to be up to 65536 bits in length.
<p>In both cases, the hardware can choose how long the implemented vectors actually are, and there are ways for software to find out how large the real vectors are; for code that's happy getting ~90% of the possible speed-up from vector execution, they're designed so that you run a loop asking the hardware to choose as large a vector length as possible that's smaller than the total elements to process, and repeat until you've exhausted the data to process. For code that needs all the possible speed-up, you'll need to worry about the vector length your target CPUs support, but that's less common.


      
          <div class="CommentReplyButton">
            <form action="/Articles/876545/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2021, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
