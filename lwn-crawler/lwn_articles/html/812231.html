        <!DOCTYPE html>
        <html lang="en">
        <head><title>Revisiting stable-kernel regressions [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/812231/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/812406/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/812231/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Revisiting stable-kernel regressions</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Did you know...?</b>
<p>
LWN.net is a subscriber-supported publication; we rely on subscribers
       to keep the entire operation going.  Please help out by <a
       href="/Promo/nst-nag4/subscribe">buying a subscription</a> and keeping LWN on the
       net.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>February 13, 2020</br>
           </div>
Stable-kernel updates are, unsurprisingly, supposed to be stable; that is
why the first of the <a
href="https://www.kernel.org/doc/html/latest/process/stable-kernel-rules.html">rules
for stable-kernel patches</a> requires them to be "<q>obviously correct
and tested</q>". 
Even so, 
for nearly as long as the kernel community has been producing stable update
releases, said community has also been complaining about regressions that
make their way into
those releases.  Back in 2016, LWN <a href="/Articles/692866/">did some
analysis</a> that showed the presence of regressions in stable releases, though
at a rate that many saw as being low enough.  Since then, the volume of
patches showing up in stable releases has grown considerably, so perhaps
the time has come to see what the situation with regressions is with current stable kernels.
<p>
As an example of the number of patches going into the stable kernel
updates, consider that, as of 4.9.213, 15,648 
patches have been added to the original 4.9 release — that is an entire
development cycle worth of patches added to a "stable" kernel.  Reviewing
all of those to see whether each contains a regression is not practical,
even for the maintainers of the stable updates.  But there is an automated
way to get a sense for how many of those stable-update patches bring
regressions with them. 
<p>
The convention in the kernel community is to add a <tt>Fixes</tt> tag to
any patch fixing a bug introduced by another patch; that tag includes the
commit ID for the original, buggy patch.  Since stable kernel releases are
supposed to be limited to fixes, one would expect that almost every patch
would carry such a tag.  In the real world, about 40-60% of the commits to
a stable series carry <tt>Fixes</tt> tags; the proportion appears to be
increasing over time as the discipline of adding those tags improves.
<p>
It is a relatively straightforward task (for a computer) to look at the
<tt>Fixes</tt> tag(s) in any patch containing them, extract the commit IDs
of the buggy patches, and see if those patches, too, were added in a stable
update.  If so, it is possible to conclude that the original patch was
buggy and caused a regression in need of fixing.
There are, naturally, some complications, including the fact that
stable-kernel commits have different IDs than those used in the mainline
(where all fixes are supposed to appear first); associating fixes with
commits requires creating a mapping between the two.  Outright reverts of
buggy patches tend not to have <tt>Fixes</tt> tags, so they must be caught
separately.  And so on.  The end result will necessarily contain some
noise, but there is a useful signal there as well.
<p>
For the curious, this analysis was done with the <tt>stablefixes</tt> tool,
part of the <tt>gitdm</tt> collection of repository data-mining hacks.
It can be cloned from <tt>git://git.lwn.net/gitdm.git</tt>.
<p>
Back in 2016, your editor came up with a regression rate of at least 2% for
the longer-term stable kernels that were maintained at that time.  The 4.4
series, which had 1,712 commits then, showed a regression rate of at least
2.3%.  Since then, the number of commits has grown considerably — to 14,211
in 4.4.213 — as a result of better discipline and the use of automated
tools (including <a href="/Articles/764647/">a machine-learning system</a>)
to select fixes that were not explicitly earmarked for stable backporting.
Your editor fixed up his script, ported it to Python&nbsp;3, and reran the
analysis for the currently supported stable kernels; the results look like
this.
<p>
<blockquote>
<table class="OddEven">
  <tr><th>Series</th><th>Commits</th><th colspan=2>Tags</th><th>Fixes</th>
      <th>Reverts</th><th></th></tr>
  <tr><td>5.4.18</td>
      <td align="right">2,423</td>
      <td align="right">1,482</td>
      <td align="right">61%</td>
      <td align="right">74</td>
      <td align="right">29</td>
      <td><a href="/Articles/812232/">Details</a></td></tr>
  <tr><td>4.19.102</td>
      <td align="right">11,758</td>
      <td align="right">5,647</td>
      <td align="right">48%</td>
      <td align="right">588</td>
      <td align="right">100</td>
      <td><a href="/Articles/812233/">Details</a></td></tr>
  <tr><td>4.14.170</td>
      <td align="right">15,527</td>
      <td align="right">6,727</td>
      <td align="right">43%</td>
      <td align="right">985</td>
      <td align="right">134</td>
      <td><a href="/Articles/812234/">Details</a></td></tr>
  <tr><td>4.9.213</td>
      <td align="right">15,647</td>
      <td align="right">6,286</td>
      <td align="right">40%</td>
      <td align="right">951</td>
      <td align="right">139</td>
      <td><a href="/Articles/812235/">Details</a></td></tr>
  <tr><td>4.4.213</td>
      <td align="right">14,210</td>
      <td align="right">5,110</td>
      <td align="right">36%</td>
      <td align="right">834</td>
      <td align="right">124</td>
      <td><a href="/Articles/812236/">Details</a></td></tr>
</table>

</blockquote>
<p>
In the above table, <b>Series</b> identifies the stable kernel that was
looked at.  <b>Commits</b> is the number of commits in that series, while
<b>Tags</b> is the number and percentage of those commits with a
<tt>Fixes</tt> tag.  The count under <b>Fixes</b> is the number of commits
in that series that are explicitly fixing another commit applied to that
series.  <b>Reverts</b> is the number of those fixes that were outright reverts;
a famous person might once have said that reversion is the sincerest form
of patch criticism.  
Hit the "Details" link for a list of the fixes found for each series.
<p>
Looking at those numbers would suggest that, for example, 3% of the commits
in 5.4.18 are fixing other commits, so the bad commit rate would be a
minimum of&nbsp;3%.  The situation is not actually that simple, though, for
a few reasons.  One of those is that a surprising number of the regression
fixes appear in the same stable release as the commits they are fixing.  In
a case like that, while the first commit can indeed be said to have
introduced a regression, no stable release actually contained the
regression and no user will have ever run into it.  Counting those is not
entirely fair.  If one subtracts out the same-release fixes, the results
look like this:
<p>
<blockquote>
<table class="OddEven">
  <tr><th>Series</th><th>Fixes</th><th>Same<br>release</th><th>Visible<br>regressions</th></tr>
  <tr><td>5.4.18</td>
      <td align="right">74</td>
      <td align="right">29</td>
      <td align="right">45</td></tr>
  <tr><td>4.19.102</td>
      <td align="right">588</td>
      <td align="right">176</td>
      <td align="right">412</td></tr>
  <tr><td>4.14.170</td>
      <td align="right">985</td>
      <td align="right">253</td>
      <td align="right">732</td></tr>
  <tr><td>4.9.213</td>
      <td align="right">951</td>
      <td align="right">229</td>
      <td align="right">722</td></tr>
  <tr><td>4.4.213</td>
      <td align="right">834</td>
      <td align="right">232</td>
      <td align="right">602</td></tr>
</table>
</blockquote>
<p>
Another question to keep in mind is what to do with all those commits without
<tt>Fixes</tt> tags.  Many of them are certainly fixes for bugs introduced
in other patches, but nobody went to the trouble of figuring out how the
bugs happened.  If the numbers in the table above are taken as the total
count of regressions in a stable series, that implies that none of the
commits without <tt>Fixes</tt> tags are fixing regressions, which will
surely lead to undercounting regression fixes overall.
On the other hand, if one assumes that the untagged commits contain
regression fixes in the same proportion as the tagged ones, the result
could well be a count that is too high.
<p>
Perhaps the best thing that can be done is to look at both numbers, with a
reasonable certainty that the truth lies somewhere between them:
<p>
<blockquote>
<table class="OddEven">
  <tr><th rowspan=2>Series</th><th rowspan=2>Visible<br>regressions</th>
      <th colspan=2>Regression rate</th></tr>
  <tr><th>Low</th><th>High</th></tr>
  <tr><td>5.4.18</td>
      <td align="right">45</td>
      <td align="right">1.9%</td>
      <td align="right">3.0%</td></tr>
  <tr><td>4.19.102</td>
      <td align="right">412</td>
      <td align="right">3.5%</td>
      <td align="right">7.3%</td></tr>
  <tr><td>4.14.170</td>
      <td align="right">732</td>
      <td align="right">4.7%</td>
      <td align="right">10.9%</td></tr>
  <tr><td>4.9.213</td>
      <td align="right">722</td>
      <td align="right">4.6%</td>
      <td align="right">11.5%</td></tr>
  <tr><td>4.4.213</td>
      <td align="right">602</td>
      <td align="right">4.2%</td>
      <td align="right">11.8%</td></tr>
</table>

</blockquote>
<p>
So that is about as good as the numbers are going to get, though there are
still some oddball issues.  Consider the case of <a
href="https://git.kernel.org/linus/4abb951b73ff">mainline commit
4abb951b73ff</a> ("ACPICA: AML interpreter: add region addresses in global
list during initialization").  This commit included a
"<tt>Cc:&nbsp;stable@vger.kernel.org</tt>" tag, so it was duly included (as
<a 
href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit?id=22083c028d0b3ee419232d25ce90367e5b25df8f">commit
22083c028d0b</a>) in the 4.19.2 release.  It was then <a
href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit?id=8ef305fbc50d93cc7e2f594abcf9546f3afbd435">reverted</a>
in 4.19.3, with the complaint that it didn't actually fix a bug but did
cause regressions.  
This same change <a
href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit?id=87403e35bc56">returned</a>
in 4.19.6 after an explicit <a
href="/ml/linux-kernel/20181214174220.GA30170%40kroah.com/">request</a>.
Then, two commits followed in 4.19.35:  commit <a
href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit?id=d4b4aeea5506">d4b4aeea5506</a>
addressed a related issue and the original upstream commit in a <tt>Fixes</tt> tag, while
<a
href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git/commit?id=f8053df634d4">f8053df634d4</a>
claimed to <i>be</i> the original upstream commit, which had already been
applied.  That last one looks like a fix for a partially done backport.
How does one try to
account for a series of changes like that?  Honestly, one doesn't even
try. 
<p>
So what can we conclude from all this repository digging?  The regression
rates seen in 2016 were quite a bit lower than what we are seeing now; that
would suggest that the increasing volume of patches being applied to the
stable trees is not just increasing the number of regressions, but also the
rate of regressions.  That is not a good sign.  On the other hand, the
amount of grumbling about stable regressions seems to have dropped
recently.  Perhaps that's just because people have gotten used to the
situation.  Or perhaps the worst problems, such as filesystem-destroying regressions, are no
longer getting through, while the problems that do slip through are
relatively minor.
<p>
Newer kernels have a visibly lower regression rate than the older ones.
There are two equally plausible explanations for that.  Perhaps the process
of selecting patches for stable backporting is getting better, and fewer
regressions are being introduced than were before.  Or perhaps those
kernels just haven't been around for long enough for all of the regressions
already introduced to be found and fixed yet.  The 2016 article looked at
4.4.14, which had 39 regression fixes (19 fixed in the same release).
4.4.213 now contains 110 fixes for regressions introduced in 4.4.14 or
earlier (still 19 fixed in the same release).  So there is ample reason to
believe that the regression rate in 5.4.18 is higher than indicated above.
<p>
In any case, it seems clear that the push to get more and more fixes into
the stable trees is unlikely to go away anytime soon.  And perhaps that is
a good thing; a stable tree with thousands of fixes and a few regressions
may still be far more stable than one without all those patches.  Even so,
it would be good to keep an eye on the regression rate; if that is allowed
to get too high, the result is likely to be users moving away from stable
updates, which is definitely not the desired result.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Development_model-Stable_tree">Development model/Stable tree</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/812231/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor812416"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 13, 2020 17:35 UTC (Thu)
                               by <b>arjan</b> (subscriber, #36785)
                              [<a href="/Articles/812416/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
another angle might also be that backports to very recent kernels (so small delta in the general code base) is less regression-prone than "much further back" backports which take code tested in one code base into a very different codebase<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812416/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor812419"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 13, 2020 17:59 UTC (Thu)
                               by <b>josh</b> (subscriber, #17465)
                              [<a href="/Articles/812419/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Or more recent stable kernels have had less time for people to notice regressions, and their numbers will get worse over time.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812419/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor812423"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 13, 2020 18:29 UTC (Thu)
                               by <b>arjan</b> (subscriber, #36785)
                              [<a href="/Articles/812423/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
yeah many options<br>
<p>
maybe the analysis to answer that is how many regressions are in the early stable numbers (so .1 to say .20 or whatever) compared to higher number last digits<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812423/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor812448"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 14, 2020 4:44 UTC (Fri)
                               by <b>sashal</b> (<b>&#x272D; supporter &#x272D;</b>, #81842)
                              [<a href="/Articles/812448/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I keep running this sort of analysis myself quite often to make sure that what we're doing with stable trees makes sense, and one gotcha that I feel that this article missed is the rate of "Fixes:" tags in upstream commits.<br>
<p>
Either we're getting better at finding bugs (and we are!), or people are getting more disciplined about tagging commits with the Fixes: tag, but consider the following:<br>
<p>
$ git log --oneline --no-merges -i --grep "fixes:" v4.4..v4.9 | wc -l<br>
4912<br>
$ git log --oneline --no-merges v4.4..v4.9 | wc -l<br>
67476<br>
$ git log --oneline --no-merges -i --grep "fixes:" v4.14..v4.19 | wc -l<br>
8562<br>
$ git log --oneline --no-merges v4.14..v4.19 | wc -l<br>
69363<br>
$ git log --oneline --no-merges -i --grep "fixes:" v5.0..v5.5 | wc -l<br>
10635<br>
$ git log --oneline --no-merges v5.0..v5.5 | wc -l<br>
70632<br>
<p>
So while only 7.3% of the commits between 4.4 and 4.9 had a Fixes: tag, we see that rate jump to %12.3 of the commits between 4.14 and 4.19, and again jump to %15 between 5.0 and 5.5 - more than double(!) of what we've been seeing between 4.4 and 4.9.<br>
<p>
I'd argue that if we're seeing an increase of Fixes: tags upstream, we're bound to see a similar increase in stable trees, even if the actual regression rate in stable trees has remained the same (or have gone down - which can explain your observation regarding less grumblings :) ).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812448/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor812454"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 14, 2020 7:43 UTC (Fri)
                               by <b>cpitrat</b> (subscriber, #116459)
                              [<a href="/Articles/812454/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The increase of proportion of patches with Fixes tags is mentioned in the article, and numbers take that into account (at least the new ones, not sure about the old ones). Did I miss a subtle difference in what you point out ?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812454/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor812495"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 14, 2020 14:43 UTC (Fri)
                               by <b>sashal</b> (<b>&#x272D; supporter &#x272D;</b>, #81842)
                              [<a href="/Articles/812495/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It looked to me like the article only looks at the increase of Fixes tags in the context of stable trees, without looking at a corresponding increase in the upstream tree.<br>
<p>
An interesting comparison might be to analyze how many upstream Fixes: tags fix something from a "current" merge window vs older release.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812495/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor812514"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 14, 2020 21:21 UTC (Fri)
                               by <b>tytso</b> (subscriber, #9993)
                              [<a href="/Articles/812514/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
My understanding of the article was that it was looking at Fixes: tags which point at a commit which was introduced in the stable kernel series.   The analysis then excluded those commits which introduced a bug in the stable kernel, but where the Fix was added before it was visible --- that is, where the regression and the fix for the regression both happened between X.Y.Z and X.Y.Z+1, so that the regression was not visible to the user.  This might happen if the first commit fixed a real problem, but had a side effect which was bad, and then the fix which fixed the side effect was backported in the same stable kernel release.<br>
<p>
It would seem to me that a really interesting thing to do would be to identify those commits in stable kernels which caused a regression (e.g., which had a commit which had an applicable fixes line later on), and see if we can identify any kind of machine learning features for commits that are likely to be problematic, and perhaps use that to delay the length of time between when a commit which might be at risk of introducing an a regression lands in Linus's tree, and when it gets picked up by a stable branch.   <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812514/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor812517"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 14, 2020 21:38 UTC (Fri)
                               by <b>sashal</b> (<b>&#x272D; supporter &#x272D;</b>, #81842)
                              [<a href="/Articles/812517/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Right, but if more "Fixes:" tags appear upstream, does it mean we introduce more regressions, or are we better at fixing/tagging?<br>
<p>
With regards to your question, I've actually looked into that and did a talk last year (LWN covered it here: <a href="https://lwn.net/Articles/803695/">https://lwn.net/Articles/803695/</a>). Based on the results, it seemed to me that letting -rc patches (and especially late -rc cycle patches) spend more time in -next would be valuable as those tend to be buggy.<br>
<p>
I raised it with Linus at the Maintainer's summit (<a href="https://lwn.net/Articles/799219/">https://lwn.net/Articles/799219/</a>): "Sasha Levin asked about whether the same sort of checking happens after -rc1 comes out; the answer was "generally not". Code entering the mainline after the merge window is supposed to be limited to important fixes, and linux-next is less useful for those. As far as Torvalds is concerned, fixes that do not appear in linux-next are not an issue at all. Levin protested that fixes are often broken; putting them in linux-next at least gives continuous-integration systems a chance to find the problems".<br>
<p>
So Linus is just fine with taking patches during -rc cycle that weren't in -next even for a single day, and he isn't too interested in changing that.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812517/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor812521"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 14, 2020 22:17 UTC (Fri)
                               by <b>tytso</b> (subscriber, #9993)
                              [<a href="/Articles/812521/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes, I understand that Linus doesn't have a problem with letting things drop into stable right away.   Then again, Linus may not be using the stable kernel series, or at least not the same way as say, Google's Contianer-Optimized OS (COS), which is trying to be upstream-first and based on the Stable kernel.   There *have* been customer visible regressions that where some stable kernel X.Y.Z caused more problems than if COS had stayed on X.Y.Z-1.    I've told them that this means they need to do more testing, and not trust that X.Y.Z+1 will have fewer bugs that they care about than X.Y.Z --- because that's simply not true, and I'm not sure there's anything that can be done to reduce the bug introduction rate to zero.<br>
<p>
But if there is something we can do to decrease the bug introduction rate, that would certainly be a good thing.    And that's why I'm suggesting that if we can use ML to figure out which commits contain bug fixes, maybe there is a way that we can use a training set of commits that landed in the stable kernels *and* which apparently had regressions, and see if we can find some features that tell us that those commits should get more careful screening.  Whether that's "wait longer", or create a list of commits that can be sent around  for humans to take a closer look, I don't have any concrete proposals, because I'm not sure what's the best way thing we could do with that information.  But I think it's worth some consideration and reflection to see if there's something we can do to further leverage ML; not just to select commits, but to flag commits for special care/handling/testing/review.<br>
<p>
Finally, Sasha, please don't take this as a criticism of the job you are currently doing.   Bugs and regressions in Linus's tree are inevitable; that's why we have thousnads of commits flowing into the stable kernels.   But this also means that bugs caused by bug fixes are also inevitable, and so the question is there something we can do to improve the process to deal with the fact that we are all humans.   Trying to improve any kind of development or ops processes are best done in a blame-free manner.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812521/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor812525"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 15, 2020 1:29 UTC (Sat)
                               by <b>sashal</b> (<b>&#x272D; supporter &#x272D;</b>, #81842)
                              [<a href="/Articles/812525/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Not trying to blame anyone, just pointing out that I've already done the research you've suggested to look into but I couldn't convert it into any result in practice. I'd be happy to discuss it further if you have input as to how improve the process.<br>
<p>
There is more information about the work here: <a href="https://lwn.net/Articles/753329/">https://lwn.net/Articles/753329/</a> .<br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812525/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor812946"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Revisiting stable-kernel regressions</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 20, 2020 21:27 UTC (Thu)
                               by <b>smfrench</b> (subscriber, #124116)
                              [<a href="/Articles/812946/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Seems like the easiest step would be to introduce more automated testing of stable trees (especially for file systems, network drivers etc.).   Some of the components have public automated tests (like cifs.ko CIFS/SMB3 client has automated tests run against various servers, Samba, Windows, new SMB3 Linux kernel server, the Cloud etc.) but how could maintainers like me pass the information on the recommended automated tests for our component to someone who is involved in the stable kernel validation process?  And who could run those? Is there dedicated hardware or VMs for validating stable builds?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/812946/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2020, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
