        <!DOCTYPE html>
        <html lang="en">
        <head><title>LSFMM: Lock scaling [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/547782/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/547782/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>LSFMM: Lock scaling</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Please consider subscribing to LWN</b>
<p>
Subscriptions are the lifeblood of LWN.net.  If you appreciate this
content and would like to see more of it, your subscription will
help to ensure that LWN continues to thrive.  Please visit
<a href="/Promo/nst-nag1/subscribe">this page</a> to join up and keep LWN on
the net.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>April 23, 2013</br>
           <hr>
<a href="/Articles/LSFMM2013/">LSFMM Summit 2013</a>
</div>
Andi Kleen opened the LSFMM 2013 session on locking performance by
noting that, over the years, kernel developers have worked to improve
scalability by adding increasingly fine-grained locking to the kernel.
Locks with small coverage help to avoid contention, but, when there
<i>is</i> contention, the resulting communication overhead wipes out the
advantages that fine-grained locks are supposed to provide.  We were, he
said, risking the defeat of our scalability goals through excessive
application of techniques designed to improve scalability.

<p>
His main assertion was that processing single objects within a lock is not a
scalable approach.  What we need, he said, is interfaces that handle groups
of objects in batches.  Processing multiple objects under a single lock
will amortize the cost of that lock over much more work, increasing the
overall scalability of the system.  That said, there are some challenges,
starting with the choice of the optimal batch size.  Developers tend to
like 64, he said, but that may not be the right value.  The best batch size
may be hardware-dependent and needs to be tunable.
<p>
As an example, he mentioned the per-zone LRU lock that protects the lists of
pages maintained by the memory management subsystem.  That lock is
currently taken and released for every page processed, even when many pages
need to be operated on.  Taking the lock once to process a larger batch of
pages would improve the scalability of the system.

<p>
Ted Ts'o objected that the tuning of batch sizes is a problem.  Lots of
users will never try, and many who do will get it wrong.  Automatic tuning
is an obvious solution, but, there, too, there are difficulties, starting
with a high-level policy question: should the system be tuned for
throughput or latency?  Large batches may improve throughput, but longer
lock hold times can cause increased latencies â€” a change that some users
may well object to.
<p>
Dave Chinner pointed out that adding batching interfaces
may risk creating unpredictable behavior (unknown latencies, for example)
in the system; it would also increase 
memory use as a result of the arrays needed to track the batches.  There
are, he said, not that many problematic locks in the kernel.  He would
prefer developers to look for algorithmic changes to avoid the lock
contention altogether.
<p>
A suggestion was made that a lot of contention could be avoided by moving
to message passing for communication between NUMA nodes.  It is fair to say
that support for this idea was minimal, though.  Ted asked about which
locks, in particular, would be amenable to batching; Andi responded that
per-page processing in filesystem code was at the top of his list,
especially in code dealing with buffered writes.  There are also some locks
in the networking subsystem, but the increasing use of segmentation offload
means that batching is being done in the hardware.  Translation lookaside
buffer (TLB) flushes are also done individually, even when multiple entries
need to be flushed.
<p>
There was a general agreement that it would be a good idea to enhance the
kernel to provide better information about which locks are contended, but
nobody committed to actually doing that work.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Scalability">Scalability</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Storage_Filesystem_and_Memory-Management_Summit-2013">Storage, Filesystem, and Memory-Management Summit/2013</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/547782/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor548252"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">LSFMM: Lock scaling</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 24, 2013 4:37 UTC (Wed)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/548252/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; the tuning of batch sizes is a problem.</font><br>
<p>
In rsyslog, locking around the main message queue was a limiting factor (exactly the per-item locking that Andi is complaining about)<br>
<p>
When we introduced batching of messages, we were worried about the same throughput vs latency tradeoff, but Rainer identified the batch processing algorithm that we ended up using which has not required much tuning in practice.<br>
<p>
Instead of the knee-jerk thinking of trying to wait until you have enough items to fill your batch size, instead just process however many items are outstanding _right_now_, up to your max batch size. If that's only one item, you process one item. If the rate of new items being generated is low, you continue to lock for each item, but there is zero contention for the lock.<br>
<p>
As the rate of new items climbs, eventually you get to the point where there are multiple items waiting to be processed when the system goes to process one of them. You then process all outstanding items with one lock cycle<br>
<p>
This way, the latency for any item is always as small as it can possibly be (one lock cycle * (# outstanding items/max batch size)), but as the load goes up the efficiency climbs to let you keep going.<br>
<p>
It doesn't matter if the load is caused by items being generated faster, or by the resources needed to process the items being used for other things.<br>
<p>
The drawback to this approach is that it uses more CPU at low load levels, which is just fine for this one task, but may impact the system as a whole.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/548252/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor548284"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">LSFMM: Lock scaling</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 24, 2013 14:15 UTC (Wed)
                               by <b>martinfick</b> (subscriber, #4455)
                              [<a href="/Articles/548284/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; This way, the latency for any item is always as small as it can possibly be (one lock cycle * (# outstanding items/max batch size)).</font><br>
<p>
I suspect that the latencies they are concerned about are those caused by processing more items without releasing the lock, not those caused by waiting to fill up a batch.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/548284/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor548402"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">LSFMM: Lock scaling</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 25, 2013 7:55 UTC (Thu)
                               by <b>dlang</b> (guest, #313)
                              [<a href="/Articles/548402/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; I suspect that the latencies they are concerned about are those caused by processing more items without releasing the lock, not those caused by waiting to fill up a batch.</font><br>
<p>
This latency is bounded by setting the max batch size.<br>
<p>
But unless you allow for items to be re-ordered, allowing batching will greatly decrease latency for most items, because it gets more work done.<br>
<p>
In addition, in many cases you don't need to hold the lock for the entire time you are working on something.<br>
<p>
for example, in rsyslog the threads delivering logs out lock the main queue, mark what messages they are working on, unlock the queue, work on the message, then lock the queue to mark the messages as completed (and unlock the queue as they are done)<br>
<p>
The old way where the output threads locked the queue, processed one message, unlocked the queue and repeated meant that the queue was locked for a much larger percentage of the time, and a lot of CPU time was spent on lock contention issues<br>
<p>
appropriate batching (and adjustment of data structures) can work wonders with this sort of problem.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/548402/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2013, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
