        <!DOCTYPE html>
        <html lang="en">
        <head><title>Priority-Boosting RCU Read-Side Critical Sections [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/220677/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/220677/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Priority-Boosting RCU Read-Side Critical Sections</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Please consider subscribing to LWN</b>
<p>
Subscriptions are the lifeblood of LWN.net.  If you appreciate this
content and would like to see more of it, your subscription will
help to ensure that LWN continues to thrive.  Please visit
<a href="/Promo/nst-nag1/subscribe">this page</a> to join up and keep LWN on
the net.
</blockquote>
<div class="GAByline">
           <p>February 5, 2007</p>
           <p>This article was contributed by Paul McKenney</p>
           </div>
<h3>Introduction</h3>

Read-copy update (RCU) is a synchronization API that is sometimes used
in place of reader-writer locks.  RCU's read-side primitives offer
extremely low overhead and deterministic execution time.
These properties imply that RCU updaters cannot block RCU readers,
which means that RCU readers can be expensive, as they must leave
old versions of the data structure in place to accommodate pre-existing
readers.
Furthermore, these old versions must be reclaimed after all pre-existing
readers complete.
The Linux kernel offers a number of RCU implementations, the first
such implementation being called "Classic RCU".
<p>
The RCU implementation for the -rt patchset is unusual in that
it permits read-side critical
sections to be blocked waiting for locks and due to preemption.
If these critical sections are blocked for too long,
grace periods will be stalled,
and the amount of memory awaiting the end of a grace
period will continually increase, eventually resulting
in an out-of-memory condition.
This theoretical possibility was apparent from the start,
but when Trevor Woerner actually made it happen, it was
clear that something needed to be done.
Because priority boosting is used in locking, it seemed natural to
apply it to realtime RCU.
<p>
Unfortunately, the priority-boosting algorithm used for locking
could not be applied straightforwardly to RCU because this
algorithm uses locking, and the whole point of RCU is to
<I>avoid</I> common-case use of such heavy-weight operations
in read-side primitives.
In fact, RCU's read-side primitives need to avoid common-case
use of <I>all</I>
heavyweight operations, including atomic instructions,
memory barriers, and cache misses.
Therefore, bringing priority boosting to RCU turned out to
be rather challenging, not because the eventual solution is
all that complicated, but rather due to the large number of
seductive but subtly wrong almost-solutions.
<p>
This document describes a way of providing light-weight
priority boosting to RCU, and also describes several of the
number of seductive but subtly wrong almost-solutions.
<p>
<h3>Approaches</h3>
<p>
This paper describes three approaches to priority-boosting blocked RCU
read-side critical sections.
The first approach minimizes scheduler-path overhead and uses locking
on non-fastpaths to decrease complexity.
The second approach is similar to the first, and was in fact a
higher-complexity intermediate point on the path to the first approach.
The third approach uses a per-task lock solely for its priority-inheritance
properties, which introduces the overhead of acquiring this lock into
the scheduler path, but avoids adding an "RCU boost" component to the
priority calculations.
Unfortunately, this third approach also cannot be made to reliably
boost tasks blocked in RCU read-side critical sections, so the first
approach should be used to the exclusion of the other two.
Each of these approaches is described in a following section,
after which is a section enumerating other roads not taken.
<p>
<h3>RCU Explicit Priority Boosting</h3>
<A NAME="#sec:RCU Explicit Priority Boosting"></A>
<p>
The solution described in this paper makes use of a separate RCU-booster
task that monitors per-CPU arrays of lists of target tasks that have been
blocked while in an RCU read-side critical section.
Overhead is incurred only when such blocking occurs, permitting
the RCU read-side-acquisition primitive (e.g., <TT>rcu_read_lock()</TT>)
to contain exactly the same sequence of instructions contained
in its non-boosted counterpart.
<p>
<H3>Data Structures</H3>
<p>
Each element of each per-CPU array is a structure named
<TT>struct</TT>&nbsp;<TT>rcu_boost_dat</TT> as shown below:

<p>
<LISTING>
  1 struct rcu_boost_dat {
  2   raw_spinlock_t rbs_mutex;
  3   struct list_head rbs_toboost;
  4   struct list_head rbs_boosted;
  5   long rbs_blocked;
  6   long rbs_boost_attempt;
  7   long rbs_boost;
  8   long rbs_unlock;
  9   long rbs_unboosted;
 10   long rbs_stats[][];
 11 }
</LISTING>
<p>

The <TT>rbs_mutex</TT> field guards all fields in the structure,
<TT>rbs_toboost</TT> is a list containing target tasks that are candidates
for boosting, and <TT>rbs_boosted</TT> is a list containing target tasks that
have already been boosted.
The rest of the fields are statistics:
<TT>rbs_blocked</TT> counts the number
of RCU read-side critical sections that were blocked (whether once
or multiple times),
<TT>rbs_boost_attempt</TT> counts the number of tasks that the RCU-booster
task has attempted to boost,
<TT>rbs_boost</TT> counts the number of such attempts in which
boosting was accomplished,
<TT>rbs_unlock</TT> counts the number of outermost <TT>rcu_read_unlock()</TT>
operations that end a blocked RCU read-side critical section,
and <TT>rbs_unboosted</TT> counts the number of tasks whose that needed
to be unboosted by <TT>rcu_read_unlock()</TT>.
The <TT>rbs_stats[]</TT> array tracks the number of transitions due
to each event from each state.
<p>
Next we'll look at the <TT>task_struct</TT> fields that are used in RCU
priority boosting:

<p>
<LISTING>
  1   struct rcu_boost_dat *rcub_rbdp;
  2   enum rcu_boost_state rcub_state;
  3   struct list_head rcub_entry;
</LISTING>
<p>


The <TT>rcub_rbdp</TT> is a pointer to the <TT>rcu_boost_dat</TT> struct on which
this task is enqueued,
<TT>rcub_state</TT> holds the RCU priority-boost state for this task,
and <TT>rcub_entry</TT> is the list entry used to enqueue this task on either
the <TT>rbs_toboost</TT> or the <TT>rbs_boosted</TT> lists.
<p>


<img src="https://static.lwn.net/images/ns/kernel/rcuboost-fig1.png" width=242 height=230
alt="[Schematic]" border=0 align="right" hspace=3>


A schematic of the organization of the <TT>rcu_boost_dat</TT>
data structure is shown to the right.
The <TT>rbs_toboost</TT> fields are represented by the upper set of
elements, and the <TT>rbs_boosted</TT> fields are represented by the
lower set of elements.
These elements are indexed
in a circular fashion based on the value of the global index,
which is named <TT>rcu_boost_idx</TT>.
Please note that corresponding elements in the upper and lower
sets in the figure are guarded by the same spinlock, the
<TT>rbs_mutex</TT> field.
Use of this index eliminates the need to physically move target
tasks from one locking domain to another, thus guaranteeing that a given task
is subject to the same lock throughout, eliminating the need for
latency-prone retry-style lock acquisition.
<p>
For a given CPU, the indexed element indicates in which list
to place target tasks that have just blocked within an RCU
read-side critical section.
When a given target task exits its outermost RCU read-side critical section
that was blocked,
that task removes itself from whatever list it was added to, and
also unboosts itself if need be.
<p>

<img src="https://static.lwn.net/images/ns/kernel/rcuboost-fig2.png" width=245 height=232
alt="[Figure]" align="left" border=0 hspace=3>

A separate RCU priority-boosting task increments the index periodically
(modulo the size of the array),
resulting in the configuration shown on the left.
After each such increments, this RCU-boost task
boosts the priority of those (hopefully few) target tasks that have remained
for a full time period, as well as any previously boosted tasks that
still remain in the list.
This reboosting is performed to allow for the possibility that the
system administrator changed the priority of the RCU-booster task
since the last time those tasks were boosted.
Such boosting might well be attempted concurrently with the target task
removing itself from the list.
Much care is required in order to avoid boosting a target task just after
it removes itself from its list.
Failure to avoid this scenario could result in an otherwise low-priority
task remaining boosted indefinitely, in turn causing other high-priority
realtime tasks to miss their deadlines.
<p>

The state machine described in the next section prevents such failure
scenarios from occurring.
<p>
<H3>State Diagram</H3>
<p>
<img src="https://static.lwn.net/images/ns/kernel/rcuboost-fig3.png" width=242 height=142
alt="[State diagram]" align="right" border=0 hspace=3>

Each task has an associated RCU-booster state, which can take on
the values shown on the right.
Tasks in the <TT>RCU_BOOST_BLOCKED</TT> state are linked into the uppermost of
the two sets of lists shown above,
while
tasks in the <TT>RCU_BOOSTED</TT> state are linked into the lower of these
two sets of lists,
and tasks in the <TT>RCU_BOOST_IDLE</TT> state are not linked into either set
of lists.
The black state transitions are traversed by the task, while the
red transitions are traversed by the RCU-booster task.
<p>

All priority boosting is carried out by the RCU-booster task,
while all priority unboosting is carried out by the target task.
This approach ensures that unboosting is exact, preventing
low-priority tasks from running at high priority any longer than
necessary.
<p>
<H3>Per-State Details</H3>
<p>
The purpose of the individual states are as follows:
<UL>
<LI>	<TT>RCU_BOOST_IDLE</TT>: This is the initial state.
	A target task resides in this state when not in an RCU read-side
	critical section, or when in an RCU read-side critical section
	that has not yet blocked.
<LI>	<TT>RCU_BOOST_BLOCKED</TT>: The target task
	has blocked while in an RCU read-side critical section.
<LI>	<TT>RCU_BOOSTED</TT>: The RCU-booster task has completed boosting
	the target task's priority.
</UL>
<p>
<H3>Events</H3>
<p>
The important events for a target task are (1)&nbsp;being blocked
in an RCU read-side critical section and (2)&nbsp;completing a previously
blocked RCU read-side critical section.
When a target task is blocked in an RCU read-side critical section, it
always adds itself to the current list of its per-CPU array.
Conversely, when a target task completes a previously blocked RCU read-side
critical section, it removes itself from this list.
If its priority has been boosted, it also unboosts itself.
<p>
The important event for the RCU-booster task is boosting
a target task's priority.

<H3>Implementation</H3>
<p>
<H4>Helper Functions</H4>
<p>
The listing below
shows functions used to access the proper element of the
arrays used to track tasks that are candidates for RCU priority
boosting.
<p>
<LISTING>
  1 struct rcu_boost_dat *rcu_rbd_new(void)
  2 {
  3   int cpu = raw_smp_processor_id();
  4   int idx = rcu_boost_idx;
  5 
  6   smp_read_barrier_depends(); barrier();
  7   if (unlikely(idx &lt; 0))
  8     return (NULL);
  9   return &amp;per_cpu(rcu_boost_dat, cpu)[idx];
 10 }
 11 
 12 struct rcu_boost_dat *rcu_rbd_boosting(int cpu)
 13 {
 14   int idx = (rcu_boost_idx + 1) &amp; (RCU_BOOST_ELEMENTS - 1);
 15 
 16   return &amp;per_cpu(rcu_boost_dat, cpu)[idx];
 17 }
</LISTING>
<p>

The <TT>rcu_rbd_new()</TT> function is
used by newly blocked tasks adding themselves to the data structure,
while the <TT>rcu_rbd_boosting()</TT>
function is used by the RCU-booster task to locate tasks in need
of boosting.
<p>
The <TT>rcu_rbd_new()</TT> function returns the <TT>rcu_boost_dat</TT> element
be used for newly blocked tasks adding themselves to the data structure.
Lines&nbsp;3 and 4 pick up the CPU ID and the current value of the index,
respectively.
Line 6 issues any memory barriers needed on Alpha and prevents the
compiler from optimizing bugs into this function on other platforms.
Line&nbsp;7 checks to see if this function is being called before the
RCU-booster task has completed initialization, and, if so, line&nbsp;8
returns.
Otherwise, line&nbsp;9 uses the CPU and index to select the right
<TT>rcu_boost_dat</TT> structure to queue on.
<p>
The <TT>rcu_rbd_boosting</TT> is simpler because it is invoked only
from the RCU-booster task, and therefore cannot run concurrently
with a counter increment (although this could change if there are
ever multiple RCU-booster tasks).
Line&nbsp;14 selects the index that was least-recently the target of
tasks newly blocked in RCU read-side critical sections, and
line&nbsp;16 uses the index and the specified CPU to select the right
<TT>rcu_boost_dat</TT> structure to boost from.
<p>
The <TT>rcu_boost_prio()</TT> and <TT>rcu_unboost_prio()</TT> functions
shown below
boost and unboost the specified task's RCU priority.

<p>
<LISTING>
  1 static void rcu_boost_prio(struct task_struct *taskp)
  2 {
  3   unsigned long oldirq;
  4   int rcuprio;
  5 
  6   spin_lock_irqsave(&amp;current-&gt;pi_lock, oldirq);
  7   rcuprio = rt_mutex_getprio(current) + 1;
  8   if (rcuprio &gt;= MAX_USER_RT_PRIO)
  9     rcuprio = MAX_USER_RT_PRIO - 1;
 10   spin_unlock_irqrestore(&amp;current-&gt;pi_lock, oldirq);
 11   spin_lock_irqsave(&amp;taskp-&gt;pi_lock, oldirq);
 12   if (taskp-&gt;rcu_prio != rcuprio) {
 13     taskp-&gt;rcu_prio = rcuprio;
 14     if (taskp-&gt;rcu_prio != taskp-&gt;prio)
 15       rt_mutex_setprio(taskp, taskp-&gt;rcu_prio);
 16   }
 17   spin_unlock_irqrestore(&amp;taskp-&gt;pi_lock, oldirq);
 18 }
 19 
 20 static void rcu_unboost_prio(struct task_struct *taskp)
 21 {
 22   int nprio;
 23   unsigned long oldirq;
 24 
 25   spin_lock_irqsave(&amp;taskp-&gt;pi_lock, oldirq);
 26   taskp-&gt;rcu_prio = MAX_PRIO;
 27   nprio = rt_mutex_getprio(taskp);
 28   if (nprio &gt; taskp-&gt;prio)
 29     rt_mutex_setprio(taskp, nprio);
 30   spin_unlock_irqrestore(&amp;taskp-&gt;pi_lock, oldirq);
 31 }
</LISTING>
<p>
Lines&nbsp;6-10 of <TT>rcu_boost_prio()</TT> get the priority of the current
(RCU-booster) task, setting the target task's <TT>rcu_prio</TT> field
to one notch less-favored priority
if possible, and to the least-favored realtime priority otherwise.
The <TT>rt_mutex_getprio()</TT> primitive is used to actually obtain
this priority.
Lines&nbsp;11-17 boost the target task's priority, with line&nbsp;12 checking
to see if the task has already been RCU-boosted to the desired priority.
If not, line&nbsp;13 updates the task's <TT>rcu_prio</TT> field,
line&nbsp;14 checks to see if the task is already running at the desired
priority (perhaps due to lock-based boosting), and, if not, line&nbsp;15
does the actual priority change.
Note that this function is capable of decreasing a task's priority,
as will be described below.
<p>
Lines&nbsp;25-30 of <TT>rcu_unboost_prio()</TT> unboost the target task,
again using <TT>rt_mutex_getprio()</TT> and <TT>rt_mutex_setprio()</TT>
to manipulate the priorities.
Line&nbsp;26 updates the task's <TT>rcu_prio</TT> field to prevent any future
priority calculations from adding an RCU component to the priority.
Line&nbsp;28 checks to see if the
task is already running at a less-favorable priority before
actually deboosting on line&nbsp;29.
<p>
Both functions hold the given task's <TT>pi_lock</TT> in order to
properly synchronize with other changes to that task's priority.
In addition, the <TT>rt_mutex_getprio()</TT> and <TT>rt_mutex_setprio()</TT>
primitives have been modified to take the task's <TT>rcu_prio</TT>
field into account in the priority calculations, ensuring that
possible lock-based priority deboosts will not remove the RCU
priority boost.
<p>
<H4>Blocking Within an RCU Read-Side Critical Section</H4>
<p>
The scheduler contains a call to <TT>rcu_preempt_boost</TT>, which
is shown on lines&nbsp;1-5 below:

<p>
<LISTING>
  1 #define rcu_preempt_boost() \
  2   do { \
  3     if (unlikely(current-&gt;rcu_read_lock_nesting &gt; 0)) \
  4       __rcu_preempt_boost(); \
  5   } while (0)
  6 
  7 void __rcu_preempt_boost(void)
  8 {
  9   struct rcu_boost_dat *rbdp;
 10   unsigned long oldirq;
 11 
 12   local_irq_save(oldirq);
 13   rbdp = rcu_rbd_new();
 14   if (rbdp == NULL) {
 15     local_irq_restore(oldirq);
 16     printk("Preempted RCU too early.\n");
 17     return;
 18   }
 19   spin_lock(&amp;rbdp-&gt;rbs_mutex);
 20   rbdp-&gt;rbs_blocked++;
 21   rcu_boost_dat_stat_block(rbdp, current-&gt;rcub_state);
 22   if (current-&gt;rcub_state != RCU_BOOST_IDLE) {
 23     spin_unlock_irqrestore(&amp;rbdp-&gt;rbs_mutex, oldirq);
 24     return;
 25   }
 26   current-&gt;rcub_state = RCU_BOOST_BLOCKED;
 27   list_add_tail(&amp;current-&gt;rcub_entry, &amp;rbdp-&gt;rbs_toboost);
 28   current-&gt;rcub_rbdp = rbdp;
 29   spin_unlock_irqrestore(&amp;rbdp-&gt;rbs_mutex, oldirq);
 30 }
</LISTING>
<p>


This macro checks to see if the current task is in an RCU read-side
critical section, and, if so, invokes the <TT>__rcu_preempt_boost()</TT>
function to place the calling task on the priority-boost lists.
<p>
The <TT>__rcu_preempt_boost()</TT> function runs with irqs disabled,
and is potentially invoked with irqs already disabled.
Line&nbsp;12 disables irqs, and line&nbsp;13 identifies the
<TT>struct</TT> <TT>rcu_boost_dat</TT> that is to be used
Line&nbsp;14 then checks to see whether the RCU-booster task has started, and
lines&nbsp;15-18 restore irqs and returns if so.
<p>
Otherwise, line&nbsp;19 acquires the lock.
Note that the index can change during this time, but because the
index must be incremented three times in order for the RCU-booster
task to get to this entry, this situation is unlikely to result in
premature boosting.
Lines&nbsp;20-21 gather statistics.
<p>
Lines&nbsp;22-25 check to see if this task is already on the priority-boost
lists, and if so, restores irqs and returns.
Otherwise, line&nbsp;26 updates the task's state to indicate that this
task has blocked in its current RCU read-side critical section,
line&nbsp;27 adds it to the
appropriate priority-boost list, line&nbsp;28 caches a pointer to the
list in the task structure, and line&nbsp;29 releases the lock and
restores irqs.
<p>
<H4>Boosting The Priority of a List of Tasks</H4>
<p>
The <TT>rcu_boost_one_reader_list</TT> function shown below
is invoked by the
RCU-booster task to priority-boost all tasks still remaining on the
specified <TT>rcu_boost_dat</TT> structure.
<p>
<LISTING>
  1 static void rcu_boost_one_reader_list(struct rcu_boost_dat *rbdp)
  2 {
  3   LIST_HEAD(list);
  4   unsigned long oldirq;
  5   struct task_struct *taskp;
  6 
  7   spin_lock_irqsave(&amp;rbdp-&gt;rbs_mutex, oldirq);
  8   list_splice_init(&amp;rbdp-&gt;rbs_toboost, &amp;list);
  9   list_splice_init(&amp;rbdp-&gt;rbs_boosted, &amp;list);
 10   while (!list_empty(&amp;list)) {
 11     spin_unlock_irqrestore(&amp;rbdp-&gt;rbs_mutex, oldirq);
 12     schedule_timeout_uninterruptible(1);
 13     spin_lock_irqsave(&amp;rbdp-&gt;rbs_mutex, oldirq);
 14     if (list_empty(&amp;list))
 15       break;
 16     taskp = list_entry(list.next, typeof(*taskp), rcub_entry);
 17     list_del_init(&amp;taskp-&gt;rcub_entry);
 18     rbdp-&gt;rbs_boost_attempt++;
 19     if (taskp-&gt;rcub_state != RCU_BOOST_BLOCKED) {
 20       list_add_tail(&amp;taskp-&gt;rcub_entry, &amp;rbdp-&gt;rbs_toboost);
 21       rcu_boost_dat_stat_boost(rbdp, taskp-&gt;rcub_state);
 22       continue;
 23     }
 24     rcu_boost_prio(taskp);
 25     taskp-&gt;rcub_state = RCU_BOOSTED;
 26     rbdp-&gt;rbs_boost++;
 27     rcu_boost_dat_stat_boost(rbdp, RCU_BOOST_BLOCKED);
 28     list_add_tail(&amp;taskp-&gt;rcub_entry, &amp;rbdp-&gt;rbs_boosted);
 29   }
 30   spin_unlock_irqrestore(&amp;rbdp-&gt;rbs_mutex, oldirq);
 30 }
</LISTING>
<p>


The boosting is done under the protection of this structure's mutex,
but this mutex is periodically dropped to allow the RCU-booster task
to sleep, thus avoiding imposing excessive scheduling latencies on
realtime tasks.
Lines&nbsp;8 and 9 pull the contents of the <TT>rcu_boost_dat</TT> structure's
two lists onto a local list.
This has the effect of reboosting tasks, which is useful in case the
system administrator manually increased the RCU-booster task's priority
since the previous boost.
Line&nbsp;10 sequences through the list, and lines&nbsp;11-13 sleep as noted earlier.
Lines&nbsp;14-15 recheck the list to allow for the possibility of the tasks
having exited their RCU read-side critical sections in the meantime,
thus removing themselves from the list.
<p>
Line&nbsp;16-17 removes the first task on the list, and line&nbsp;18 updates
statistics.
Lines&nbsp;19-23 reject tasks that are in the wrong state (but counts them),
and puts them back on the <TT>rbs_toboost</TT> list.
Line&nbsp;24 boosts the task, line&nbsp;25 updates state to indicate that
this task has had its priority boosted, lines&nbsp;26-27
accumulate statistics, and line&nbsp;28 puts the task on the
<TT>rbs_boosted</TT> list.
If the task is still present after the index has been incremented four
more times, it may be boosted again, as noted above, allowing any
recent changes in the priority of the RCU-booster task to be taken
into account.
<p>
<H4>Sequencing Through Lists of Tasks</H4>
<p>
The <TT>rcu_booster()</TT> function:
<p>
<LISTING>
  1 static int rcu_booster(void *arg)
  2 {
  3   int cpu;
  4   struct sched_param sp;
  5 
  6   sp.sched_priority = PREEMPT_RCU_BOOSTER_PRIO;
  7   sched_setscheduler(current, SCHED_RR, &amp;sp);
  8   current-&gt;flags |= PF_NOFREEZE;
  9   do {
 10     rcu_boost_idx = (rcu_boost_idx + 1) % RCU_BOOST_ELEMENTS;
 11     for_each_possible_cpu(cpu) {
 12       rcu_boost_one_reader_list(rcu_rbd_boosting(cpu));
 13     }
 14     schedule_timeout_uninterruptible(HZ / 100);
 15     rcu_boost_dat_stat_print();
 16   } while (!kthread_should_stop());
 17   return 0;
 18 }
</LISTING>

<p>
periodically cycles through the
lists of tasks that may be in need of priority boosting, running
as a kernel thread.
Lines&nbsp;6-8 set this task to its default realtime priority, and prevent
it from interfering with suspend processing.
The loop starting at line&nbsp;9 makes one pass through each CPU's candidate
RCU-boost target tasks, with line&nbsp;10 advancing the index so as to
"age" all tasks that have blocked while in their current RCU read-side
critical section.
This advancing of the index will require special coordination should
it ever be necessary to have multiple RCU-booster tasks.
Lines&nbsp;11-13 invoke <TT>rcu_boost_one_reader_list()</TT> on each CPU's
most-aged <TT>rcu_boost_dat</TT> structure in order to boost any tasks
that have been blocked for a long time in an RCU read-side critical
section for each CPU.
Line&nbsp;14 waits for about 10 milliseconds, which means that tasks must
remain in their RCU read-side critical sections for at least 30 milliseconds
to become candidates for boosting -- <I>and</I> they have to have
blocked at least once during that time.
This seems like a good default setting, but more experience is required
to determine what really is appropriate.
Line&nbsp;15 prints statistics if the <TT>PREEMPT_RCU_BOOST_STATS</TT>
config parameter is set.
<p>
<H4>Unboosting</H4>
<p>
The listing below shows
<TT>rcu_read_unlock_unboost()</TT>, which is invoked from
<TT>rcu_read_unlock()</TT> to unboost the current task's priority
if needed.
<p>
<LISTING>
  1 static inline void rcu_read_unlock_unboost(void)
  2 {
  3   if (unlikely(current-&gt;rcub_state != RCU_BOOST_IDLE))
  4     __rcu_read_unlock_unboost();
  5 }
  6 
  7 static void __rcu_read_unlock_unboost(void)
  8 {
  9   unsigned long oldirq;
 10   struct rcu_boost_dat *rbdp;
 11 
 12   rbdp = current-&gt;rcub_rbdp;
 13   spin_lock_irqsave(&amp;rbdp-&gt;rbs_mutex, oldirq);
 14 
 15   list_del_init(&amp;current-&gt;rcub_entry);
 16   rbdp-&gt;rbs_unlock++;
 17   current-&gt;rcub_rbdp = NULL;
 18 
 19   rcu_boost_dat_stat_unlock(rbdp, current-&gt;rcub_state);
 20   if (current-&gt;rcub_state == RCU_BOOSTED) {
 21     rcu_unboost_prio(current);
 22     rbdp-&gt;rbs_unboosted++;
 23   }
 24   current-&gt;rcub_state = RCU_BOOST_IDLE;
 25   spin_unlock_irqrestore(&amp;rbdp-&gt;rbs_mutex, oldirq);
 26 }
</LISTING>
<p>


The call from <TT>rcu_read_unlock()</TT> is placed so that
<TT>rcu_read_unlock_unboost()</TT> is only invoked from the end of the
outermost of a set of nested RCU read-side critical sections.
This function is an inlineable wrapper around
<TT>__rcu_read_unlock_unboost()</TT>, which it invokes only if the
current task was blocked during the preceding RCU read-side critical
section.
<p>
This same listing also shows the <TT>__rcu_read_unlock_unboost()</TT>
helper function starting at line&nbsp;7.
Line&nbsp;12 retrieves the pointer to the <TT>rcu_boost_dat</TT> that
was cached by line&nbsp;28 of <TT>__rcu_preempt_boost()</TT>.
Line&nbsp;13
then acquires the corresponding lock.
Line&nbsp;15 removes this task from whatever list it is on,
line&nbsp;16 counts the unlock, and line&nbsp;17 NULLs out the cached pointer.
Line&nbsp;19 accumulates statistics, and lines&nbsp;20-23 unboost the task's
priority and count the unboost, but only if the task was boosted.
Line&nbsp;24 sets the task's state to indicate that it is no longer in
an RCU read-side critical section in which it has blocked,
and, finally, line&nbsp;25 releases the lock.
<p>
<H4>Initialization</H4>
<p>
The early-boot initialization
code looks like this:
<p>
<LISTING>
  1 static void init_rcu_boost_early(void)
  2 {
  3   struct rcu_boost_dat *rbdp;
  4   int cpu;
  5   int i;
  6 
  7   for_each_possible_cpu(cpu) {
  8     rbdp = per_cpu(rcu_boost_dat, cpu);
  9     for (i = 0; i &lt; RCU_BOOST_ELEMENTS; i++) {
 10       rbdp[i].rbs_mutex =
 11         RAW_SPIN_LOCK_UNLOCKED(rbdp[i].rbs_mutex);
 12       INIT_LIST_HEAD(&amp;rbdp[i].rbs_toboost);
 13       INIT_LIST_HEAD(&amp;rbdp[i].rbs_boosted);
 14       rbdp[i].rbs_blocked = 0;
 15       rbdp[i].rbs_boost_attempt = 0;
 16       rbdp[i].rbs_boost = 0;
 17       rbdp[i].rbs_unlock = 0;
 18       rbdp[i].rbs_unboosted = 0;
 19 #ifdef CONFIG_PREEMPT_RCU_BOOST_STATS
 20       {
 21         int j, k;
 22 
 23         for (j = 0; j &lt; N_RCU_BOOST_DAT_EVENTS; j++)
 24           for (k = 0; k &lt;= N_RCU_BOOST_STATE; k++)
 25             rbdp[i].rbs_stats[j][k] = 0;
 26       }
 27 #endif /* #ifdef CONFIG_PREEMPT_RCU_BOOST_STATS */
 28     }
 29     smp_wmb();
 30     rcu_boost_idx = 0;
 31   }
 32 }
</LISTING>
<p>



This is quite straightforward, aside from the memory barrier on line&nbsp;29
to prevent other CPUs from seeing <TT>rcu_boost_idx</TT> with a non-negative
value but uninitialized values for the structures.
Just in case early boot processing ever goes SMP!
<p>
However, <TT>init_rcu_boost_early()</TT> is called early in the boot process,
as the name suggests -- early enough, in fact, that the scheduler is
not yet functional.
Therefore, the creation of the RCU-booster task must be deferred until
later, when the scheduler is functional:
<p>
<LISTING>
  1 void init_rcu_boost_late(void)
  2 {
  3   int i;
  4 
  5   printk(KERN_ALERT "Starting RCU priority booster\n");
  6   rcu_boost_task = kthread_run(rcu_booster, NULL, "RCU Prio Booster");
  7   if (IS_ERR(rcu_boost_task)) {
  8     i = PTR_ERR(rcu_boost_task);
  9     printk(KERN_ALERT
 10            "Unable to create RCU Priority Booster, errno %d\n", -i);
 11     rcu_boost_task = NULL;
 12   }
 13 }
</LISTING>
<p>
This code
shows the <TT>init_rcu_boost_late()</TT> function, which simply spawns the
RCU-booster task and then returns.
<p>


<H4>Statistics Gathering and Output</H4>
<p>
This listing shows the statistics-accumulation
functions and macros, which are defined only if the
<TT>PREEMPT_RCU_BOOST_STATS</TT> configuration parameter is set.
<p>
<LISTING>
  1 static inline void
  2 rcu_boost_dat_stat(struct rcu_boost_dat *rbdp,
  3                    int event,
  4                    enum rcu_boost_state oldstate)
  5 {
  6   if (oldstate &gt;= RCU_BOOST_IDLE &amp;&amp;
  7       oldstate &lt;= RCU_BOOSTED) {
  8     rbdp-&gt;rbs_stats[event][oldstate]++;
  9   } else {
 10     rbdp-&gt;rbs_stats[event][N_RCU_BOOST_STATE]++;
 11   }
 12 }
 13 
 14 #define rcu_boost_dat_stat_block(rbdp, oldstate) \
 15   rcu_boost_dat_stat(rbdp, RCU_BOOST_DAT_BLOCK, oldstate)
 16 #define rcu_boost_dat_stat_boost(rbdp, oldstate) \
 17   rcu_boost_dat_stat(rbdp, RCU_BOOST_DAT_BOOST, oldstate)
 18 #define rcu_boost_dat_stat_unlock(rbdp, oldstate) \
 19   rcu_boost_dat_stat(rbdp, RCU_BOOST_DAT_UNLOCK, oldstate)
</LISTING>
<p>

The <TT>rcu_boost_dat_stat()</TT> function increments the element of
the <TT>rbs_stats[]</TT> array selected by the event and state,
but only for valid state values.
Invalid state values cause one of the special invalid-state elements
to be incremented, depending on the event.
The <TT>rcu_boost_dat_stat_block()</TT>, <TT>rcu_boost_dat_stat_boost()</TT>,
and <TT>rcu_boost_dat_stat_unlock()</TT> macros serve as short-hand wrappers
for the <TT>rcu_boost_dat_stat</TT> function.
<p>
The listing below shows arrays
used to assist in <TT>printk()</TT>-ing of statistics.
<p>
<LISTING>
  1 static char *rcu_boost_state_event[] = {
  2   "block:  ",
  3   "boost:  ",
  4   "unlock: ",
  5 };
  6 
  7 static char *rcu_boost_state_error[] = {
  8        /*ibBe*/
  9   "   ?",  /* block */
 10   "!  ?",  /* boost */
 11   "?  ?",  /* unlock */
 12 };
</LISTING>
<p>

The labels defined in <TT>rcu_boost_state_event[]</TT> serve as output
line labels, while the characters defined in
<TT>rcu_boost_state_error[]</TT> are used to note invalid state
transitions.
The "?" character indicates a completely invalid state, either
because the state itself is undefined or because there is an
enclosing check eliminating it, while the "!" character indicates
a list-manipulation error.
The space character indicates a valid state transition.
<p>
This long listing shows accumulation and printing
of statistics.
<p>
<LISTING>
  1 static void rcu_boost_dat_stat_print(void)
  2 {
  3   char buf[N_RCU_BOOST_STATE * (sizeof(long) * 3 + 2) + 2];
  4   int cpu;
  5   int event;
  6   int i;
  7   static time_t lastprint = 0;
  8   struct rcu_boost_dat *rbdp;
  9   int state;
 10   struct rcu_boost_dat sum;
 11 
 12   if (xtime.tv_sec - lastprint &lt;
 13       CONFIG_PREEMPT_RCU_BOOST_STATS_INTERVAL)
 14     return;
 15   sum.rbs_blocked = 0;
 16   sum.rbs_boost_attempt = 0;
 17   sum.rbs_boost = 0;
 18   sum.rbs_unlock = 0;
 19   sum.rbs_unboosted = 0;
 20   for_each_possible_cpu(cpu)
 21     for (i = 0; i &lt; RCU_BOOST_ELEMENTS; i++) {
 22       rbdp = per_cpu(rcu_boost_dat, cpu);
 23       sum.rbs_blocked += rbdp[i].rbs_blocked;
 24       sum.rbs_boost_attempt += rbdp[i].rbs_boost_attempt;
 25       sum.rbs_boost += rbdp[i].rbs_boost;
 26       sum.rbs_unlock += rbdp[i].rbs_unlock;
 27       sum.rbs_unboosted += rbdp[i].rbs_unboosted;
 28     }
 29   for (event = 0; event &lt; N_RCU_BOOST_DAT_EVENTS; event++)
 30     for (state = 0; state &lt;= N_RCU_BOOST_STATE; state++) {
 31       sum.rbs_stats[event][state] = 0;
 32       for_each_possible_cpu(cpu) {
 33         for (i = 0; i &lt; RCU_BOOST_ELEMENTS; i++) {
 34           sum.rbs_stats[event][state]
 35               += per_cpu(rcu_boost_dat,
 36                    cpu)[i].rbs_stats[event][state];
 37         }
 38       }
 39     }
 40   printk(KERN_ALERT
 41          "rcu_boost_dat: idx=%d "
 42          "b=%ld ul=%ld ub=%ld boost: a=%ld b=%ld\n",
 43          rcu_boost_idx,
 44          sum.rbs_blocked, sum.rbs_unlock, sum.rbs_unboosted,
 45          sum.rbs_boost_attempt, sum.rbs_boost);
 46   for (event = 0; event &lt; N_RCU_BOOST_DAT_EVENTS; event++) {
 47     i = 0;
 48     for (state = 0; state &lt;= N_RCU_BOOST_STATE; state++) {
 49       i += sprintf(&amp;buf[i], " %ld%c",
 50              sum.rbs_stats[event][state],
 51              rcu_boost_state_error[event][state]);
 52     }
 53     printk(KERN_ALERT "rcu_boost_dat %s %s\n",
 54            rcu_boost_state_event[event], buf);
 55   }
 56   lastprint = xtime.tv_sec;
 57 }
</LISTING>
<p>


This function refuses to take action unless sufficient time has elapsed
since the last time it printed statistics, as can be seen from
lines&nbsp;12-14 and line 56.
Locking will be required should multiple RCU-booster tasks ever become
necessary.
Lines 15-39 sum the corresponding statistical counters from all of the
<TT>rcu_boost_dat</TT> structures, and lines&nbsp;40-55 print out the sums.
<p>
<H4>Possible Future Enhancements</H4>
<p>
The act of getting any piece of software working (or even sort of working)
almost always immediately suggested enhancements, and RCU priority boosting
is no exception.
This following list includes a few possibilities.
<p>
<OL>
<LI>	Boosting upon OOM.
	This is currently to be accomplished by having the RCU-booster
	task more aggressively boost when it becomes aware of OOM
	conditions, for example, reducing or omitting timed sleeps.
	Alternatively, one could activate the "canary" mechanism
	upon OOM, which could downgrade realtime tasks to non-realtime
	status, allowing the normal aging mechanisms to boost any
	blocked task that might be holding up a grace period.
<p>
<LI>	Successive boosting to ever-higher priorities.
	This will likely be required in cases where the system administrator
	manually increases the priority of the RCU-booster task.
	The intent in this case is no doubt to kick some laggart
	RCU read-side critical section, which won't happen if the
	corresponding task has already been boosted.
	This is deferred until needed.
<p>
<LI>	Use of multiple per-CPU or per-NUMA-node RCU booster tasks.
	This will undoubtedly be required for large systems, but
	is deferred until needed.
</OL>
<p>
<h3>RCU Priority Boosting With Minimal Scheduler-Path Overhead</h3>
<A NAME="#sec:RCU Priority Boosting With Minimal Scheduler-Path Overhead"></A>
<p>
The solution described in this paper makes use of a separate RCU-booster
task that monitors per-CPU arrays of lists of target tasks that have been
blocked while in an RCU read-side critical section.
Overhead is incurred only when such blocking occurs, permitting
the RCU read-side-acquisition primitive (e.g., <TT>rcu_read_lock()</TT>)
to contain exactly the same sequence of instructions contained
in its non-boosted counterpart.
<p>
<H3>Data Structures</H3>
<A NAME="#sec:Data Structures"></A>
<p>
Each element of each per-CPU array is a structure named
<TT>struct</TT>&nbsp;<TT>rcu_boost_dat</TT> as shown below:

<p>
<LISTING>
  1 struct rcu_boost_dat {
  2   raw_spinlock_t rbs_mutex;
  3   struct list_head rbs_toboost;
  4   struct list_head rbs_boosted;
  5   wait_queue_head_t rbs_target_wq;
  6   wait_queue_head_t rbs_booster_wq;
  7   int rbs_exit_done;
  8   long rbs_blocked;
  9   long rbs_boost_attempt;
 10   long rbs_boost_wrongstate;
 11   long rbs_boost_cmpxchgfail;
 12   long rbs_boost_start;
 13   long rbs_boost_end;
 14   long rbs_unboosted;
 15   long rbs_unlock;
 16   long rbs_stats[][];
 17 }
</LISTING>
<p>


The <TT>rbs_mutex</TT> field guards all fields in the structure,
<TT>rbs_toboost</TT> is a list containing target tasks that are candidates
for boosting, and <TT>rbs_boosted</TT> is a list containing target tasks that
have already been boosted.
The next three fields govern interactions between the RCU-booster task
and an exiting target task:
(1)&nbsp;<TT>rbs_target_wq</TT> is a wait queue for exiting target tasks, which
ensures that the RCU-booster task has finished accessing the target
before the target exits, 
(2)&nbsp;<TT>rbs_booster_wq</TT> is a wait queue for the RCU-booster task, which
ensures that any exiting target task has completed blocking before
the RCU-booster task reuses the <TT>rbs_target_wq</TT> field, and
(3)&nbsp;<TT>rbs_exit_done</TT> is the flag that the RCU-booster conditions
its <TT>wait_event()</TT> call on.
The rest of the fields are statistics:
<TT>rbs_blocked</TT> counts the number
of RCU read-side critical sections that were blocked (whether once
or multiple times),
<TT>rbs_boost_attempt</TT> counts the number of tasks that the RCU-booster
task has attempted to boost,
<TT>rbs_boost_wrongstate</TT> counts the number of such attempts that
were abandoned due to the target task being in the wrong state,
<TT>rbs_boost_cmpxchgfail</TT> counts the number of such attempts that
were abandoned due to concurrent state manipulation by some other
task,
<TT>rbs_boost_start</TT> counts the number of such attempts in which
boosting was started,
<TT>rbs_boost_end</TT> counts the number of such attempts in which
boosting was completed normally,
<TT>rbs_unlock</TT> counts the number of outermost <TT>rcu_read_unlock()</TT>
operations that end a blocked RCU read-side critical section,
and <TT>rbs_unboosted</TT> counts the number of tasks whose boosting had
to be backed out due to a concurrent <TT>rcu_read_unlock()</TT>.
The <TT>rbs_stats[]</TT> array tracks the number of transitions due
to each event from each state.
However, these structures are organized as described in
"RCU Explicit Priority Boosting," above.

<p>
This approach uses the same task-struct fields as that of
"RCU Explicit Priority Boosting,"
with the addition of a pointer to a <TT>struct</TT> <TT>rcu_boost_dat</TT>
named <TT>rcub_rbdp_wq</TT>, which is used to mediate <TT>exit()</TT> processing.
<p>
Note that boosting might well be attempted concurrently with the target task
removing itself from the list.
Much care is required in order to avoid boosting a target task just after
it removes itself from its list.
Failure to avoid this scenario could result in an otherwise low-priority
task remaining boosted indefinitely, in turn causing other high-priority
realtime tasks to miss their deadlines.
Worse yet, a task being boosted could call <TT>exit()</TT> immediately
after exiting its critical section, possibly resulting in memory
corruption due to the RCU-booster task attempting to unboost it after it
had been completely removed from the system.
<p>
The state machine described in the next section prevents these failure
scenarios from occurring.
<p>
<H3>State Diagram</H3>
<p>
Each task has an associated RCU-booster state, which can take on
the values shown in this diagram:
<p>
<img src="https://static.lwn.net/images/ns/kernel/rcuboost-fig4.png" width=683 height=384
alt="[State diagram]" border=0>
<p>

Tasks in any of the yellow states are linked into the uppermost of
the two sets of lists shown in the data structure figure toward the
beginning of this article,
tasks in any of the red states are linked into the lower of these
two sets of lists,
and tasks in any of the unshaded states are not linked into either set
of lists.
The black state transitions are traversed by the task, while the
red transitions are traversed by the RCU-booster task.
The double-walled states may be exited either of these two,
requiring that the state value be atomically manipulated.
Fortunately, the RCU-booster task can only make three consecutive changes to
the state before reaching a state that can only be exited
by the task itself.
Therefore, the number of consecutive compare-and-exchange failures
for the task is limited to three, permitting $O(1)$ task-side state
change.  (The locking design used in the actual implementation
	further limits the number of consecutive compare-and-exchange
	failures to one.)

<p>
When a task resides in any of the single-walled states, however, the
state may be manipulated non-atomically by the sole task permitted
to exit that state.
<p>
Similarly, priority manipulations in a state that can be exited
by the RCU-booster task are carried out by the RCU-booster task, even if that
state can also be exited by the target task -- concurrent manipulation
of priorities does not reduce the number of states, but does increase
the probability of bugs.
However, priority manipulations in a state that can only be exited
by the target task are carried out by the target task.
<p>
<H3>Per-State Details</H3>
<p>
The purpose of the individual states are as follows:
<UL>
<LI>	<TT>RCU_BOOST_IDLE</TT>: This is the initial state.
	A target task resides in this state when not in an RCU read-side
	critical section, or when in an RCU read-side critical section
	that has not yet blocked.
<p>
<LI>	<TT>RCU_BOOST_BLOCKED</TT>: The target task
	has blocked while in an RCU read-side critical section.
<p>
<LI>	<TT>RCU_BOOSTING</TT>: The RCU-booster task has begun boosting
	the target task's priority.
<p>
<LI>	<TT>RCU_BOOSTED</TT>: The RCU-booster task has completed boosting
	the target task's priority.
<p>
<LI>	<TT>RCU_UNBOOST_IDLE</TT>: The target task exited its RCU read-side
	critical section while in the process of being boosted.
	This task has removed itself from its list, but it is
	the responsibility of the RCU-booster task to back out of
	any boosting that has taken place.
<p>
<LI>	<TT>RCU_UNBOOST_BLOCKED</TT>: The target task not only exited its
	RCU read-side critical section, but entered another one
	and further was blocked before the RCU-booster task managed
	to finish boosting.
	The target task will have added itself back to the appropriate list,
	which might well be a different one than it was one before.
	This situation will need to be addressed if there are ever
	per-CPU RCU-booster tasks.
<p>
<LI>	<TT>RCU_UNBOOST_EXITING</TT>: The target task not only exited its
	RCU read-side critical section, but also managed to invoke
	<TT>exit()</TT> before the RCU-booster task managed to finish
	boosting.
	To avoid memory corruption, the target task must wait for the
	RCU-booster task to get done manipulating it before completing
	the <I>exit()</I> code path.
<p>
<LI>	<TT>RCU_EXIT_OK</TT>: The RCU-booster task has finished manipulating
	the target task, which may therefore safely complete the <I>exit()</I>
	code path.
	This is the final state for each target task.
</UL>
<p>
<H3>Events</H3>
<p>
The important events for a target task are (1)&nbsp;being blocked
in an RCU read-side critical section, (2)&nbsp;completing a previously
blocked RCU read-side critical section, and (3)&nbsp;invoking <I>exit()</I>.
When a target task is blocked in an RCU read-side critical section, it
always adds itself to the current list of its per-CPU array.
Conversely, when a target task completes a previously blocked RCU read-side
critical section, it removes itself from this list.
If priority boosting has completed, it also unboosts itself.
During <I>exit()</I> processing, the target task must wait for
the RCU-booster task to complete any concurrent boost/unboost actions.
<p>
The important events for the RCU-booster task are (1)&nbsp;starting to boost
a target task's priority, (2)&nbsp;finishing boosting a target task's priority,
and (3)&nbsp;unboosting a target task.
<p>
<h3>RCU Priority Boosting With Per-Task Lock</h3>
<A NAME="#sec:RCU Priority Boosting With Per-Task Lock"></A>
<p>
One of the issues with the approach described in the previous section
is that RCU boosting must be explicitly accounted for in all task-priority
calculations.
The approach described in this section avoids this by providing a per-task
lock whose main purpose is to provide priority-boosting to the target
tasks, and also has a somewhat simpler state machine.
This leads to a corresponding drawback, namely, that processes blocking
in RCU read-side critical sections incur a latency penalty corresponding
to the overhead of acquiring this additional lock.
<p>
Another drawback that became apparent only after extensive experimentation
is that this method cannot work completely reliably.
It is possible for the target task to block waiting for its own lock
in the (unlikely, but possible) case where the RCU-booster task has
just boosted it, but not yet released the lock.
In this case, the target task will block waiting for the lock, and,
if it is sufficiently low priority, never get a chance to run again.
Since it does not yet hold the lock, the RCU-booster task is unable
to priority boost it.
<p>

You should therefore instead use the approach described in
"RCU Priority Boosting With Minimal Scheduler-Path Overhead," above.
<p>
Nevertheless, this approach is described in some detail in the hope
that someone will figure out a way to make it work.
After all, it is a bit simpler.
Too bad about it not working in all cases!
<p>
<H3>Data Structures</H3>
<p>
The data structures are very similar to those called out
in the "Data Structures" section above.
<p>
<H3>State Diagram</H3>
<p>
Here is a state diagram for the per-task-lock version of RCU
priority boosting.
<p>
<img src="https://static.lwn.net/images/ns/kernel/rcuboost-fig5.png" width=683 height=386
alt="[State diagram]" border=0>
<p>
This fairly closely resembles the one shown in the previous section,
but is slightly simpler, having one fewer node and fewer edges.
<p>
Target tasks in any of the yellow states are linked into the uppermost of
the two sets of lists shown above,
target tasks in any of the red states are linked into the lower of these
two sets of lists,
and target tasks in any of the unshaded states are not linked into either set
of lists.
Target tasks in shaded states hold the per-task lock, and the
RCU-booster task might or might not hold a target task's per-task lock while
the target task is in any of the <TT>RCU_END_BOOST_IDLE</TT>,
<TT>RCU_END_BOOST_BLOCKED</TT>, or <TT>RCU_END_BOOST_EXITING</TT> states.
The black state transitions are traversed by the task, while the
red transitions are traversed by the RCU-booster task.
The double-walled states may be exited either of these two,
requiring that the state value be atomically manipulated.
<p>

<H3>Per-State Details</H3>
<p>
The purpose of the individual states are as follows:
<UL>
<LI>	<TT>RCU_BOOST_IDLE</TT>: This is the initial state.
	A target task resides in this state when not in an RCU read-side
	critical section, or when in an RCU read-side critical section
	that has not yet blocked.
	The task does <I>not</I> hold the per-task lock.
<p>
<LI>	<TT>RCU_BOOST_BLOCKED</TT>: The target task
	has blocked while in an RCU read-side critical section,
	and holds its per-task lock.
	The target task will release its per-task lock upon exiting
	this state, so the RCU-booster task should never see this state.
	Of course, this state is the Achilles's heel of this approach.
	The target task might block on the lock, and never get a chance
	to run again.
	There are a number of amusing (but broken) strategies one might
	use, including reader-writer locks that the target task attempts
	to acquire recursively and the like.
<p>
<LI>	<TT>RCU_BOOSTING</TT>: The RCU-booster task has begun boosting
	the target task's priority.
	It first changes state, and only then acquires the target
	task's per-task lock.
	The target task can see this state either before or after
	the RCU-booster task has blocked on its per-task lock, but
	either way removes itself from the list and changes state
	to <TT>RCU_END_BOOST_IDLE</TT> -- and only then releases its
	per-task lock.
<p>
<LI>	<TT>RCU_END_BOOST_IDLE</TT>: The target task completed its RCU read-side
	critical section after (or while in the process of) being boosted.
	Once the RCU-booster task acquires the lock, it will transition
	the state to <TT>RCU_BOOST_IDLE</TT>, then release the lock.
<p>
<LI>	<TT>RCU_END_BOOST_BLOCKED</TT>: The target task not only exited its
	RCU read-side critical section, but entered another one
	and further was blocked before the RCU-booster task managed
	to acquire the target task's lock.
	The target task will have added itself back to the appropriate list,
	and will hold its own per-task lock.
	Similarly to <TT>RCU_BOOST_BLOCKED</TT>, the target task will
	change state to <TT>RCU_END_BOOST_IDLE</TT> and only then release
	its per-task lock.
<p>
<LI>	<TT>RCU_UNBOOST_EXITING</TT>: The target task not only exited its
	RCU read-side critical section, but also managed to invoke
	<TT>exit()</TT> before the RCU-booster task acquired
	the target task's per-task lock.
	To avoid memory corruption, the target task must wait for the
	RCU-booster task to get done manipulating it before completing
	the <I>exit()</I> code path.
<p>
<LI>	<TT>RCU_EXIT_OK</TT>: The RCU-booster task has finished manipulating
	the target task, which may therefore safely complete the <I>exit()</I>
	code path.
	This is the final state for each target task.
</UL>
<p>
<H3>Events</H3>
<p>
The important events for a target task are (1)&nbsp;blocking
in an RCU read-side critical section, (2)&nbsp;completing a previously
blocked RCU read-side critical section, and (3)&nbsp;invoking <I>exit()</I>.
When a target task is blocked in an RCU read-side critical section, it
always adds itself to the current list of its per-CPU array.
Conversely, when a target task completes a previously blocked RCU read-side
critical section, it removes itself from this list.
If priority boosting has completed, it also unboosts itself.
During <I>exit()</I> processing, the target task must wait for
the RCU-booster task to complete any concurrent boost/unboost actions.
<p>
The important events for the RCU-booster task are (1)&nbsp;starting to boost
a target task's priority and (2)&nbsp;finishing boosting a target task's priority.
<p>
<H3>Important Safety Tip</H3>
<p>
Again, this lock-per-task approach simply does not work reliably in all cases.
It is included only because I thought it would work, and because
I feel that the cautionary tale might be valuable.
You should instead use the approach described in
"RCU Priority Boosting With Minimal Scheduler-Path Overhead."
<p>
<h3>Issues and Roads Not Taken</h3>
<p>
Priority-boosting RCU read-side critical sections, although simple
in concept, is fraught with subtle pitfalls.
This section records some of the pitfalls that I fell into, in the
hope that it saves others the time and trouble.
<p>
<OL>
<LI>	Aggregating lists over multiple CPUs.
	This might be needed for very large systems, but wait until
	needed before increasing the complexity.
	However, on large systems, it probably makes more sense to
	instead provide multiple RCU-boost tasks, perhaps one per
	CPU or per NUMA node.
<p>
<LI>	Dedicating a per-task lock to priority-boosting of target
	tasks.
	As was noted in
	"RCU Priority Boosting With Per-Task Lock,"
	this simply does not work in all cases.
<p>
<LI>	Simpler list locking, for example, single lock per CPU.
	This was rejected because it could in greater contention
	between the RCU-booster task and target tasks.
	With the current design under normal conditions, contention
	should only occur during <TT>rcu_read_unlock()</TT> and
	<TT>exit()</TT> processing.
	Even then, multi-jiffy RCU read-side critical sections are
	required for the <TT>rcu_read_unlock()</TT> to contend with
	the RCU-booster task.
	For example, if such critical sections are blocked!
<p>
<LI>	Immediate boosting upon blocking was rejected
	due to the additional scheduling latency it imposes.
	(Although earlier prototypes did just this, a <I>very</I> few of
	them reliably so.)
<p>
<LI>	Use of <TT>preempt_disable()</TT> instead of <TT>local_irq_disable()</TT>
	works, but subjects the code to extra preemption checks upon
	<TT>preempt_enable()</TT>.
<p>
<LI>	Zero scheduling-path latency.
	The idea here is to require that the RCU-booster task walk the entire
	task list in search of tasks in need of boosting.
	This may be necessary for some workloads, but the overhead of the
	full task-list walk seems prohibitive for any server-class
	workload featuring large numbers of tasks.
</OL>
<p>
<h3>Lessons Learned Along the Way</h3>
<p>
<OL>
<LI>	Interactions with RCU read-side critical sections are very
	touchy.
	By definition, a CPU can exit such a critical section with
	very few ripples, after all, the whole point of RCU's read-side
	primitives is to be very lightweight.
	Therefore, synchronizing with these primitives, as the
	RCU-booster task must, is fraught with peril.
	It is not that the final solution is all that complex or
	difficult, it is rather that there is a very large number
	of seductive but incorrect "solutions".
<p>
<LI>	Interacting with tasks (which might exit at any time) can
	also be quite touchy.
	Most of the methods used to keep a task pinned down simply
	keep the task structure itself pinned down.
	Unfortunately, the RCU-booster task needs the target task
	to be alive and able to respond, for which a separate
	mechanism was (perhaps redundantly) constructed.
<p>
<LI>	The <TT>__rcu_init()</TT> function is called extremely early.
	Not that this was a surprise, but what <I>was</I> a surprise
	was just how many common kernel APIs cannot be called that
	early.
	The solution is straightforward (add a second initialization
	function that is called later from <TT>do_basic_setup()</TT>,
	though there may well be a better solution),
	but this nevertheless somehow managed to be a surprise.
	The <TT>system_state</TT> variable is very helpful in marking
	when the scheduler becomes usable.
<p>
<LI>	The act of designing enterprise-level "torture tests"
	can have the beneficial side-effect of inspiring much
	simpler (and thus easier to test) solutions.
<p>
<LI>	The act of documenting a tricky algorithm can also have
	the beneficial side-effect of inspiring much simpler
	(and thus easier to document) solutions.
</OL>
<p>
I had of course encountered the last two lessons much earlier in
my career, but this problem offered a much-needed refresher course.
<p>
<h3>Acknowledgements</h3>
<p>
I owe a debt of gratitude to the developers and maintainers of
the graphviz package, which greatly eased design of RCU priority
boosting.
I also owe thanks to Josh Triplett for introducing me to this
invaluable package.
<p>
<h3>Legal Statement</h3>
<p>
This work represents the view of the author and does not necessarily
represent the view of IBM.

Intel is a registered trademark of Intel Corporation or its subsidiaries
in the United States and other countries.

% Java and all Java-based trademarks are trademarks of Sun Microsystems,
% Inc. in the United States, other countries, or both.

Linux is a registered trademark of Linus Torvalds in the United States,
other countries, or both.

Other company, product, or service names may be trademarks or service
marks of others.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Read-copy-update">Read-copy-update</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#McKenney_Paul_E.">McKenney, Paul E.</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/220677/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor221301"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Priority-Boosting RCU Read-Side Critical Sections</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 8, 2007 18:05 UTC (Thu)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/221301/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      It's a little worrying that all of these approaches add a new task waking up 100 times a second or thereabouts. Even ignoring the extra icache hit this imposes, doesn't this somewhat torpedo all the effort that's been going on to increase the amount of time the system can go without being woken up?<br>
<p>
(At the very least this whole thing ought to be turned off on power-sensitive devices: but in the end, won't that be pretty much *all* devices, especially embedded ones, which is one domain where realtime stuff becomes important?)<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/221301/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor221461"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Priority-Boosting RCU Read-Side Critical Sections</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Feb 9, 2007 14:44 UTC (Fri)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/221461/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Indeed, and this turns out to be a problem for dynticks -- the CPU running the RCU priority booster will never be able to shut off its scheduling-clock interrupt.  Therefore, the next step is to avoid waking the RCU priority-booster task when there are no sleeping RCU readers.  In the meantime, Ingo Molnar has wisely turned the wakeup rate down from 100 times per second to one time per second.<br>
      
          <div class="CommentReplyButton">
            <form action="/Articles/221461/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2007, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
