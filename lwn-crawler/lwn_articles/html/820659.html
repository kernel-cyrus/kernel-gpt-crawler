        <!DOCTYPE html>
        <html lang="en">
        <head><title>The many faces of &quot;latency nice&quot; [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/820659/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/820566/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/820659/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>The many faces of &quot;latency nice&quot;</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Did you know...?</b>
<p>
LWN.net is a subscriber-supported publication; we rely on subscribers
       to keep the entire operation going.  Please help out by <a
       href="/Promo/nst-nag4/subscribe">buying a subscription</a> and keeping LWN on the
       net.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>May 18, 2020</br>
           <hr>
<a href="/Articles/820337/">OSPM</a>
</div>
A task's "nice" value describes its priority within the completely fair
scheduler; its semantics have roots in ancient Unix tradition.  Last
August, a <a
href="/ml/linux-kernel/20190830174944.21741-1-subhra.mazumdar@oracle.com/">"latency
nice" parameter</a> was proposed to provide similar control over a task's
response-time requirements.  At the 2020 <a
href="http://retis.sssup.it/ospm-summit/">Power Management and Scheduling
in the Linux Kernel summit</a> (OSPM), Parth Shah, Chris Hyser, and Dietmar
Eggemann ran a discussion about the latency nice proposal; it seems that
everybody agrees that it would be a useful feature to have, but there is a
wide variety of opinions about what it should actually do.
<p>
<h4>A different kind of nice</h4>
<p>
Shah started by describing the latency nice value as a per-task attribute
that behaves much like the normal nice value.  It gives the scheduler a hint
about what the task's latency needs are.  It can be tweaked via the <tt><a
href="http://man7.org/linux/man-pages/man2/sched_getattr.2.html">sched_setattr()</a></tt>
system call, though there is some desire to switch to a control-group
interface.  Its values vary between -20 and 19 (as with nice), with -20
indicating a high degree of latency sensitivity and 19 indicating a
complete indifference to latency.  The default value is zero.
<p>
The first question he raised had to do with privilege: should an
unprivileged process be able to decrease its latency nice value?  Ordinary
nice does not allow that, of course; processes must have the
<tt>CAP_SYS_NICE</tt> capability to reduce their nice values.  The
advantage of establishing a similar rule for latency nice is that it might
block potential denial-of-service problems, but at the cost of preventing
ordinary users from taking advantage of this feature.
<p>
Whether this knob should be privileged depends on what it actually does,
which had not yet been discussed.  The initial effect of this feature 
is to control how hard the scheduler will look for an idle core to place a
task on when it wakes up.  This search takes time (thus increasing
latency); an idle core may also have to be roused out of a sleep state,
increasing latency further.  Dhaval Giani pointed out a use case that
Oracle cares about, where some 
latency-sensitive tasks will typically run for
very short periods — less than the time spent searching for an idle core
sometimes.  That search can be avoided by setting a low latency nice value.
<p>
Giani also mentioned a use case from Facebook, which is more interested in
getting longer-running tasks up to full speed quickly; Facebook still wants
low latency, but is better served by finding an idle core that will be able
to get a significant amount of work done quickly.  IBM, meanwhile is hoping
to use this knob to influence 
the scheduler to avoid placing tasks on a CPU that is currently running

<a href="/Articles/820743/"><img
src="https://static.lwn.net/images/conf/2020/ospm/latency-nice-sm.png" alt="[Latency nice
session]" title="Latency nice session" width=405 height=304 hspace=3
vspace=3 border=0 align="right"></a>

latency-sensitive tasks.  The discussion on use cases was cut off at this
point, though, with a promise to revisit it later.
<p>
Returning to privilege, Qais Youssef suggested keeping the ability to
reduce latency nice values as a privileged operation for now, especially
given that this knob could gain new meanings in the future.  Shah said that
there do not appear to be any denial-of-service issues with the
implementation for the current use
cases.
<p>
Eggemann wondered about the range of values for this knob; there is a wish
to bias latency in both directions, but it's not clear what the actual
effects of a positive latency nice value would be.  Patrick Bellasi
suggested that the time before one task could preempt another could be
scaled by the latency nice value.  Vincent Guittot said that, with ordinary
nice, each increment makes about a 10% difference in the amount of CPU time
the process may use.  With latency nice, he said, the values of -19, zero,
and +20 make sense, but he couldn't say what the values in between would
mean.  Hyser said that, for negative values, there could be a fairly direct
effect on the number of CPUs that will be searched before placing a task.
Shah suggested that positive values could allow task placement anywhere in the
system, even to CPUs that do not share low-level memory cache, which is
something the scheduler normally tries hard to avoid.
<p>
Eggemann then expressed a sentiment that would be heard a few times in the
session: latency nice is trying to control too many functionalities with a
single knob.  Bellasi suggested that the use cases could be hammered out
during review of the patch and asked whether there were any real use cases
with contradictory semantics.  Giani mentioned the Oracle and Facebook
cases mentioned above.
<p>
<h4>Control groups</h4>
<p>
Eggemann took over the presentation at this point to talk about what the
Android developers would like to see.  Android currently uses a
control-group interface that includes a "prefer idle" attribute; setting
that will bias CPU selection toward an idle CPU.  The real effect of this
setting, though, is to short out the energy-aware scheduling logic, which
brings a 
certain amount of latency of its own.  Thus, in this context, searching for
an idle CPU is something that is preferable to do for latency-sensitive
tasks — just the opposite of the situation described above.
<p>
His real purpose, though, was to discuss a potential control-group-based
interface for latency nice.  Control groups are a mechanism to organize
processes and distribute resources, which is what is needed here.  With the
CPU controller, there are three ways in which CPU resources are
controlled.  The "weight" value gives a relative priority to the group,
while the "max" value limits the maximum CPU time available and the "min"
value ensures that a minimal amount of CPU time will be granted.
Utilization clamping is also handled here.
<p>
How could the latency nice value be managed in this setting?  The resource
controlled would still have to be CPU cycles, he said.  But the association
between latency requirements and CPU cycles is not as clear as it is with
the parameters described above.  He is not sure what sort of semantics
would be acceptable to the control-group maintainer.  Bellasi suggested a
clamping model, where each group would have values indicating the minimum
and maximum latency nice values a task in that group could request.
Guittot pointed out, though, that changes to latency nice values would have
to be propagated up to the root of the control-group hierarchy.  The
discussion wandered around this point for a while before bogging down in
just how latency nice would work

<p>
Eggemann eventually suggested moving on, saying that perhaps the use cases
should have been discussed from the outset.  The control-group interface is
only really important to Android, he said, so perhaps it would be better to
figure out what the per-task attribute implementation would actually be
doing.
<p>
<h4>Use cases at last</h4>
<p>
Hyser took over at this point to talk about use cases; he reiterated that
the original purpose of the patch set was to skip the idle-CPU search for
latency-sensitive tasks.  This resulted in a 1% increase in a
transaction-processing benchmark.  Many workloads have critical processes
that do not run for long but need to run immediately when the time comes.
The latency nice change can make it possible for many of these workloads to
avoid the need to use the realtime patches.
<p>
He put up some plots showing that latency nice does result in better
latencies; the effect is more pronounced on systems with more cores.
<p>
<blockquote>
<img src="https://static.lwn.net/images/conf/2020/ospm/lnice.png" alt="[Latency plot]"
class="photo" width=651>
</blockquote>
<p>

 He
suggested that negative values should be interpreted as the number of cores
to search; a value of -20 means search no cores at all, -19 would search
one core, etc.  But should this value be scaled by the number of CPUs in
the system?  It's still not clear how it should be interpreted.  He
suggested that latency nice looks a lot like a Boolean value in real-world
use; either other cores are searched to place a task or not.
<p>
Giani said that the effect of changing a task's nice value is well
understood; the effect of changing latency nice is rather less so.  Hyser
suggested that it could be seen as adjusting the size of the scheduling
domain for latency-sensitive tasks.  But scheduling domains are hardware
dependent, making it hard to come up with a hardware-independent
description of the semantics of latency nice.  The -20 value, which
searches zero cores, is not dependent on hardware at least, Hyser said.
He concluded by saying that a value of -1 could mean that the CPU search
would happen, but energy-aware scheduling would be disabled.
<p>
Giani said that latency nice appears to be trying to do a bunch of things
and wondered if it makes sense to control it all with a single interface;
Peter Zijlstra responded that those things do all affect latency, at
least.  Rafael Wysocki said that a single integer value is not enough to
express everything that is needed here.  Zijlstra said that the session
really should have started with the use cases, then looked at tunables to
suit those cases.
<p>
Shah discussed the task-packing use case.  In particular, on systems with
Intel's "turbo" mode, packing tasks onto a small number of cores <a
href="/Articles/792471/">can save enough resources</a> to allow others to
go into turbo mode.  He suggested that tasks marked with a latency nice
value greater than 15 could be packed this way, as long as they don't push
the utilization of the target core above a threshold value.  Doing so led
to a 14% performance benefit on a workload he tested.
<p>
Another use case involves restricting the sleep states that a CPU can go
into.  The <a href="/Articles/386139/">pm_qos</a> mechanism can do that
now, but it is a system-wide parameter with no per-task control, so it does
not work as well as one would like on larger systems; it has no notion of
where the latency-sensitive task will run.  He suggested implementing a
per-CPU counter indicating how many latency-sensitive tasks are present; if
a CPU is running such tasks, the sleep states it could go into would be
restricted.
<p>
Wysocki responded that this isn't a realistic scenario.  It could become
confused if the task is migrated, for example; he said that latency nice is
not a good interface for this case.  There is no way to map a latency nice
value and the set of permissible exit latencies for the CPU.  Bundling
semantics in this way is not going to work, he said.  Bellasi said that
such an interface would require users to determine their latency nice
values through experimentation on a specific platform.
<p>
Shah persisted, though, saying that it can be beneficial to keep CPUs with
latency-sensitive tasks from going idle.  Scheduler benchmark runs showed a
significant latency reduction with these semantics while maintaining
similar power consumption.  A pgbench run also showed big improvements in
latency, but at a cost (sometimes large) in power consumption.
<p>
Youssef said that the interface to all of this is the sticking point.
Thomas Gleixner agreed, saying that the -20..19 range "requires a crystal
ball" to use properly.  Zijlstra repeated his call to enumerate the use
cases before getting into the interface details.  Giani repeated that the
interface does not look correct now, and agreed that a more comprehensive
look at the use cases was needed.  Things were being done backwards
currently, he said.
<p>
Eggemann concluded by saying that the group needed to collect use cases and
"take them all seriously".  While the discussion continued to circle around
these points for a while, it was, for all practical purposes, done.  
<p>
[See <a href="/images/conf/2020/ospm/latency-nice-slides.pdf">the slides
from this session [PDF]</a> for more plots and other details.]<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Latency">Latency</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Scheduler-Latency">Scheduler/Latency</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#OS-Directed_Power-Management_Summit-2020">OS-Directed Power-Management Summit/2020</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/820659/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor820837"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The many faces of &quot;latency nice&quot;</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 19, 2020 4:43 UTC (Tue)
                               by <b>alogghe</b> (subscriber, #6661)
                              [<a href="/Articles/820837/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Wouldn't audio processing and delivering frames to a vr headset be use cases for this interface?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/820837/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor820838"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The many faces of &quot;latency nice&quot;</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 19, 2020 5:23 UTC (Tue)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/820838/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I would even say very good "test" cases? The human ear is a great latency benchmark, down to a couple tens of milliseconds. No one ever translated scheduler activity into sounds yet?<br>
<p>
I suspect the same sort of delays in VR can make you sick but that require more than one missed deadline.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/820838/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor820881"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The many faces of &quot;latency nice&quot;</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 19, 2020 20:57 UTC (Tue)
                               by <b>iabervon</b> (subscriber, #722)
                              [<a href="/Articles/820881/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I think that's likely to want more of a "soft realtime" approach (setting deadlines, attempting to meet them as often as possible) rather than a "nice" approach (optimizing for latency over throughput), particularly because the program knows exactly when it's going to need the next frame, and doesn't know exactly how big a trade-off is necessary to make that schedule.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/820881/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor820888"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The many faces of &quot;latency nice&quot;</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 20, 2020 0:31 UTC (Wed)
                               by <b>NYKevin</b> (subscriber, #129325)
                              [<a href="/Articles/820888/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
YAGNI. The time between frames tends to be long enough that you can get away with a certain amount of thread preemption without serious issue. Even when running at 90 FPS (minimum recommended for VR to avoid motion sickness), you still have more than 11 ms to draw each frame. When you consider that the bulk of the work is done by the GPU (which cannot be preempted), I don't think it's necessary to use SCHED_DEADLINE just to make sure the CPU gets scheduled every ~5-10 ms to "drive." A negative nice value really ought to be sufficient for that, unless you're doing something unreasonable with the rest of the system.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/820888/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor820906"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Too few knobs, or one too many?</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 20, 2020 9:15 UTC (Wed)
                               by <b>epa</b> (subscriber, #39769)
                              [<a href="/Articles/820906/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
For the big boys I agree that "latency nice is trying to control too many functionalities with a single knob".  If you are Facebook or IBM or Google, you know the latency requirements of your application and you need control over each individual parameter.<br>
<p>
But as a top-level interface for nonspecialists, I think that a separate "latency nice" knob is one knob too many.  Instead, the latency should be included in the ordinary "nice" level.  Setting a nice value of 10 should not only reduce the CPU timeslice priority but also make the process less latency-sensitive.  Setting -10 should both boost the CPU priority and make the scheduling a bit more responsive.  So there's still a simple way to just "be nice" in general.<br>
<p>
I am not saying at all that adjusting the CPU timeslice priority should always require you to tweak the scheduler parameters too.  Far from it.  Those who know what they are doing will need to control all of the tunables separately.  They don't rely on a single "nice" level.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/820906/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor821027"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The many faces of &quot;latency nice&quot;</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 20, 2020 23:28 UTC (Wed)
                               by <b>benjamir</b> (subscriber, #133607)
                              [<a href="/Articles/821027/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
While on a different scale, it sounds a little bit like the SLURM multifactor priority plugin, where several aspects are weighted and tunable.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/821027/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2020, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
