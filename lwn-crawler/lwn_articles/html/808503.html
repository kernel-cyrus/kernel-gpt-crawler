        <!DOCTYPE html>
        <html lang="en">
        <head><title>A medley of performance-related BPF patches [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/808503/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/808497/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/808503/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>A medley of performance-related BPF patches</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>LWN.net needs you!</b>
<p>
Without subscribers, LWN would simply not exist.  Please consider
       <a href="/Promo/nst-nag2/subscribe">signing up for a subscription</a> and helping
       to keep LWN publishing.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>January 2, 2020</br>
           </div>
One of the advantages of the in-kernel BPF virtual machine is that it is
fast.  BPF programs are just-in-time compiled and run directly by the CPU,
so there is no interpreter overhead.  For many of the intended use cases,
though, "fast" can never be quite fast enough.  It is thus unsurprising
that there are currently a
number of patch sets under development that are intended to speed up one
aspect or another of using BPF in the system.  A few, in particular, seem
about ready to hit the mainline.
<br clear="all">
<p>
<h4>The BPF dispatcher</h4>
<p>
BPF programs cannot run until they are "attached" to a specific call
point.  Tracing programs are attached to tracepoints, while networking
express data path (XDP) programs are attached to a specific network
device.  In general, more than one program can be attached at any given
location.  When it comes time to run attached programs, the kernel will
work through a linked list and invoke each program in turn.
<p>
Actually executing a compiled BPF program is done with an indirect jump.
Such jumps were never entirely fast, but in the age of
speculative-execution vulnerabilities those jumps have been turned into <a
href="https://support.google.com/faqs/answer/7625886">retpolines</a> — a
construct that defeats a number of Spectre attacks, but which also turns
indirect jumps into something that is far slower than they were before.
For cases where BPF programs are invoked frequently, such as for every
incoming network packet, that extra overhead hurts.
<p>
There have been <a href="/Articles/774743/">a number of efforts</a> aimed
at reducing the retpoline performance penalty in various parts of the
kernel.  The <a
href="/ml/netdev/20191213175112.30208-1-bjorn.topel@gmail.com/">BPF
dispatcher patch set</a> is Björn Töpel's approach to the problem for BPF
programs, and for the XDP use case in particular.  It maintains a
machine-code trampoline containing a direct jump instruction for every
attached BPF
program; this trampoline must be regenerated whenever a program is added to or
removed from the list.  When the time comes to call a BPF program, the
trampoline is invoked with the address of the program of interest; it then
executes a binary search to find the direct-jump instruction corresponding
to that program.  The jump is then executed, causing the desired program to
be run.

<p>
That may seem like a lot of overhead to replace an indirect call, but it is
still faster than using a retpoline — by a factor of about three, according
to the performance result posted with the patch series.  In fact, indirect
jumps are so expensive that the dispatcher is competitive even in the
absence of retpolines, so it is enabled whether retpolines are in use or not.
This code is in its fifth revision and seems likely to make its way into
the mainline before too long.
<p>
<h4>Memory-mappable maps</h4>
<p>
BPF maps are the way that BPF programs store persistent data; they come in
a number of varieties but are essentially associative arrays that can be
shared with other BPF programs or with user space.  Access to maps from
within BPF programs is done by way of special helper functions; since
everything happens within the kernel, this access is relatively fast.
Getting at a BPF map from user space, instead, must be done with the <tt><a
href="http://man7.org/linux/man-pages/man2/bpf.2.html">bpf()</a></tt>
system call, which provides operations like <tt>BPF_MAP_LOOKUP_ELEM</tt>
and <tt>BPF_MAP_UPDATE_ELEM</tt>.
<p>
If one simply needs to read out the results at the end of a tracing run,
calling <tt>bpf()</tt> is unlikely to be a problem.  In the case of
user-space programs that run for a long time and access a lot of data in
BPF maps, though, the system-call overhead may well prove to be too much.
Much of the time, the key to good performance is avoiding system calls as
much as possible; making a call into the system for each item of data
exchanged with a BPF program runs counter to that principle.

Andrii Nakryiko has a partial solution to this problem in the form of <a
href="/ml/netdev/20191117172806.2195367-1-andriin@fb.com/">memory-mappable
BPF maps</a>.  It allows a user-space process to map a BPF array map (one
that is 
indexed with simple integers) directly into its address space; thereafter,
data in BPF maps can be accessed directly, with no need for system calls at
all.
<p>
There 
are some limitations in the current patch set; only array maps can be
mapped in this way, and maps containing spinlocks cannot be mapped (which
makes sense, since user space will be unable to participate in the locking
protocol anyway).  Maps must be created with the <tt>BPF_F_MAPPABLE</tt>
attribute (which causes them to be laid out differently in memory) to be
mappable.

This patch set has been <a
href="/ml/netdev/04403b43-3a08-e63e-729e-5f9e66ca0dc2@iogearbox.net/">applied</a>
to the BPF repository and can be expected to show up in the 5.6 kernel.
<p>
<h4>Batched map operations</h4>
<p>
Memory-mapping BPF maps is one way of avoiding the <tt>bpf()</tt> system
call but, as seen above, it has some limitations.  A different approach to
reducing system calls can be seen in the <a
href="/ml/linux-kernel/20191211223344.165549-1-brianvv@google.com/">batched
operations patch set</a> from Brian Vazquez.  System calls are still
required to access BPF map elements, but it becomes possible to access
multiple elements with a single system call.
<p>
In particular, the patch set introduces four new map-related commands for
the <tt>bpf()</tt> system call: <tt>BPF_MAP_LOOKUP_BATCH</tt>,
<tt>BPF_MAP_LOOKUP_AND_DELETE_BATCH</tt>, <tt>BPF_MAP_UPDATE_BATCH</tt>,
and <tt>BPF_MAP_DELETE_BATCH</tt>.  These commands require the following
structure to be passed in the <tt>bpf()</tt> call:
<p>
<pre>
    struct { /* struct used by BPF_MAP_*_BATCH commands */
        __aligned_u64   in_batch;
        __aligned_u64   out_batch;
        __aligned_u64   keys;
        __aligned_u64   values;
        __u32           count;
        __u32           map_fd;
        __u64           elem_flags;
        __u64           flags;
    } batch;
</pre>
<p>
For lookup operations (which, despite their name, are intended to read
through a map's entries rather than look up specific entries),
<tt>keys</tt> points to an array able to hold 
<tt>count</tt> keys; <tt>values</tt> is an array for <tt>count</tt>
values.  The kernel will pass through the map, storing the keys and
associated values for a maximum of that
many elements, and setting <tt>count</tt> to the number actually returned.
Setting <tt>in_batch</tt> to <tt>NULL</tt> starts the lookup at the
beginning of the map; the <tt>out_batch</tt> value can be used for
subsequent calls to pick up where the previous call left off, thus allowing
traversal of the entire map.
<p>
Update and delete operations expect <tt>keys</tt> to contain the keys for
the map elements to be affected.  Updates also use <tt>values</tt> for the
new values to be associated with <tt>keys</tt>.
<p>
The batch operations do not eliminate system calls for access to map
elements, but they can reduce those calls considerably; one call can affect
100 (or more) elements at a time rather than just one element.  The batch
operations do have some significant advantages over memory-mapping; for
example, they can be used for any map type, not just array maps.  It is
also possible to perform operations (like deletion) that cannot be done
with memory-mapping.
<p>
There is thus a place for both approaches.
This patch set is in its third revision, having picked up a number of
reviews and acks along the way, so it, too, seems likely to be merged in
the near future.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#BPF">BPF</a></td></tr>
            <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Retpoline">Retpoline</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/808503/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor808550"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A medley of performance-related BPF patches</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 3, 2020 9:24 UTC (Fri)
                               by <b>scientes</b> (guest, #83068)
                              [<a href="/Articles/808550/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Why don't we rename Linux to BPF-kernel?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/808550/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor808556"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A medley of performance-related BPF patches</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 3, 2020 11:07 UTC (Fri)
                               by <b>darwi</b> (subscriber, #131202)
                              [<a href="/Articles/808556/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<p>
<font class="QuotedText">&gt; Why don't we rename Linux to BPF-kernel?</font><br>
<p>
A heavy reliance on BPF is not a bad thing in and out of itself.<br>
<p>
It makes me remember the GCC scenario: it made pluggability quite hard, on purpose, due to a political fear of plugins and GNU losing control. Meanwhile, LLVM, heavily encouraged extensibility: static analysis, R&amp;D in compilers and programming-languages, etc.<br>
<p>
In around 10 years or so, a lot of new programming languages and static analysis tools began using LLVM *exclusively*, and GCC has taken a back seat.<br>
<p>
TLDR: no need to hate BPF here. It's encouraging a lot of R&amp;D in the kernel and surrounding plumbing layer. Let the technology progress freely...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/808556/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor809598"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A medley of performance-related BPF patches</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 15, 2020 14:03 UTC (Wed)
                               by <b>anton</b> (subscriber, #25547)
                              [<a href="/Articles/809598/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      Actually, correctly predicted indirect branches are relatively cheap on modern CPUs.  Unfortunately, I cannot compare them to direct branches easily (I have seen a case where replacing an indirect call by a direct call had no performance effect, though), but I can compare them to not branching at all: In Gforth with dynamic superinstructions (the default if you build it yourself), you have a kind of JIT compiler that puts one code fragment after the other.  If you call it with --no-super (and --ss-number=1 to disable a conflicting optimization), you get two moves and an indirect jump inserted between two consecutive fragments, with each of these jumps jumping directly to the next fragment.  Here are the results for

<pre>
perf stat -e cycles:u -e instructions:u \
-e cpu/event=0xc4,umask=0x20,name=br_inst_retired_near_taken/u \
-e cpu/event=0xc5,umask=0x20,name=br_misp_retired_near_taken/u \
gforth-fast --ss-states=1 onebench.fs
perf stat -e cycles:u -e instructions:u \
-e cpu/event=0xc4,umask=0x20,name=br_inst_retired_near_taken/u \
-e cpu/event=0xc5,umask=0x20,name=br_misp_retired_near_taken/u \
gforth-fast --ss-states=1 --no-super onebench.fs
</pre>

on a Core i5-6600K (Skylake):

<pre>
  default      --no-super
1,337,788,988  1,859,774,730  cycles:u                                                    
3,602,683,259  5,132,418,005  instructions:u           
  177,471,986    646,173,626  br_inst_retired_near_taken                                   
    5,677,645      7,353,850  br_misp_retired_near_taken                                   
</pre>

As you can see, the --no-super variant has many more (correctly predicted) indirect branches, and also more cycles, but only 1.1 additional cycles per additional indirect branch (and these cycles also cover the two additional moves per indirect branch).

<p>Concerning BPF-kernel, Greenspun's tenth rule comes to mind.
      
          <div class="CommentReplyButton">
            <form action="/Articles/809598/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor809968"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A medley of performance-related BPF patches</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 18, 2020 9:59 UTC (Sat)
                               by <b>Wol</b> (subscriber, #4433)
                              [<a href="/Articles/809968/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Actually, correctly predicted indirect branches are relatively cheap on modern CPUs. </font><br>
<p>
And therein lies the problem you have missed. Predicting branches is a variant of the Spectre attack. Plus, "relatively cheap" doesn't preclude the possibility of something else being cheaper.<br>
<p>
Indirect branches are now deprecated because (a) they are easy to use in an attack, and (b) we've found something cheaper.<br>
<p>
Cheers,<br>
Wol<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/809968/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor809970"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A medley of performance-related BPF patches</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 18, 2020 11:40 UTC (Sat)
                               by <b>anton</b> (subscriber, #25547)
                              [<a href="/Articles/809970/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <blockquote>
Predicting branches is a variant of the Spectre attack.
</blockquote>

More precisely, Spectre variants work by getting the program to mispredict branches, and combining that with a side channel.

<blockquote>
Plus, "relatively cheap" doesn't preclude the possibility of something else being cheaper.
</blockquote>

Yes, obviously straight-line code is cheaper, as I demonstrated above.  Concerning the proposed conditional branch trees, a correctly predicted taken branch takes 1 cycle on Skylake, a not-taken conditional branch can take 0 cycles (but the Skylake can only process two branches per cycle), so with all predictions correct, the tree takes at least one cycle, and with 64 targets (i.e., a 6-deep conditional branch tree), it takes 3-6 cycles.  By contrast, a correctly predicted indirect branch costs 1 cycle.  The claim in the original article that "indirect branches were never entirely fast" is nonsense.

<p>If we assume a worst-case branch prediction accuracy, the indirect branch costs one misprediction (~20 cycles), while the 6-deep conditional branch tree costs three mispredictions on average (50% prediction accuracy), for a total of ~60 cycles.

<p>It is possible that for in-between branch prediction accuracy, the conditional branch predictor may work so much better than the indirect branch predictor, that the end result is better for the tree.  But I would have to see measurements before I believe it.  I have read the patch announcement, but the information provided there is insufficient for me to understand what was measured, and what the numbers mean.

<blockquote>
Indirect branches are now deprecated because (a) they are easy to use in an attack, and (b) we've found something cheaper.
</blockquote>

I have yet to see an instruction set manual that says that indirect branches are deprecated.  As for the claimed reasons:

<p>a) If they were easy to use in an attack, we would hear a lot about such attacks in the wild.  But sure, in some environments (e.g., in the kernel), you do not want to use indirect branches and replace them with something else.  That does not mean that indirect branches are deprecated in general.

<p>b) No, you have not, as discussed above.  But I invite you to substantiate your claim by replacing the indirect branches in Gforth with "something cheaper", and measure the result.

      
          <div class="CommentReplyButton">
            <form action="/Articles/809970/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor810499"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">A medley of performance-related BPF patches</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 25, 2020 1:31 UTC (Sat)
                               by <b>Shabbyx</b> (guest, #104730)
                              [<a href="/Articles/810499/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I didn't read well enough to understand why there's a jump, but this gave me an idea.<br>
<p>
Why not put all bpf programs attached to the same point all sequentually in memory? That way when one program finishes, the next instruction would naturally be the start of the next program. No jumps involved.<br>
<p>
Obviously removing bpf programs would involve a shift.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/810499/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2020, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
