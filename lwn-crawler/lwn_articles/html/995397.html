        <!DOCTYPE html>
        <html lang="en">
        <head><title>AutoFDO and Propeller [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/995397/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/995491/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/995397/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>AutoFDO and Propeller</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>This article brought to you by LWN subscribers</b>
<p>
Subscribers to LWN.net made this article &mdash; and everything that
       surrounds it &mdash; possible.  If you appreciate our content, please
       <a href="/Promo/nst-nag3/subscribe">buy a subscription</a> and make the next
       set of articles possible.
</blockquote>
<div class="FeatureByline">
           By <b>Jake Edge</b><br>October 28, 2024</br>
           <hr>
<a href="/Archives/ConferenceIndex/#Linux_Plumbers_Conference-2024">LPC</a>
</div>
<p>
Rong Xu and
Han Shen described the kernel-optimization techniques that Google uses in the <a
href="https://lpc.events/event/18/sessions/180/#20240918">toolchains
track</a> at the <a
href="https://lpc.events/event/18/page/224-lpc-2024-overview">2024 Linux
Plumbers Conference</a>.
They talked about <a
href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45290.pdf">automatic
feedback-directed optimization</a> (AutoFDO), which can be used with the <a
href="https://research.google/pubs/propeller-a-profile-guided-relinking-optimizer-for-warehouse-scale-applications/">Propeller</a>
optimizer to produce kernels with better performance using profile
information gathered from real workloads.  There is a fair amount of
overlap between these tools and the <a
href="https://github.com/llvm/llvm-project/tree/main/bolt#bolt">BOLT</a>
post-link optimizer, which was the subject of a <a
href="/Articles/993828/">talk</a> that directly preceded this session.
</p>


<h4>AutoFDO</h4>

<p>
Xu started by saying that he would be covering AutoFDO, then Shen would talk
about further performance enhancements using Propeller on top of AutoFDO.
At Google, where Xu and Shen work, the amount of time spent executing in the kernel
on its fleet was measured.  Xu put up a slide 
showing the CPU-cycle percentage of the kernel, with idle time excluded,
for a variety of workloads, which can be seen in the <a
href="https://lpc.events/event/18/contributions/1922/attachments/1450/3084/AutoFDO%20&amp;%20Propeller%20in%20LPC%202024.pdf">slides</a> or
<a href="https://www.youtube.com/watch?v=tPMvuFKI2Xo">YouTube video</a> of
the talk.  Anywhere from 17-60% of the CPU cycles were
spent in the kernel; the fleet-wide average is about 20%.
</p>

<p>
There have been lots of efforts toward optimizing the Linux kernel, he
said; at Google, one of the main techniques is <a
href="https://en.wikipedia.org/wiki/Profile-guided_optimization">feedback-directed
optimization</a> (FDO), which uses run-time information to improve code
generation.  The core idea is to gather profile information on real workloads to
allow the compiler to focus on the optimizations that have the most impact
based on how the program runs.
</p>

<p>
FDO has proven to be effective and is used
on nearly all of the applications at Google, for Android, ChromeOS, and in
the data center, he said.  It improves instruction-cache usage, reduces
TLB misses, and improves branch performance.  The overall improvement can
be up to 20% for the run time, but there is another benefit; FDO usually also
reduces code size.
</p>

<a href="/Articles/995371/">
<img src="https://static.lwn.net/images/2024/lpc-xu-sm.png" border=0 hspace=5 align="right"
alt="[Rong Xu]" title="Rong Xu" width=235 height=270>
</a>

<p>
There are two major types of FDO: instrumentation-based and sample-based.
The instrumentation-based variant (also known as iFDO) is the original one; it
uses an 
instrumented kernel to run tests that represent the real workload, which
result in the profile to be used. 
The profile is then fed to the compiler to build an optimized kernel that
can be deployed to production.  The instrumented kernel provides accurate
profiles, without depending on performance monitoring unit (PMU) hardware,
but the resulting kernel is up to ten times slower, so it cannot be used in
production. The load tests still need to be representative, however.  Beyond
that, another disadvantage is that iFDO requires kernel changes for the instrumentation.
</p>

<p>
Sample-based FDO (or AutoFDO) starts with a kernel built with debug
symbols, then the perf tool is used to measure a representative workload.
The raw perf data is converted to an AutoFDO profile that is fed to the
compiler to build the optimized kernel.  Because the perf-based data
collection has such low overhead, the test kernel can be used in production
with real workloads, which eliminates the concern about having truly
representative test cases.  But, AutoFDO does not optimize quite as well as
iFDO
because the profile data is not as complete; "<q>so if you use the same
load test, you will get close performance, but not as good</q>".  In
addition, AutoFDO requires support for both a hardware PMU and perf.
</p>

<p>
For fast-moving projects with incremental releases, the suggested
model is to 
use an iterative process where the profile information gathered running the
kernel in production for a particular 
release is fed to the compiler building the test kernel for the next
release.  That release is run in production and the profile gathered is fed
in to build the following release—and so on.  There are code mismatches, but
AutoFDO uses line numbers relative to the start of functions; if there is
no major refactoring in the release, "<q>we find this works pretty
well</q>".  The developers think this mode will work well for minor releases of the kernel, he said.
</p>

<p>
AutoFDO requires last branch record LBR or similar support in the
processor; AMD branch sampling (BRS) and Arm embedded trace macrocell (ETM)
can provide the same kind of information.  With that information, AutoFDO
can create a profile that allows multiple types of optimizations to be
made.  There are three that usually have the most impact: function
inlining, increasing branch fall-through, and indirect-call promotion.
</p>

<p>
Inlining helps reduce both the
size and run time of the code. Falling through branches is faster
than taking a branch even if it is correctly predicted; in addition, that
optimization groups hot basic blocks together for better instruction-cache
utilization.  Lastly, indirect calls can be promoted to direct calls, which
allows them to be inlined.  Other optimization passes can query the profile
data to retrieve counts for basic blocks, branches taken, and so on, so
those optimizations will be improved as well.
</p>

<p>
Xu gave a brief report of some performance numbers.  In nearly all of the
tests (a mixture of micro-benchmarks and workload tests), iFDO improved
performance slightly more than AutoFDO, and most were fairly modest gains
(2-10%) overall.  In a workload test of a Google database application,
AutoFDO performance improved by 2.6%, while iFDO saw 2.9%.  He worked with
some Meta engineers who reported a roughly 5% performance increase in one
of their services using AutoFDO and around 6% with iFDO.
</p>

<p>
Overall, the path for using AutoFDO on the kernel has been fairly smooth.
"<q>The testing turns out to be the most challenging part of the work</q>";
finding representative workloads and benchmarks is difficult.  Along the
way, the developers have learned that profiles from Intel machines work
well on AMD machines.  For even better performance, he recommended using
<a href="https://llvm.org/docs/LinkTimeOptimization.html">link-time
optimization</a> (LTO) and <a
href="https://clang.llvm.org/docs/ThinLTO.html">ThinLTO</a>.
</p>

<h4>Propeller</h4>

<p>
Shen then stepped up to describe using Propeller to build kernels.  He
started by describing what a post-link optimizer is, but noted that the
BOLT talk just prior  had covered it well.  A post-link optimizer
only requires the binary and a profile of it running on a representative
workload, it does not usually need the source code.  It uses a disassembler
to convert the machine code into a compiler intermediate representation (IR), then does analysis and
optimization, and finally converts back to machine code for the final output.
</p>

<p>
Conceptually, Propeller is a post-link optimizer, but it takes a different
approach; it uses the compiler and linker to do the transformations.  As
with other post-link optimizers, it takes in a binary and a profile to
identify a series of optimizations, but it does not directly apply them.
Instead, it writes compiler and linker profiles, then redoes the build
using the same source code. The compiler and linker do their usual jobs,
but use the profile
information to apply the optimizations as part of the process.  The result
is the same, an 
optimized binary, but the internal steps are different.
</p>

<a href="/Articles/995372/">
<img src="https://static.lwn.net/images/2024/lpc-shen-sm.png" border=0 hspace=5 align="right"
alt="[Han Shen]" title="Han Shen" width=202 height=280>
</a>

<p>
There are a few reasons why this approach was used.
While working on post-link optimization, the developers found that the
disassembler does not work on all binaries.  For example, it does not work
on binaries with
read-only data intertwined with code, or for binaries that must comply with various standards, such as <a
href="https://en.wikipedia.org/wiki/Federal_Information_Processing_Standards">FIPS</a>
compliance.  Beyond that, there are scalability problems: "<q>the
single-machine multithreaded design of the post-link optimizer leads to
excessive processing time and memory usage</q>".  That led them to shift
some of that burden to the compiler and linker, he said.
</p>

<p>
There are a few advantages to the Propeller mechanism.  First, the
optimization transformation is "<q>done with the uttermost accuracy</q>"
because they are handled by the compiler and linker.  It also "<q>opens the
door for parallelizing because each compilation job is independent</q>".  A
distributed build cache can be used; if no optimization instructions are
found for a particular source file, it does not need to be rebuilt and the
cached object file can be used.  It also means that Propeller itself does
not need to deal with the kernel metadata that gets built; that is all
handled by the existing build process.  Propeller does require the source
code, however, and the rebuild step, which are disadvantages of the approach.
</p>

<p>
There are currently two major optimizations that are made by Propeller:
basic-block layout and path cloning.  There is also active work on adding
inter-procedure register allocation, Shen said.
</p>

<p>
Propeller can be combined with AutoFDO by building an AutoFDO profile that
is used to build a kernel that is then profiled for Propeller.  The
profile used to build the AutoFDO kernel is also used to rebuild the kernel
again with the Propeller profiles.  Each kernel is run in production to
generate the profiles needed.  The final result is a kernel that has been
optimized by both AutoFDO and Propeller.
</p>

<p>
Unlike other post-link optimizers, Propeller can optimize kernel modules.
Post-link optimizers operate on executables and shared libraries, but
kernel modules are relocatable objects.  Propeller can resolve the
relocation information in the module to link to the proper symbols.
</p>

<p>
As mentioned earlier, AutoFDO can tolerate minor source-code changes and
small differences in the build options, but that is not true for Propeller.
The source code and build options of the kernel used for generating the
profile must be identical to those that Propeller uses.  The developers
"<q>are working hard to try to mitigate this limitation</q>", he said.
</p>

<p>
Propeller requires specific software and hardware support to do its job.
It depends on a <a href="https://github.com/google/autofdo">tool</a> that
lives outside of the LLVM source tree.  The developers are currently
working on migrating the functionality into LLVM.  It also needs branch
information from the CPU, which comes from features that vary across
architectures (LBR for Intel, BRS or LBRv2 for AMD, and SPE or ETM for
Arm).  For internal applications, Propeller has been verified on each
architecture (though not each branch-tracking feature); for the kernel,
only Intel LBR has been validated at this point.
</p>

<p>
Shen showed some heat maps and graphs of PMU stats for 
no FDO, iFDO, AutoFDO, and the latter two with ThinLTO and Propeller.  As
might be guessed, there were improvements in nearly all of the categories
for Propeller.
</p>

<p>
Currently, patches enabling AutoFDO and Propeller in LLVM have been <a href="/ml/all/20241014213342.1480681-1-xur@google.com/">sent
upstream for review</a>, Shen said.  Internally, the developers are doing
"<q>large-scale production tests to measure the performance
company-wide</q>"; they are also looking at customer kernels based on
specific workloads with the idea of building different kernels for
individual applications. 
</p>

<p>
In summary, he said that FDO, using either iFDO and AutoFDO, "<q>improves
kernel performance significantly</q>".  AutoFDO integrates well with the
kernel build and allows profiling in production, which is a huge benefit
over iFDO.  Their advice is to add Propeller on top to get the best possible performance.
</p>

<p>
During Q&amp;A, Peter Zijlstra asked about why there was a need for
multiple profile runs; the AutoFDO profile should already have the needed
information, he said.  Shen said that the first-pass optimizations change
the code such that the profile information is out of date, which is where
the Propeller profiling picks up.  Zijlstra noted that the code is
transformed again at that point, so another profile would be needed; Shen
agreed that it is an iterative process and that more profiling and
rebuilding passes improve the results.
</p>

<p>
Zijlstra also complained that calling Propeller a post-link optimizer was
not accurate.  The optimization happens during the build process.  Another
audience member agreed, saying that the profile information was gathered
post-link, but that it was simply another form of profile-guided
optimization; Zijlstra suggested that Propeller should simply be called
that to avoid the confusion.
</p>

<p>
There is, it seems, a lot of work going into producing optimized kernels
using LLVM, though BOLT can also operate on kernels built with GCC.  That
this work is being done by companies with large fleets of cloud systems is
no real surprise; a tiny increase in performance multiplied by the fleet
size makes for a rather large impact on CPU usage, thus power requirements,
number of systems needed, and so on—all of which boils down to spending less
money, of course.
</p>

<p>
[ I would like to thank LWN's travel sponsor, the Linux Foundation, for
travel assistance to Vienna for the Linux Plumbers Conference. ]
</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Optimization_tools">Optimization tools</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Linux_Plumbers_Conference-2024">Linux Plumbers Conference/2024</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/995397/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor1000468"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">upstreamed</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Dec 2, 2024 17:16 UTC (Mon)
                               by <b>ndesaulniers</b> (subscriber, #110768)
                              [<a href="/Articles/1000468/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Looks like this landed upstream in 6.13.<br>
<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=6a34dfa15d6edf7e78b8118d862d2db0889cf669">https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/...</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/1000468/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2024, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
