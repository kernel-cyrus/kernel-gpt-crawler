        <!DOCTYPE html>
        <html lang="en">
        <head><title>Lockless patterns: full memory barriers [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/847481/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/848236/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/847481/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Lockless patterns: full memory barriers</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Did you know...?</b>
<p>
LWN.net is a subscriber-supported publication; we rely on subscribers
       to keep the entire operation going.  Please help out by <a
       href="/Promo/nst-nag4/subscribe">buying a subscription</a> and keeping LWN on the
       net.
</blockquote>
<div class="GAByline">
           <p>March 5, 2021</p>
           <p>This article was contributed by Paolo Bonzini</p>
           <hr>
<a href="/Articles/844224/">Lockless patterns</a>
</div>
The first two articles in this series introduced four ways to order memory
accesses: load-acquire and store-release operations in the <a
href="https://lwn.net/Articles/844224/">first installment</a>, read and
write memory barriers in the <a
href="https://lwn.net/Articles/846700/">second</a>.  The series continues
with an exploration of full memory barriers, why they are more expensive,
and how they are used in the kernel.

<p>
The primitives that were introduced so far constrain the ordering of
loads and stores in four different ways:
</p><ul class="spacylist">
<li> Load-acquire operations are ordered before subsequent loads and stores.
</li><li> Store-release operations are ordered after earlier loads and stores.
</li><li> Read memory barriers order earlier loads against subsequent loads.
</li><li> Write memory barriers order earlier stores against subsequent stores.
</li></ul>

<p>
It may be surprising that no combination of these operations orders
an earlier store against a later load:

</p><blockquote>
<table class="OddEven">
<tbody><tr><th></th><th colspan="2">Ordered against</th></tr>
<tr><th></th><th>Load</th><th>Store</th></tr>
<tr><th align="left">Earlier load</th>
  <td align="center"><tt>smp_load_acquire()</tt>,<br> <tt>smp_rmb()</tt></td>
  <td align="center"><tt>smp_load_acquire()</tt>, <br><tt>smp_store_release()</tt></td>
</tr>
<tr><th align="left">Earlier store</th>
    <td align="center">??</td>
    <td align="center"><tt>smp_store_release()</tt>, <br> <tt>smp_wmb()</tt></td></tr>
</tbody></table>
</blockquote>

<p>
It turns out that guaranteeing a global ordering of stores against later loads
is much more complicated for the processor, and it deserves a primitive of
its own.  To find out why, we need to abandon even the high-level concepts
that we have used so far and take a direct peek at how processors operate.

</p><h4>How processors really do it</h4>

<p>
The first article already mentioned that, deep down, processors communicate
via a message-passing architecture, such as
<a
href="https://en.wikipedia.org/wiki/Intel_QuickPath_Interconnect">QPI</a>
or <a
href="https://en.wikipedia.org/wiki/HyperTransport">HyperTransport</a>.  At
the  
assembly-language level, however, the programmer sees
operations like
memory loads and stores.  Any acquire and release semantics
associated with these memory
operations are an illusion that is provided by the processor's execution
pipeline, based on the program it runs and on the constraints of the
architecture.

</p><p>
For example, on x86 processors, all memory loads count as "load-acquire",
and all memory stores count as "store-release"; this behavior is required by the
architecture.  When compiling for these processors, it's still important
to annotate acquire and release operations and/or to insert memory barriers,
but these annotations are only used by the compiler to block invalid
optimizations.  Even in this model, the architecture does not
guarantee that all processors see stores and loads in the same order.
Consider this example, where <tt>a</tt> and <tt>b</tt> are initially zero:

</p><pre>    CPU 1                    CPU 2
    -------------------      --------------------
    store 1 into a           store 1 into b
    load b into x            load a into y
</pre>

<p>
If you try interleaving the four operations by hand, you'll see that at least
one store will come before the corresponding load.  Therefore one would expect
that at least one of <tt>x</tt> and <tt>y</tt> will be 1
after the above sequence runs to completion.  Yet, even on an x86
processor, it is possible that both <tt>x</tt> and <tt>y</tt> read as zero.

</p><p>How so?  The reason lies in the existence of the <em>store buffer</em>, which
lives between the CPU and its L1 cache.  Stores to memory usually only
change one part of a cache line; completing those stores, even just to
cache, may require fetching the full cache line from memory â€” a slow
operation.  The store buffer holds the stored data while this fetch takes
place, allowing the CPU to proceed with execution.

</p><p>
Even a CPU with a store buffer can provide load-load, load-store,
and store-store ordering relatively easily:

</p><ul class="spacylist">

<li> On out-of-order CPUs (which can execute operations in an order
     different from how they appear in the code to improve performance),
     ordering memory operations against earlier loads
     can be done via speculative execution.  During the time between a
     cache line access and the retiring of the instruction that caused the
     access, the CPU tracks evictions of that cache line.  Retiring of
     instructions happens in order, so this tracking will last until all
     earlier loads have completed.  If the cache line is evicted before
     the instruction is retired,
     speculation is canceled and the processor retries the
     memory operation.

</li><li> Keeping stores ordered is even simpler; it is enough to flush the
     entries of the store buffer to the cache in FIFO order.
</li></ul>

<p>
However, store-load ordering is a different story.  First of all,
one CPU's store might be stuck in its store buffer, and therefore it will
not be visible to another CPU when that CPU loads data from L1 cache.  Second,
a store buffer also provides <em>store forwarding</em>, where the result
of memory loads is taken directly from the store buffer instead of going
through the cache.  If either CPU&nbsp;1 or CPU&nbsp;2 has an entry for
respectively <tt>b</tt> or <tt>a</tt> in its store buffer, the value
could be <em>forwarded</em> to the load, which would return zero.

</p><p>
The only way around these problems is to flush the store buffer entirely
between the store and the load.  This is as expensive as it sounds (a
few tens of clock cycles), but this is what the <em>full memory
barrier</em> <tt>smp_mb()</tt> does under the hood.  Here is the same
pseudocode as above, fixed and rewritten into C:

</p><pre>    thread 1                 thread 2
    -------------------      --------------------
    WRITE_ONCE(a, 1);        WRITE_ONCE(b, 1);
    smp_mb();                smp_mb();
    x = READ_ONCE(b);        y = READ_ONCE(a);
</pre>

<p>
Let's say <tt>x</tt> is zero.  I will use a
squiggly horizontal line from a read to a write to express that
<tt>WRITE_ONCE(b, 1)</tt> overwrites
the value that thread&nbsp;1 had read; then the situation
(which is <a 
href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/tools/memory-model/Documentation/explanation.txt?h=v5.11&id=f40ddce88593482919761f74910f42f4b84c004b#n682">described
in detail</a> in the kernel's memory-model documentation) is as follows:

</p><pre>    WRITE_ONCE(a, 1);
           |
      -----+----- smp_mb();
           |
           v
    x = READ_ONCE(b);   âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿âˆ¿&gt;  WRITE_ONCE(b, 1);
                                         |
                                    -----+----- smp_mb();
                                         |
                                         v
                                  y = READ_ONCE(a);
</pre>

<p>Because these are relaxed operations, this is not enough to introduce a
happens-before edge between thread&nbsp;1 and thread&nbsp;2.  The barriers
also do not have acquire or release semantics by themselves, so there
are no happens-before edges across the two threads at all.

<p>However, the barriers do provide enough information to order the
operations in the two threads.  In particular, continuing with the case
of <tt>x=0</tt>, the full memory barrier in thread&nbsp;2 guarantees that
the store buffer has been flushed by the time <tt>READ_ONCE(a)</tt>
executes.  Could this be even before <tt>READ_ONCE(b)</tt> executed?
If so, <tt>READ_ONCE(b)</tt> would certainly see
the earlier <tt>WRITE_ONCE(b,&nbsp;1)</tt> from thread&nbsp;2 (remember
the store buffer has been flushed), and <tt>x</tt>
would be 1.  That's a contradiction, therefore
<tt>READ_ONCE(b)</tt> must have executed first:

</p><pre>    WRITE_ONCE(a, 1);              WRITE_ONCE(b, 1);
           |                              |
           |                         -----+----- smp_mb();
           |                              |
           v                              v
    x = READ_ONCE(b); -----------&gt; y = READ_ONCE(a);
                        (if x=0)
</pre>

<p>Due to transitivity, <tt>READ_ONCE(a)</tt> can
see the effect of <tt>WRITE_ONCE(a, 1)</tt> and <tt>y=1</tt>.
Likewise, if thread&nbsp;2 reads <tt>a</tt> as zero, thread&nbsp;1's
full memory barrier ensures that the <tt>READ_ONCE(a)</tt>
must have executed before thread&nbsp;1's <tt>READ_ONCE(b)</tt>:

</p><pre>    WRITE_ONCE(a, 1);              WRITE_ONCE(b, 1);
           |                              |
      -----+----- smp_mb();               |
           |                              |
           v                              v
    x = READ_ONCE(b); &lt;----------- y = READ_ONCE(a);
                        (if y=0)
</pre>

<p>
meaning that <tt>y=0</tt> implies <tt>x=1</tt>.  Different executions
may show one or the other possibility, but in any case <tt>x</tt>
and <tt>y</tt> cannot both be zero; that would mean that
<tt>READ_ONCE(a)</tt> executed before <tt>READ_ONCE(b)</tt> <em>and</em>
vice versa, which is impossible.

</p><p>
The Linux kernel memory model <a
href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/tools/memory-model/Documentation/explanation.txt?h=v5.11&id=f40ddce88593482919761f74910f42f4b84c004b#n1350">does
not call these read-read edges "happens-before"</a>, because there's no
indication of which is the release operation and which is the acquire
operation; nevertheless, they have the same effect of ordering memory
operations across threads.  Therefore we <em>can</em> state that high-level
APIs have acquire or release semantics even if internally they
use full memory barriers; users of those APIs will be able to
think of their code in terms of the happens-before framework, too.
The next example will show how this is done in practice.

</p><h4>Sleep/wake-up synchronization</h4>

<p>
The detailed description in the previous section shows that full memory
barriers impose constraints in a complicated and unintuitive manner.
Fortunately, the above pattern of "two threads and two flags", where
each thread writes to a flag and reads from the other, is probably all
that you need to know about full memory barriers.

</p><p>
This pattern has many important and practical applications.  Suppose
thread&nbsp;2 wants thread&nbsp;1 to act on 2's requests; thread&nbsp;1 on the other
hand wants to do something elseâ€”something that could even
take an indefinite amount of time, for example removing itself from
the scheduler's run queue and going to sleep.
In this case, the code will look like this:

</p><pre>    thread 1                                   thread 2
   -------------------                        --------------------------
    WRITE_ONCE(dont_sleep, 1);                 WRITE_ONCE(wake_me, 1);
    smp_mb();                                  smp_mb();
    if (READ_ONCE(wake_me))                    if (!READ_ONCE(dont_sleep))
      wake(thread2);                             sleep();
</pre>

<p>
If thread&nbsp;2 reads <tt>dont_sleep</tt> as zero, thread&nbsp;1
will read <tt>wake_me</tt> as one and wake up thread&nbsp;2; it's
useful to think of thread&nbsp;1 as having release semantics (imagine
that the <tt>wake()</tt> happens as part of <tt>mutex_unlock</tt>).
If thread&nbsp;1 reads <tt>wake_me</tt> as zero, thread&nbsp;2
will read <tt>dont_sleep</tt> as one and will not go to sleep.
Usually this is the side that needs to exhibit acquire semantics.

</p><p>
There is a hidden assumption that thread&nbsp;1's wake-up requests
are never lost, even if for example <tt>wake()</tt> is called after
thread&nbsp;2's <tt>READ_ONCE()</tt> but before <tt>sleep()</tt>.
A way to avoid this bug is for <tt>wake()</tt> and
<tt>sleep()</tt> calls to take the same lock.  Again, we see how lockless
patterns cooperate with traditional synchronizationâ€”after all this
is a slow path.

</p><p>
It really does work, and we can see this, for example, in Linux's
<a href="https://elixir.bootlin.com/linux/v5.11.1/source/kernel/sched/wait.c#L241"><tt>prepare_to_wait()</tt></a>
and <a href="https://elixir.bootlin.com/linux/v5.11.1/source/kernel/sched/core.c#L3525"><tt>wake_up_process()</tt></a>
APIs.  This interface was introduced in the 2.5.x development kernels, and was <a href="https://lwn.net/Articles/22913/">duly covered</a> back then by LWN.
Here is how the pattern appears after expanding some of the functions
that are involved:

</p><pre>    thread 1                                     thread 2
    -------------------                          --------------------------
    <b>WRITE_ONCE(condition, 1);</b>                    prepare_to_wait(..., TASK_INTERRUPTIBLE) {
    wake_up_process(p) {                           set_current_state(TASK_INTERRUPTIBLE) {
      try_to_wake_up(p, TASK_NORMAL, 0) {            <b>WRITE_ONCE(current-&gt;state, TASK_INTERRUPTIBLE);</b>
        <b>smp_mb();</b>                                    <b>smp_mb();</b>
        <b>if (READ_ONCE(p-&gt;state) &amp; TASK_NORMAL)</b>     }
	  <b>ttwu_queue(p);</b>                         }      
      }                                          <b>if (!READ_ONCE(condition))</b>
    }                                              <b>schedule();</b>
</pre>

<p>

As we saw in the seqcount case, the memory barriers are hidden inside the
implementation of higher-level APIs.  Embedding memory barriers or
load-acquire/store-release operations inside the implementation is in fact
how one defines an API that has acquire and release semantics; in this case,
<tt>wake_up_process()</tt> has release semantics, while
<tt>set_current_state()</tt> and its caller <tt>prepare_to_wait()</tt> have
acquire semantics.

</p><p>
The sleep condition is often checked twice to limit unnecessary wakeups,
like this:

</p><pre>    thread 1                               thread 2
    -------------------                    --------------------------
    WRITE_ONCE(dont_sleep, 1);             if (!READ_ONCE(dont_sleep)) {
    smp_mb();                                WRITE_ONCE(wake_me, 1);
    if (READ_ONCE(wake_me))                  smp_mb();
        wake(thread2);                       if (!READ_ONCE(dont_sleep))
                                               sleep();
                                           }
</pre>

<p>

In the kernel we can see this kind of check in the interaction between <a
href="https://elixir.bootlin.com/linux/v5.11.1/source/net/ipv4/tcp_input.c#L5380"><tt>tcp_data_snd_check()</tt></a>
and the call to <tt>tcp_check_space()</tt>, defined immediately above it
(thread&nbsp;1) and <a
href="https://elixir.bootlin.com/linux/v5.11.1/source/net/ipv4/tcp.c#L496"><tt>tcp_poll()</tt></a>
(thread&nbsp;2).  In this case,
the code does not have the luxury of relying on a higher-level abstraction,
so it merits a closer look.  Thread&nbsp;2 wants to sleep if the socket has
no room in its send buffer, therefore <tt>tcp_poll()</tt> sets the "wake me"
<tt>SOCK_NOSPACE</tt> flag before checking
<tt>__sk_stream_is_writeable()</tt>.
The core of the <a href="https://elixir.bootlin.com/linux/v5.11.1/source/net/ipv4/tcp.c#L572">lockless 
synchronization</a> in <tt>tcp_poll()</tt> is:
</p><pre>    set_bit(SOCK_NOSPACE, &amp;sk-&gt;sk_socket-&gt;flags);
    smp_mb__after_atomic();
    if (__sk_stream_is_writeable(sk, 1))
      mask |= EPOLLOUT | EPOLLWRNORM;
</pre>

<p>
The caller will ultimately go to sleep if mask is zero. 
<tt>smp_mb__after_atomic()</tt> is a specialized version of <tt>smp_mb()</tt>
and has the same semantics. These optimized barriers will be explained in a
future article.

</p><p>
Thread&nbsp;1, instead, must wake up thread&nbsp;2 after consuming data in
the send buffer. 
<tt>tcp_data_snd_check()</tt> first sends out packets to make room in the buffer
("do not sleep, there's room now"), then checks <tt>SOCK_NOSPACE</tt>,
and finally (through the <tt>sk-&gt;sk_write_space()</tt> function pointer)
reaches <tt>sk_stream_write_space()</tt>, where thread&nbsp;2 is woken up.
The call stack is relatively shallow, so I'll let the reader
explore the code.  I will however point out this comment in
<tt>tcp_check_space()</tt>:

</p><pre>    /* pairs with tcp_poll() */
    smp_mb();
    if (test_bit(SOCK_NOSPACE, &amp;sk-&gt;sk_socket-&gt;flags))
      tcp_new_space(sk);
</pre>

<p>
The reference to the "pairing" of barriers tells us that this function
has either acquire or release semantics.  A read or write memory barrier
would tell us straight away that the function has respectively acquire
and release semantics.  With a full memory barrier, we need to look at
the code around the barrier.  In this case, we know that the function is
on the "wake-up" side of the pattern and therefore has release
semantics; <tt>tcp_poll()</tt> instead has acquire semantics.

</p><p>
Something similar happens almost everywhere a
<tt>smp_mb()</tt> can be found in the kernel.  For example:
</p><ul class="spacylist">
<li> Workqueues use this idiom to decide whether workers have more work
  to do.  In this case, thread&nbsp;1's role is taken by <a href="https://elixir.bootlin.com/linux/v5.11.1/source/kernel/workqueue.c#L1312"><tt>insert_work()</tt></a>, 
  while thread&nbsp;2's role is taken by <a href="https://elixir.bootlin.com/linux/v5.11.1/source/kernel/workqueue.c#L857"><tt>wq_worker_sleeping()</tt></a>. 

</li><li> In the <tt>futex()</tt> system call, thread&nbsp;1's write is in user
  space, while the memory barrier and read are part of
  <tt>futex(FUTEX_WAKE)</tt>.  Thread&nbsp;2's operation is entirely part
  of the <tt>futex(FUTEX_WAIT)</tt> (because <tt>wake_me</tt> is a flag in
  kernel memory); <tt>FUTEX_WAIT</tt> accepts the expected value of the
  futex as an argument to the system call, and uses it to decide whether
  to sleep.  See <a href="https://elixir.bootlin.com/linux/v5.11.1/source/kernel/futex.c#L48">the
  long comment</a> at the head of <tt>kernel/futex.c</tt> for details on
  how this works.

</li><li> Within KVM, <tt>sleep()</tt> is replaced by the act of entering
  the processor's guest mode and running a virtual machine.  In order
  to kick the processor out of guest mode, <a href="https://elixir.bootlin.com/linux/v5.11.1/source/virt/kvm/kvm_main.c#L2873"><tt>kvm_vcpu_kick()</tt></a>
  sends an inter-processor interrupt to the processor.  The familiar comment
  around memory barrier pairing can be found down the call chain in <a href="https://elixir.bootlin.com/linux/v5.11.1/source/include/linux/kvm_host.h#L326"><tt>kvm_vcpu_exiting_guest_mode()</tt></a>,
  which also where <tt>vcpu-&gt;mode</tt> is read.

</li><li> Virtio devices use two instances of the above pattern.  On one
  hand, the driver wants to stop processing completed requests, and
  waking it up consists of sending an interrupt.  On the other
  hand, the device wants to stop processing submitted requests, and
  the device can wake it up by writing to a "doorbell" memory location.
</li></ul>

<p>
That completes the introduction of memory barriers.  From here, we will
look at compare-and-swap operations, how they can be combined with locks to
create lock-free fast paths, and their role in the implementation of
lock-free linked lists.</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Lockless_algorithms">Lockless algorithms</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Bonzini_Paolo">Bonzini, Paolo</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/847481/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor848454"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 5, 2021 18:50 UTC (Fri)
                               by <b>jcm</b> (subscriber, #18262)
                              [<a href="/Articles/848454/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
A key thing to remember with memory barriers is they are only about the observed order of memory operations. An implementation is actually free to do very different things with those barriers (including speculating right through them, which you can do as long as there is no circumstance under which someone can observe incorrect ordering).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848454/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor848456"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 5, 2021 19:06 UTC (Fri)
                               by <b>pbonzini</b> (subscriber, #60935)
                              [<a href="/Articles/848456/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes, it&#x27;s only about the observed order, and in different ways depending on whether the tricks come from the compiler or the processor.<br>
<p>
The genius stroke of C++11 compared to e.g. the Java memory model was to treat the compiler+processor combo as weak memory ordering even if the underlying architecture is TSO. I don&#x27;t think any compiler applies very much the leeway that it&#x27;s given, but it does make for a nice and consistent model at the language level.<br>
<p>
I do prefer the LKMM and its clear foundation on the behavior of hardware (which I tried to convey in this article) to C++11&#x27;s slightly too handwavy &quot;just use sequential consistency unless you need something else&quot;.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848456/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor848540"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 6, 2021 15:25 UTC (Sat)
                               by <b>jcm</b> (subscriber, #18262)
                              [<a href="/Articles/848540/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
One of the things that has been keeping me up at night recently thinking has been speculating through barriers. You do it by tracking cache ownership/state transitions as you go through and roll back as needed. The easiest way to think about it is probably as close to the apparatus needed for transactions. And there are a few papers in this area. So anyway, the point is draining various buffers isnâ€™t the only way to pull this off. Think how Intel does their MOB for TSO by tracking updates and replaying too.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848540/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor848541"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 6, 2021 15:28 UTC (Sat)
                               by <b>jcm</b> (subscriber, #18262)
                              [<a href="/Articles/848541/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The mental rabbit hole is separating the perceived observed order from reality. Reality might involve combinations of invalidation queue and store/load buffer tracking, but it might involve something very different :)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848541/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor848545"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 6, 2021 17:44 UTC (Sat)
                               by <b>pbonzini</b> (subscriber, #60935)
                              [<a href="/Articles/848545/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yep, I even mentioned (with a little bit of simplification) what Intel does for TSO. To some extent it should be possible to do the same for full barriers, by delaying invalidate messages and keeping them buffered until the store buffer has been flushed. After all in most cases there is no race and therefore the effect of the barrier is kind of invisible.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848545/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor848764"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 9, 2021 5:00 UTC (Tue)
                               by <b>jcm</b> (subscriber, #18262)
                              [<a href="/Articles/848764/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thing is you donâ€™t even need to flush the sucker, just track age and ensure that theyâ€™ve all passed through. You can blow right through every barrier without cost provided you are willing to track enough cache lines in the process. I have been doing a lot of thinking lately about renaming SPRs and speculating through serializing instructions too. Thereâ€™s no reason you couldnâ€™t (provided you tracked everything, were willing to pay the cost, and also could precisely unwind the state to prevent side-channel crumbs, which might force you to add eg a side buffer). This has been dancing in my head for the past week solid.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848764/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
<a name="CommAnchor848603"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 7, 2021 16:02 UTC (Sun)
                               by <b>jcm</b> (subscriber, #18262)
                              [<a href="/Articles/848603/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
x86 processors maintain the illusion of TSO ordering through the use of a MOB (Memory Ordering Buffer), which not only tracks the cache lines for ownership/invalidation but also replays at retirement if necessary in order to maintain ordering. So e.g. a load might be performed twice in order to ensure it retires correctly.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848603/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor848604"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 7, 2021 16:10 UTC (Sun)
                               by <b>jcm</b> (subscriber, #18262)
                              [<a href="/Articles/848604/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Btw, in the SB example, it&#x27;s not that the store buffer is forwarding locally, &quot;which would return zero&quot;, it&#x27;s that each is writing into its local store buffer while reading the other variable from the initial state. The SB allows the stores to be delayed in terms of observation by other processors relative to the local one.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848604/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor848612"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 7, 2021 20:56 UTC (Sun)
                               by <b>pbonzini</b> (subscriber, #60935)
                              [<a href="/Articles/848612/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Read the paragraph again, it mentions both scenarios. :)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848612/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor848735"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 8, 2021 20:56 UTC (Mon)
                               by <b>jcm</b> (subscriber, #18262)
                              [<a href="/Articles/848735/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yea, I did after. I agree, thanks :)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848735/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor848757"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 9, 2021 1:41 UTC (Tue)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/848757/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Nice gentle introduction to the reads-from relation!  (&quot;~~~~~~~~&quot;)  ;-)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848757/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor848880"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 9, 2021 20:31 UTC (Tue)
                               by <b>pbonzini</b> (subscriber, #60935)
                              [<a href="/Articles/848880/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If &quot;that&#x27;s all you have to say about that&quot; (as Forrest Gump would put it), then I guess you didn&#x27;t find any mistake, yay!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848880/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor848883"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 9, 2021 20:57 UTC (Tue)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/848883/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Or I haven&#x27;t yet had a chance to read it thoroughly, your choice.  ;-)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/848883/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor849227"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 12, 2021 17:03 UTC (Fri)
                               by <b>firolwn</b> (guest, #96711)
                              [<a href="/Articles/849227/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Hi Paolo, great article. I think maybe you forgot to add &#x27;smp_mb();&#x27; to the two diagrams  which are just around the line starting with &#x27;Due to transitivity&#x27;.<br>
--<br>
Firo<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/849227/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor849345"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 15, 2021 14:35 UTC (Mon)
                               by <b>firolwn</b> (guest, #96711)
                              [<a href="/Articles/849345/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
After reading &#x27;Multicopy atomicity&#x27; section from kernel Documentation/memory-barriers.txt, I realize that I am wrong and no more smp_mb() is necessary to add.<br>
--<br>
Firo<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/849345/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor852875"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Lockless patterns: full memory barriers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 16, 2021 7:01 UTC (Fri)
                               by <b>pbonzini</b> (subscriber, #60935)
                              [<a href="/Articles/852875/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It&#x27;s not intuitive at all, but only one memory barrier matters in each of the two cases. But both are needed (separately) to ensure that x=0 &amp;&amp; y = 0 is not possible.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/852875/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2021, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
