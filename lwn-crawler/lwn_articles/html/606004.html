        <!DOCTYPE html>
        <html lang="en">
        <head><title>Control groups, part 4: On accounting [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/606004/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/605745/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/606004/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Control groups, part 4: On accounting</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>We're bad at marketing</b>
<p>
We can admit it, marketing is not our strong suit. Our strength is
writing the kind of articles that developers, administrators, and
free-software supporters depend on to know what is going on in the
Linux world. Please <a href="/Promo/nsn-bad/subscribe">subscribe today</a> to help us keep doing that, and so
we don’t have to get good at marketing.
</blockquote>
<div class="GAByline">
           <p>July 23, 2014</p>
           <p>This article was contributed by Neil&nbsp;Brown</p>
           <hr>
<a href="/Articles/604609/">Control groups</a>
</div>
<p>In our ongoing quest to understand Linux control groups,
at least 
enough to enjoy the debates that inevitably arise when they are
mentioned, it is time to explore the role that accounting plays and to
consider how the needs of the accountant are met by the design and
structure of cgroups.</p>

<p>Linux and Unix are not strangers to the idea of the accounting of
resource usage.  Even in V6 Unix, the CPU time for each process was
accounted and the running total could be accessed with the <code>times()</code>
system call.  To a limited extent, this extended to groups of processes
too.  One of the process groupings we found when we first looked at V6
Unix was the group of all descendants of a given process.  When all
processes in that group have exited, the total CPU time used by them
(or at least those that haven't escaped) was available from
<code>times()</code> as well.  Before a process has exited and been waited for,
its CPU time was known only to itself.</p>

<p>In 2.10BSD, the set of resources that were accounted for grew to include
memory usage, page faults, disk I/O, and other statistics.  Like CPU
time, these were gathered into the parent when a child is waited
for.  They can be accessed by the <a href="http://man7.org/linux/man-pages/man2/getrusage.2.html"><code>getrusage()</code></a>
system call that is still available in modern Linux, largely unchanged.</p>

<p>With <code>getrusage()</code> came <a href="http://man7.org/linux/man-pages/man2/setrlimit.2.html"><code>setrlimit()</code></a>, which could impose
limits on the use of some of these resources, such as CPU time and
memory usage.  These limits were only imposed on individual processes,
never on a group: a group's statistics are only accumulated as processes
exit, and that is rather too late to be imposing limits.</p>

<p><a href="/Articles/605039/">Last time</a>, we looked at various cgroups subsystems that did not need
to keep any accounting across the group to provide their services,
though <code>perf_event</code> was in a bit of a grey area.  This week, we look at
the remaining five subsystems, each of which involve whole-group
accounting in some way, and so support limits of a sort that
<code>setrlimit()</code> could never support.</p>

<h4><code>cpuacct</code> — accounting for the sake of accounting</h4>

<p><code>cpuacct</code> is the simplest of the accounting subsystems, in part
because all it does is accounting; it doesn't exert control at all.</p>

<p><code>cpuacct</code> appears to have originally been written largely as a
demonstration of the capabilities of cgroups, with no expectation
of mainline inclusion.  It <a href="http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=62d0df64065e7c135d0002f069444fbdfc64768f">slipped into</a> mainline with other cgroups
code in 2.6.24-rc1, was <a href="http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=cfb5285660aad4931b2ebbfa902ea48a37dfffa1">removed with an explanation</a> of this original
intent shortly afterward, and then <a href="http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=d842de871c8c5e2110c7e4f3f29bbe7b1a519ab8">re-added</a> well before 2.6.24-final
because it was actually seen as quite useful.  Given this history, we probably shouldn't expect <tt>cpuacct</tt> to fit neatly
   into any overall design.</p>

<p> Two separate sorts of accounting information are kept by <code>cpuacct</code>.  First,
there is the total CPU time used by all processes in the group, which is
measured by the scheduler as precisely as it can and is recorded in
nanoseconds.  This information is gathered on a per-CPU basis and can
be reported per-CPU or as a sum across all CPUs.</p>

<p>Second, there is (since 2.6.30) a breakdown  into "user" and
"system" time of the total CPU time
used by all processes in the group.
These times are accounted in the same way as the times returned by the
<code>times()</code> system call and are recorded in clock ticks or "jiffies".
Thus, they may not be as precise as the CPU times accounted in
nanoseconds.</p>

<p>Since 2.6.29, these statistics are collected hierarchically.  Whenever
some usage is added to one group, it is also added to all of the
ancestors of that group. So, the usage accounted in each group is
the sum of the usage of all processes in that extended group including processes
that are members of sub-groups.</p>

<p>This is the key characteristic of all the subsystems that we will look
at this time: they account hierarchically.  While <code>perf_event</code> does do
some accounting, the accounting for each process stays in the
cgroup that the process is an immediate member of and does not propagate
up into ancestor processes.</p>

<p>For these two subsystems (<code>cpuacct</code> and <code>perf_event</code>), it is not clear
that hierarchical accounting is really necessary.  The totals collected are never used within the kernel, but are only made available
to user-space applications, which are unlikely to read the data at a
particularly high rate.  This implies it would be quite effective for
an application that needs whole-group accounting information to walk
the tree of descendants from a given group and add up the totals in
each sub-group.  When a cgroup is removed it could certainly be useful
to accumulate its usage into its parent, much like process
times are accumulated on exit.  Earlier accumulation brings no obvious
benefit.</p>

<p>Even if it were important to present the totals directly in the
cgroups filesystem, it would be quite practical for the kernel to add
the numbers up when required, rather than on every change.  This is how
the sum across all CPUs is managed, but it is not done for the sum across
sub-groups.</p>

<p>There is an obvious tradeoff between the complexity for an
application to walk the tree on those occasions when data is needed
and the cost for the kernel in walking up the tree to add a new charge
to every ancestor of the target process on every single accounting event.
A proper cost/benefit analysis of this tradeoff would need to take
into account the depth of the tree and the frequency of updates.  For
<code>cpuacct</code>, updates only happen on a scheduler event or timer tick,
which would normally be every millisecond or more on a busy machine.
While this may seem a fairly high frequency, there are other events
that can happen much more often, as we shall see.</p>

<p>Whether the accounting approach in <code>cpuacct</code> and <code>perf_event</code> involve
sensible or questionable choices in not really important for
understanding cgroups — what is worth noting is the fact that
there are choices to be made and tradeoffs to be considered.
These subsystems have freedom to choose because the accounting data is
not used within the kernel.  The remaining subsystems all keep account
of something in order to exert control and, thus, need fully correct
accounting details.</p>

<h4>Sharing out the memory</h4>

<p>Two cgroup subsystems are involved in tracking and restricting memory
usage: <code>memory</code> and <code>hugetlb</code>.  These two use a common data structure
and support library for tracking usage and imposing limits: the "resource
counter" or
<code>res_counter</code>.</p>

<p>A <code>res_counter</code>, which is declared in <a href="http://lxr.free-electrons.com/source/include/linux/res_counter.h?v=3.15"><code>include/linux/res_counter.h</code></a>
and implemented in <a href="http://lxr.free-electrons.com/source/kernel/res_counter.c?v=3.15"><code>kernel/res_counter.c</code></a>, stores a usage of some
arbitrary resource together with a limit and a "soft limit".  It also
includes a high-water mark that records the highest level the usage has
ever reached, and a failure count that tracks how many times a request
for extra resources was denied.</p>

<p>Finally, a <code>res_counter</code> contains a spinlock to manage concurrent
access and a parent pointer.  This pointer demonstrates a recurring
theme among the accounting cgroup subsystems in that they often create
a parallel tree-like data structure that exactly copies the tree data
structure provided directly by cgroups.</p>

<p>The <code>memory</code> cgroup subsystem allocates three <code>res_counter</code>s, one for
user-process memory usage, one for the sum of memory and swap usage,
and one for usage of memory by the kernel on behalf of the process.
Together with the one <tt>res_counter</tt> allocated by
<code>hugetlb</code> (which accounts the 
memory allocated in huge pages), this means there are four extra <code>parent</code>
pointers when the <code>memory</code> and <code>hugetlb</code> subsystems are both enabled.
This seems to suggest that the implementation of the hierarchy
structure provided by cgroups doesn't really meet the needs of
its users, though why that might be is not immediately obvious.</p>

<p>When one of the various memory resources is requested by a process,
the <code>res_counter</code> code will walk up the parent pointers, checking
if limits are reached and 
     updating the usage at each ancestor.  This requires taking a spinlock
     at each level, so it is not a cheap operation, particularly if the hierarchy is
at all deep.  Memory allocation is generally a highly optimized
operation in Linux, with per-CPU free lists along with batched allocation and
freeing to try to minimize the per-allocation cost.  Allocating memory
isn't always a high-frequency operation, but sometimes it is; those
times should still perform well if possible.
So, taking a series of spinlocks for multiple nested cgroups to update
accounting on every single memory allocation doesn't sound like a good
idea.  Fortunately, this is not something that the <code>memory</code> subsystem
does.</p>

<p>
When authorizing a memory allocation request of less than 32 pages (most
    requests are for one page), the memory controller will request that a full
    32 be approved by the <tt>res_counter</tt>.
If that request is granted, the excess above what
was actually required is recorded in a per-CPU "stock" that notes
which cgroup last made an allocation on each CPU and how much excess
has been approved.  If the request is not granted, it requests the actual
number of pages allocated.</p>

<p>Subsequent allocations by the same process on the same CPU will use what
remains in the stock until that drops to zero, at which point another
32-page authorization will be requested.  If a scheduling change causes
another process from a different cgroup to allocate memory on that
CPU, then the old stock will be returned and a new stock for the new
cgroup will be requested.</p>

<p>Deallocation is also batched, though with a quite different mechanism,
presumably because deallocations often happen in much larger batches
and because deallocations can never fail.  The batching for
deallocation uses a per-process (rather than per-CPU) counter that
must be explicitly enabled by the code that is freeing memory.
So a sequence of calls:</p>

<pre>
    mem_cgroup_uncharge_start()
    repeat mem_cgroup_uncharge_page()
    mem_cgroup_uncharge_end()
</pre>


<p>will use the uncharge batching, while a lone
<code>mem_cgroup_uncharge_page()</code> will not.</p>

<p>The key observation here is that, while a naive accounting of resource
usage can be quite expensive, there are various ways to minimize the
cost and different approaches will be more or less suitable in
different circumstances.  So it seems proper for cgroups to take a
neutral stance on the issue and allow each subsystem to solve the
problem in the way best suited to its needs.</p>

<h4>Another cgroup subsystem for the CPU</h4>

<p>As the CPU is so central to a computer it is not surprising that there
are several cgroup subsystems that relate to it.  Last time, we met the <code>cpuset</code>
subsystem that limits which CPUs a process can run on, and
the <code>cpuacct</code> subsystem, above, which accounts for how much time is spent on
the CPU by processes in a cgroup.  The third and last CPU-related
subsystem is simply called <code>cpu</code>. It is used to control how the
scheduler shares CPU time among different processes and different cgroups.</p>

<p>The <a href="/Articles/230574/">Linux scheduler</a> has a surprisingly simple design.
It is modeled on a hypothetical, ideal multi-tasking CPU that can run
an arbitrary number of threads simultaneously, though at a
proportionally reduced speed.  Using this model, the scheduler can
calculate how much effective CPU time each thread "should" have
ideally received.  The scheduler simply selects the thread for which
the actual CPU time used is furthest behind the ideal and lets it run
for a while to catch up.</p>

<p>If all processes were equal, then the proportionality would mean that
if there are <i>N</i> runnable processes, each should get one-<i>N</i>th
of real time.  Of course, processes often aren't all equal, as
scheduling priority or <code>nice</code> values can assign different weights to
each process so they get different proportions of real time.  The sum
of these proportions must, of course, add up to one (or to the number
of active CPUs).</p>

<p>When the <code>cpu</code> cgroup subsystem is used to request <a
href="/Articles/240474/">group scheduling</a>,
these proportions must be calculated based on the group hierarchy, so
some proportion will be given to a top-level group, and that is then
shared among the processes and sub-groups in that group.</p>

<p>Further, the "virtual runtime", which tracks the discrepancy between
ideal and actual CPU time, needs to be accounted for each group
as well as for each process.  One might expect the virtual runtime of a
group to be exactly the sum of the times from the processes.  However, when a
process exits, any excess or deficit it has is lost.  To prevent this loss
from leading to unfairness between groups, the scheduler keeps account
of the time used by each group as well as by each process.</p>

<p>To manage these different values across the hierarchy, the <code>cpu</code>
subsystem creates a parallel hierarchy of <code>struct sched_entity</code>
structures, 
which is what
the scheduler uses to store proportional weights and virtual runtime.
There are actually a multitude of these hierarchies, one for each CPU.
This means that runtime values can be propagated up the tree without
locking, so it is much more efficient than the <code>res_counter</code> used by
the memory controller.</p>

<p>In accord with the recurring theme that one subsystem will often have
two or more distinct (though related) functions, the <code>cpu</code> subsystem
allows a maximum CPU bandwidth to be imposed on each group.  This is quite
separate from the scheduling priority discussed so far.</p>

<p>The bandwidth is measured in CPU time per real time.  Both the CPU
time limit, referred to as the quota, and the real time period during
which that quota can be used must be specified.  When setting the quota
and period for each group, the subsystem checks that the limit imposed
on any parent is always enough to allow all children to make full use
of their quota.  If that is not met, then the change will be rejected.</p>

<p>The actual implementation of the bandwidth limits is done largely in
the context of the <code>sched_entity</code>.  As the scheduler updates how much
virtual time each <code>sched_entity</code> has used, it also updates the
bandwidth usage and checks if throttling is appropriate.</p>

<p>To some extent, this case study simply reinforces some ideas we have
already seen, that restrictions are often pushed down the hierarchy
while accounting data is often propagated up a parallel hierarchy.  We
do see here one convincing reason why a parallel hierarchy might be
needed.  In this case, the parallel hierarchies are per-CPU so they can
be updated without taking any locks.</p>

<h4><tt>blkio</tt> - a final pair</h4>

<p>As we have repeatedly observed, some cgroup subsystems manage
multiple, though related, aspects of the contained processes.  With
<tt>blkio</tt>, this idea becomes more formalized.  <code>blkio</code> allows for various
"policies" to be registered that act much like cgroup subsystems in
that they are advised of changes to the cgroup hierarchy and they can
add files to the cgroup virtual filesystem.  They are not able to
disallow the movement of processes or get told about <code>fork()</code> or <code>exit()</code>.</p>

<p>There are two <tt>blkio</tt> policies in Linux 3.15: "throttle" and
"cfq-iosched".  These have a remarkable similarity to the two
functions of the <code>cpu</code> subsystem (bandwidth and scheduling priority),
though the details are quite different.  Many of the ideas we find in
these two have already been seen in other subsystems, so there is
little point going over similar details in a different guise.  But there
are two ideas worth mentioning.</p>

<p>One is that the <code>blkio</code> subsystem adds a new ID number to each
cgroup.  We saw last time that the cgroup core provides an ID number
for each group and this is used by <code>net_prio</code> to identify groups.  The
new <code>id</code> added by <code>blkio</code> fills a similar role but with one important
difference.  <code>blkio</code> ID numbers use 64 bits and are never reused,
while cgroup-core ID numbers are just an <code>int</code> (typically 32 bits) and
are reused.  A unique ID number seems like it could be a generally useful
feature 
that the cgroups core could provide.  A little over a year after
the <code>blkio</code> ID <a href="http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=9a9e8a26da4c2c5ddc60999bdea957935fb22b6b">was added</a>, a remarkably similar <code>serial_nr</code> was
<a
href="http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=53fa5261747a90746531e8a1c81eeb78fedc2f71">indeed
added</a> to the cgroup core, though <code>blkio</code> hasn't been revised
to use it.  Note when reading the code: <tt>blkio</tt> is known internally as <tt>blkcg</tt>.</p>

<p>The other new idea we find in <code>blkio</code>, and in the <code>cfq-iosched</code> policy
in particular, is possibly more interesting.  Each cgroup can be
assigned a different <code>weight</code>, similar to the weights calculated by
the CPU scheduler, to balance scheduling of requests from this group
against requests from sibling groups.  Uniquely to <code>blkio</code>, each cgroup
can also have a <code>leaf_weight</code> that is used to balance requests from
processes in this group against requests from processes in child
groups.</p>

<p>The net effect of this is that when non-leaf cgroups contain
processes, the <code>cfq-iosched</code> policy pretends that those processes are
really in a virtual child group and uses <code>leaf_weight</code> to assign a
weight to that virtual child.  

If we consider this against the
different aspects of hierarchy that we explored earlier, it seems to
be a clear statement from <code>cfq-iosched</code> that "organization"
hierarchies are not something that it wants to deal with and that
everything should be, or will be treated as, "classification"
hierarchies.
</p>

<p>The CPU scheduler doesn't appear to be concerned about this issue.
The processes in an internal group are scheduled against each other and
against any child group as a whole.  It isn't really clear which
approach to scheduling is <em>right</em>, but it would be nice if they were
consistent.  One way to achieve
    consistency would be to forbid non-leaf cgroups from containing
    processes.  There is work underway to exactly this end, as we will see
    later in this series.</p>

<h4>What can we learn?</h4>

<p>If we combine all that we learned in this analysis with what we found
with the first set of subsystems last time, it is easy to get lost in the
details.  Some differences may be deep conceptual differences, others
may be important, but shallow, implementation differences, while still
others could be pointless differences due to historical accident.</p>

<p>In the first class, I see a strong distinction between control
elements that share out resources (CPU or block I/O bandwidth), those
that impose limits on resources (CPU, block I/O, and memory), and the
rest that are largely involved with identifying processes.  The first
set need a view of the whole hierarchy, as each branch competes with
all others.  The second set need to see only the local branch, as limits in
one branch can not affect usage in another.  The third set don't
really need the hierarchy at all — it might be useful, but its presence
isn't intrinsic to the functionality.</p>

<p>The fact that several controllers create parallel hierarchies seems to
be largely an implementation detail, though, as we will see next time,
there may be a deeper conceptual issue underlying that.</p>

<p>The almost chaotic relationship between functionality and subsystems
is most likely pointless historical accident.  There is no clear
policy statement concerning what justifies a new subsystem, so
sometimes new functionality is added to an existing subsystem and
sometimes it is provided as a brand new subsystem.  The key issues
that could inform such a policy statement are things we can be
looking out for as our journey continues.</p>

<p>In the next installment, we will step back from all this fine detail
and try to assemble a high level view of cgroups and their relationships.
We will look at the hierarchical structures provided by cgroups and
how those interact with the three core needs: sharing resources,
limiting resource usage, and identifying processes.</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Control_groups-LWNs_guide_to">Control groups/LWN's guide to</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Brown_Neil">Brown, Neil</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/606004/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2014, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
