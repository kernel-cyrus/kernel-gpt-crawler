        <!DOCTYPE html>
        <html lang="en">
        <head><title>Evolving ext4 for SMR drives [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/720226/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/719986/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/720226/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Evolving ext4 for SMR drives</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>We're bad at marketing</b>
<p>
We can admit it, marketing is not our strong suit. Our strength is
writing the kind of articles that developers, administrators, and
free-software supporters depend on to know what is going on in the
Linux world. Please <a href="/Promo/nsn-bad/subscribe">subscribe today</a> to help us keep doing that, and so
we don’t have to get good at marketing.
</blockquote>
<div class="FeatureByline">
           By <b>Jake Edge</b><br>April 19, 2017</br>
           <hr>
<a href="/Archives/ConferenceByYear/#2017-Vault">Vault</a>
</div>
<p>
At the 2017 Vault conference for Linux storage, Ted Ts'o and Abutalib
Aghayev gave a talk on some work they have done to make the ext4 filesystem
work better on <a
href="https://en.wikipedia.org/wiki/Shingled_magnetic_recording">shingled
magnetic recording (SMR)</a> drives.  Those devices have some major
differences from conventional drives, such that random writes perform quite
poorly.  Some fairly small changes that were made to ext4 had a dramatic
effect on its performance on SMR drives—and provided a performance boost for
metadata-heavy workloads on conventional magnetic recording (CMR) media as well.
</p>

<p>
Ts'o said that he and Aghayev, who is a student at Carnegie Mellon
University (CMU), had developed the ext4 changes; two professors, Garth
Gibson at CMU and Peter Desnoyers at Northeastern, also provided useful
input and advice.
</p>

<h4>SMR basics</h4>

<p>
SMR drives pack more data into the same space as CMR drives by overlapping
the tracks on the platter.  Sequential writes will work well with SMR,
while overwriting existing data will require copying data from adjacent
tracks and rewriting it in a sequential fashion.  SMR is targeted at
backups, large media files, and similar use cases.</p>

<a href="/Articles/720414/">
<img src="https://static.lwn.net/images/2017/vault-tso-sm.jpg" border=0 hspace=5 align="right"
alt="[Ted Ts'o]" title="Ted Ts'o" width=211 height=280>
</a>

<p>
To the extent that rotational drives will stick around, SMR will be with
us, Ts'o said. 
There are additional technologies
"coming down the pike" that will be compatible with SMR.  Millions of SMR
drives have shipped and even consumers are using the technology for
backups while using SSDs for data they need faster access to. 
</p>

<p>
There are two kinds of SMR drives, drive-managed and host-managed; the talk
(and work) focused on drive-managed SMR, rather than host-managed, where
the operating system has to actively manage the storage device.  For
drive-managed SMR, there is a shingle translation layer (STL) that is akin
to the flash translation layer (FTL) for SSDs.  The STL hides the various
zones in an SMR device, which might be 256M in size and need to be written
sequentially; it presents a block interface that masks the device's
constraints. 
</p>

<p>
SMR disks typically have a persistent cache that is a lot faster than a
CMR disk.  The theory is that if there is idle time, and most disks in
enterprise settings will have some, data can be moved from the persistent
cache to the disk itself in a sequential manner at that time, Ts'o said.
In addition, idle time allows for various cleaning and housekeeping tasks.
As long as there is room in the persistent cache, writes to the device are
extremely fast, but once it fills up, throughput drops off drastically.
</p>

<p>
The persistent cache is invisible to the kernel unless the vendor provides
some magic command to query its size and other characteristics.  The exact
behavior of the STL is vendor specific and subject to change, much
like the situation with FTL implementations.  But flash is so fast that it
is hard to notice the difference when the translation layer chooses to
write in different locations; for the STL, writing to the persistent cache
is so much faster than to disk that it is quite noticeable.
</p>

<p>
The STL will try to recognize sequential writes and bypass the persistent
cache for those.  In some ways the persistent cache is like the ext4
journal, Ts'o said.  With a random write workload, once the persistent
cache is full, each write becomes a large read-modify-write operation.  The
exact details of the persistent cache, how much there is and where it is
located on the disk, for example, will vary; some drives they tested had
25GB of persistent cache, others were different.
</p>

<h4>Small changes</h4>

<p>
The work that he and Aghayev did was to make fairly small changes to ext4
(40 lines of code modified, 600 lines added in new files) that made a
dramatic difference.  Those changes improved the performance of
metadata-light workloads by 1.7-5.4x.  For metadata-heavy workloads, the
improvement was 2-13x.
</p>

<p>
The way that ext4 uses the disk is particularly bad for SMR devices, he
said, because the metadata is spread across the disk.  Metadata writes are
4KB random writes, which is the worst possible thing for SMR.  Those writes
can dominate the work that the STL has to do even when you are storing
large video streams that are SMR-friendly.  If there is lots of idle time,
the change is not all that dramatic but, if not, performance drops off
substantially while the
STL turns the random writes into sequential ones.
</p>

<p>
Ext4 uses writeahead logging, which means that it writes metadata to a
journal, which is sequential, but then does random writes to put the
metadata in its final location once the journal fills or the dirty
writeback timeout is reached.  That means that every metadata block is
written twice, once to the journal and once to its final destination; why
not use the journal entry as the authoritative entry?   The block in memory
can be mapped to the journal location and be marked as clean in the page
cache; if it gets evicted and is needed again, it can be looked up in the
journal. 
</p>

<p>
When the journal gets full, something needs to be done, however.  Many of
the blocks in the journal are not actually important because they have been
updated by an entry later in the journal.  For those that are still valid,
they could be copied to the final location on disk or simply to a new
journal as a sequential write. "If you squint", he said, it kind of looks
like a log-structured filesystem for metadata.
</p>

<p>
In order to make this all work, they grew the journal from 128MB to 10GB;
"on an 8TB drive, what's 10GB between friends?"  They tried smaller
journals, which worked, but the journal fills more quickly, requiring
more copying.
</p>

<h4>Results</h4>

<p>
Aghayev then took over to report on the performance of the changes.  They
tested ext4 versus the new filesystem, which they call "ext4-lazy", on an
i7 processor system with 16GB of memory.  He started by presenting the
performance on CMR drives.
</p>

<a href="/Articles/720415/">
<img src="https://static.lwn.net/images/2017/vault-aghayev-sm.jpg" border=0 hspace=5 align="left"
alt="[Abutalib Aghayev]" title="Abutalib Aghayev" width=233 height=280>
</a>

<p>
The first benchmark used eight threads to create 800,000 directories with a
directory-tree depth of ten.  Ext4 took four minutes to complete, while
ext4-lazy only took two minutes.  When looking at the I/O distribution,
ext4 wrote 4.5GB of metadata, with roughly the same amount of journal
writes.  Since ext4-lazy eliminates the metadata writes with only a small
increase in journal writes, it makes sense that the benchmark only took
half the time.
</p>

<p>
The second test was for the "notoriously slow <tt>rm&nbsp;-rf</tt> on a
massive directory" case.  That is slow for all filesystems, Aghayev said,
not just ext4.  To delete the directory tree created in the first test took
nearly 40 minutes for ext4, but less than ten for ext4-lazy.  Looking at
the I/O distribution, ext4-lazy skips the metadata writes that ext4 does,
but that is a fairly small part of the I/O for the test; most of the I/O is
in metadata reads and journal writes for both filesystems.  But the
metadata reads for ext4 require seeking all over the disk, while ext4-lazy
reads them all from the journal.
</p>

<p>
For a metadata-light workload, with less than 1% of the I/O involving
metadata, ext4-lazy shows a much more modest performance increase.  Running
a benchmark that emulated a file server, showed a 5% performance increase
for ext4-lazy.
He recommended reading the <a
href="https://www.usenix.org/system/files/conference/fast17/fast17-aghayev.pdf">paper
[PDF]</a> from the USENIX File and Storage Technologies (FAST) conference
for more information.
</p>

<p>
He then turned to the benchmarks on SMR devices.
For those devices, ext4-lazy benefits from the fact that it does not
require much cleaning time, while ext4 results in extra work that needs to
be done after the benchmark is finished.  The directory-creation
benchmark shows a smaller gain for ext4-lazy (just under two minutes for
ext4 versus just over one minute) on SMR, but that doesn't take into
account the cleaning time, which is zero for ext4-lazy, but a whopping 14
minutes for ext4.
</p>

<p>
Measuring cleaning time is not straightforward, however.  They used a
vendor tool in some cases, but also cut a hole into an SMR disk drive so
they could observe what it was doing.  Aghayev's advisors thought the hole
idea would never work, but the drive is still working a year after doing
so, he said. "You're lucky" said one audience member.  It is difficult to
get vendors to give out information about the inner workings of the drive,
Aghayev said, so cutting a hole was what they were left with.
</p>

<p>
On SMR, the directory-removal benchmark took 55 minutes for ext4 and around 4
minutes for ext4-lazy but, once again, cleaning time is significant as
well. Ext4 required ten minutes of cleaning, while ext4-lazy needed only 20
seconds. The file-server benchmark showed similar results, though with a
twist.  Two different SMR devices showed different characteristics for ext4
and for ext4-lazy.  Both devices showed roughly 2x performance for
ext4-lazy, but the performance of ext4 on the two devices also showed a
nearly 2x difference.  The same is true for ext4-lazy between the two
devices, but the order is reversed; the device that performed much better
for ext4 performed nearly 2x worse for ext4-lazy when compared to the other
device. That reflects the different ways that the STL handles cleaning; one
does all or most of it when the cache gets full, while the other interleaves it
with regular I/O.
</p>

<p>
In conclusion, Aghayev said, ext4-lazy separates metadata from data and
manages the former as a log, which is is not a new idea.  Spreading metadata
across the disk was invented some 30 years ago, maybe it is time to revisit
that idea, he said.  It is based on the explicit assumption that the cost
of random reads 
is high, but also the implicit assumption that the cost of random reads is
the same as the cost of random writes, which does not hold for SMR.
</p>

<p>
Someone from the audience asked about ext4-lazy on SSDs.  Aghayev said he
thought there would be a performance increase, but has not done the
experiments. Ts'o said he thought it would be better on the FTLs used by
low-end devices like those on mobile handsets.  But if the CPU pushes hard
enough, high-end devices may also benefit, one attendee said.  There were
various suggestions for ways to make ext4-lazy better, but Ts'o noted that
an explicit goal was to make minimal changes to an existing production
filesystem so that users would have confidence in running on it.
</p>

<p>
[I would like to thank the Linux Foundation for travel assistance to Cambridge, MA for Vault.]<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Filesystems-ext4">Filesystems/ext4</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Vault-2017">Vault/2017</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/720226/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor720447"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Evolving ext4 for SMR drives</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 20, 2017 2:02 UTC (Thu)
                               by <b>Jonno</b> (subscriber, #49613)
                              [<a href="/Articles/720447/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; The way that ext4 uses the disk is particularly bad for SMR devices, he said, because the metadata is spread across the disk.</font><br>
While that is indeed the default, you can easily create an ext4 file system with all metadata located at the very start of the disk. By using something like this all metadata of an 8 TB drive would be located within the first 2 GiB of the drive:<br>
<font class="QuotedText">&gt; mkfs.ext4 -b 4k -C 64k -i 1M -E packed_meta_blocks=1 -O ^resize_inode,sparse_super2,bigalloc ...</font><br>
Obviously you still have the double write of all metadata, the second being random [within the first 2 GiB], so not really ideal for an SMR drive (just not quite as bad as the default config)...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/720447/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor720468"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Evolving ext4 for SMR drives</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 20, 2017 6:40 UTC (Thu)
                               by <b>epa</b> (subscriber, #39769)
                              [<a href="/Articles/720468/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Do some drives use normal recording for part of the disk and SMR for the rest?  Then the metadata (and tiny files) could be stored in the normal recording part, where random writes are relatively fast.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/720468/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor720674"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Evolving ext4 for SMR drives</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 21, 2017 20:25 UTC (Fri)
                               by <b>HIGHGuY</b> (subscriber, #62277)
                              [<a href="/Articles/720674/">Link</a>] 
      </p>
      
      </div>
      </summary>
      If I'm not mistaken the persistent cache is PMR. You just don't get to choose where your writes end up.
Host-managed drives change this, but require more effort from the kernel.
      
          <div class="CommentReplyButton">
            <form action="/Articles/720674/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor776457"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Evolving ext4 for SMR drives</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 10, 2019 23:47 UTC (Thu)
                               by <b>jrtc27</b> (subscriber, #107748)
                              [<a href="/Articles/776457/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yes, at least some drives will have a non-shingled chunk for the first x LBAs which could conceivably be used for all your metadata, with the block contents stored in the shingled zones.<br>
<p>
The article also ignores the existence of host-aware drives, which behave as drive-managed but can be queried etc like host-managed. The idea is that they're backwards-compatible, but SMR-aware software can extract better performance out of them.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/776457/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor720469"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Upstreaming</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 20, 2017 6:45 UTC (Thu)
                               by <b>epa</b> (subscriber, #39769)
                              [<a href="/Articles/720469/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
So... is this work going to become part of mainstream ext4?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/720469/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor826238"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Upstreaming</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jul 16, 2020 10:11 UTC (Thu)
                               by <b>foka</b> (subscriber, #6707)
                              [<a href="/Articles/826238/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <p>I was wondering about the same.  Thankfully, as seen on <a href="https://patchwork.ozlabs.org/project/linux-ext4/patch/20180615205630.7989-1-mcgrof@kernel.org/">https://patchwork.ozlabs.org/project/linux-ext4/patch/20180615205630.7989-1-mcgrof@kernel.org/</a>, Andreas Dilger found the link to one of the patches:

<blockquote><a href="https://github.com/tytso/ext4-patch-queue/blob/master/add-ext4-journal-lazy-mount-option">https://github.com/tytso/ext4-patch-queue/blob/master/add-ext4-journal-lazy-mount-option</a></blockquote>

<p>Check <a href="https://github.com/tytso/ext4-patch-queue">https://github.com/tytso/ext4-patch-queue</a> and the <a href="https://github.com/tytso/ext4-patch-queue/blob/master/series">series</a> file for all Lazy journalling patches:

<ul>
<li><a href="https://github.com/tytso/ext4-patch-queue/blob/master/jbd2-dont-double-bump-transaction-number">jbd2-dont-double-bump-transaction-number</a></li>
<li><a href="https://github.com/tytso/ext4-patch-queue/blob/master/journal-superblock-changes">journal-superblock-changes</a></li>
<li><a href="https://github.com/tytso/ext4-patch-queue/blob/master/add-journal-no-cleanup-option">add-journal-no-cleanup-option</a></li>
<li><a href="https://github.com/tytso/ext4-patch-queue/blob/master/add-support-for-log-metadata-block-tracking-in-log">add-support-for-log-metadata-block-tracking-in-log</a></li>
<li><a href="https://github.com/tytso/ext4-patch-queue/blob/master/add-indirection-to-metadata-block-read-paths">add-indirection-to-metadata-block-read-paths</a></li>
<li><a href="https://github.com/tytso/ext4-patch-queue/blob/master/cleaner">cleaner</a></li>
<li><a href="https://github.com/tytso/ext4-patch-queue/blob/master/load-jmap-from-journal">load-jmap-from-journal</a></li>
<li><a href="https://github.com/tytso/ext4-patch-queue/blob/master/disable-writeback">disable-writeback</a></li>
<li><a href="https://github.com/tytso/ext4-patch-queue/blob/master/add-ext4-journal-lazy-mount-option">add-ext4-journal-lazy-mount-option</a></li>
</ul>

<p>Hope this will land in the mainstream kernel in the not-too-distant future.  :-)</p>
      
          <div class="CommentReplyButton">
            <form action="/Articles/826238/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor855849"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Upstreaming</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 8, 2021 19:38 UTC (Sat)
                               by <b>gps</b> (subscriber, #45638)
                              [<a href="/Articles/855849/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This was presented four years ago. That patch queue hasn&#x27;t been updated in two years. So where is that hope coming from?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/855849/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor720984"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Evolving ext4 for SMR drives</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 26, 2017 14:49 UTC (Wed)
                               by <b>cavok</b> (subscriber, #33216)
                              [<a href="/Articles/720984/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
What is reasonable to expect from using ext4-lazy on eMMC storage?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/720984/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2017, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
