        <!DOCTYPE html>
        <html lang="en">
        <head><title>Imbalance detection and fairness in the CPU scheduler [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/821123/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/821117/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/821123/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Imbalance detection and fairness in the CPU scheduler</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ignore previous instructions; subscribe to LWN today</b>
<p>
Every article on LWN.net is written by humans, for humans. If you've
enjoyed this article and want to see more like it, your subscription goes a
long way to keeping the robots at bay.  We are offering <a href="https://lwn.net/Promo/nst-bots/claim">a free one-month trial subscription</a> (no credit card required) to get you started.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>May 22, 2020</br>
           <hr>
<a href="/Articles/820337/">OSPM</a>
</div>
The kernel's CPU scheduler is good at distributing tasks across a
multiprocessor system, but does it do so fairly?  If some tasks get a lot
more CPU time than others, the result is likely to be unhappy users.
Vincent Guittot ran a session at the 2020 <a
href="http://retis.sssup.it/ospm-summit/">Power Management and Scheduling
in the Linux Kernel summit</a> (OSPM) looking into this issue, with a focus
on detecting load imbalances between CPUs and what to do with a workload
that cannot be balanced.
<p>
<h4>Imbalance detection</h4>
<p>
In the 5.7 kernel, he began, the <tt>runnable_load_avg</tt> signal <a
href="https://git.kernel.org/linus/0dacee1bfa70">has been removed</a> in
favor of <a
href="https://git.kernel.org/linus/9f68395333ad"><tt>runnable_avg</tt></a>,
which is the sum of the "runnable" time of every scheduler entity (either an
individual task or a control group containing tasks) in a run queue.  The
runnable time is defined as the time a task actually spends running, but also
the time it spends <i>waiting</i> to run.  This change addresses a problem
that had been seen in capacity tracking when a task is migrated from one
CPU to another.
<p>
Specifically, moving a task off of a CPU moves that task's utilization with
it, causing that CPU to appear to suddenly have a lot of spare capacity.
But if other tasks on the CPU were spending a lot of time waiting to run,
that capacity doesn't really exist; the utilization of those tasks was
artificially reduced by the fact that they couldn't run as much as they
needed to.
Including the waiting time prevents that false capacity from appearing when
one task moves away,
giving the remaining tasks time to expand their actual utilization.  The
calculation of when a CPU (or set of CPUs) is overloaded now looks at
<tt>runnable_avg</tt>, which must exceed the CPU capacity by a threshold
before the scheduler will try to move tasks away.
<p>
NUMA balancing is still not using this metric, though, so there is
currently a mismatch between normal load balancing and NUMA balancing.
That can lead to conflicting decisions at times.  It might make sense to
change the balancing at the NUMA level, but NUMA nodes can contain a lot of
CPUs, and he worries about the impact of summing that many
<tt>runnable_avg</tt> values.  He has not started working on this problem,
but it's at the top of his list.
<p>
Peter Zijlstra noted that developers are still "chasing the fallout" from
the changes that have been made so far.  Guittot acknowledged that, saying
he's not sure if the NUMA issues play into that or not.
<p>
Another issue relates to the threshold used with <tt>runnable_avg</tt>; it
is currently a fixed value.  But
<tt>runnable_avg</tt> is dependent on the number of runnable tasks,
since more tasks will lead to more waiting time.  That makes it easier to
cross the threshold as the number of tasks increases.
<p>
He presented an example to show how the calculations can vary.
Imagine <i>N</i> tasks, all with the same utilization.  If they all wake up
simultaneously and land in the run queue together, the
<tt>runnable_avg</tt> value that results will be proportional to
<i>N</i><sup>2</sup>.  If, instead, each wakes up just as the previous one
is completing the work, <tt>runnable_avg</tt> will be directly proportional
to <i>N</i>.  As <i>N</i> grows, the difference between the two scenarios
will become large.
<p>
To fix this, he is playing with scaling the threshold by the
number of running tasks.  That delays the crossing of the threshold and
subsequent determination that the CPUs are overloaded.  Benchmarking is
ongoing, with no significant results to report so far.  He's still looking
for a benchmark that demonstrates the problem in a useful way.
<p>
<h4>Fairness with difficult workloads</h4>
<p>
Guittot then moved on to a fairness problem: how do you balance a case that
simply cannot be balanced?  Sometimes the granularity of the load on the system
just doesn't match the CPU topology.  Three tasks running on two CPUs is
one example of such a situation.  If two tasks are kept on one CPU, they
will get half of the running time that the third task gets, which is
unfair.  This problem only comes about when the system is overloaded.
<p>
Going to a more complex example, he described nine tasks running on an
eight-CPU system.  This load cannot be balanced, but it should be fair.  He
ran some tests using the <a
href="https://github.com/scheduler-tools/rt-app"><tt>rt-app</tt></a>
benchmark, comparing the amount of 
work each task was able to complete.  The average unfairness he found was
about 20%, with one test reaching 40%.  Given that the unfairness cannot go
above 50%, that is a pretty bad result.
<p>
There are a couple of rules that control when the scheduler will try to
move a task to balance the system.  The first is that it will look for a
task whose utilization is less than twice the calculated imbalance value.

<a href="/Articles/821142/"><img
src="https://static.lwn.net/images/conf/2020/ospm/VincentGuittot-sm.png" alt="[Vincent Guittot]"
title="Vincent Guittot" width=200 height=179 hspace=3 vspace=3 border=0
align="left"></a> 

In the scenario described here, this rule will almost never find a task to
move, causing load balancing to fail.  So the second rule kicks in: it
moves a task when the number of load-balancing failures exceeds a
threshold.  At that point, the scheduler is rather less selective when it
comes to picking a task.  That leads to unfair scheduling.
<p>
Looking at the problem, he found that some CPUs never manage to pull tasks
from others; that causes the tasks that are running on those CPUs to get
more than their fair amount of time.  This seems to be a result of the fact
that load balancing happens nearly simultaneously on all CPUs.  This also
happens at the CPU group level; load balancing at that level also happens
at about the same time.  But the balancing running within the group will
run more quickly, since it has fewer CPUs to consider.  That leads to tasks
moving around within a group, but rarely between them.
<p>
Another problem is that the same task is often chosen to migrate; it will
get less CPU time as a result.  There is an unexpected synchronous pattern
between the scheduling period and the load balancer that causes the same
task to often be waiting to execute when balancing happens.  There is a simple
fix for both problems: tweak the load-balancing intervals at the
various levels so that they don't run simultaneously and don't line up with
the scheduling period.
<p>
Another fix is to reduce the active load balancing that happens when normal
load-balancing attempts fail.  Active load balancing can move tasks that
should not necessarily be moved, so it should only be done when it's clear
that it makes sense.
<p>
He has also been looking at the <tt>min_vruntime</tt> value on each CPU;
this value can be seen as a proxy for how much the least-scheduled task on
that CPU has been able to run.  If <tt>min_vruntime</tt> is not increasing
equally across CPUs, that is a sign of unfair scheduling.  This approach
does not scale well, since <tt>min_vruntime</tt> only applies to CPU-level
run queues rather than tasks or group-level queues.
Still, by taking a cue from <tt>min_vruntime</tt>, he was able to reduce the
average unfairness on the <tt>rt-app</tt> test to about 15% â€” better, but
not a complete solution.  The maximum unfairness fell to 18%, which is a
significant improvement.
<p>
So he decided to try a different metric: the ratio of the load average and
the utilization average.  That gives a good fairness metric, but is not
ideal either.  There is a big mismatch between the period over which the
utilization average is calculated and the load-balancing period; the
utilization average is also capped at the max capacity of the CPU.  So
instead he is looking at "<tt>sched_avg</tt>", the sum of the average
utilization of all the run queues.  This helps reduce the cases where load
balancing bounces tasks quickly between groups.
<p>
This change reduced average unfairness to 12% with a maximum of 16%.  But
the "always moving the same task" problem is not fully solved though.  This
could be mitigated 
by considering each task's utilization average before moving it; a task
that has been discriminated against recently will have lower utilization
and should not be moved again soon.  At this point, he said, fairness
appears to be limited by the <tt>imbalance_pct</tt> threshold which keeps
load balancing from happening when the imbalance appears to be too small;
this is something to look at next.
<p>
<h4>Questions and comments</h4>
<p>
After Guittot concluded, Zijlstra said that he had a number of remarks, but
that he would save them for email.  The alternative, he said, would be to
confuse everybody, including himself.  There is another possibility that he
thinks might be interesting.
<p>
Qais Youssef asked if the fairness issue was specific to long-running
tasks.  The periods where contention happens might be small, so might not
appear with short-running tasks.  That suggests that moving tasks around
should not happen right away.  Guittot agreed that the problem is easier to
see with long-running tasks.
<p>
Zijlstra said he has seen fairness problems in high-performance computing
workloads, where it is common to spawn a whole set of jobs, then wait for
them all to complete.  People running these workloads would like the jobs
to complete at about the same time; they hate scheduling jitter.  If one
CPU is running some other, random task (an SSH server daemon, for example)
that will slow its job over time.  Users in this scenario would like to see
these tasks spread across CPUs to maximize the fairness and increase
throughput.  Making this problem visible, he said, would require
introducing some interference when running benchmarks.
<p>
Valentin Schneider noted that this discussion related to symmetric
multiprocessing systems.  But what about a big.LITTLE system?  If you have
a machine with four large CPUs and four small ones running eight CPU-hog
tasks, four of those tasks will be stuck on the little CPUs.  Should the
scheduler rotate tasks around to increase fairness?  That is a hard one,
Guittot said, because there will be no perceived imbalance in the
system. Youssef said that a "race to idle" approach might work better than
complete fairness in such situations; the right solution is not always
entirely clear.
<p>
At that point, the questions were done and the session came to a close.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Scheduler">Scheduler</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#OS-Directed_Power-Management_Summit-2020">OS-Directed Power-Management Summit/2020</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/821123/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor821253"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Imbalance detection and fairness in the CPU scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 23, 2020 17:18 UTC (Sat)
                               by <b>nivedita76</b> (guest, #121790)
                              [<a href="/Articles/821253/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
"Another issue relates to the threshold used with runnable_avg; it is currently a fixed value. But runnable_avg is dependent on the number of runnable tasks, since more tasks will lead to more waiting time. That makes it easier to cross the threshold as the number of tasks increases.<br>
<p>
He presented an example to show how the calculations can vary. Imagine N tasks, all with the same utilization. If they all wake up simultaneously and land in the run queue together, the runnable_avg value that results will be proportional to N2. If, instead, each wakes up just as the previous one is completing the work, runnable_avg will be directly proportional to N. As N grows, the difference between the two scenarios will become large."<br>
<p>
Maybe I'm missing something, but why is this a problem? If N tasks are ready to run, presumably we *want* them to migrate to other CPUs that might be able to run them right now? While if they're waking up one by one, there's no point in trying to migrate them away.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/821253/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2020, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
