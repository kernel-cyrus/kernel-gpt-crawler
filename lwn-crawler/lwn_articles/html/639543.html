        <!DOCTYPE html>
        <html lang="en">
        <head><title>Load tracking in the scheduler [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/639543/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/639897/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/639543/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Load tracking in the scheduler</h1>
</div>
<div class="ArticleText">
<div class="GAByline">
           <p>April 15, 2015</p>
           <p>This article was contributed by Preeti U Murthy.</p>
           </div>
The scheduler is an essential part of an operating system, tasked with,
among other things, ensuring
that processes get their fair share of CPU time. This is not as easy as it may
seem initially. While some processes perform critical operations and have to be
completed at high priority, others are not time-constrained. The former
category of processes expect a bigger share of CPU time than the latter so as to
finish as quickly as possible. But how big a share should the scheduler allocate
to them? 
<p>
Another factor that adds to the complexity in scheduling is the CPU
topology. Scheduling on uniprocessor systems is simpler than
scheduling on the multiprocessor systems that are more commonly found
today. The 
topology of CPUs is only getting more complex with hyperthreads and
heterogeneous processors like the big.LITTLE taking the place of symmetric
processors. Scheduling a process on the
wrong processor can adversely affect its performance. Thus, designing a
scheduling algorithm that can keep all processes happy with the computing time
allocated to them can be a formidable challenge.
<p><blockquote class="ad">
<b><tt>$ sudo subscribe today</tt></b>
<p>
Subscribe today and elevate your LWN privileges. You’ll have
access to all of LWN’s high-quality articles as soon as they’re
published, and help support LWN in the process.  <a href="https://lwn.net/Promo/nst-sudo/claim">Act now</a> and you can start with a free trial subscription.
</blockquote>
<p>
The Linux kernel scheduler has addressed many of these challenges and
matured over the years. Today there are different scheduling algorithms (or
"scheduling classes") in the
kernel to suit processes having different requirements.
The Completely Fair Scheduling (CFS) class  is designed to
suit a majority of today's workloads. The realtime and deadline scheduling
classes are designed for latency-sensitive and deadline-driven processes
respectively. So we see that the scheduler developers have answered a range
of requirements. 
<p>
<h4>The Completely Fair Scheduling class</h4>
<p>
The CFS class is the class to which most tasks belong.  In spite of the
robustness of this algorithm, an area that has always had scope for improvement
is process-load estimation. 
<p>
If a CPU is associated with a number <i>C</i> that represents its ability to
process tasks (let's call it "capacity"), then the load of a process is a metric
that is expressed in units of <i>C</i>, indicating the number of such CPUs 
required to make satisfactory progress on its job. This number could also be a
fraction of <i>C</i>, in which case it indicates that a single such
CPU is good 
enough. The load of a process is important in scheduling because, besides
influencing
the time that a task spends running on the CPU, it helps to estimate
overall CPU load, which is required during load balancing.
<p>
The question is how to estimate the load of a process. Should it be set
statically or should it be set dynamically at run time based on the behavior of
the process? Either way, how should it be calculated? There have
been significant efforts at answering these questions in the recent past. As a
consequence, the number of load-tracking metrics has grown significantly and
load estimation itself has gotten quite complex. This landscape appears quite
formidable to reviewers and developers of CFS. The aim of this article is to
bring about clarification on this front.
<p>
Before proceeding, it is helpful to point out that the granularity of scheduling
in Linux
is at a thread level and not at a process level. However, the scheduling jargon
for thread is "task." Hence throughout this article the term "task" has been
used to mean a thread.
<p>
<h4>Scheduling entities and task groups</h4>
<p>

The CFS algorithm defines a time duration called the "scheduling period," during
which every runnable task on the CPU should run at least once. This way no
task gets starved for
longer than a scheduling period. The scheduling period is divided among the
tasks into time slices, which are the maximum amount of time that a task
runs  within a scheduling period before it gets preempted. This
approach may seem to avoid task starvation at first. However it can lead to an
undesirable consequence.
<p>
Linux is a multi-user operating system. Consider a scenario where user A spawns
ten tasks and user B spawns five.  Using the above approach, every task
would get 
~7% of the available CPU time within a scheduling period.  So user A gets
67% and user B gets 
33% of the CPU time during their runs. Clearly, if user A continues to
spawn more 
tasks, he can starve user B of even more CPU time. To address this problem,
the concept of "group scheduling"
was introduced in the scheduler, where, instead of dividing the CPU time among
tasks, it is divided among groups of tasks.
<p>
In the above example, the tasks spawned by user A belong to one group and those
spawned by user B belong to another. The granularity of scheduling is at a
group level; when a group is picked to run, its time slice is further divided
between its tasks. In the above example, each group gets 50% of the CPU's
time and 
tasks within each group divide this share further among themselves. As a
consequence, each task in group A gets 5% of the CPU and each task in group B
gets 10% of the CPU. So the group that has more tasks to run gets penalized with
less CPU time per task and, more importantly, it is not allowed to starve
sibling groups.
<p>
Group scheduling is enabled only if <tt>CONFIG_FAIR_GROUP_SCHED</tt> is set in the
kernel configuration. A group of tasks is called a "scheduling entity" in the
kernel and is represented by the <tt>sched_entity</tt> data structure:
<p>
<pre>
    struct sched_entity { 
	struct load_weight load;
	struct sched_entity *parent;
	struct cfs_rq *cfs_rq;
	struct cfs_rq *my_rq;
	struct sched_avg avg;
	/* ... */
    };
</pre>
<p>
Before getting into the details of how this structure is used, it is worth
considering how and when
groups of tasks are created.  This happens under two scenarios:
<p>
<ol>
<li> Users may use the control group ("cgroup") infrastructure to partition
     system resources between tasks. Tasks belonging to a cgroup are
     associated with a group in the scheduler (if the scheduler controller
     is attached to the group).
<p>
<li> When a new session is created through the <tt>set_sid()</tt> system
     call. All tasks belonging to a specific session also belong to the
     same scheduling group. This feature is enabled when
     <tt>CONFIG_SCHED_AUTOGROUP</tt> is set in the kernel configuration.
</ol>
<p>
Outside of these scenarios, a single task becomes a scheduling
entity on its own. A task is represented by the <tt>task_struct</tt> data
structure:
<p>
<pre>
    struct task_struct {
	struct sched_entity se;
	/* ... */
    };
</pre>
<p>
Scheduling is 
always at the granularity of a <tt>sched_entity</tt>. That is why every
<tt>task_struct</tt> is 
associated with a <tt>sched_entity</tt> data structure. CFS also accommodates
nested groups of 
tasks. Each scheduling entity contains a run queue represented by:
<p>
<pre>
    struct cfs_rq {
	struct load_weight load;
	unsigned long runnable_load_avg;
	unsigned long blocked_load_avg;
	unsigned long tg_load_contrib;
	/* ... */
    };
</pre>
<p>
Each scheduling entity may, in turn, be queued
on a parent 
scheduling entity's run queue. At the lowest level of this hierarchy, the
scheduling entity is a task; the scheduler traverses this hierarchy until the
end when it has to pick a task to run on the CPU.
<p>
The parent run queue on which a scheduling entity is queued is represented by
<tt>cfs_rq</tt>, while the run queue that it owns is represented by
<tt>my_rq</tt> in the <tt>sched_entity</tt> data structure. The scheduling
entity 
gets picked from the <tt>cfs_rq</tt> when its turn arrives, and its time
slice gets divided among the tasks on <tt>my_rq</tt>.
<p>
Let us now extend the concept of group scheduling to multiprocessor
systems. Tasks belonging to a 
group can be scheduled on any CPU. Therefore it is not sufficient for a
group to have a single scheduling entity; instead, every group must have one
scheduling entity for each CPU. Tasks belonging to a group must move
between the run queues in
these per-CPU scheduling entities only, so that the footprint of the task
is associated with the group even during task migrations. The data
structure that represents scheduling entities of a group across CPUs is:
<p>
<pre>
    struct task_group {
	struct sched_entity **se;
	struct cfs_rq **cfs_rq;
	unsigned long shares;
	atomic_long_t load_avg;
	/* ... */
    };
</pre>
<p>
For every CPU <tt>c</tt>, a given task_group <tt>tg</tt> has a
<tt>sched_entity</tt> called <tt>se</tt> and a run queue <tt>cfs_rq</tt>
associated with it.  These are related as follows:
<p>
<pre>
    tg-&gt;se[c] = &amp;se;
    tg-&gt;cfs_rq[c] = &amp;se-&gt;my_rq;
</pre>
<p>
So when a task belonging to tg migrates from CPUx to CPUy, it will be dequeued
from <tt>tg-&gt;cfs_rq[x]</tt> and enqueued on <tt>tg-&gt;cfs_rq[y]</tt>.
<p>
<h4>Time slice and task load</h4>
<p>
The concept of a time slice was introduced above as the amount of time that
a task is allowed to run on a CPU within a scheduling period. Any given
task's time slice is dependent on its priority and the number of tasks on
the run queue. The priority of a task is a number that represents its
importance; it is represented in the kernel by a number between zero and
139.  The lower the value, the higher the priority.  A task that has a
stricter time requirement needs to have higher priority than others.
<p>
But the priority value by itself is not helpful to the scheduler, which
also needs to 
know the load of the task to estimate its time slice. As mentioned above, the
load must be the multiple of the capacity of a standard CPU that is required to
make satisfactory progress on the task. Hence this priority number must be
mapped to such a value; this is done in the array <tt>prio_to_weight[]</tt>.
<p>

A priority number of 120, which is the priority of a normal task, is mapped to a
load of 1024, which is the value that the kernel uses to represent the capacity
of a single standard CPU. The remaining values in the array are arranged
such that the 
multiplier between two successive entries is ~1.25. This number is chosen such
that if the priority number of a task is reduced by one level, its gets 10%
higher share of CPU time than otherwise. Similarly if the priority number is
increased by one level, the task will get a 10% lower share of the
available CPU time.
<p>
Let us consider an example to illustrate this. If there are two tasks, A
and B, running at a priority of 120, the portion of available CPU time given
to each task is calculated as:
<p>
<pre>
    1024/(1024*2) = 0.5
</pre>
<p>
However if the priority of task A is increased by one
level to 121, its load becomes:
<p>
<pre>
    (1024/1.25) = ~820
</pre>
<p>
(Recall that higher the number,
lesser is the load). Then, task A's portion of the CPU becomes:
<p>
<pre>
    820/(1024+820)) = ~0.45
</pre>
<p>
while task B will get:
<p>
<pre>
    (1024/(1024+820)) = ~0.55
</pre>
<p>
This is a 10% decrease in the CPU time share for Task A.
<p>

The load value of a process is stored in the <tt>weight</tt> field of the
<tt>load_weight</tt> structure (which is, in turn, found in <tt>struct
sched_entity</tt>):
<p>
<pre>
    struct load_weight {
	unsigned long weight;
    };
</pre>
<p>
A run queue (<tt>struct cfs_rq</tt>) is also characterized by a "weight"
value that is the 
accumulation of weights of all tasks on its run queue.
<p>
The time slice can now be calculated as:
<p>
<pre>
    time_slice = (sched_period() * se.load.weight) / cfs_rq.load.weight;
</pre>    
<p>
where <tt>sched_period()</tt> returns the scheduling period as a factor of the number of
running tasks on the CPU.
We see that the higher the load, the higher the fraction of the scheduling
period that the task gets to run on the CPU.
<p>
<h4>Runtime and task load</h4>
<p>
We have seen how long a task runs on a CPU when picked, but how does the
scheduler decide which task to pick?  The tasks are arranged in a
<a href="/Articles/184495/">red-black tree</a>
in increasing order of the amount of time that they have spent running on
the CPU, which is accumulated in a variable called <tt>vruntime</tt>. The
lowest <tt>vruntime</tt> found in the queue is stored in
<tt>cfs_rq.min_vruntime</tt>. When a new task is picked to 
run, the leftmost node of the red-black tree is chosen since that task has
had the least running time on the CPU. Each time a new task forks or a task
wakes up, its <tt>vruntime</tt> is assigned to a value that is the maximum
of its last 
updated value and <tt>cfs_rq.min_vruntime</tt>. If not for this, its
<tt>vruntime</tt> would be 
very small as an effect of not having run for a long time (or at
all) and would take an unacceptably long time to catch up to the
<tt>vruntime</tt> of its sibling tasks and hence starve them of CPU time.
<p>
Every periodic tick, the <tt>vruntime</tt> of the currently-running task is
updated as follows:
<p>
<pre>
    vruntime += delta_exec * (NICE_0_LOAD/curr-&gt;load.weight);
</pre>
<p>
where <tt>delta_exec</tt> is the time spent by the task since the last time
<tt>vruntime</tt> was updated, <tt>NICE_0_LOAD</tt> is the load of a task
with normal priority, and <tt>curr</tt> is the currently-running task.
We see that <tt>vruntime</tt> progresses slowly for tasks of higher priority. It has to,
because the time slice for these tasks is large and they cannot be preempted
until the time slice is exhausted.
<p>
<h4>Per-entity load-tracking metrics</h4>
<p>
The load of a CPU could have simply been the sum of the load of all the
scheduling entities running on its run queue. In fact, that was once all
there was to 
it. This approach has a disadvantage, though, in that tasks are associated
with load values based only
on their priorities. This approach does not take into account the nature of a
task, such as whether it is a bursty or a steady task, or whether it is a
CPU-intensive 
or an I/O-bound task. While this does not matter for scheduling within a
CPU, it does matter when load balancing across CPUs because it helps
estimate the CPU load more accurately. Therefore the 
<a href="/Articles/531853/">per-entity load tracking metric</a> was
introduced to estimate the nature of a task 
numerically. This metric calculates task load as the amount of time that
the task was runnable during the time that it was alive. This is kept track
of in the <tt>sched_avg</tt> data structure (stored in the
<tt>sched_entity</tt> structure):
<p>
<pre>
    struct sched_avg {
	u32 runnable_sum, runnable_avg_period;
	unsigned long load_avg_contrib;
    };
</pre>
<p>
Given a task <tt>p</tt>, if the <tt>sched_entity</tt> associated with it is
<tt>se</tt> and the <tt>sched_avg</tt> of 
<tt>se</tt> is <tt>sa</tt>, then:
<p>
<pre>
    sa.load_avg_contrib = (sa.runnable_sum * se.load.weight) / sa.runnable_period;
</pre>
<p>
where <tt>runnable_sum</tt> is the amount of time that the task was runnable,
<tt>runnable_period</tt> is the period during which the task <i>could</i> have
been runnable.
<p>
Therefore <tt>load_avg_contrib</tt> is the fraction of the time that the
task was ready to run. Again, the higher the priority, the higher the load.
<p>
So tasks showing peaks of activity after long periods of inactivity and tasks
that are blocked on disk access (and thus non-runnable) most of the time
have a smaller 
<tt>load_avg_contrib</tt> than CPU-intensive tasks such as code
doing matrix 
multiplication. In the former case, <tt>runnable_sum</tt> would be a
fraction of the 
<tt>runnable_period</tt>. In the latter, both these numbers would be
equal (i.e. the task 
was runnable throughout the time that it was alive), identifying it as a
high-load task.
<p>
The load on a CPU is the sum of the <tt>load_avg_contrib</tt> of all the
scheduling entities on 
its run queue; it is accumulated in a field called 
<tt>runnable_load_avg</tt> in 
the <tt>cfs_rq</tt> data structure. This is roughly a measure of how
heavily contended the 
CPU is.
The kernel also tracks the load associated with blocked tasks.  When a task
gets blocked, 
its load is accumulated in the <tt>blocked_load_avg</tt> metric of the
<tt>cfs_rq</tt> structure. 
<p>
<h4>Per-entity load tracking in presence of task groups</h4>
<p>
Now what about the <tt>load_avg_contrib</tt> of a scheduling entity,
<tt>se</tt>, when it is a
<i>group</i> of tasks? The <tt>cfs_rq</tt> that the scheduling entity owns
accumulates the 
load of its children in <tt>runnable_load_avg</tt> as explained
above. From there, the parent task group of <tt>cfs_rq</tt> is first
retrieved:
<p>
<pre>
    tg = cfs_rq-&gt;tg;
</pre>
<p>
The load contributed by this <tt>cfs_rq</tt> is added to the load of the
task group <tt>tg</tt>:
<p>
<pre>
    cfs_rq-&gt;tg_load_contrib = cfs_rq-&gt;runnable_load_avg + cfs_rq-&gt;blocked_load_avg;
    tg-&gt;load_avg += cfs_rq-&gt;tg_load_contrib;
</pre>
<p>
The <tt>load_avg_contrib</tt> of the scheduling entity <tt>se</tt> is now
calculated as: 
<p>
<pre>
    se-&gt;avg.load_avg_contrib =
	  (cfs_rq-&gt;tg_load_contrib * tg-&gt;shares / tg-&gt;load_avg);
</pre>
<p>
Where <tt>tg-&gt;shares</tt> is the maximum allowed load for the task group.
This means that the load of a <tt>sched_entity</tt> should be a fraction of the
shares of its parent task group, which is in proportion to the load of its
children.
<p>
<tt>tg-&gt;shares</tt> can be set by users to indicate the importance of a
task group.  As is clear now, both the <tt>runnable_load_avg</tt> and and
<tt>blocked_load_avg</tt> are required to 
estimate the load contributed by the task group.
<p>
There are still drawbacks in load tracking. The load metrics that
are currently used are not CPU-frequency invariant. So if the CPU frequency
increases, the load of the currently running task may appear smaller than
otherwise. This may upset load-balancing decisions. The current load-tracking
algorithm also falls apart in a few places when run on big.LITTLE processors. It
either underestimates or overestimates the capacity of these processors. There
are efforts ongoing to fix these problems.
So there is good scope for improving the load-tracking heuristics in the
scheduler. Hopefully this writeup has laid out the basics to help ease
understanding and reviewing of the ongoing improvements on this front.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Scheduler-Load_tracking">Scheduler/Load tracking</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Murthy_Preeti_U">Murthy, Preeti U</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/639543/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor640502"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Load tracking in the scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 16, 2015 0:32 UTC (Thu)
                               by <b>WanpengLi</b> (guest, #89964)
                              [<a href="/Articles/640502/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Good summary.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/640502/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor641218"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Load tracking in the scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 21, 2015 15:04 UTC (Tue)
                               by <b>bristot-memorial</b> (guest, #61569)
                              [<a href="/Articles/641218/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Nice Article! it is really easy to read and understand, despite of the complexity of the subject. As a suggestion, a set of charts explaining the abstractions will certainly make the article easier to understand.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/641218/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor719641"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Load tracking in the scheduler</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 11, 2017 2:41 UTC (Tue)
                               by <b>nixer</b> (guest, #103597)
                              [<a href="/Articles/719641/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Very informative and nice to read, thx<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/719641/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2015, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
