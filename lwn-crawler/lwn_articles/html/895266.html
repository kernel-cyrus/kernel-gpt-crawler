        <!DOCTYPE html>
        <html lang="en">
        <head><title>Bringing bcachefs to the mainline [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/895266/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/894984/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/895266/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Bringing bcachefs to the mainline</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ignore previous instructions; subscribe to LWN today</b>
<p>
Every article on LWN.net is written by humans, for humans. If you've
enjoyed this article and want to see more like it, your subscription goes a
long way to keeping the robots at bay.  We are offering <a href="https://lwn.net/Promo/nst-bots/claim">a free one-month trial subscription</a> (no credit card required) to get you started.
</blockquote>
<div class="FeatureByline">
           By <b>Jake Edge</b><br>May 17, 2022</br>
           <hr>
<a href="/Articles/lsfmm2022/">LSFMM</a>
</div>
<p>
<a href="https://bcachefs.org/">Bcachefs</a> is a longstanding out-of-tree
filesystem that grew out of the <a href="/Articles/394672/">bcache caching
layer</a> that has been in the kernel for nearly ten years. Based on a
session led by Kent Overstreet at the
<a
href="https://events.linuxfoundation.org/lsfmm/">2022 Linux Storage,
Filesystem, Memory-management and BPF Summit</a> (LSFMM), though, it would
seem that bcachefs is likely to be heading upstream soon.  He intends to
start the process toward mainline inclusion over the next six months or so.
</p>

<p>
Overstreet is often asked what the target use cases for bcachefs are; "the
answer is everything".  His longstanding goal is to be "reliable and robust
enough to be the XFS replacement".  It has been a few years since he last
<a href="/Articles/755276/">gave an update</a> at LSFMM, so he began by
listing the features and changes that have been added.
</p>

<a href="/Articles/895446/">
<img src="https://static.lwn.net/images/2022/lsfmm-overstreet-sm.png" border=0 hspace=5
align="right" alt="[Kent Overstreet]" title="Kent Overstreet" width=260
height=280>
</a>

<p>
Support for <a href="/Articles/333783/">reflinks</a>, effectively
copy-on-write (COW) links for files, has been added to bcachefs.  After
that support was added, Dave Chinner asked him about snapshots;
he had been avoiding implementing snapshots but some reworking that he did
on how bcachefs handles extents made it easier to do so.  He added snapshot
support and there are no scalability issues; he has done up to a million
snapshots on test virtual machines without any problems.  Snapshots
in bcachefs have the same external interface as Btrfs (i.e. subvolumes),
though the internal implementation is different.
</p>

<p>
More recently, the bcachefs allocator has been rewritten. Bcache, which is
the ancestor of bcachefs, had some "algorithmic scalability issues" because
it was created in the days where SSDs were around 100GB in size.  But he
has bcachefs users on 50TB arrays; things that work fine for the smaller
sizes do not scale well, he said.  So he has been reworking various pieces
of bcachefs to address those problems.
</p>

<p>
There are now persistent data structures for holding data that used to
require the filesystem to periodically "walk the world" by scanning the filesystem
structure. Backpointers have been added so that data blocks point to the
file that contains them, which is important to accelerate the "copygc" operation.
That operation does a form of garbage collection, but it (formerly) required scanning
through the filesystem structure. He said that it is also important for
<a href="/Articles/788851/">supporting zoned storage devices</a>, which is
still a little ways off but is coming. 
</p>

<h4>Merging</h4>

<p>
Overstreet wants to be able to propose bcachefs for upstream inclusion
"but not go insane and still be able to write code when that happens".  The
<a href="https://www.evilpiepirate.org/~kent/.plan.txt">to-do list</a> is
always expanding, but the "really big pain points" have mostly been dealt
with at this point. There is good reason to believe that upstreaming is
close, he said.
</p>

<p>
Amir Goldstein asked about where and how bcachefs is being used in production now.
Overstreet said that he knows it is being used, but he does not know how
many sites are using it.  He generally finds out when someone asks him to
look at a problem.  Bcachefs is mostly used by video production companies that need
to deal with multiple 4K streams for editing multi-camera setups, he
said; they have been using it for several years now.  Bcachefs was chosen
because it had better performance than Btrfs for those workloads and, at
the time, was the only filesystem with certain features that were needed.
</p>

<p>
Josef Bacik said that he looked at the to-do list and noted that it was
mostly bcachefs-internal items.  He said that the goal when bcachefs was
discussed at LSFMM in 2018 was to get the interfaces to the rest of Linux
into good shape, since that would be the focus of any mailing-list review.
None of the other filesystem developers know much about the internals of
bcachefs, so they would not be able to review that code directly. He wondered
what was left to do before the upstream process could begin.
</p>

<p>
Overstreet said that the <tt>ioctl()</tt> interface was one of the things
discussed, but it has not changed in a while.  He is more concerned about
ensuring that the on-disk format changes are settling down.  He had been
pushing out those kinds of changes fairly frequently, and the backpointer
support requires another, but after that, he does not see any other changes
of that sort on the horizon.
</p>

<p>
Bacik asked how much more work Overstreet wanted to do internally before he
would be ready to start talking about merging bcachefs and what was holding
it back. Bacik also wanted
to know what Overstreet needed from other filesystem developers as part of
that process.   The biggest thing holding him back, Overstreet said, is
that he wants to be able to respond to all of the bug reports that will
arise when there are lots more users of bcachefs.  So he wants to make
sure that the bigger development projects get taken care of before he gets
to that point.
</p>

<p>
He said that it is far faster for him to fix a bug when he finds it
himself, rather than having to figure out a way to reproduce a problem that
someone else has found.  So he is hoping to get rid of as many bugs as he
can before merging.  That process has been improved greatly by the
debugging support he added to bcachefs over the last few years; over the
last six months, he said, that effort "has been paying off in a big way".
For example, the allocator rewrite went smoothly because of those tools.
</p>

<p>
Much of that revolves around the <a href="/Articles/892611/">printbuf
mechanism</a> that he recently proposed for the kernel.  That work came out
of his interest in getting better logging information for bcachefs.  There
are "pretty printers" for various bcachefs data structures and their output can be
logged.  He is now able to debug using <tt>grep</tt>, rather than a
debugger for many of the kinds of problems he encounters.  He said that he
would be talking more about that
infrastructure in a <a href="/Articles/894546/">memory-management session</a> the next day.
</p>

<h4>Wart sharing</h4>

<p>
Chris Mason said that he had a question along the lines of those from
Bacik, but "a lot more selfish".  Btrfs has a lot of warts in how it
interfaces with the virtual filesystem (VFS) layer, in part because its
inode numbers are effectively huge, but also due to various
<tt>ioctl()</tt> commands  for
features like reflink.  He is looking forward to some other filesystem coming
into Linux that is "sharing my warts"; that may lead to finding better ways
to solve some of those problems, he said.
</p>


<p>
Overstreet said that bcachefs has the same basic problem that Btrfs does
with regard to <a href="/Articles/866582/">inode numbers, subvolumes, and
NFS</a>; he has not spent a lot of time thinking about it but would like to
use the Btrfs solution once one is found.  Mason said that every eight
months or so, someone comes along to say that the problem is stupid and
easy to fix, then the Btrfs developers have to show once again that the
problem is stupid, but hard to fix.
Bacik agreed that a second filesystem with some of the same kinds of
problems will help;  it is
difficult to make certain kinds of changes because there "seems to be an
allergic reaction" to interface 
changes that are only aimed at Btrfs problems.
</p>

<p>
Ted Ts'o had two suggestions for Overstreet; first, before adding a whole lot of
new users, some kind of bcachefs repair facility is probably necessary.
Overstreet said that part was all taken care of.  Ts'o also said that
having an automated test runner that exercised various different bcachefs
configuration options would be useful.  He has a test harness, and Luis
Chamberlain has a different one, either of which would probably serve the
needs of bcachefs.  Bacik noted that there is a slot later in LSFMM to
discuss some of that.
</p>

<p>
Overstreet returned to the subject of debugging tools, as it is "the thing
that excites me the most".  The pretty-printer code is shared by both
kernel and user space, which makes it easier to find problems, he said.
<tt>grep</tt> is his tool of choice for finding problems, even for
difficult things like deadlocks.  He demonstrated some of the kinds of
information he could extract using those facilities.
</p>

<p>
Mason suggested looking into integrating this work into the <a
href="https://github.com/osandov/drgn">drgn kernel debugger</a>, which was
the subject of a <a href="/Articles/789641/">session at
LSFMM 2019</a>.  It is a Python-based, live and post-crash kernel debugger that is used
extensively at Facebook; every investigation of a problem in production
starts by poking around using the tool.  Bacik agreed, noting that
drgn allows writing programs that can step through data structures in running
systems to track down a wide variety of filesystem (and other) problems.
Overstreet said that he would be looking into it.
</p>

<p>
Overstreet pointed to the <a
href="https://bcachefs.org/bcachefs-principles-of-operation.pdf">bcachefs: Principles
of Operation</a> document as a starting point for user documentation.  It
is up to 25 pages at this point, organized by feature, and will be getting
fleshed out further soon.
</p>

<p>
While Overstreet's hesitance to push for merging bcachefs is understandable, Bacik
said, he and others have some selfish reasons for wanting to see that
happen.  He said he did not want to rush things, but did Overstreet have a timeline?
Overstreet said that he would like to see it happen within the next six
months.  Based on the recent bug reports, he thinks that is a realistic goal.
</p>

<p>
Goldstein wondered when the Rust rewrite would be coming.  Overstreet said
that there is already some user-space Rust code in the repository; as soon
as Rust support lands in the kernel, he would like to make use of it.
There are "so many little quality-of-life improvements in Rust", such as
proper iterators rather than "crazy for-loop macros".  Bacik said that
many were waiting for that support in the kernel; Overstreet suggested that those who are
waiting be a bit noisier to make it clear that there is demand for it.
With that, time expired on the session, but it seems we may see bcachefs and
Rust racing to see which can land in the kernel first.
</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Filesystems-bcachefs">Filesystems/bcachefs</a></td></tr>
            <tr><td><a href="/Archives/ConferenceIndex/">Conference</a></td><td><a href="/Archives/ConferenceIndex/#Storage_Filesystem_Memory-Management_and_BPF_Summit-2022">Storage, Filesystem, Memory-Management and BPF Summit/2022</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/895266/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor895601"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 7:38 UTC (Wed)
                               by <b>xanni</b> (subscriber, #361)
                              [<a href="/Articles/895601/">Link</a>] (23 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I&#x27;m very excited by bcachefs and while waiting for it decided to start using bcache.  I&#x27;ve been using it to back a (large, cheap) shingled magnetic recording hard drive with an SSD cache for my Steam games library, to improve performance especially for the larger games (Horizon Zero Dawn is nearly 80GB.)  It&#x27;s been working great so far.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895601/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor895615"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 11:41 UTC (Wed)
                               by <b>Sesse</b> (subscriber, #53779)
                              [<a href="/Articles/895615/">Link</a>] (22 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
As a data point on the opposite side, I&#x27;ve tried using bcache with a 240GB SSD against a 2x3TB disk array to accelerate a seek-heavy video load, and it&#x27;s been completely useless. The SSD is hardly ever used, even though the actual working set should be in the tens of gigabytes at a any time.<br>
<p>
While the article is interesting, I&#x27;m not entirely sure why I should be excited for bcachefs; how does it fare in benchmarks, for one? (I don&#x27;t like to mix up my RAID/LVM and my filesystems in general, so I don&#x27;t care about the ZFS/btrfs-like features.)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895615/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor895616"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 11:59 UTC (Wed)
                               by <b>xanni</b> (subscriber, #361)
                              [<a href="/Articles/895616/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Note that the default settings for bcache are to only cache random reads and writes, and pass sequential reads and writes through without caching.  You may want to adjust those default settings for your use case!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895616/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor895619"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 12:20 UTC (Wed)
                               by <b>Sesse</b> (subscriber, #53779)
                              [<a href="/Articles/895619/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Well, 130 kB random reads all over the file? Should be well below the 4MB default limit.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895619/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor895620"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 12:39 UTC (Wed)
                               by <b>xanni</b> (subscriber, #361)
                              [<a href="/Articles/895620/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
This discussion may help: <a href="https://bbs.archlinux.org/viewtopic.php?id=250525">https://bbs.archlinux.org/viewtopic.php?id=250525</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895620/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor895671"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 15:26 UTC (Wed)
                               by <b>cmurf</b> (subscriber, #112853)
                              [<a href="/Articles/895671/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
There&#x27;s a reason why writethrough is the default. It&#x27;s safe. Write back is only as safe as the reliability of the cache device. If it fails while using write back mode, you lose the entire fs. And that&#x27;s because it&#x27;s likely critical metadata writes only make it to the cache device, not the backing device. I think the reality is, if your workload requires significant random write performance, you need to pay for for big enough SSDs to accommodate the workload, rather than expecting you can get SSD random write performance all the way to the backing device. Where this really bites people, is when they use a single cache device for multiple backing devices, e.g. in a RAID configuration. Lose the cache device while in write back mode, and the entire array is toast.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895671/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor895675"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 15:32 UTC (Wed)
                               by <b>xanni</b> (subscriber, #361)
                              [<a href="/Articles/895675/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If the cache device fails, you can still fsck and mount the underlying device without the cache.  You will only have lost whatever was pending writeback.  Depending on the underlying filesystem, that may or may not be a major issue.  ext4 is pretty robust.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895675/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor895678"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 16:18 UTC (Wed)
                               by <b>developer122</b> (guest, #152928)
                              [<a href="/Articles/895678/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
fsck is nice when it works, but I think everyone has stockholm syndrome from over 45 years of using it.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895678/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899222"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 28, 2022 13:12 UTC (Tue)
                               by <b>kena</b> (subscriber, #2735)
                              [<a href="/Articles/899222/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I&#x27;ll admit, I don&#x27;t come to LWN for humor, but this made me literally laugh out loud.  I mean, &quot;fsck -y /dev/foo&quot; -- what could possibly go wrong?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899222/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor895694"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 19:35 UTC (Wed)
                               by <b>zblaxell</b> (subscriber, #26385)
                              [<a href="/Articles/895694/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
ext4 is quantitatively less robust than ext3 in this scenario because ext4&#x27;s metadata is more efficient, so you lose more metadata per byte of dropped write.<br>
<p>
fsck can only delete stuff until you can mount the filesystem read-write again.  Lose a few of the wrong blocks on ext4, and the big and interesting files that aren&#x27;t already in your backups end up mostly deleted.<br>
<p>
Writeback caches can get pretty big these days.  Losing a few sectors can destroy the most interesting data, but losing a few hundred million sectors and you might as well go directly to mkfs + restore backups because it will take less time than verifying everything by hand, or even using rsync with -c and --del options from your backups.<br>
<p>
It&#x27;s possible to set up multi-device arrays with writeback caches, but you have to be very careful to avoid having faults in the cache impact multiple fault isolation domains in the backing storage.  The simplest form of this is to build multi-drive arrays out of pairs of SSD and HDD, and treat a SSD failure as if the paired HDD failed at the same time.  Another way to do it is to have redundant cache SSDs so that faults in the cache are isolated from the backing storage, but some faults (e.g. undetected SSD corruption) can&#x27;t be easily isolated this way.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895694/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor895618"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 12:06 UTC (Wed)
                               by <b>xanni</b> (subscriber, #361)
                              [<a href="/Articles/895618/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
More specifically, take a look at <a href="https://www.kernel.org/doc/html/latest/admin-guide/bcache.html#troubleshooting-performance">https://www.kernel.org/doc/html/latest/admin-guide/bcache...</a> and consider decreasing /sys/block/bcache0/bcache/sequential_cutoff to see if that helps.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895618/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor896054"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 23, 2022 21:25 UTC (Mon)
                               by <b>bartoc</b> (guest, #124262)
                              [<a href="/Articles/896054/">Link</a>] (12 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Filesystem based RAID is just … better than block based. Even btrfs raid5/6 should be less prone to data corruption than any of the block based solutions, simply because it has the ability to actually tell which possible version of the data is correct. With block based raid (5 esp) if you get some silent data corruption the raid controller/OS will just pick an option essentially at random, so it only helps you if the drive either tells you the read went bad or an entire drive fails. <br>
<p>
Block based RAID can be useful if you have real raid controllers and a big storage array though, as that will reduce bandwidth usage. <br>
<p>
bcachefs’s approach to raid sounds extremely appealing, and its not something block based raid can really do. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896054/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896059"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 23, 2022 22:09 UTC (Mon)
                               by <b>Sesse</b> (subscriber, #53779)
                              [<a href="/Articles/896059/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If you have RAID-6, and a spurious bit flip (which generally needs to happen before it&#x27;s written to disk, as ECC protects you well afterwards), you can tell which disk is bad.<br>
<p>
Also, btrfs&#x27; RAID-[56] has spent 10+ years getting to production quality, and still is at “should not be used in production, only for evaluation or testing” (<a href="https://btrfs.readthedocs.io/en/latest/btrfs-man5.html#raid56-status-and-recommended-practices">https://btrfs.readthedocs.io/en/latest/btrfs-man5.html#ra...</a>, linked from the btrfs wiki at kernel.org), so if nothing else, it&#x27;s amazingly hard to get right.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896059/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896066"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 7:46 UTC (Tue)
                               by <b>atnot</b> (subscriber, #124910)
                              [<a href="/Articles/896066/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Also, btrfs&#x27; RAID-[56] has spent 10+ years getting to production quality, and still is at “should not be used in production, only for evaluation or testing”</font><br>
<p>
I don&#x27;t think this is accurate. My perception is that the RAID56 implementation has been more or less abandoned in it&#x27;s current unfinished state. This is not that surprising to me because in general, OS-level parity RAID is kind of dead, at least amongst the people who could afford to put significant money behind developing it.<br>
<p>
In a modern datacenter you&#x27;re basically just going to have three types of storage: Local scratchpad SSDs, network block devices and blob storage services. The first is usually RAID10 for performance, the second solves redundancy at a lower level and the third solves redundancy at a higher level. This puts RAID56 in an awkward spot where it&#x27;s useful for many home users, still decently well supported, but nobody else is really there to care about it anymore.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896066/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896146"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 18:53 UTC (Tue)
                               by <b>raven667</b> (subscriber, #5198)
                              [<a href="/Articles/896146/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Although at some point, the network storage devices, whether they are sharing out a block or blob service, need to run on something and manage the storage, and who is writing that code?  Even on a hardware raid controller, is the actual raid card itself just an embedded linux system?   It&#x27;s turtles all the way down, do all the vendors of this kind of hardware write their own proprietary in-house raid and filesystems or do some use the built-in linux support and innovate in the higher layer management, by actually using those building blocks to their fullest potential?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896146/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896147"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 19:05 UTC (Tue)
                               by <b>xanni</b> (subscriber, #361)
                              [<a href="/Articles/896147/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Many years ago I worked for an ISP that had a hardware RAID controller fail with a firmware bug that caused it to write bad data to all copies on all redundant storage devices... in both data centres in Adelaide and Sydney.  We had an engineer from the vendor in the US on a flight to Australia the same day, and had to spend several days restoring all our customers&#x27; data from tapes.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896147/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor896148"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 20:05 UTC (Tue)
                               by <b>atnot</b> (subscriber, #124910)
                              [<a href="/Articles/896148/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Although at some point, the network storage devices, whether they are sharing out a block or blob service, need to run on something and manage the storage, and who is writing that code?</font><br>
<p>
Afaict, there&#x27;s two reasons storage folks generally skip the kernel. The first is that the UNIX filesystem API semantics are a poor fit for what they are doing, the second is that the code isn&#x27;t capable of running in a distributed manner.<br>
<p>
So for blob storage it&#x27;s generally going to be almost entirely in user space, with no disk-level redundancy at all. See e.g. Ceph, Minio, Backblaze.<br>
<p>
EMC/netapp/vSAN all have, to my knowledge, their own proprietary disk layouts. VMWare has their own kernel, not sure about the others. The block devices they present are all also redundant across multiple machines, so dm-raid alone wouldn&#x27;t quite cut it there. You can use Ceph for block storage too, but that also skips the kernel.<br>
<p>
So in general, this is why I say I find it hard to see a place for filesystem-level parity RAID in the near future. It basically amounts to a layering violation in today&#x27;s virtualized infrastructure. But who knows, things might change again.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896148/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor896075"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 11:22 UTC (Tue)
                               by <b>Wol</b> (subscriber, #4433)
                              [<a href="/Articles/896075/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Filesystem based RAID is just … better than block based. Even btrfs raid5/6 should be less prone to data corruption than any of the block based solutions, simply because it has the ability to actually tell which possible version of the data is correct. With block based raid (5 esp) if you get some silent data corruption the raid controller/OS will just pick an option essentially at random, so it only helps you if the drive either tells you the read went bad or an entire drive fails.</font><br>
<p>
Which is why I run dm-integrity underneath my raid.<br>
<p>
That is the WHOLE POINT of raid - it&#x27;s primarily to protect against disk failure. Raid 5 contains ONE additional data point, allowing you to recover from ONE unknown, eg &quot;the disk failed, what were the contents?&quot;. It&#x27;s useless if you have TWO unknowns - &quot;oh shit! One of my disks is corrupt - which disk and what were the original contents?&quot; That&#x27;s why you need raid 6 - you have TWO additional data points allowing you to recover from those said two unknowns. The problem, of course, is if your data is corrupt it&#x27;s expensive to check on every access ... <br>
<p>
And which is why I run dm-integrity - that catches the &quot;which disk is corrupt?&quot;, leaving my raid-5 to deal with &quot;and what were the original contents?&quot; I&#x27;ve decided that, on a personal level, the time hit from the integrity check is okay.<br>
<p>
(Oh, and just like ordinary raid, btrfs will be no help whatsoever if your disk is corrupt - it&#x27;ll just tell you you&#x27;ve lost your file - which admittedly is a bit more than md-raid-5, but then btrfs stores that second bit of info, a file checksum. Just a shame that second bit of info doesn&#x27;t let you recover the file ...)<br>
<p>
Cheers,<br>
Wol<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896075/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896082"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 12:49 UTC (Tue)
                               by <b>xanni</b> (subscriber, #361)
                              [<a href="/Articles/896082/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Just a shame that second bit of info doesn&#x27;t let you recover the file ...</font><br>
<p>
But it does.  If you have any level of BTRFS redundancy, you can run &quot;btrfs scrub&quot; to replace any data whose checksum doesn&#x27;t match with one of the other copies where it does match.  I like to run it monthly.  That&#x27;s one of the big advantages of BTRFS.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896082/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896127"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 15:22 UTC (Tue)
                               by <b>Wol</b> (subscriber, #4433)
                              [<a href="/Articles/896127/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
How does that work then? If you&#x27;ve got raid-5, and the checksum reports &quot;this file is corrupt&quot;, how do you recover the original file? If all you&#x27;ve got is raid-5 then it&#x27;s mathematically impossible.<br>
<p>
If you&#x27;ve got raid-1, the checksum identifies which copy is corrupt and therefore which copy is correct. If you&#x27;ve got raid-6, then you can solve the equations to get your data back. But raid-5? Sorry, unless that checksum tells you which disk block is corrupt, you&#x27;re stuffed.<br>
<p>
Cheers,<br>
Wol<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896127/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896133"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 16:02 UTC (Tue)
                               by <b>xanni</b> (subscriber, #361)
                              [<a href="/Articles/896133/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
RAID5 allows you to recover the data with any 2 of the 3 blocks for each block of the file.  RAID6 allows you to use any 2 of the 4 blocks and is designed to address the issue of a second failure during the recovery from a single failure, since recovery from a full drive failure can take quite a while.  If you lose an entire drive with block-level RAID5, you can replace it and recover all data online with zero downtime.  If you regularly scrub any level of btrfs RAID, you can repair corrupted blocks with zero downtime.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896133/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896138"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 16:15 UTC (Tue)
                               by <b>xanni</b> (subscriber, #361)
                              [<a href="/Articles/896138/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I haven&#x27;t looked at the BTRFS implementation to confirm, but I believe it simply keeps a checksum for each file block, so it&#x27;s easy to tell which disk blocks are valid: any combination of two RAID5 or RAID6 blocks that don&#x27;t recover a block with the correct checksum include a corrupted disk block, in which case try one of the other combinations.  If none are valid, you have more corrupt disk blocks than your redundancy level.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896138/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896155"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 20:28 UTC (Tue)
                               by <b>Wol</b> (subscriber, #4433)
                              [<a href="/Articles/896155/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yup, if it keeps a check-sum per DISK block, fine. But if the check-sum is *file*-based, how does it know which *disk* is corrupt?<br>
<p>
Cheers,<br>
Wol<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896155/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896156"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 24, 2022 21:18 UTC (Tue)
                               by <b>zblaxell</b> (subscriber, #26385)
                              [<a href="/Articles/896156/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It doesn&#x27;t.  For RAID1* mirroring btrfs simply reads each copy until the csum matches.  For parity RAID[56], it assumes the blocks that have bad csums are bad, and reconstructs them in the normal parity raid way by reading the other blocks from the stripe and recomputing the bad blocks.  If that doesn&#x27;t provide a block with the right csum, or there are additional csum errors when reading other data blocks, then the block is gone and read returns EIO.<br>
<p>
Strictly speaking, the csum is on the extent, not the file, which only matters when things like snapshots and dedupe make lots of files reference the same physical disk blocks, or compression transforms the data before storing it on disk.  There&#x27;s a single authoritative csum that covers all replicas of that block, whether they are verbatim copies or computed from other blocks.  That csum is itself stored in a tree with csums on the pages.<br>
<p>
There are no csums on the parity blocks, so btrfs&#x27;s on-disk format cannot correctly identify the corrupted disk in RAID[56] if the parity block is corrupted and some of the data blocks in the stripe have no csums (either free space or nodatasum files).  It&#x27;s possible to determine that parity doesn&#x27;t match the data and the populated data blocks are correct, but not whether the corrupted device is the one holding the parity block or one of the devices holding the unpopulated data blocks.<br>
<p>
There&#x27;s some fairly significant missing pieces in the btrfs RAID[56] implementation:   scrub neither detects faults in nor corrects parity blocks, and neither do RMW stripe updates (which are sort of a bug in and of themselves), and half a dozen other bugs that pop up in degraded mode.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896156/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor895612"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">bcachefs and scrub</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 10:10 UTC (Wed)
                               by <b>fratti</b> (guest, #105722)
                              [<a href="/Articles/895612/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
In [1], it&#x27;s described that bcachefs does not yet do scrubbing. Is this document outdated and it&#x27;s already implemented, or is this feature on the horizon? If the latter, will it arrive before mainline inclusion or after? I may be misunderstanding the importance of data scrubbing in the context of long-term data safety though, so if this isn&#x27;t critical in ensuring an array keeps functioning for a decade or more without data loss, feel free to correct me.<br>
<p>
I&#x27;m excited about the possibilities bcachefs opens, but not quite adventurous enough to try and use an out-of-tree filesystem. The idea of just giving the system a bunch of block devices and saying &quot;here&#x27;s how durable I consider them, here&#x27;s how many replicas I want&quot; and having it figure it out on its own seems very appealing, as well as being able to set replication and compression on a per-file granularity.<br>
<p>
[1]: <a href="https://bcachefs.org/bcachefs-principles-of-operation.pdf">https://bcachefs.org/bcachefs-principles-of-operation.pdf</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895612/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor895672"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 18, 2022 15:20 UTC (Wed)
                               by <b>developer122</b> (guest, #152928)
                              [<a href="/Articles/895672/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It sounds like it would be better solve those warts before upstreaming, rather than further cement them.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/895672/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor896533"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">bcachefs needs scrub</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted May 28, 2022 13:39 UTC (Sat)
                               by <b>LinAdmin</b> (guest, #158773)
                              [<a href="/Articles/896533/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It looks like the creator of bcachefs does not care to implement scrubbing. <br>
I got no answer when offering to help testing when this important feature is ready.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/896533/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor951935"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 20, 2023 14:34 UTC (Mon)
                               by <b>donald.buczek</b> (subscriber, #112892)
                              [<a href="/Articles/951935/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      &gt; Overstreet said that bcachefs has the same basic problem that Btrfs does with regard to inode numbers, subvolumes, and NFS
<p>
It not just NFS. I couldn't wait for bcachefs to hit mainline. But now I've realized, that an _unprivileged_ user can do this:

<pre>
buczek@dose:/scratch/local3$ bcachefs subvolume create vol1
buczek@dose:/scratch/local3$ mkdir vol1/dir1
buczek@dose:/scratch/local3$ bcachefs subvolume snapshot vol1/snp1
buczek@dose:/scratch/local3$ ls -li vol1/
total 0
1342189197 drwxrwxr-x 2 buczek buczek 0 Nov 20 15:01 dir1
1476413180 drwxrwxr-x 3 buczek buczek 0 Nov 20 15:01 snp1
buczek@dose:/scratch/local3$ ls -li vol1/snp1/
total 0
1342189197 drwxrwxr-x 2 buczek buczek 0 Nov 20 15:01 dir1
buczek@dose:/scratch/local3$ find .
.
./vol1
find: File system loop detected; ‘./vol1/snp1’ is part of the same file system loop as ‘./vol1’.
./vol1/dir1
buczek@dose:/scratch/local3$ ls -lR
.:
total 0
drwxrwxr-x 3 buczek buczek 0 Nov 20 15:03 vol1

./vol1:
total 0
drwxrwxr-x 2 buczek buczek 0 Nov 20 15:01 dir1
drwxrwxr-x 3 buczek buczek 0 Nov 20 15:01 snp1

./vol1/dir1:
total 0
ls: ./vol1/snp1: not listing already-listed directory
buczek@dose:/scratch/local3$ 
</pre>

Multiple files with the same inode number on the same filesystem would break too many  tools, for example backup.








      
          <div class="CommentReplyButton">
            <form action="/Articles/951935/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor952013"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Bringing bcachefs to the mainline</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 20, 2023 18:15 UTC (Mon)
                               by <b>kreijack</b> (guest, #43513)
                              [<a href="/Articles/952013/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<span class="QuotedText">&gt; &gt; Overstreet said that bcachefs has the same basic problem that Btrfs does with regard to inode numbers, subvolumes, and NFS</span><br>
<p>
<span class="QuotedText">&gt; It not just NFS. I couldn't wait for bcachefs to hit mainline. But now I've realized, that an _unprivileged_ user can do this: </span><br>
<p>
Both BTRFS and BCacheFS (but also a basic LVM/dm snapshot) shared the same problem of having snapshots with (necessarily) file having the same inode number.<br>
<p>
However BTRFS create for each subvolume a different fsid (see statfs(2), f_fsid).<br>
<p>
[code]<br>
ghigo@venice:/var/btrfs/@test-subvol$ btrfs sub cre vol1<br>
Create subvolume './vol1'<br>
ghigo@venice:/var/btrfs/@test-subvol$ mkdir vol1/dir1<br>
ghigo@venice:/var/btrfs/@test-subvol$ btrfs sub snap vol1 vol1/snp1<br>
Create a snapshot of 'vol1' in 'vol1/snp1'<br>
ghigo@venice:/var/btrfs/@test-subvol$ ls -li vol1/<br>
total 0<br>
257 drwxr-xr-x 1 ghigo ghigo 0 2023-11-20 18:59 dir1<br>
256 drwxr-xr-x 1 ghigo ghigo 8 2023-11-20 18:59 snp1<br>
ghigo@venice:/var/btrfs/@test-subvol$ find .<br>
.<br>
./vol1<br>
./vol1/dir1<br>
./vol1/snp1<br>
./vol1/snp1/dir1<br>
<p>
<p>
higo@venice:/var/btrfs/@test-subvol$ stat -f vol1/.<br>
  File: "vol1/."<br>
    ID: 727f02496c886f2e Namelen: 255     Type: btrfs<br>
Block size: 4096       Fundamental block size: 4096<br>
Blocks: Total: 26214400   Free: 4149320    Available: 3830236<br>
Inodes: Total: 0          Free: 0<br>
ghigo@venice:/var/btrfs/@test-subvol$ stat -f vol1/dir1/<br>
  File: "vol1/dir1/"<br>
    ID: 727f02496c886f2e Namelen: 255     Type: btrfs<br>
Block size: 4096       Fundamental block size: 4096<br>
Blocks: Total: 26214400   Free: 4149320    Available: 3830236<br>
Inodes: Total: 0          Free: 0<br>
ghigo@venice:/var/btrfs/@test-subvol$ stat -f vol1/snp1/dir1/<br>
  File: "vol1/snp1/dir1/"<br>
    ID: 727f02496c886f21 Namelen: 255     Type: btrfs<br>
Block size: 4096       Fundamental block size: 4096<br>
Blocks: Total: 26214400   Free: 4149320    Available: 3830236<br>
Inodes: Total: 0          Free: 0<br>
<p>
[/code]<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/952013/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2022, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
