        <!DOCTYPE html>
        <html lang="en">
        <head><title>NFS: the new millennium [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/898262/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/898730/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/898262/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>NFS: the new millennium</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Please consider subscribing to LWN</b>
<p>
Subscriptions are the lifeblood of LWN.net.  If you appreciate this
content and would like to see more of it, your subscription will
help to ensure that LWN continues to thrive.  Please visit
<a href="/Promo/nst-nag1/subscribe">this page</a> to join up and keep LWN on
the net.
</blockquote>
<div class="GAByline">
           <p>June 24, 2022</p>
           <p>This article was contributed by Neil&nbsp;Brown</p>
           </div>
The network filesystem (NFS) protocol has been with us for nearly 40 years.
While defined initially as a stateless protocol, NFS implementations have
always had to manage state, and that need has been increasingly built into
the protocol over successive revisions.  The early days of NFS were
discussed, with a focus on state management, in the <a
href="/Articles/897917/">first part of this series</a>.  This article
completes the job with a look at the evolution of NFS since, approximately,
the beginning of this millennium. 
<p>

<p>The early days of NFS were controlled by Sun Microsystems, the
originator of the NFS protocol and author of both the specification and
implementation.  As the new millennium approached, interest in NFS
increased and independent implementations appeared.  Of particular
relevance here are the implementations in the Linux kernel that drew my
attention — particularly the server implementation — and the Filer
appliance produced and sold by Network Appliance (NetApp).  The community's
interest in NFS extended as far as a desire to have more say in the
further development of the protocol.  I do not know what negotiations
happened, but happen they did, and one clear outcome is documented for us
in <a href="https://www.rfc-editor.org/rfc/rfc2339.html">RFC&nbsp;2339</a>,
wherein Sun Microsystems agreed to assign to The
Internet Society certain rights concerning the development of version&nbsp;4
(and beyond) of NFS, providing this development achieved "Proposed
Standard" status within 24 months, meaning by early 2000.  That
particular deadline went wooshing past and was extended.  We got a
"Proposed Standard" in late 2000 with <a
href="https://www.rfc-editor.org/rfc/rfc3010.html">RFC&nbsp;3010</a>, which was revised
for <a href="https://www.rfc-editor.org/rfc/rfc3530.html">RFC&nbsp;3530</a> in April 2003 and again for <a
href="https://www.rfc-editor.org/rfc/rfc7530.html">RFC 7530</a> in March 2015.</p>

<p>The <a href="https://datatracker.ietf.org/wg/nfsv4/about/">IETF working group</a> tasked with this
development was mostly driven
by Sun and NetApp; it had two co-chairs, one from each company, and
most of the authors listed on the RFC are from these companies.  My
memory of these discussions is that there was quite a long list of
perceived needs but no shared vision of a coherent whole.  The impending
(and changing) deadline drove a desire to get <em>something</em> out, even if it
wasn't perfect.  Consequently NFSv4 — particularly this first attempt
which is now referred to as NFSv4.0 — felt to me like useful pieces
that had been glued together, rather than carefully woven into a fabric;
the elegance that I could see in NFSv2 was gone.</p>

<p>NFSv4 brought all of the various protocols that we saw before into one
single protocol with one single specification.  While the "tools"
approach can be extremely powerful and is great for building prototypes,
there usually comes a time when the strength provided by integration
outweighs the agility provided by discrete components — for NFS,
version&nbsp;4 was that time.  Support for access-control lists (ACLs), quota-tracking, security
negotiation, namespace management, byte-range locking, and status
management were all brought together, often in quite different forms
than in their original separate incarnations.  Of all these many changes,
I want to focus on just two areas that have implications for the
management of shared state.</p>

<h4>The change attribute and delegations for cache consistency</h4>

<p>As we have already seen, timestamps are not ideal for tracking when file
content has changed on the server.  Even if the client knows that timestamps
are reported with some high precision, it cannot know how many write
requests can be processed in that unit of time.  So a timestamp is, at best, a
useful hint.  The designers of NFSv4 wanted something better, so they
introduced the "change" attribute, sometimes called a "changeid".  This
is a 64-bit number that must be increased whenever the object (such as a file
or directory) changes in any way.</p>

<p>This changeid is a mandatory aspect of the protocol so, for several
years, the Linux NFS server was noncompliant since no Linux filesystem
could provide a conforming changeid.  This was fixed in Linux
2.6.31, but only for ext4, with XFS following in v3.11.  For filesystems
that don't provide an <a
href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/linux/iversion.h?h=v5.18"><code>i_version</code></a>,
the Linux NFS server lies and uses
the inode's change time instead, which may not provide the same
guarantees.</p>

<p>The wcc (weak cache consistency) attribute information that NFSv3
introduced is preserved in NFSv4, but only for directories, though it uses the
changeid rather than the change time and, strangely, is not
provided for the SETATTR operation.  Wcc attributes are not
provided for files.  It is still possible to get "before" and "after"
attributes for WRITE requests, as every NFSv4 request is a  <a
href="https://datatracker.ietf.org/doc/html/rfc7530#section-14.1">COMPOUND
procedure</a> 
comprising a sequence of basic operations, and this can contain the
sequence GETATTR, WRITE, GETATTR.  However, these are not guaranteed to
be performed atomically, so some other client could also perform a WRITE
between the two GETATTR calls.  If the difference between the "before"
and "after" changeids is precisely one, it should be safe to assume no
intervening changes, but the protocol specification doesn't make this
explicit.  Instead, NFSv4 provides delegations.</p>

<p>A delegation (or more specifically a "read delegation") is a promise
made by the server to the client that no other client (or local
application on the server) can write to the file.  The server will
proactively recall the delegation before any conflicting open request
will be allowed to complete.  While a client holds a delegation, it can
be sure that all changes made on the server were made by itself, so it
doesn't even need to check the changeid to ensure that its cache
remains accurate.  This provides a strong cache-coherency guarantee.</p>

<p>So, providing that the server offers a read delegation whenever a client
opens a file that no one else is writing to, caching is easy.  Exactly
when the server should do that is not entirely clear; there is a cost
in offering delegations since they need to be recalled when the file is
opened for write access, and this can delay the open request.</p>

<p>Note that the server can also offer a "write delegation" if no other
clients or applications have the file open for either read or write.  It
is not clear to me how useful this really is.  The most obvious
theoretical benefits are that writes do not need to be flushed before a
file is closed, and that byte-range locks do not need to be notified to
the server.  Whether these benefits are practical is less obvious.  The
Linux kernel's NFS server never offers write delegations.</p>

<h4>clientids, stateids, seqids, and client state management</h4>

<p>As mentioned, NFSv4 integrates byte-range locking and thus needs the
server to track the state of all locks held by each client; the server also
needs to know when the client restarts.  The design of this
functionality is all new in NFSv4 (and somewhat improved in NFSv4.1).</p>

<p>The biggest difference in usability is that, rather than a client
reporting that it was rebooted (as the STATMON protocol allows), the
NFSv4 client needs to regularly report that it <i>hasn't</i> rebooted.  If the
server hasn't heard from the client for the "lease time" (typically 90
seconds in Linux) it is permitted to assume the client has disappeared,
and must not prevent another client from performing an access that would
be blocked by the state held by the first client.  So clients that are
not otherwise active need to at least send an "I'm still here" message
(RENEW in NFSv4.0) often enough so that, even with possible network
delays, the server will never go 90 seconds (or whatever is configured)
without seeing something.</p>

<p>This all means that, if a machine crashes without rebooting, locked
files do not remain locked indefinitely.  Conversely, it means that, if a
router failure or cabling problem causes network traffic to be
interrupted for too long (known as a "network partition"), locks
can be lost even while the client is still up and, when the network is
fixed, the client will not be able to proceed.  On Linux, the client
application will receive an <tt>EIO</tt> error for any attempt to access
a file descriptor on which it held a lock that has since been lost.</p>

<p>All of this could have been achieved relatively simply.  For example, each request
could contain a timestamp of when the client booted.  The server would
remember this against the IP address of the client and, if it ever
changed, or if nothing were seen for a period of at least the lease time,
the server could discard any state that the client previously owned.
Correspondingly, each reply from the server could contain a timestamp so
that server reboots could be detected by the client.  However, this would
have been too simplistic.  The designers of NFSv4 had considerable
experience with NFSv3 and with the Network Lock Manager to guide them, and they decided that
there was sufficient justification for some more complexity.</p>

<h4>Clientids and the client identifier</h4>

<p>Depending on a client's IP address is not really a good idea.  Partly,
this is because running multiple clients in user space, or using network address translation (NAT),
can result in several clients having the same IP address, and partly
because mobile devices can change their IP address.  The latter wasn't a
big concern during NFSv4.0 development (though 4.1 handles it better),
but user-space clients and the problems of NAT certainly were.
Different clients could be identified by their port number, but if a
client connecting through a NAT gateway lost its connection and had to
re-establish it, the new connection could use a different port, thus appearing to be a
different client.  So NFSv4 requires each client to generate a
universally unique client identifier (which can be up to 1KB in size), combine
that with an instance identifier (like a boot timestamp), and submit
both to the server via the SETCLIENTID request.  The server responds
with a 64-bit clientid number that can then be used in any request in
which the client needs to identify itself.</p>

<p>This client identifier is the <a href="/Articles/895556/">one recently discussed</a> at
the Linux Storage, Filesystem, and Memory-management Summit (LFSMM).  By
default, Linux uses the host name as the main source of 
uniqueness.  This works well enough on private networks when hosts are
well configured.  Problems arise, though, in containers that do not configure a
unique host name but which do create a new network namespace and, as a
result, get an
independent NFS client instance.  Problems may also arise in situations
where clients in different administrative domains (and hence with
possible host-name overlap) access a shared server.</p>

<h4>stateids and seqid — per-file state</h4>

<p>Another shortcoming with the simple approach is that it collects all of the
state together without clear differentiation in either space or time.</p>

<p>Differentiation in space means that the state of each file can be
managed separately.  In particular, if the server hasn't heard from the
client for the lease time, it must discard any state for which there is
a conflicting request, but it isn't required to discard state which is
uncontested.  So, when the client regains contact, it might have lost
access to some files but not others.  This requires that it be possible
to identify different elements of state so that the server can tell the
client which have been lost and which are still valid.  The Linux NFS
server wasn't able to realize the full benefits of this until
recently, when the <a
href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=6d29d7fe4f0c1e81c39622cce45cd397b23dc48f">"Courteous
Server" functionality</a> was merged.</p>

<p>This finer-grained state management is largely realized by the NFSv4
OPEN request.  The very existence of OPEN is a departure from the
approach of NFSv3 and is only possible because the server can track the
state of the client and, in particular, which files it has open.  An
OPEN request can indicate which of READ or WRITE access is required, or
both, and it can ask the server to DENY READ or WRITE access to all other
clients.  This denial is anathema for POSIX interfaces, but is needed
for interoperability with other APIs.  The Linux server supports such
denial between NFSv4 clients, but doesn't allow local access on the
server, or NFSv3 access, to be blocked; in addition,  existing local
opens do not cause a conflicting NFSv4 OPEN to fail.</p>

<p>The NFSv4 OPEN request also indicates an "open owner", which is formed from an
active clientid combined with an arbitrary label.  The Linux client
generates a different label for each user so, if a single user opens a
file multiple times concurrently, the server will just see the file opened
once.  The OPEN request
returns a "stateid" which represents the open file and should be used in
any READ/WRITE requests.  Each such stateid is distinct and can be
invalidated by the server (in exceptional circumstances) without
affecting any other.</p>

<p>Subsequent OPEN or OPEN_DOWNGRADE requests can change both the access
flags and the DENY flags associated with the file (for the relevant
open-owner).  Each of these yields a new stateid, though it is not
entirely new.  Each stateid has two parts: the "seqid", which increments on
each change, and an "other" part, which doesn't.  This allows the client
to unambiguously determine whether a second OPEN request opened the same file
as the first — as the "other" parts of the stateids will match.  It also
makes it clear in what order various changes were performed on the
server, so the client can be sure it remains synchronized with the
server.  Thus the "seqid" gives a time dimension to the states.
<p>
This can be particularly relevant when a CLOSE request is sent at much
the same time as an OPEN request for the same file.  The client may not
know it is operating on the same file, due to the presence of hard links, so this
cannot be seen as incorrect behavior by the client.  If the server
performs the CLOSE first, the OPEN will then likely succeed and all will
be well. If the server performs the OPEN first it will increment the
seqid of the state for that file and, when it sees the CLOSE, it will
reject it because the seqid is old.  The file will stay open in either
case, which is what the client wanted (since it opened the file twice but
only closed it once).



<p>There are similar stateids, including seqids, for LOCK and UNLOCK
requests, and these have a corresponding "lock owner".  The lock owner
will correspond to a process for POSIX locks, or an open file descriptor
for <a href="https://lwn.net/Articles/586904/">OFD locks</a>.</p>

<h4>NFSv4.1 — a step forward</h4>

<p>The NFSv4 working group went to some trouble to allow for future
versions and to describe the sorts of things that might change.  This
was not in vain and, in January 2010, NFSv4.1 was described in <a
href="https://www.rfc-editor.org/rfc/rfc5661.html">RFC&nbsp;5661</a>
(with an update in <a href="https://www.rfc-editor.org/rfc/rfc8881.html">RFC&nbsp;8881</a> about 10 years
later).</p>

<p>V4.1 contains lots of little improvements based on several years of
experience with what had been nearly an entirely new protocol.  Many people
are suspicious of "dot-zero" releases and, with NFSv4, there is some
justification for this.  NFSv4.0 does work, and works quite well, but 4.1 works
better.  Most of the little things don't rate a mention here, but the
decision to exclude UDP as a supported transport is interesting because
it is user-visible.  UDP has no congestion control, so NFS doesn't work
well over it in general.  Of course, UDP can still be used as long as
some other protocol that manages congestion, like QUIC, is layered in
between.  V4.1 also allows the server to tell the client that it is safe
to unlink files that are still open so the clumsy renaming-on-remove can
be avoided.</p>

<p>Possibly the biggest user-visible change in NFSv4.1 is the addition of
"<a href="http://www.pnfs.org/">pNFS</a>" — parallel NFS.  This appears to be a
marketing term, as it is
easy to say but only loosely captures the important changes.  With
NFSv4.1, it becomes possible to offload I/O requests (READ and WRITE) to
some other protocol, which could well communicate over a different
medium to a different server.  This allows a single NFS client to
communicate with a cluster filesystem without having to channel all the
requests through a single IP address.  This is certainly an extra
level of parallelism, but it is not fair to say that earlier NFS did not
allow any parallelism.  Even NFSv2 could have multiple outstanding
requests that the server could be handling concurrently.</p>

<p>These offload protocols, and how they integrate, are described in
separate RFCs.  There is support for a block-access protocol
(<a href="https://www.rfc-editor.org/rfc/rfc5663.html">RFC&nbsp;5663</a>) or the OSD object storage
protocol (<a href="https://www.rfc-editor.org/rfc/rfc5664.html">RFC 5664</a>), which might
run over iSCSI, for example, or a "flexible file" based approach using
NFSv3 or later (<a
href="https://www.rfc-editor.org/rfc/rfc8435.html">RFC&nbsp;8435</a>) for
the data 
access.  This is only of
particular interest here because there is a new sort of state that needs
to be managed — there are objects called "layouts".</p>

<p>A layout describes how to access part of a file using some other
protocol.  Each layout has a stateid which can be allocated and then
relinquished, so the server always knows which layouts might
still be in use.  This is important if the server needs, for example, to
migrate a file to a different storage location — it probably shouldn't
do that while a client thinks it knows what block location it can use to
access that file.</p>

<h4>Sessions and a reliable DRC</h4>

<p>From our perspective of managing state, the biggest change in NFSv4.1 is
that the protocol finally allows for a completely reliable duplicate
request cache.  As described in part&nbsp;1, this is needed for the rare case when
a request or reply might have been lost and the client has to resend a
request.  In versions up to and including NFSv4.0, the server would just
make a best-effort guess at which requests and replies might be worth
remembering of a while.  In NFSv4.1, it can know.</p>

<p>An NFSv4.1 session is a new element of state that is forked off from
the global clientid by the CREATE_SESSION request.  Given a clientid and
a sequence number, a new sessionid is allocated that has a collection
of different attributes associated with it, including a
maximum number of concurrent requests.  The server will allocate this
many "slots" in its duplicate request cache, and the client will assign
a slot number less than this number to each request.  The client
promises never to reuse a slot number until it has seen a reply to the
previous request with that number, and the server promises to remember
the replies to the most recent request in each slot, if the client asked
it to.</p>

<p>The client can even ask the server to store the cached replies in stable
storage so that they survive a reboot.  If the server implements this
functionality and agrees to provide it, then the result is as close to perfect
exactly-once semantics as it is possible to get.</p>

<p>There is, superficially, an imbalance here.  The requests that are most
common (READ, WRITE, GETATTR, ACCESS, LOOKUP) are idempotent and do not
need to be cached, yet the server must reserve cache space for each
slot, thus either wasting cache space or unnecessarily limiting
concurrency.  This not a problem in practice, since the protocol allows the
client to create multiple sessions with different parameters.  It could
create one with a large slot count and a maximum cached size of zero, and
use this for all idempotent requests.  It could also create a session
with a more modest slot count and much larger maximum cached size, and
use this for requests that mustn't be repeated.</p>

<h4>Directory delegations</h4>

<p>A third new sort of state in NFSv4.1 — accompanying layouts and
sessions — is directory delegations.  In NFSv4.0, it is possible to open
files, but all interactions with directories remained much as they were
in NFSv3, where each operation was discrete and there was no ongoing state.  In v4.1, we
get something a bit like an OPEN of a directory with
GET_DIR_DELEGATION.  This request doesn't contain an explicit
clientid; instead, it uses the clientid associated with the session that
the request is part of.  The delegation is essentially a standing
request that the client be informed of any changes made to the directory
by other clients.  Depending on what specifics are negotiated, this
might involve the server saying "something has changed, you no longer
have the delegation", or it may provide more fine-grained details of
what, specifically, has changed.  This allows for strong file-name cache coherence
and even allows client-side applications to
receive notifications of changes.  This functionality is not implemented
by Linux, either for the server or the client.</p>
<h4>NFSv4.2 - meeting customer needs</h4>

<p>The latest version of NFS is v4.2, described in <a
href="https://www.rfc-editor.org/rfc/rfc7862.html">RFC&nbsp;7862</a> (Nov 2016).
That document describes the goals of this revision being "<q>to take common
local file system features that have not been available
through earlier versions of NFS and to offer them remotely.</q>"

<p>In contrast to NFSv4.1, which primarily provided existing functionality
in a more efficient or reliable manner, v4.2 provides genuinely new
functionality — at least new to NFS.  These include support for the
<tt>SEEK_DATA</tt> and <tt>SEEK_HOLE</tt> <a
href="https://lwn.net/Articles/440255/">functionality</a> of
<a href="https://man7.org/linux/man-pages/man2/lseek.2.html"><tt>lseek()</tt></a>, which
allows sparse
files to be managed efficiently, support of <a
href="https://man7.org/linux/man-pages/man3/posix_fallocate.3.html"><tt>posix_fallocate()</tt></a>
to 
explicitly allocate and deallocate space in a file, support for
<a
href="https://man7.org/linux/man-pages/man2/posix_fadvise.2.html"><tt>posix_fadvise()</tt></a>,
so the client can tell the server what sort of I/O
patterns to optimize for, and support for reflinks, which allow content
to be shared between files without copying.  None of these add any new
state to the protocol, so they aren't directly in our area of focus for
this discussion.</p>

<p>One new element of functionality that does involve a new form of state
is server-side copy.  This functionality can support <a
href="https://man7.org/linux/man-pages/man2/copy_file_range.2.html"><tt>copy_file_range()</tt></a>
and can copy between two files on one server or — if the servers
cooperate — between two files on different servers.  Closely related
functionality (using the WRITE_SAME operation) can initialize a file
using a given pattern repeated as necessary.</p>

<p>When the client sends a COPY request, the server has the option of
either performing the full copy before replying, or scheduling the
operation asynchronously and returning immediately.  In the latter case,
a stateid is returned to the client which represents the ongoing action
on the server.  The client can use this stateid to query status (for the
all-important progress bar) or to cancel the copy.  The server can use
the stateid to notify the client of completion or failure.</p>
<h4>The future for NFS</h4>

<p>As yet, there are no hints of an NFSv4.3 in the foreseeable future, and it
could be that no such version will ever be described.  The v4.2
specification differs from its predecessors in that it is not a complete
specification, but instead references the v4.1 specification and adds
some extensions.  The model for future extension, which is itself extended in
<a href="https://www.rfc-editor.org/rfc/rfc8178.html">RFC&nbsp;8178</a>
(July 2017), allows for further incremental changes to be
added without requiring that the minor version number be changed.  This
has already been put to good use with <a
href="https://www.rfc-editor.org/rfc/rfc8275.html">RFC&nbsp;8275</a> which allows the POSIX
"umask" to be sent to the server during file creation, and
<a href="https://www.rfc-editor.org/rfc/rfc8276.html">RFC&nbsp;8276</a> which adds support for extended
attributes.</p>

<p>There are, of course, still ongoing development efforts around NFS.  One
of the more interesting areas involves describing how the NFS protocol
can be usefully transported on something other than TCP or RDMA, which are the
main two protocols in use today.</p>

<p>
NFS <a
href="https://www.ietf.org/archive/id/draft-cel-nfsv4-rpc-tls-pseudoflavors-02.html">draft-cel-nfsv4-rpc-tls-pseudoflavors-02</a>
looks at using ONC-RPC (the
underlying RPC layer used by NFS) over TLS and, particularly, explores
how the authentication provided by TLS can interact with the
authentication requirements of NFS.
Then,
<a
href="https://www.ietf.org/archive/id/draft-cel-nfsv4-rpc-over-quicv1-00.html">draft-cel-nfsv4-rpc-over-quicv1-00</a>
builds on this to explore how
NFS can be used over the <a href="https://lwn.net/Articles/558826/">QUIC</a> protocol;
The "cel" in the names of the drafts refer to Chuck Lever, the current
maintainer of the Linux NFS server.</p>

<p>Other drafts and all the RFCs can be found on the <a
href="https://datatracker.ietf.org/wg/nfsv4/documents/">web page</a> for the
IETF NFSv4 working group.</p>
<p>
While NFS, much like Linux, does not seem to be finished yet, it does
appear to have come to terms with being a stateful protocol, with all
the state fitting into one coherent model.  This is highlighted by the
way that a totally new form of state — asynchronous copying on the
server — was fit into the model in NFSv4.2 with no fuss.  So it is
likely the future improvements will focus elsewhere, perhaps following
the recent moves toward improved security and support for new
filesystem functionality.  Who knows, maybe one day it will even <a
href="/Articles/866582/">make 
peace with Btrfs</a>.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Filesystems-NFS">Filesystems/NFS</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Brown_Neil">Brown, Neil</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/898262/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor899004"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2022 0:39 UTC (Sat)
                               by <b>gerdesj</b> (subscriber, #5446)
                              [<a href="/Articles/899004/">Link</a>] (12 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Great write up about something that I generally take for granted but by &#x27;eck, NFS has shifted some bytes from A to B for me alone.  It&#x27;s nice to get some real insights into the background of these things from someone who knows what they are on about.<br>
<p>
NFS for me has a killer feature when compared to SMB and I was only made aware of it by Veeam.  This may or may not still be true:  SMB will tell you it has received a lump of data whereas NFS will tell you when it has been committed to storage.  Is this still true?  When you are doing backups to NAS, which involves some pretty monstrous files, this is rather important.  <br>
<p>
Your 5TB backup is pretty useless with a hole in the middle of it due to a transient error that allowed a block or two to wander off and have a smoke behind the bikesheds and then sidling off for a night out in town instead of resting on disc like good data.  OK, a decent backup app will have lots of failsafes available such as reading backups back against the source but ideally data should flow from A to B safely out of the box.<br>
<p>
Given the sheer complexity of file access these days - pick a protocol, pick a medium, wedge in a VPN or two and shake it up and see what happens!  It&#x27;s a wonder that files seem to turn up as requested, in one piece.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899004/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899026"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2022 11:42 UTC (Sat)
                               by <b>willy</b> (subscriber, #9762)
                              [<a href="/Articles/899026/">Link</a>] (10 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; SMB will tell you it has received a lump of data whereas NFS will tell you when it has been committed to storage.</font><br>
<p>
NFS v2 only allowed for the WRITE command to be acknowledged when the data was on stable storage. NFS v3 turned it into a two-phase commit, allowing the server to tell the client both &quot;I have received it&quot; and &quot;It is now stable&quot;.<br>
<p>
Two phase commit isn&#x27;t particularly useful to clients with a competent local cache. The latency of a write is almost irrelevant; you need to know when the write is durable, not just when it&#x27;s visible to others. It was of great interest to non-Unix clients, though.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899026/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899036"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2022 16:14 UTC (Sat)
                               by <b>pbonzini</b> (subscriber, #60935)
                              [<a href="/Articles/899036/">Link</a>] (9 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
The write is only durable after fsync, write is not enough. So even on POSIX systems it&#x27;s useful to know the moment when the write has been received.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899036/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899050"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2022 21:55 UTC (Sat)
                               by <b>willy</b> (subscriber, #9762)
                              [<a href="/Articles/899050/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
On a system with a competent local cache, the kernel returns success to the application after the write is copied to the local cache. NFSv3 offers no improvement here because we weren&#x27;t even calling WRITE in this path. WRITE was called on writeback and on fsync, and the NFSv2 semantics were just fine for this usage.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899050/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899051"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2022 22:29 UTC (Sat)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/899051/">Link</a>] (5 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; the NFSv2 semantics were just fine for this usage.</font><br>
<p>
Not really. The NFSv2 semantics require the server to sync each request individually, though maybe it could merge concurrent requests by delaying the sync for the first.<br>
The NFSv3 semantics make it easy for the server to gather lots of writes in its cache and sync them all together.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899051/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899053"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2022 22:57 UTC (Sat)
                               by <b>willy</b> (subscriber, #9762)
                              [<a href="/Articles/899053/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I suppose by &quot;a competent local cache&quot;, I include the ability for the client to merge writes, which Linux will do.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899053/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899054"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2022 23:10 UTC (Sat)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/899054/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
NFS limits the size of a single write request in that the server specifies a maximum that the client must honour.<br>
Typically 1MB on Linux.  There are costs in making to bigger, so just setting to 1GB wouldn&#x27;t work.  When NFSv3 was first described UDP was still common and 64KB is a hard limit there.<br>
Is there no value in merging multiple 1MB writes on the server?<br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899054/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899079"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 26, 2022 12:15 UTC (Sun)
                               by <b>willy</b> (subscriber, #9762)
                              [<a href="/Articles/899079/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I guess that&#x27;s going to depend on the backend storage device. You hit diminishing returns pretty quickly above 1MB on any storage device I&#x27;ve ever worked on. Even a 5-disc RAID-5 with 256kB stripe width would handle 1MB writes with aplomb.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899079/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899104"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 26, 2022 21:05 UTC (Sun)
                               by <b>janfrode</b> (guest, #244)
                              [<a href="/Articles/899104/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I&#x27;ve seen large throughput improvements by increasing rsize from 1 MB to 16 MB with Oracle dNFS client, towards NFS-Ganesha on top of GPFS (ESS). The ESS does 8+2p erasure coding, with 1 MB strip size, so 16 MB IOs is the optional size. I don&#x27;t think wsize was as important, since it could buffer up and do full block size writes on server side -- but this large rsize was needed to ensure full block (16MB) reads.<br>
<p>
I don&#x27;t think other NFS clients support larger than 1 MB rsize/wsize, which seems unfortunate for this kind of storage backend. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899104/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor899208"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 27, 2022 23:31 UTC (Mon)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/899208/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; You hit diminishing returns pretty quickly above 1MB on any storage device I&#x27;ve ever worked on. </font><br>
<p>
I suspect you are correct.<br>
How about a database update that needs to perform lots of random writes before a sync is needed?  Any single NFS write must be contiguous, so there must be several.  Without the v3 COMMIT, every one of those random writes would need to be committed before the write could return.<br>
<p>
Or what about writing lots of small files.  The NFS client doesn&#x27;t need to COMMIT until the writeback timer fires, or memory reclaim wants the cache back, or a sync() is requested.   Would it not be more efficient to commit when there are lots of dirty files, rather than once for each file?<br>
<p>
But the real point is that EVERY other layer in the storage stack has the two phases: write then sync/flush/commit.  Why are you so sure that NFS doesn&#x27;t benefit from also have the same two phases?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899208/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</details>
<a name="CommAnchor900610"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jul 10, 2022 8:58 UTC (Sun)
                               by <b>ssmith32</b> (subscriber, #72404)
                              [<a href="/Articles/900610/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Wasn&#x27;t fsync caught &quot;lying&quot; a while ago? And disks as well, to inflate performance numbers? <br>
<p>
Or have I not kept up? I guess SSDs can probably hit their numbers &amp; still guarantee data is truly flushed from every volatile cache...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/900610/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor900617"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jul 10, 2022 12:04 UTC (Sun)
                               by <b>Wol</b> (subscriber, #4433)
                              [<a href="/Articles/900617/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I don&#x27;t think fsync was lying. It just assumed disks were telling the truth ...<br>
<p>
Cheers,<br>
Wol<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/900617/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor899193"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 27, 2022 19:03 UTC (Mon)
                               by <b>jra</b> (subscriber, #55261)
                              [<a href="/Articles/899193/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; SMB will tell you it has received a lump of data whereas NFS will tell you when it has been committed to storage. Is this still true?</font><br>
<p>
No. SMB2 write has a flag that tells it not to return success until the write has hit stable storage.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899193/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor899021"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2022 10:12 UTC (Sat)
                               by <b>wtarreau</b> (subscriber, #51152)
                              [<a href="/Articles/899021/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thanks for this detailed explanation and for the numerous links, Neil!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899021/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor899025"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2022 11:36 UTC (Sat)
                               by <b>willy</b> (subscriber, #9762)
                              [<a href="/Articles/899025/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
A protocol which came between NFSv3 and v4 that certainly informed the design of v4 was WebNFS. It also integrated several protocols into one and discarded the use of Portmap.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899025/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor899056"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 25, 2022 23:40 UTC (Sat)
                               by <b>zerolagtime</b> (guest, #102835)
                              [<a href="/Articles/899056/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Thanks for a great look at the internals. <br>
I am very surprised that you skipped over a still-standing limit on the number of gids that will be compared on a complex network. <br>
16 gids is the limit (<a href="https://www.xkyle.com/solving-the-nfs-16-group-limit-problem/">https://www.xkyle.com/solving-the-nfs-16-group-limit-prob...</a>) and deferring permissions to an external server with the sec mount option seems to be the only way. Is this a protocol or implementation limit?<br>
I’d love more discussion on the evolution of various security functionality, like xattrs, encryption algorithm, and the impact felt by stateful firewalls trying to accommodate port ranges. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899056/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899066"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 26, 2022 1:51 UTC (Sun)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/899066/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; I am very surprised that you skipped over  .....</font><br>
<p>
I skipped over a lot of things.  If it didn&#x27;t relate to state management, then I felt free to skip it unless it helped tell the story.<br>
<p>
<font class="QuotedText">&gt; (<a href="https://www.xkyle.com/solving-the-nfs-16-group-limit-prob">https://www.xkyle.com/solving-the-nfs-16-group-limit-prob</a>...)</font><br>
<p>
That link contains a section &quot;The Best Solution Ever!: A New Option for the NFS Server&quot;.  I&#x27;m glad my contribution there was appreciated :-)<br>
<p>
<font class="QuotedText">&gt;  deferring permissions to an external server with the sec mount option seems to be the only way.</font><br>
<p>
Yes.  At least you do need to have the NFS server determine the list of gids.  You don&#x27;t need to use the sec= mount option.  Using the default sec=sys works fine with the Linux NFS server if you use --manage-gids.  The NetApp server has similar functionality.  Others might too.<br>
<p>
<font class="QuotedText">&gt;  Is this a protocol or implementation limit?</font><br>
<p>
It is a limit in the RPC protocol<br>
<p>
<font class="QuotedText">&gt; I’d love more discussion on the evolution of various security functionality</font><br>
<p>
Not really my area of expertise, sorry.<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899066/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor904307"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 10, 2022 0:05 UTC (Wed)
                               by <b>seamus</b> (guest, #159731)
                              [<a href="/Articles/904307/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Broken/incomplete(?) link<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/904307/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor904511"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Aug 12, 2022 2:44 UTC (Fri)
                               by <b>mathstuf</b> (subscriber, #69389)
                              [<a href="/Articles/904511/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
See the GP for the full thing; LWN will elide links and the link quoted is indeed the LWN truncation.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/904511/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor899111"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 27, 2022 3:55 UTC (Mon)
                               by <b>lathiat</b> (subscriber, #18567)
                              [<a href="/Articles/899111/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Neil, seems you forgot about the dangerous fragmentation alluded to in the last installment!<br>
<p>
Great review though, loved it, thanks! Long time NFS user from web hosting environments since circa 2006. <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899111/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899207"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 27, 2022 23:24 UTC (Mon)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/899207/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Neil, seems you forgot about the dangerous fragmentation alluded to in the last installment!</font><br>
<p>
I didn&#x27;t forget - but there wasn&#x27;t really anything to say.  The fact that fragmentation (of the community, or of the protocol) might happen when separate people have separate needs should be obvious.  A possible example of this is JMAP which risks fragmenting the IMAP community.  Beyond the fact that I didn&#x27;t like JMAP when I reviewed it 6 years ago, I don&#x27;t know any details of this or whether it is a real fragmentation.<br>
<p>
But NFS didn&#x27;t fragment (to my knowledge).  The community had regular Connectathon gatherings to ensure interoperability and to discuss issues.  And importantly the IETF process was started that allowed anyone to contribute to NFSv4.  So the IETF process, which I did mention, likely headed off any possible risk of protocol fragmentation.<br>
 <br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899207/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899217"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 28, 2022 8:47 UTC (Tue)
                               by <b>Sesse</b> (subscriber, #53779)
                              [<a href="/Articles/899217/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I assumed you were talking about UDP fragmentation!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899217/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899313"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 28, 2022 23:12 UTC (Tue)
                               by <b>neilbrown</b> (subscriber, #359)
                              [<a href="/Articles/899313/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; I assumed you were talking about UDP fragmentation!</font><br>
<p>
You aren&#x27;t the only one (I think).  See <a href="https://lwn.net/Articles/898842/">https://lwn.net/Articles/898842/</a><br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899313/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor899421"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">NFS: the new millennium</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 30, 2022 4:13 UTC (Thu)
                               by <b>lathiat</b> (subscriber, #18567)
                              [<a href="/Articles/899421/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Yep that&#x27;s what I though too. It was quite a famous issue where it would re-assemble fragments incorrectly but then pass the checksum and corrupt the UDP data inflight. Partly to do with the NFS/RPC packet size versus MTU.<br>
<p>
All good.. just a misunderstanding :D I just happened to discuss the issue with a colleague the day the first post came out :)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/899421/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2022, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
