        <!DOCTYPE html>
        <html lang="en">
        <head><title>Adaptive mutexes in user space [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/704843/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/704817/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/704843/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Adaptive mutexes in user space</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>We're bad at marketing</b>
<p>
We can admit it, marketing is not our strong suit. Our strength is
writing the kind of articles that developers, administrators, and
free-software supporters depend on to know what is going on in the
Linux world. Please <a href="/Promo/nsn-bad/subscribe">subscribe today</a> to help us keep doing that, and so
we don’t have to get good at marketing.
</blockquote>
<div class="GAByline">
           <p>November 2, 2016</p>
           <p>This article was contributed by Neil&nbsp;Brown</p>
           </div>
<p>One of the frustrations of computer programming (almost certainly shared
with other engineering disciplines) is that, often, a simple, elegant, and
general design doesn't work as well as an ugly hack.  Such designs still
have value as they are more maintainable and more extensible, so it is not
uncommon to need to find a balance between simple elegance and practical
efficiency.  The <a href="https://lwn.net/Kernel/Index/#Futex">story of
futex support</a> in Linux could be seen as a story of trying to find just
this balance.  The latest episode adds a new special case, but provides
impressive performance improvements.</p>

<p>
<h4>Some futex history</h4>

<p>The original design of futexes — a kernel interface to support Fast
User-space muTEXes — introduced a four-byte memory location that would always
be updated atomically.  A key aspect of the design was that the kernel needed
only the simplest understanding of a futex's contents; a comparison with a value
provided by user space was all that was ever needed.  All updates were
handled by user-space code and, if a program ever found that it needed to
wait for the value to change, such as to wait for a lock to be released, it
would use the <tt>futex()</tt> system call to ask the kernel to wait
for that change.  When some other thread changed the value, it
would tell the kernel to wake up some number of sleeping processes, and
they could examine the new value and act accordingly.</p>

<p>This design is simple and elegant, but imperfect.  The kernel has
minimal knowledge of what user space is doing, and user space has little
access to relevant information that the kernel maintains, so they are
limited in the extent to which they can work together.  This disconnect has
required a 
number of extensions over the years, three that are in the mainline now,
and one that is on the horizon.</p>

<p>The <a
href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=4732efbeb997189d9f9b04708dc26bf8613ed721">first
extension</a> was needed to optimize the implementation of <a
href="http://man7.org/linux/man-pages/man3/pthread_cond_broadcast.3p.html"><tt>pthread_cond_signal()</tt></a>,

which sometimes needs to send a wakeup on one
   futex (a condition variable), unlock a mutex (represented by another
   futex), then possibly send a wakeup on that second futex.  At the same time,
   another thread might be waiting on the first futex and will
   immediately try to lock the mutex, which could require waiting on the
   second futex.  Having this second thread wake up and go straight back
   to sleep leads to measurably poor performance.  Neither <a
href="http://man7.org/linux/man-pages/man2/futex.2.html">the
   documentation</a> nor the changelogs make it clear why the wakeups
   cannot both be performed after the mutex is unlocked, but they do
   assert that this is racy and so a new futex operation was created.
<p>
   <tt>FUTEX_WAKE_OP</tt> is given two futexes and instructions on how to unlock
   the second.  It will perform that unlocking, wake up waiters on the
   first futex, then conditionally wake up waiters on the second as
   well.  It does all this atomically with respect to any other
   operations on either futex.   This
was the first time that the kernel needed to modify the value of the futex
itself; 
Jakub Jelinek came up with a fairly generic mechanism to describe the
unlock operation.  Five different operations are provided to combine an
operand with the current value of the futex, and then one of six different
comparisons can be performed against a second operand to decide if the
second wakeup should happen.  This seems fairly powerful and suitably
general, but was probably wasted effort.  Only a single operation (set to
zero) is ever used by glibc, and only a single comparison (greater than
one).    It is unlikely that the other
options will ever be used, in part because of the subsequent extensions
that impose structure on the value.</p>

<p>It is possible for a thread to be killed before it makes an expected change to a
futex that other threads are waiting for.  Only the user-space code
knows which thread &quot;owns&quot; the lock (or even what sort of locking
is being used) and only the kernel knows when a process dies unexpectedly.
To allow those waiting threads to discover that something is wrong, some
extra communication was needed.  This gave rise to <a
href="https://lwn.net/Articles/172149/">&quot;robust futexes&quot;</a> that
allow a thread to register a linked list of futexes whose waiting threads
need to be woken 
up if the thread ever dies.</p>

<p>The use of robust futexes significantly reduced the flexibility of
futexes.  The four-byte memory location now has a fully defined meaning:
30&nbsp;bits provide the thread ID of the owner of the futex, one bit
records if 
any other threads are waiting on the futex, and one bit indicates if the
previous owner died.  This means that robust futexes cannot be used to
create counting semaphores, or reader/writer locks.  They can only be used
for binary mutual-exclusion locks.  It also means that most of the
operations provided for <tt>FUTEX_WAKE_OP</tt> are of no value for
robust futexes.</p>

<p>The more flexible, non-robust futexes could still be used as private
futexes between threads in a single process and never shared between
processes. In that context, an unexpected failure will kill the whole
process rather than a single thread, so no recovery handling is needed.

<p>The <a
href="https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=e2970f2fb6950183a34e8545faa093eb49d186e1">third
extension</a> of interest was to support <a
href="/Articles/178253/">priority inheritance</a>.  If it is
possible for threads of different priorities to claim a lock then, when a
low-priority process holds the lock and a high-priority process is waiting
for it, any medium priority process that prevents the low-priority process
from running will indirectly interfere with the high-priority process,
which is not desirable.  This &quot;priority inversion&quot; is usually
addressed using priority inheritance, which causes the low-priority
process to run with the priority of the highest-priority process that
is waiting for it. Linux has priority-inheritance mutex locks internally,
so the priority-inheritance (PI) extension to futexes allocates
one of those whenever a PI futex is contended, and uses it to manage
priority.</p>

<p>This extension was the first to introduce the verbs &quot;lock&quot; and
&quot;unlock&quot; (and &quot;trylock&quot;) into the futex interface.
Previously the interfaces only talked about &quot;waking&quot; and
&quot;waiting&quot; with the implication that a variety of different
services could be built on that.  For priority-inheritance locks, at least,
that pretense in now gone.  It really is just a lock.</p>

<h4>What's next for futexes</h4>

<p>In the kernel, one of the improvements that has been made to mutexes in
recent years is to add adaptive spinning.  The theory is that sometimes a
mutex is only held for a short period of time and, in those cases, it is more
efficient to busy-wait for the lock to be free than to go to sleep and then
be woken up.  If the busy-wait doesn't look like it will be successful,
only then is the thread put to sleep.  Making a choice between spinning and
sleeping is the adaption included in the name.</p>

<p>It should be no surprise that this optimization should be useful for
user-space locking using futexes. Waiman Long <a
href="http://www.mail-archive.com/search?l=mid&amp;q=1475270782-51720-8-git-send-email-Waiman.Long%40hpe.com">has
found</a> that, for a particular micro-benchmark, standard (wait/wake)
futexes can achieve a mere 35&nbsp;million operations in ten seconds, while
adaptive spinning can increase that to over 54&nbsp;million.  This
technique had been <a href="https://lwn.net/Articles/386536/">tried
before</a> by Darren Hart, though his reported results weren't quite so
impressive, probably because modern processors have many more cores and
high core counts can tip the balance towards spinning over sleeping.  While
micro-benchmark results should be treated with caution, a 50% improvement
deserves some attention.</p>

<p>The user-space code could, of course, simply spin for, say, 20
microseconds before giving up and asking the kernel to put it to sleep.
While simple, this approach is far from ideal.  If the process holding the
lock is sleeping, busy-waiting for it is a waste of power and could
possible increase the total wait time.  It only makes sense to busy-wait if
the process owning the lock is itself busy.</p> <p>Here again, the
separation between user space and kernel space is a problem.  Only the
kernel knows which processes are busy or sleeping.  Either we need to tell
user space when the owner of a futex is sleeping, or tell the kernel that
it should spin for a while before taking the lock.  Both of these are
probably possible, but moving the whole locking operation into the kernel
is probably easiest, matches the approach that PI futexes use, and is the
approach that Long is exploring.</p>

<h4>The patchset</h4>

<p>Long's <a
href="http://www.mail-archive.com/search?l=mid&amp;q=1475270782-51720-1-git-send-email-Waiman.Long%40hpe.com">latest
patchset</a> adds the <tt>FUTEX_LOCK</tt> and <tt>FUTEX_UNLOCK</tt>
operations to the <tt>futex()</tt> system call; they work in a
similar fashion to <tt>FUTEX_LOCK_PI</tt> and
<tt>FUTEX_UNLOCK_PI</tt>, but without the priority inheritance.  They
use a regular mutex to help implement the locking, but in a slightly
different way than the PI extension's use of an <tt>rt_mutex</tt>.</p>

<p>The first time the <tt>futex()</tt> system call is made, there are 
two processes 
interested in the lock.  One already holds the lock, while the other wants to
acquire it.  The PI extension initializes a new <tt>rt_mutex</tt> in
a locked state and makes it appear that the thread that owns the futex also
owns this <tt>rt_mutex</tt>.  There is substantial complexity in making
this work in a race-free way, but in essence, that is what happens.  The
second process then waits for the mutex in a fairly normal way.</p>

<p>The new adaptive spinning extension (called &quot;throughput
optimized&quot;, which describes the goal rather than the implementation)
uses a mutex only to arbitrate between the different threads that might be
waiting, not to arbitrate between them and the thread that owns the lock.
Whichever thread manages to claim this mutex is the &quot;top waiter&quot;
and gets to decide
whether to busy-wait for the current owner to release the lock, or to go to
sleep to be woken by the usual futex wakeup mechanism.</p>

<p>Long <a
href="http://www.mail-archive.com/search?l=mid&amp;q=57E43EF9.8000400%40hpe.com">did
originally try</a> to follow the same model as PI mutexes but found that the
performance wasn't close to what he wanted, as too many unlock requests still
went through the kernel.  Futexes only need the kernel to be involved when
there is contention; the kernel only gets involved when there is one
lock owner and at least one lock waiter.  Additionally, if there is only one
waiter, when the owner releases the lock and that waiter becomes the
owner, the kernel no longer needs to be involved.  When that new owner
drops the lock it should be able to complete without involving the kernel.
With PI mutexes, the <tt>rt_mutex</tt> stays allocated until completely
unlocked (i.e. until there are no more owners).  This means that last unlock
goes through the kernel.  Long claims that this extra kernel involvement reduces
throughput significantly.</p>

<p>Another benefit from maintaining control of the busy-waiting separately
from the kernel mutex is that the benefits of lock stealing can be
realized; this sacrifices some fairness for performance.  There is a small
window between the moment when the owning thread unlocks a futex and when
the top waiter locks that futex.  If another thread tries to claim the lock
during that window it can successfully steal the lock.  This is seen as a
good thing, presumably because that new thread has its working set of memory
in cache and will likely make progress quickly.  Long's patches explicitly
allow this stealing, but also put a limit on it.  If the top waiter is
woken up after sleeping and fails to get the lock, it sets a flag asking
that the next time some thread unlocks the lock, that they perform a
handoff instead and explicitly give the lock to that top waiter, thus
avoiding further theft.  Long <a
href="http://www.mail-archive.com/search?l=mid&amp;q=1475270782-51720-10-git-send-email-Waiman.Long%40hpe.com">provides
numbers</a> that seem to suggest that this improves throughput (the main
goal) and also improves fairness.</p>

<h4>Responses</h4>

<p>The reception to the patch set so far has been cautious.  The results
appear encouraging, but there are some questions, including whether the
code might be driven too much by that one benchmark. Two comments that
reveal Thomas Gleixner's concerns are <a
href="https://www.mail-archive.com/linux-doc@vger.kernel.org/msg06484.html">first</a>:</p>

<div class="BigQuote">
I'm not really happy about these heuristics. The chosen value fits a
particular machine and scenario. Now try to do the same on some slow ARM
SoC and the 1024 loops are going to hurt badly.
</div>

<p>and <a
href="http://www.mail-archive.com/search?l=mid&amp;q=alpine.DEB.2.20.1609231455110.5640%40nanos">later</a>:</p>

<div class="BigQuote">
So the benefit of these new fangled futexes is only there for extreme short
critical sections and a gazillion of threads fighting for the same futex,
right?
<p>I really wonder how the average programmer should pick the right flavour,
not to talk about any useful decision for something like glibc to pick the
proper one.</p>
</div>

<p>Given that adaptive spinning has made its way into the in-kernel
mutexes, it would be surprising if a way cannot be found to make them work
well for user space too.  Of course, it would also be surprising if the first
attempt at providing such a feature would have found the right balance between
the various competing needs.  We don't have efficient adaptive spinning for
futexes yet, but if it really brings value, it shouldn't be too far
away.</p><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Futex">Futex</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#Brown_Neil">Brown, Neil</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/704843/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor705668"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Adaptive mutexes in user space</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 4, 2016 15:29 UTC (Fri)
                               by <b>mm7323</b> (subscriber, #87386)
                              [<a href="/Articles/705668/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; often, a simple, elegant, and general design doesn't work as well as an ugly hack</font><br>
<p>
If we were still using green-threads in userspace, making the locks efficient wouldn't be such a problem as you could essentially control thread pre-emption and scheduling.  <br>
<p>
Having pulled threading into the kernel (and do I think that is the right choice), it would seem to me that the synchronisation primitives should follow whole-heartedly.  By that I'm thinking that the creation of locks (pthread_mutex_init + pthread_cond_init) as well as all the access and manipulations functions should end up in the vDSO and be fully controlled by kernel devs and enhanced as and when needed (and for each architecture), selectively making system calls when needed.  That could also remove the legacy problem by pushing the kernel API right out something like the pthread API calls.<br>
<p>
Now, should the kernel really be getting into all this level of userspace nitty gritty?   It seems that decision was already made when threads were pulled in and the futex calls added.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/705668/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2016, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
