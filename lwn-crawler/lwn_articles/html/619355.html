        <!DOCTYPE html>
        <html lang="en">
        <head><title>Recent read-mostly research [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/619355/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/619333/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/619355/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Recent read-mostly research</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>This article brought to you by LWN subscribers</b>
<p>
Subscribers to LWN.net made this article &mdash; and everything that
       surrounds it &mdash; possible.  If you appreciate our content, please
       <a href="/Promo/nst-nag3/subscribe">buy a subscription</a> and make the next
       set of articles possible.
</blockquote>
<div class="GAByline">
           <p>November 11, 2014</p>
           <p>This article was contributed by Paul McKenney</p>
           </div>
<p>One of my more unusual hobbies is occasionally reviewing academic papers.
It should come as no surprise that I pay special attention
to papers related to
<a href="/Kernel/Index/#Read-copy-update">read-copy update (RCU)</a>, which is
a category that I am happy to see has been growing significantly
over the past few years.
This article gives a quick summary of some recent papers in this category.

<p>But first, what is RCU?
It is a synchronization mechanism that was added to
the Linux kernel in October&nbsp;2002.
RCU is most frequently described as a replacement for reader-writer locking,
but has also been used in a number of other ways.
It is notable in that RCU readers do not directly synchronize with
 updaters,
which makes RCU read paths extremely fast. It also
permits readers to accomplish useful work even
when running concurrently with updaters&mdash;and vice versa.

<p>Although the earliest known work on mechanisms resembling
RCU was carried
out by academics (see for example Kung and Lehman's landmark 1980
<a href="http://dl.acm.org/citation.cfm?id=320619">paper</a>), 
by the early 1990s, with a few notable exceptions (<a
href="http://www.usenix.org/events/osdi99/full_papers/gamsa/gamsa.pdf">Ben
Gamsa, University of Toronto, et al. [PDF]</a>, 
<a
href="http://www.nada.kth.se/~snilsson/publications/TRASH/trash.pdf">Robert
Olsson, Uppsala University, et al. [PDF]</a>,
<a href="http://www.rdrop.com/users/paulmck/RCU/hart_ipdps06.pdf">Thomas
E. Hart, University of Toronto, et al. [PDF]</a>, and
<a
href="http://www.cs.bu.edu/~jappavoo/Resources/Papers/a6-appavoo.pdf">Jonathan
Appavoo, IBM T.J. Watson Research Center, et al. [PDF]</a>),
much of the work in this area was carried out by practitioners.
By the early 2000s, the initiative had passed to open-source projects,
most notably to the Linux kernel community.

<div class="tlr"><a name="Quick Quiz 1"><b>Quick Quiz 1</b>:</a>
But what can I do if I work with production-quality code but
nevertheless would like to discover something new?
<br><a href="#qq1answer">Answer</a>
</div>

<p>However, there are welcome signs that some in academia are
showing interest in RCU; see, for example, Michael L.&nbsp;Scott's
<a href="http://www.morganclaypool.com/doi/abs/10.2200/S00499ED1V01Y201304CAC023">textbook</a>
that includes a chapter on RCU.
One reason that this interest is welcome is that academics, unlike large
open-source projects, are unconstrained by the need to develop
production-quality code.
This allows them to try crazier and more experimental ideas.

<p>
Although many of these ideas might seem to have no value outside of
academia, the fact is that many of the best yet-undiscovered ideas are
protected by wide moats of insanity&mdash;with RCU itself being a case
in point.
Therefore, if you are unwilling to deal with insanity, the odds on
your discovering something new decrease, and, of course, those of us who
deal with production-quality code must be quite careful with any insanity
we encounter.
Furthermore, even an otherwise useless idea might inspire a developer
to come up with something that is both valuable and useful, or failing
that, to avoid a pitfall.
Although there are no guarantees, the hope is that increased academic
work in the area of read-mostly concurrency will result in new breakthroughs.

<h4>Validation</h4>

<p>Validation is one important area in which breakthroughs would be
quite welcome.
Peter Sewell's and Susmit Sarkar's groups at the University of Cambridge
have done some
<a href="http://www.cl.cam.ac.uk/~pes20/weakmemory/">important work</a>
in validating memory barriers and atomic instructions, as was <a href="/Articles/470681/">reported
earlier</a>.
This work has been extended with greatly increased performance by
some of Sewell's and Sarkar's collaborators at University College London
(Jade Alglave),
INRIA (Luc Maranget), and Queen Mary University of London (Michael Tautschnig),
most notably in
<a href="http://www0.cs.ucl.ac.uk/staff/j.alglave/papers/toplas14.pdf">this
paper [PDF]</a>, which was described in
this
<a href="/Articles/608550/">LWN article</a>.
Researchers at Stony Brook University have produced an RCU-aware data-race
detector, described by
<a
href="http://www.filesystems.org/docs/abhinav-thesis/abhinav_thesis.pdf">Abhinav Duggal [PDF]</a>
and
<a
href="http://www.fsl.cs.sunysb.edu/docs/jseyster-dissertation/redflag.pdf">Justin
Seyster [PDF]</a>.
Alexey Gotsman of IMDEA, Noam Rinetzky of Tel Aviv University, and
Hongseok Yang of the University of Oxford have published
<a
href="http://software.imdea.org/~gotsman/papers/recycling-esop13-ext.pdf">a
paper [PDF]</a>
expressing the formal semantics of RCU in terms of separation logic,
and have continued with
<a href="http://www.advent-project.eu">other aspects of concurrency</a>.
With some luck, all of this validation work will eventually result in
more and better tools for validating concurrent code.

<h4>Using RCU</h4>

<p>Phil Howard and Jon Walpole of Portland State University (PSU) have
applied RCU to 
<a
href="http://www.usenix.org/event/hotpar11/tech/final_files/Howard.pdf">red-black
trees [PDF]</a>
combined with updates synchronized using software transactional memory.
Josh Triplett and Jon Walpole (again of PSU) applied RCU to
<a
href="http://www.usenix.org/event/atc11/tech/final_files/Triplett.pdf">resizable
hash tables [PDF]</a>,
reported on in two parts:
<a href="/Articles/612021/">Part 1</a> and
<a href="/Articles/612100/">Part 2</a>.
(Other RCU-protected resizable hash tables have been <a href="http://thread.gmane.org/gmane.linux.network/153338">created by
Herbert Xu</a>
and <a href="/Articles/573431/">by Mathieu Desnoyers</a>.)

<div class="tlr"><a name="Quick Quiz 2"><b>Quick Quiz 2</b>:</a>
Why don't more academic research projects make full use of open-source
projects such as the Linux kernel?
<br><a href="#qq2answer">Answer</a>
</div>

<p>Austin Clements, Frans Kaashoek, and Nickolai Zeldovich of MIT created an
<a
href="http://people.csail.mit.edu/nickolai/papers/clements-bonsai.pdf">RCU-optimized
balanced binary tree (Bonsai) [PDF]</a>,
and applied this tree to the Linux kernel's VM subsystem
(<a href="http://pdos.csail.mit.edu/mosbench">Git trees</a>)
in order to reduce read-side contention on <tt>mmap_sem</tt>.
This work resulted in order-of-magnitude speedups and scalability
	up to at least 80 CPUs for a microbenchmark featuring large
	numbers of minor page faults.
This is similar to a
<a href="https://lkml.org/lkml/2010/1/4/257">patch</a>
developed earlier by Peter Zijlstra, and both were limited by
the fact that, at the time,
<a href="https://lkml.org/lkml/2010/1/4/532">filesystem data structures
were not safe for RCU readers</a>.
Clements et al.&nbsp;avoided this limitation by optimizing the page-fault
path for anonymous pages only.
More recently, filesystem data structures have been made
safe for RCU readers (covered in a
<a href="/Articles/419811/">2010 article</a> and
<a href="/Articles/452117/">another from 2011</a>),
so perhaps this work can be implemented for all page types, not
just anonymous pages&mdash;Peter Zijlstra has, in fact, recently prototyped
<a href="https://lkml.org/lkml/2014/10/20/620">exactly this</a>.
In any case,
this use of the Linux kernel itself as a testbed for cutting-edge
academic research is a welcome development.

<p>Yandong Mao and Robert Morris of MIT and Eddie Kohler of Harvard University
created another RCU-protected tree named
<a
href="http://www.read.seas.harvard.edu/~kohler/pubs/mao12cache.pdf">Masstree
[PDF]</a>
that combines ideas from
<a href="http://en.wikipedia.org/wiki/B%2B_tree">B+ trees</a>
and
<a href="http://en.wikipedia.org/wiki/Trie">tries</a>.
Although this tree is about 2.5x slower than an RCU-protected hash table,
it supports operations on key ranges, unlike hash tables.
In addition, Masstree supports efficient storage of objects with long
shared key prefixes and, furthermore, provides persistence via logging
to mass storage.

<p>
The paper notes that Masstree's performance rivals that of memcached,
even given that Masstree is persistently storing updates and memcached is not.
The paper also compares Masstree's performance to the persistent datastores
MongoDB, VoltDB, and Redis, reporting significant performance advantages
for Masstree, in some cases exceeding two orders of magnitude.
Another
<a
href="http://www.read.seas.harvard.edu/~kohler/pubs/tu13speedy.pdf">paper [PDF]</a>,
by Stephen Tu, Wenting Zheng, Barbara Liskov, and Samuel Madden of
MIT and Kohler, applies Masstree to an in-memory database
named Silo, achieving 700K transactions per second (42M transactions
per minute) on a well-known transaction-processing benchmark.
Interestingly enough, Silo guarantees <a href="http://en.wikipedia.org/wiki/Linearizability">linearizability</a> without
incurring the overhead of grace periods while holding locks.

<p>For my part, I have been doing some work enabling complex atomic
updates to RCU-protected data structures with minimal copying, which
I recently
<a
href="http://www2.rdrop.com/users/paulmck/RCU/C++Updates.2014.09.11a.pdf">presented
[PDF]</a>
at the
<a href="http://cppcon.org/">C++ Conference</a> (CppCon).
(Next step: Deal with bottlenecks in user-mode memory allocators.)

<h4>Using and implementing RCU</h4>

Maya Arbel and Hagit Attiya of Technion took
<a href="http://www.cs.technion.ac.il/~mayaarl/podc047f.pdf">a more
rigorous approach [PDF]</a>
to an RCU-protected
search tree that, like Masstree, allows concurrent updates.
This paper includes a proof of correctness, including proof that
all operations on this tree are
linearizable.
Unfortunately, this implementation achieves linearizability by incurring
the full latency of grace-period waits while holding locks, which degrades
scalability of update-only workloads.
One way around this problem is to abandon linearizability
(as advocated
<a
href="http://soft.vub.ac.be/races/wp-content/uploads/2012/09/p1-haas.pdf">here
[PDF]</a>
and
<a
href="http://www.rdrop.com/users/paulmck/scalability/paper/AtomicTreeMove.2014.05.26a.pdf">here
[PDF]</a>),
however, Arbel and Attiya instead created an RCU variant that reduces
low-end grace-period latency.
Of course, nothing comes for free, and this RCU variant appears to hit
a scalability limit at about 32 CPUs.
Although I personally favor dropping linearizability, thus gaining
<i>both</i> performance and scalability, it is very good to
see academics experimenting with alternative RCU implementations.
Researchers at Charles University in Prague have also been working on RCU
implementations, including dissertations by
<a href="https://andrej.podzimek.org/thesis.pdf">Andrej Podzimek [PDF]</a>
and
<a href="http://www.helenos.org/doc/theses/ah-thesis.pdf">Adam Hraska [PDF]</a>.

<p>RCU-like mechanisms are also finding their way into Java.
<a href="http://doi.acm.org/10.1145/2258996.2259005">Sivaramakrishnan et al.</a>
use an RCU-like mechanism to eliminate the read barriers that are
otherwise required when interacting with Java's garbage collector,
resulting in significant performance improvements.

<h4>A specialized RCU implementation and its use</h4>

<p>The final piece of academic work that is described in this article was
carried out at the Shanghai Jiao Tong University by Ran Liu,
Heng Zhang, and Haibo Chen, who created a specialized variant of
RCU that they used for an optimized reader-writer lock.
This is important because traditional reader-writer lock
implementations, such as the Linux kernel's <tt>rwlock_t</tt>,
do not scale well.
The reason for this is that all readers must atomically update
the single memory location that represents the <tt>rwlock_t</tt>,
both with entering and when leaving their read-side critical sections.
The cache line containing this memory location will shuttle among
all of these CPUs.
Each access to this memory location will therefore result in a cache miss,
which will in turn result in the accessing CPU stalling for hundreds
or even thousands of clock cycles.

<p>
The more CPUs attempting to acquire or release the lock, the longer
the stalls.
Unless the read-side critical sections are extremely long
(hundreds of thousands or millions of instructions), the result
will be poor performance and scalability.
Furthermore, some of the Linux kernel's lock implementations favor
readers over writers (which can be OK), but to the extent of starving
waiting writers (which can be a big problem).

<p>This is, of course, why RCU is often used, but RCU has different
semantics than do reader-writer locks.
In a surprisingly large number of situations, this difference in
semantics is not a problem. However, there are some parts of the
Linux kernel that are notoriously difficult to apply RCU to.
This situation has motivated a number of attempts to find more
scalable implementations of reader-writer locking, going all the
way back to <tt>brlock</tt> in the 2.4 Linux kernel
(which has since been replaced by <tt><a href="/Articles/401738/">lglocks</a></tt>).
These implementations provide a lock for each CPU.
To read-acquire a lock, a CPU acquires its own lock, which still
requires an atomic instruction and memory barrier on most architectures,
but does <i>not</i> incur a cache miss in the absence of writers.
Writers must acquire all CPUs' locks, which requires an atomic
instruction and usually a cache miss per CPU.
This overhead increases linearly with the number of CPUs, which
can result in high overhead for updates.

<p>In some cases, decreased read-side overhead is required.
One
<a href="http://lkml.org/lkml/2006/10/26/73">scheme</a>
was put forward by Gautham Shenoy, and a similar
<a href="https://patchwork.kernel.org/patch/2157401">approach</a>
was put forward by Srivatsa Bhat.
The idea behind both of these patches is that readers check a flag
before entering their read-side critical sections.
If that flag indicates that there are no writers, then
the readers proceed without executing any atomic instructions or
memory barriers, and, in the common case, without incurring any
cache misses.
However, nothing comes for free, and for these approaches,
the penalty is paid by the writers.

<p>A writer must first set the flag, then wait for all the
pre-existing readers, who might have loaded the flag before
the writer set it.
This is handled by requiring readers to check the flag within
an RCU read-side critical section, and, if the flag is clear,
to execute their entire read-side critical section under RCU
protection.
This allows the writer to use <tt>synchronize_rcu()</tt>
after setting the flag to wait for pre-existing readers.
Of course, the resulting grace-period latency
can be problematic in many cases.
This latency can be reduced by using expedited grace-period
primitives such as
<tt>synchronize_rcu_expedited()</tt>, but these result
in high CPU overhead as well as a set of inter-processor interrupts (IPIs)
to other CPUs. 
The high overhead can reduce throughput, and the IPIs can
spell trouble for real-time applications.

<p>Liu, Zhang, and Chen take a slightly different approach in their
<a href="http://blogs.usenix.org/conference/atc14/technical-sessions/presentation/liu">USENIX paper</a>.
As noted earlier, they use
a special-purpose RCU implementation tailored specifically for
reader-writer locking, which they call a "passive reader-writer lock" or prwlock.
In a manner roughly similar to
<a href="http://urcu.so">signal-based user-space RCU</a>,
writers increment a version number, and then wait for all CPUs
to acknowledge the new version.
Readers automatically acknowledge when acquiring or releasing the
lock, but CPUs that are not using the lock will not
acknowledge the new version.

<p>One way of handling this would be to place full memory barriers in
the read-side code, but this group decided to strive for ultimate
read-side performance, which means that the read-to-write transition
involves IPIs.
The idea is that if a given CPU has not either entered or exited a
read-side critical section in a timely fashion,
it is sent an IPI, which causes it to respond.
The group also looked at a few optimizations, including scoping the
IPIs on a per-process basis for <tt>mmap_sem</tt>, optimizing the
wakeup path, and, for user-space implementations, using an in-kernel helper
similar in some ways to
<a href="/Articles/369567/"><tt>sys_membarrier()</tt></a>.
This optimized reader-writer lock provided significant increases in
performance for systems of up to 64 CPUs on a number of workloads
(see pages 11-13 of the
paper 
for details).

<p>Like most conferences, USENIX imposes strict length limits,
which means that this paper does leave some unanswered questions.

<p>One question is whether the number of
IPIs could be reduced by taking advantage of the Linux kernel's
per-CPU dyntick-idle state.
This seems possible, and it seems especially beneficial for
<a href="/Articles/549580/"><tt>NO_HZ_FULL</tt></a>
kernels, where it would prevent IPIing time-critical user-mode realtime
and HPC applications.
It would be interesting to see how this approach plays out.

<p>A second question involves Figure&nbsp;17 on page&nbsp;12, which shows that
an RCU-based resizable hash table takes considerably longer to resize than
does one protected by the prwlock.
This is quite true, but it is also true that when using RCU, reads and
updates can proceed concurrently with the resizing.
It would be interesting to directly measure the actual effect of a resize
operation on read and update throughput and latency.

<p>A third question involves the paper's comparison of a user-mode
implementation of the reader-writer lock to signal-based user-space RCU.
In this case, the reader-writer lock used an in-kernel optimization.
However, user-space RCU also has an in-kernel optimization in the form
of <tt>sys_membarrier()</tt>.
It would therefore be interesting to compare both
mechanisms using their in-kernel optimizations.
Similarly, it would be interesting to compare prwlock to
RCU expedited grace periods as well as the slower normal
grace periods.

<p>A fourth question involves configuration of the benchmark runs.
For example, the comparisons of prwlock to user-space RCU set user-space
RCU's batch size to one.
This is of course an attractive setting if you wish to
highlight prwlock, but it would be more interesting to
compare against the much larger default setting of 4096 for the batch size.
It also raises the question of how and to what extent prwlock can
amortize single sets of IPIs over the write acquisitions of multiple
prwlocks.

<div class="tlr"><a name="Quick Quiz 3"><b>Quick Quiz 3</b>:</a>
Given the need to examine per-CPU data for each and
every CPU, isn't prwlock inherently non-scalable?
<br><a href="#qq3answer">Answer</a>
</div>

<p>A final question involves scalability, both in terms of numbers
of prwlocks and in terms of system size.
Exploring these areas should provide much interesting future work.
All these questions aside, and in part because of these questions,
this was an extremely interesting paper that might well have significant
practical applicability.

<h4>Conclusions</h4>

<p>It is very good to see increased academic interest in read-mostly
techniques such as RCU.
We can all look forward to much interesting (and hopefully some useful)
work along the way.

</p><h4>Acknowledgments</h4>

<p>We all owe thanks to Davidlohr Bueso, Austin Clements, Hagit Attiya,
Maya Arbel, Eddie Kohler, and Haibo Chen for their help making this
human-readable.
I am grateful to Jim Wasko for his support of this effort.


<h4><a name="Answers to Quick Quizzes">
Answers to Quick Quizzes</a></h4>

<a name="qq1answer"></a>
<p><b>Quick Quiz 1</b>:
But what can I do if I work with production-quality code but
nevertheless would like to discover something new?


</p><p><b>Answer</b>:
There are no guarantees.
That said, here are some things you can try:

<ol class="spacylist">
<li>	Set up automated testing for your code, and make this testing
	as vicious as you possibly can.
	Otherwise, you will be spending all your time dealing with
	bugs and will therefore have no time to discover something new.
	(Yes, it is quite possible that one of your bugs will lead to
	something new, but the odds are stacked against you.)
<li>	Learn as much as you can about the area of your interest.
	However, emphasize learning by doing, and especially try doing
	things wrong to see what happens.
<li>	Study things completely unrelated to your area of interest.
	It is surprising how often standard practice in one area
	inspires something new in another area.
<li>	Seek out trouble, especially when the trouble involves doing
	something that has never been done before.
	(Important safety tip: It is almost as easy to overdo this particular
	piece of advice as it is to avoid it completely.)
<li>	Make heavy use of source-code control systems such as Git in order
	to manage the resulting chaos&mdash;or at least to keep the chaos
	safely removed from your production systems.
</ol>

<p>With some luck, persistence, and hard work, who knows what you might
find?



</p><p><a href="#Quick%20Quiz%201"><b>Back to Quick Quiz 1</b>.</a>

<a name="qq2answer"></a>
<p><b>Quick Quiz 2</b>:
Why don't more academic research projects make full use of open-source
projects such as the Linux kernel?


</p><p><b>Answer</b>:
As you can see from this article, a goodly number of researchers do use
Linux.
That said, the size and complexity of the Linux kernel can be problematic
for some research projects&mdash;considerable courage and talent are
required to take on Linux-kernel internals.


</p><p><a href="#Quick%20Quiz%202"><b>Back to Quick Quiz 2</b>.</a>

<a name="qq3answer"></a>
<p><b>Quick Quiz 3</b>:
Given the need to examine per-CPU data for each and
every CPU, isn't prwlock inherently non-scalable?


</p><p><b>Answer</b>:
Not necessarily.

<p>For example, there is no reason why multiple kernel threads could not
be brought to bear in order to parallelize the scan of the per-CPU data.
In fact, if examining one CPU's data required 100&nbsp;ns and waking
up a helper kthread required 5&nbsp;us, then it might make sense to
provision a helper kthread for each group of (say) 100 CPUs.

<p>That said, this approach would get quite &ldquo;interesting&rdquo; from
irq-disabled regions of code.


</p><p><a href="#Quick%20Quiz%203"><b>Back to Quick Quiz 3</b>.</a><br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Read-copy-update">Read-copy-update</a></td></tr>
            <tr><td><a href="/Archives/GuestIndex/">GuestArticles</a></td><td><a href="/Archives/GuestIndex/#McKenney_Paul_E.">McKenney, Paul E.</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/619355/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor620338"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Recent read-mostly research</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 13, 2014 15:04 UTC (Thu)
                               by <b>etienne</b> (guest, #25256)
                              [<a href="/Articles/620338/">Link</a>] (3 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Validation is one important area in which breakthroughs would be quite welcome.</font><br>
<p>
I understand that the target is to optimize the Linux kernel when the number of processor grows to large numbers, but the fact that Linux still has to work on single processor systems - or dual processor where one of them is reserved for some special tasks - should not be underestimated.<br>
<p>
My current problem is probably not related at all - but I have hard freeze (no SysReq response) sometimes when I boot with "maxcpus=0" Linux parameter.<br>
It would be nice to know if some cases of this RCU (that I do not completely understand) requires at least two processors (then at least printk a message).<br>
For instance, does hardware lockup detection relies on the secondary processor to check the health of the primary processor and see if it is permanently stuck somewhere? Then that will not work on single processor...<br>
Also, is there some cases where RCU will wait for another processor to un-stuck the algorithm?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/620338/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor620361"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Recent read-mostly research</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 13, 2014 16:32 UTC (Thu)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/620361/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      If you really meant &ldquo;maxcpus=0&rdquo;, then all I can do is point you at <a href="https://lkml.org/lkml/2012/3/31/131">this patch</a>.  Or you could try booting with &ldquo;maxcpus=-1&rdquo;.  ;-)

<p>If you instead meant &ldquo;maxcpus=1&rdquo;, then RCU should work just fine.  I frequently test in this mode, both with preemption on (which uses TREE_PREEMPT_RCU) and off (which uses TINY_RCU), and it boots and runs just fine in both cases.  If you have already posted your .config and hardware setup to LKML, feel free to send me the corresponding URL.
      
          <div class="CommentReplyButton">
            <form action="/Articles/620361/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor620384"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Recent read-mostly research</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 13, 2014 17:23 UTC (Thu)
                               by <b>etienne</b> (guest, #25256)
                              [<a href="/Articles/620384/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; If you really meant “maxcpus=0”</font><br>
<p>
Funny patch linked.<br>
<p>
BTW:<br>
maxcpus= [SMP] Maximum number of processors that an SMP kernel should make use of.  maxcpus=n : n &gt;= 0 limits the kernel to using 'n' processors. n=0 is a special case, it is equivalent to "nosmp", which also disables the IO APIC.<br>
<p>
Tried with "maxcpus=1", seeing same behaviour - but as I said the pb is probably not even linked to RCU.<br>
That card is anyway so new the soldering isn't cold yet...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/620384/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor620408"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Recent read-mostly research</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 13, 2014 18:12 UTC (Thu)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/620408/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Good point -- I clearly should have looked at Documentation/kernel-parameters.txt before replying.  Sounds like you are having too much fun!  ;-)<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/620408/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor620866"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Recent read-mostly research</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 17, 2014 12:20 UTC (Mon)
                               by <b>pbonzini</b> (subscriber, #60935)
                              [<a href="/Articles/620866/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
KVM is sometimes using SRCU even when readers can never sleep, just to have smaller grace periods without resorting to synchronized_rcu_expedited.<br>
<p>
synchronized_srcu is enough---in this case the readers are even running in atomic context so they should be exiting very soon anyway.  But even then, synchronized_srcu_expedited is basically just busy-waiting longer for the readers to exit, so the cost is mostly borne by the CPU that executes the writer.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/620866/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor620904"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Recent read-mostly research</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 17, 2014 15:44 UTC (Mon)
                               by <b>PaulMcKenney</b> (<b>&#x272D; supporter &#x272D;</b>, #9624)
                              [<a href="/Articles/620904/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Good point!<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/620904/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2014, Eklektix, Inc.<BR>
            
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
