        <!DOCTYPE html>
        <html lang="en">
        <head><title>Per-entity load tracking [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/531853/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/531496/">Return to the Kernel page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/531853/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>Per-entity load tracking</h1>
</div>
<div class="ArticleText">
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>January 9, 2013</br>
           </div>
The Linux kernel's CPU scheduler has a challenging task: it must allocate access
to the system's processors in a way that is fair and responsive while
maximizing system throughput and minimizing power consumption.  Users
expect these results regardless of the characteristics of their own
workloads, and regardless of the fact that those objectives are often in
conflict with each other.  So it is not surprising that the kernel has been
through a few CPU schedulers over the years.  That said, things have
seemed relatively stable in recent times; the current "completely
fair scheduler" (CFS) was merged for 2.6.23 in 2007.  But, behind that
apparent stability, a lot has changed, and one of the most significant
changes in some time was merged for the 3.8 release.

<p>
Perfect scheduling requires a crystal ball; when the kernel knows exactly
what demands every process will make on the system and when, it can schedule
those processes optimally.  Unfortunately, hardware manufacturers continue
to push affordable prediction-offload devices back in their roadmaps, so
the scheduler has to be able to muddle through in their absence.  Said
muddling tends to be based on the information that is actually available,
with each process's past performance being at the top of the list.  But,
interestingly, while the kernel closely tracks how much time each process
actually spends running, it does not have a clear idea of how much each
process is contributing to the load on the system.
<p>
One might well ask whether there is a difference between "CPU time
consumed" and "load."  The answer, at least as embodied in Paul Turner's
<a href="/Articles/513135/">per-entity load tracking</a> patch set, which
was merged for 3.8, would 
appear to be "yes."  A process can contribute to load even if it is not
actually running at the moment; a process waiting for its turn in the CPU
is an example.  "Load" is also meant to be an instantaneous quantity — how
much is a process loading the system right now? — as opposed to a
cumulative property like CPU usage.  A long-running process that consumed
vast amounts of processor time last week may have very modest needs at the
moment; such a process is contributing very little to load now, despite its
rather more demanding behavior in the past.
<p>
The CFS scheduler (in 3.7 and prior kernels) tracks load on a per-run-queue
basis.  It's worth noting that "the" run queue in CFS is actually a long
list of queues; at a minimum, there is one for each CPU.  When group
scheduling is in use, though, each control group has its own per-CPU run
queue array.  Occasionally the scheduler will account for how much each run
queue is contributing to the load on the system as a whole.  Accounting at
that level is sufficient to help the group scheduler allocate CPU time
between control groups, but it leaves the system as a whole unaware of
exactly where the current load is coming from.  Tracking load at the run queue
level also tends to yield widely varying estimates even when the workload is
relatively stable.
<p><blockquote class="ad">
<b><tt>$ sudo subscribe today</tt></b>
<p>
Subscribe today and elevate your LWN privileges. You’ll have
access to all of LWN’s high-quality articles as soon as they’re
published, and help support LWN in the process.  <a href="https://lwn.net/Promo/nst-sudo/claim">Act now</a> and you can start with a free trial subscription.
</blockquote>
<p>
<h4>Toward better load tracking</h4>
<p>
Per-entity load tracking addresses these problems by pushing this tracking
down to the level of 
individual "scheduling entities" — a process or a control group full of
processes.  To that end, (wall clock) time is viewed as a sequence of 1ms
(actually, 1024µs) periods.  An entity's contribution to the system load in
a period <i>p<sub>i</sub></i> is just the portion of that period that the
entity was runnable — either actually running, or waiting for an available
CPU.  The trick, though, is to get an idea of contributed load that covers
more than 1ms of real time; this is managed by adding in a decayed version
of the entity's previous contribution to system load.  If we let
<i>L<sub>i</sub></i> designate the entity's load contribution in period
<i>p<sub>i</sub></i>, then an entity's total contribution can be expressed
as:
<p>
<blockquote>
	<i>L = L<sub>0</sub> + L<sub>1</sub>*y +
	L<sub>2</sub>*y<sup>2</sup> + L<sub>3</sub>*y<sup>3</sup> + ...</i>
</blockquote>
<p>
Where <i>y</i> is the decay factor chosen.  This formula gives the most
weight to the most recent load, but allows past load to influence the
calculation in a decreasing manner.  The nice thing about this series is
that it is not actually necessary to keep an array of past load
contributions; simply multiplying the previous period's total load
contribution by <i>y</i> and adding the new <i>L<sub>0</sub></i> is
sufficient. 
<p>
In the current code, <i>y</i> has been chosen so that <i>y<sup>32</sup></i>
is equal to 0.5 (though, of course, the calculation is done with integer
arithmetic in the kernel).  Thus, an entity's load contribution 32ms in the past is
weighted half as strongly as its current contribution.
<p>
Once we have an idea of the load contributed by runnable processes, that
load can be propagated upward to any containing control groups with a
simple sum.  But, naturally, there are some complications.  Calculating the
load contribution of runnable entities is easy, since the scheduler has to
deal with those entities on a regular basis anyway.  But non-runnable
entities can also contribute to load; the fact a password cracker is
currently waiting on a page fault does not change the fact that it may be
loading the system heavily.  So there needs to be a way of tracking the
load contribution of processes that, by virtue of being blocked, are not
currently the scheduler's concern.
<p>
One could, of course, just iterate through all those processes, decay their
load contribution as usual, and add it to the total.  But that would be a
prohibitively expensive thing to do.  So, instead, the 3.8 scheduler will
simply maintain a separate sum of the "blocked load" contained in each
<tt>cfs_rq</tt> (control-group run queue) structure.  When a process
blocks, its load is subtracted from the total runnable load value and
added to the blocked load instead.  That load can be decayed in the same
manner (by multiplying it by <i>y</i> each period).  When a blocked process
becomes runnable again, its (suitably decayed) load is transferred back to
the runnable load.  Thus, with a bit of accounting during process state
transitions, the scheduler can track load without having to worry about
walking through a long list of blocked processes.
<p>
Another complication is throttled processes — those that are running under
the <a href="/Articles/428230/">CFS bandwidth controller</a> and have used
all of the CPU time available to them in the current period.  Even if those
processes wish to run, and even if the CPU is otherwise idle, the scheduler
will pass them over.  Throttled processes thus
cannot contribute to load, so removing their contribution while they
languish makes sense.  But allowing their load contribution to decay while
they are waiting to be allowed to run again would tend to skew their
contribution downward.  So, in the throttled case, time simply stops for
the affected processes until they emerge from the throttled state.
<p>
<h4>What it is good for</h4>
<p>
The end result of all this work is that the scheduler now has a much
clearer idea of how much each process and scheduler control group is
contributing to the load on the system — and it has all been achieved
without an increase in scheduler overhead.  Better statistics are usually
good, but one might wonder whether this information is truly useful for the
scheduler.
<p>
It does seem that some useful things can be done with a better idea of an
entity's load contribution.  The most obvious target is likely to be load
balancing: distributing the processes on the system so that each CPU is
carrying roughly the same load.  If the kernel knows how much each process
is contributing to system load, it can easily calculate the effect of
migrating that process to another CPU.  The result should be more accurate,
less error-prone load balancing.  There are <a
href="/Articles/521272/">some patches</a> in circulation that make use of
load tracking to improve the scheduler's load balancer; something will
almost certainly make its way toward the mainline in the near future.
<p>
Another feature needing per-entity load tracking is the <a
href="/Articles/520857/">small-task packing patch</a>.  The goal here is to
gather "small" processes onto a small number of CPUs, allowing other
processors in the system to be powered down.  Clearly, this kind of
gathering requires a reliable indicator of which processes are "small";
otherwise, the system is likely to end up in a highly unbalanced state.
<p>
Other subsystems may also be able to use this information; CPU frequency
and power governors should be able to make better guesses about how much
computing power will be needed in the near future, for example.  Now that
the infrastructure is in place, we are likely to see a number of developers
using per-entity load information to optimize the behavior of the system.
It is still not a crystal ball with a view into the future, but, at least,
we now have a better understanding of the present.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Scheduler-Load_tracking">Scheduler/Load tracking</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/531853/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor532355"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 11, 2013 3:31 UTC (Fri)
                               by <b>thoffman</b> (guest, #3063)
                              [<a href="/Articles/532355/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
"Perfect scheduling requires a crystal ball; when the kernel knows exactly what demands every process will make on the system and when, it can schedule those processes optimally".<br>
<p>
Actually, I'm pretty sure that's NP-hard, at least for some definitions of optimal. So it might very well be counterproductive to spend the time obtaining an optimal scheduling.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532355/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532361"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 11, 2013 9:06 UTC (Fri)
                               by <b>ekj</b> (guest, #1524)
                              [<a href="/Articles/532361/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
NP-hard doesn't automatically mean "too hard", just like "solvable in polynomial time" doesn't automatically mean "practical".<br>
<p>
I know you didn't claim that, it's just that I've seen one-to-many arguments that consist of "NP-hard, therefore not doable"<br>
<p>
If a problem scales as 1.1**n and n is expected to be 100 at most, then it's easily doable (barring huge constant factors), a n**7 algorithm is actually more computationally intensive up to a n of about 350.<br>
<p>
I don't know how large the problem-space tends to be for scheduling-problems though.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532361/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor533830"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 24, 2013 1:33 UTC (Thu)
                               by <b>igorrs</b> (guest, #88981)
                              [<a href="/Articles/533830/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Either you misunderstood the quoted text or you quoted the wrong part.<br>
<p>
If you were after PERFECT scheduling, finding the solution would require actual prediction of the future (with a crystal ball, for example ;-)). Time complexity was not at stake in that specific sentence.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/533830/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor532362"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 11, 2013 9:01 UTC (Fri)
                               by <b>dvdeug</b> (guest, #10998)
                              [<a href="/Articles/532362/">Link</a>] (17 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I find this obsession with CPU scheduling a little weird. YMMV, but from seat it's not a problem; Linux performs smoothly under CPU load. On the other hand, I/O load or memory pressure can make using my system practically impossible.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532362/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532393"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 11, 2013 18:19 UTC (Fri)
                               by <b>mathstuf</b> (subscriber, #69389)
                              [<a href="/Articles/532393/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
Not that I know too much about this, but now that I/O would get factored into load, I would think that things like "make --load-average 8" should work better in the face of heavy I/O. The scheduler should also be able to schedule tasks such that the heavy I/O processes aren't run together. I can see some logic behind using the CPU scheduler to help alleviate I/O slowness since the kernel can't do much about I/O speeds, but it can decide when the processes which have a history of making costly I/O get to make more. Memory pressure issues don't make as much sense in the scheduler, but the code covered in the vmpressure_fd article looks promising.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532393/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor532409"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 11, 2013 22:35 UTC (Fri)
                               by <b>man_ls</b> (guest, #15091)
                              [<a href="/Articles/532409/">Link</a>] (13 responses)
      </p>
      
      </div>
      </summary>
      My experience used to be the same. At least those other problems are eco-friendly: just add lots of memory and an insanely fast SSD and be done with it. While adding CPUs generates huge amounts of heat. If not for the planet, do it for your electricity bill -- or your sanity after a year of listening to the airplane jet on top of your desk.
<p>
Nowadays with 4 GB of RAM and an SLC SSD most of my bottlenecks are gone. Oh, and with CONFIG_PREEMPT, of course.
      
          <div class="CommentReplyButton">
            <form action="/Articles/532409/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532426"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 12, 2013 8:49 UTC (Sat)
                               by <b>jospoortvliet</b> (guest, #33164)
                              [<a href="/Articles/532426/">Link</a>] (12 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
even then, copying data to a slow USB drive can lead to minute-long stalls of the entire system. Very embarrassing that this is still such an issue on linux. I am not sure if it is a hardware problem or a software one...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532426/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532431"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 12, 2013 14:53 UTC (Sat)
                               by <b>hummassa</b> (guest, #307)
                              [<a href="/Articles/532431/">Link</a>] (9 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I tend to think it's a problem on "cp", since the same operation, when done via GUI, does not cause (for me) the same stalls. In my head, "cp file /media/usbdrive" tries to copy the files as fast as possible and trips on some strange load condition (ubuntu kernel, most recent, here) while "kde-cp", besides showing a fine progress bar and forecast-time-to-complete, takes approximately the same time to make the copy, without thrashing my whole system.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532431/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532440"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">stalls caused by USB drive copy</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 12, 2013 19:29 UTC (Sat)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/532440/">Link</a>] (8 responses)
      </p>
      
      </div>
      </summary>
      You can't blame 'cp'.  It's the kernel's job to divide up the resources and 'cp' should selfishly concentrate on getting its own work done.  If there is code in the alternative copying software which is specifically designed to leave CPU time slots or whatever for other processes it thinks are more important, I'm against that.

      
          <div class="CommentReplyButton">
            <form action="/Articles/532440/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532453"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">stalls caused by USB drive copy</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 12, 2013 22:01 UTC (Sat)
                               by <b>man_ls</b> (guest, #15091)
                              [<a href="/Articles/532453/">Link</a>] (7 responses)
      </p>
      
      </div>
      </summary>
      I have never seen this. Have you tried with CONFIG_PREEMPT? The kernel does a much better job of not letting random tasks hoard the CPU (or even CPUs these days), interactivity does not suffer even under arbitrary IO load.
      
          <div class="CommentReplyButton">
            <form action="/Articles/532453/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532455"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">stalls caused by USB drive copy</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 12, 2013 23:24 UTC (Sat)
                               by <b>nix</b> (subscriber, #2304)
                              [<a href="/Articles/532455/">Link</a>] (6 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
It's got nothing to do with the CPU. This is a longstanding problem whereby with a sufficiently large copy, cp fills memory up with dirty pages awaiting writeout and then everything freezes solid because until the writeout to the slow block device has finished, there's hardly any memory left to do anything.<br>
<p>
(It used to be much worse: it used to stall basically all I/O to *any* block device due to, IIRC from vague faded memory, everything sharing a single queue. That's not true anymore. So this has got better, though I can't tell whether I don't see it these days because the problem has improved or because machines just have huge amounts of memory these days...)<br>
<p>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532455/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532456"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">stalls caused by USB drive copy</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2013 0:14 UTC (Sun)
                               by <b>man_ls</b> (guest, #15091)
                              [<a href="/Articles/532456/">Link</a>] (4 responses)
      </p>
      
      </div>
      </summary>
      Ah, the old "a process paged all my memory" problem. Looks like bad design in cp then. But to trigger it nowadays you would have to copy a file bigger than free memory (which can be a few GB) to a USB key; I am not sure that this is what jospoortvliet and hummassa were reporting above.
<p>
The solution for the problem you describe should be, as usual, in several places: stop cp from dirtying more pages than it can move to their destination, and make the kernel avoid this behavior in any process. I really don't know how in the general case. To avoid this kind of problem I don't use swap any more, so that a misbehaving process cannot page everything else to disk. I still get severe slowdowns when memory runs out though; I am still trying to figure out how to avoid them.
      
          <div class="CommentReplyButton">
            <form action="/Articles/532456/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532457"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">stalls caused by USB drive copy</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2013 0:22 UTC (Sun)
                               by <b>nybble41</b> (subscriber, #55106)
                              [<a href="/Articles/532457/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
As I'm hardly an expert, take this with a grain of salt, but I put this line in /etc/sysctl.conf (or /etc/sysctl.d/*.conf):<br>
<p>
vm.dirty_bytes = 201326592<br>
<p>
This limits total dirty memory to 192MB before the kernel forces processes to work on writing data to disk rather than dirtying new pages. The default is something like 10% of total RAM. It seems to help.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532457/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor532462"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">stalls caused by USB drive copy</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2013 1:12 UTC (Sun)
                               by <b>cmccabe</b> (guest, #60281)
                              [<a href="/Articles/532462/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I don't think the issue here is cp's fault.  It's the kernel's job to manage the page cache and writeback.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532462/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532466"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">stalls caused by USB drive copy</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2013 1:59 UTC (Sun)
                               by <b>hummassa</b> (guest, #307)
                              [<a href="/Articles/532466/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
if, as nybble41 stated above, vm.dirty_bytes really works, the blame is in the kernel that has a bad default (10% of all RAM) because RAM is cheaper nowadays, but not proportionally faster to access. It causes contention of the cleaning the dirty pages somehow. "cp" just happens to trigger this bug. For information, I can trigger this bug by copying anything (it does not seem to be necessary to be a single file, but a single file happens to trigger it more aggressively apparently) above 1/2 GiB via USB.<br>
Trying to backup my VMs (20G each file) to a USB drive is a nightmare. Usually I do "nice -20 cp" or, more commonly, "kde-cp".<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532466/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor547057"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">stalls caused by USB drive copy</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Apr 11, 2013 20:28 UTC (Thu)
                               by <b>serzan</b> (subscriber, #8155)
                              [<a href="/Articles/547057/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Usually I do "nice -20 cp" or, more commonly, "kde-cp".</font><br>
<p>
have you tried ionice -c 3? though not sure it'd have much of an impact, if thrashing memory is the cause<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/547057/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor717485"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">stalls caused by USB drive copy</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Mar 17, 2017 15:37 UTC (Fri)
                               by <b>plhk</b> (guest, #111928)
                              [<a href="/Articles/717485/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<a href="https://www.spinics.net/lists/linux-mm/msg64864.html">https://www.spinics.net/lists/linux-mm/msg64864.html</a><br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/717485/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
</details>
<a name="CommAnchor532473"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2013 9:32 UTC (Sun)
                               by <b>BlueLightning</b> (subscriber, #38978)
                              [<a href="/Articles/532473/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <i>even then, copying data to a slow USB drive can lead to minute-long stalls of the entire system. Very embarrassing that this is still such an issue on linux. I am not sure if it is a hardware problem or a software one...</i>

<p>Have you seen this issue recently? I'm sure I read an LWN article a year or two ago where it was described how this issue was tracked down to a change in the I/O buffer window sizing or something similar (and fixed).
      
          <div class="CommentReplyButton">
            <form action="/Articles/532473/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor532477"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 13, 2013 12:56 UTC (Sun)
                               by <b>hummassa</b> (guest, #307)
                              [<a href="/Articles/532477/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I had this problem fairly recently (two months ago), i suppose my kernel was already Quantal's (today it's 3.5.0-21).<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532477/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
</details>
<a name="CommAnchor532419"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 12, 2013 1:57 UTC (Sat)
                               by <b>butlerm</b> (subscriber, #13312)
                              [<a href="/Articles/532419/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; Linux performs smoothly under CPU load.</font><br>
<p>
Historically speaking, Linux has always prioritized throughput over "smoothness".  If you want something resembling soft real time response, you must abstain from using EXT3, set the swappiness to zero, and use a kernel compiled with CONFIG_PREEMPT or something like it, a version not afflicted with the more recent "stable pages" feature.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/532419/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor532444"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">Per-entity load tracking</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 12, 2013 19:43 UTC (Sat)
                               by <b>giraffedata</b> (guest, #1954)
                              [<a href="/Articles/532444/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Adding to the confusion over the historical focus on CPU time like it's the only resource, this project (apparently for the first time) adds paging device time.  So now it's an arbitrary <em>pair</em> of resources, while still leaving out other major resources, including filesystem device time and network time.
      
          <div class="CommentReplyButton">
            <form action="/Articles/532444/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2013, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
