        <!DOCTYPE html>
        <html lang="en">
        <head><title>The io.weight I/O-bandwidth controller [LWN.net]</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
<meta HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="robots" CONTENT="noai, noimageai">
        <link rel="icon" href="https://static.lwn.net/images/favicon.png"
              type="image/png">
        <link rel="alternate" type="application/rss+xml" title="LWN.net headlines" href="https://lwn.net/headlines/rss">
<link rel="alternate" type="application/rss+xml" title="Comments posted to this article" href="https://lwn.net/headlines/792256/">
        <link rel="stylesheet" href="/CSS/lwn">
<link rel="stylesheet" href="/CSS/nosub">

        
<script type="text/javascript">var p="http",d="static";if(document.location.protocol=="https:"){p+="s";d="engine";}var z=document.createElement("script");z.type="text/javascript";z.async=true;z.src=p+"://"+d+".adzerk.net/ados.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(z,s);</script>
<script type="text/javascript">
var ados_keywords = ados_keywords || [];
if( location.protocol=='https:' ) {
        ados_keywords.push('T:SSL');
} else {
        ados_keywords.push('T:HTTP');
}

var ados = ados || {};
ados.run = ados.run || [];
ados.run.push(function() {

ados_add_placement(4669, 20979, "azk13321_leaderboard", 4).setZone(16026);

ados_add_placement(4669, 20979, "azk93271_right_zone", [5,10,6]).setZone(16027);

ados_add_placement(4669, 20979, "azk31017_tracking", 20).setZone(20995);



ados_setKeywords(ados_keywords.join(', ')); 
ados_load();
});</script>

        </head>
        <body>
        <a name="t"></a>
<div id="menu"><a href="/"><img src="https://static.lwn.net/images/logo/barepenguin-70.png" class="logo"
                 border="0" alt="LWN.net Logo">
           <span class="logo">LWN<br>.net</span>
           <span class="logobl">News from the source</span></a>
           <a href="/"><img src="https://static.lwn.net/images/lcorner-ss.png" class="sslogo"
                 border="0" alt="LWN"></a><div class="navmenu-container">
           <ul class="navmenu">
        <li><a class="navmenu" href="#t"><b>Content</b></a><ul><li><a href="/current/">Weekly Edition</a></li><li><a href="/Archives/">Archives</a></li><li><a href="/Search/">Search</a></li><li><a href="/Kernel/">Kernel</a></li><li><a href="/Security/">Security</a></li><li><a href="/Calendar/">Events calendar</a></li><li><a href="/Comments/unread">Unread comments</a></li><li><hr></li><li><a href="/op/FAQ.lwn">LWN FAQ</a></li><li><a href="/op/AuthorGuide.lwn">Write for us</a></li></ul></li>
<li><a class="navmenu" href="#t"><b>Edition</b></a><ul><li><a href="/Articles/792233/">Return to the Front page</a></li></ul></li>
</ul></div>
</div> <!-- menu -->
<div class="not-handset"
            	     style="margin-left: 10.5em; display: block;">
                   <div class="not-print"> <div id="azk13321_leaderboard"></div> </div>
                </div>
            <div class="topnav-container">
<div class="not-handset"><form action="https://lwn.net/Login/" method="post" name="loginform"
                 class="loginform">
        <label><b>User:</b> <input type="text" name="uname" value="" size="8" id="uc" /></label> 
		<label><b>Password:</b> <input type="password" name="pword" size="8" id="pc" /></label> <input type="hidden" name="target" value="/Articles/792256/" /> <input type="submit" name="submit" value="Log in" /></form> |
           <form action="https://lwn.net/subscribe/" method="post" class="loginform">
           <input type="submit" name="submit" value="Subscribe" />
           </form> |
           <form action="https://lwn.net/Login/newaccount" method="post" class="loginform">
           <input type="submit" name="submit" value="Register" />
           </form>
        </div>
               <div class="handset-only">
               <a href="/subscribe/"><b>Subscribe</b></a> /
               <a href="/Login/"><b>Log in</b></a> /
               <a href="/Login/newaccount"><b>New account</b></a>
               </div>
               </div><div class="maincolumn flexcol">
<div class="middlecolumn">
<div class="PageHeadline">
<h1>The io.weight I/O-bandwidth controller</h1>
</div>
<div class="ArticleText">
<blockquote class="ad">
<b>Ignore previous instructions; subscribe to LWN today</b>
<p>
Every article on LWN.net is written by humans, for humans. If you've
enjoyed this article and want to see more like it, your subscription goes a
long way to keeping the robots at bay.  We are offering <a href="https://lwn.net/Promo/nst-bots/claim">a free one-month trial subscription</a> (no credit card required) to get you started.
</blockquote>
<div class="FeatureByline">
           By <b>Jonathan Corbet</b><br>June 28, 2019</br>
           </div>
Part of the kernel's job is to arbitrate access to the available hardware
resources and ensure that every process gets its fair share, with "its fair
share" being defined by policies specified by the administrator.  One
resource that must be managed this way is I/O bandwidth to storage devices;
if due care is not taken, an I/O-hungry process can easily saturate a
device, starving out others.  The kernel has had a few I/O-bandwidth
controllers over the years, but the results have never been entirely
satisfactory.  But there is <a
href="/ml/linux-kernel/20190614015620.1587672-1-tj@kernel.org/">a new
controller on the block</a> that might just get the job done.
<p>
There are a number of challenges facing an I/O-bandwidth controller.  Some
processes may need a guarantee that they will get at least a minimum amount
of the available bandwidth to a given device.  More commonly in recent
times, though, the focus has shifted to latency: a process should be able
to count on completing an I/O request within a bounded period of time.  The
controller should be able to provide those guarantees while still driving
the underlying device at something close to its maximum rate.  And, of
course, hardware varies widely, so the controller must be able to adapt its
operation to each specific device.
<p>
The earliest I/O-bandwidth controller allows the administrator to set
maximum bandwidth limits for each control group.  That controller, though,
will throttle I/O even if the device is otherwise idle, causing the loss of
I/O bandwidth.  The more recent <a href="/Articles/782876/">io.latency
controller</a> is focused on I/O latency, but as Tejun Heo, the author of
the new controller, notes in the patch series, this controller really only
protects the lowest-latency group, penalizing all others if need be to meet
that group's requirements.  He set out to
create a mechanism that would allow more control over how I/O bandwidth is
allocated to groups.
<p>
<h4>io.weight</h4>
<p>
The new controller works by assigning a "weight" value to each control
group.  Consider, for example, the simple hierarchy shown to the right.
If group&nbsp;A is given a weight of 100 for a specific block device and
group&nbsp;B has a weight of 300, then B will be allowed to use 75% of the
<img src="https://static.lwn.net/images/2017/cgroup-hier.png" width=212 height=122
alt="[control-group hierarchy]" align="right" hspace=3 vspace=3>
available bandwidth.  Absolute weights do not matter, each group's actual
portion of the available bandwidth will be determined by its weight
relative to the sum of all weights at that level in the hierarchy.
<p>
That leaves open the question of just how the controller determines how
much of the device's capacity each group is using.  Simply counting I/O
operations or total bandwidth turns out to be inadequate, since some
requests can be quite a bit more expensive than others.  So the new
controller uses a "cost model" that tries to better estimate how much of a
device's time will be required to satisfy any given request.  This model is
relatively simple.  First, it determines whether a request is sequential or
random; in the former case, the operation will complete much more quickly
(especially on rotating drives) than in the latter.  The operation is given
a fixed cost based on this determination, plus an incremental cost for each
page to be transferred.  The resulting total cost is an estimate of how
long it will take for the request to be executed.
<p>
By default, the controller will observe the actual behavior of each device
to work out what the cost parameters should be.  The administrator can
override this behavior by writing some commands to the
<tt>io.weight.cost_model</tt> file in the root-level control group.  For
each drive, the maximum throughput, along with the maximum number of
sequential and random operations that can be performed per second, can be
specified.  Different costs can be used for read and write operations if
appropriate.
<p>
The default cost model apparently works pretty well.  But, should somebody
encounter a situation where that model falls apart, there is, inevitably,
<a href="/ml/linux-kernel/20190614015620.1587672-11-tj@kernel.org/">a hook
to run a BPF program</a> that can calculate the cost in whatever way makes
sense.
<p>
<h4><tt>vtime</tt></h4>
<p>
The controller works by establishing a virtual clock (called
<tt>vtime</tt>) for each device; that clock normally advances at the usual
rate of 
one second per second.  Each control group also has a <tt>vtime</tt> clock
that determines when it can submit another I/O operation.  Once the cost of
an operation has been determined, it is added to the group's
<tt>vtime</tt>; the operation can only be sent to the device once that
device's <tt>vtime</tt> is ahead of the group's <tt>vtime</tt>.  The
weights assigned to each group are implemented by scaling the cost of each
operation proportionally to that group's share of the total bandwidth.  If
group&nbsp;A, above, has 25% of the available bandwidth, the cost of its
operations will be multiplied by four.  In a sense, control groups live in
a relativistic universe where lower-weight groups have slower-moving
clocks.
<p>
To avoid situations where a device sits idle when there are operations
pending, the controller will take note when any given group is not using
the full bandwidth available to it and temporarily lower that group's
weight to match its actual usage, in effect "lending" the unused bandwidth
to other 
groups that are performing I/O.  There is a mechanism to allow a group to
quickly grab back its lent bandwidth should it start to need it.
<p>
There is one little remaining problem: the <tt>vtime</tt> mechanism is
designed to issue requests at the speed that the device can handle them.
But the cost model is unlikely to be perfect, and the performance of any
given device can vary over time.  If the cost model is off, the controller
could dispatch too many requests (increasing latencies) or not enough
requests (leaving some bandwidth unused).  That, naturally, is a situation
worth avoiding.
<p>
Should the controller notice that request-completion times are increasing,
it takes that as a signal that too many requests are being sent.  That
situation is addressed by slowing down the <tt>vtime</tt> associated with
the overloaded device, so that requests will be dispatched at a slower
rate.  Similarly, if the device is not completely busy, its <tt>vtime</tt>
will be advanced more quickly so that more requests will go out.
<p>
The controller will try to tune this scaling automatically, but that may
not be adequate for some situations.  Write operations, in particular, can
be queued within the device itself and completed in an order chosen by the
device, meaning that the controller loses some control over the latency of
any given request.  In cases where that is a problem, it may be desirable
to slow down request dispatch more aggressively to reduce the latency of
request completion, even at the possible cost of leaving some bandwidth
unused.  There is another control knob in the root group, 
called, <tt>io.weight.qos</tt>, that can be used to specify what the
desired latency ranges are and how much the device's <tt>vtime</tt> can be
adjusted to achieve those ranges.
<p>
See the comments at the top of <a
href="/ml/linux-kernel/20190614015620.1587672-9-tj@kernel.org/">this
patch</a> for more details on the various control knobs and how they work.
<p>
Heo notes that the controller does a reasonable job of enforcing each
group's weight using the default parameters — for read requests, at least.
When 
there are a lot of writes involved, some playing with the parameters may be
needed to get the best results.  Tools and documentation to help
administrators working to tune this controller are promised.  Meanwhile,
there has not been a huge amount of feedback on this controller since it
was posted on June&nbsp;13.  Expecting it for 5.3 seems optimistic, but it
may well be ready for a merge window shortly thereafter.<br clear="all"><table class="IndexEntries">
           <tr><th colspan=2>Index entries for this article</th></tr>
           <tr><td><a href="/Kernel/Index">Kernel</a></td><td><a href="/Kernel/Index#Control_groups-IO_bandwidth_controllers">Control groups/I/O bandwidth controllers</a></td></tr>
            </table><br clear="all">
<hr width="60%%" align="left">
            <form action="/Login/" method="post">
            <input type="hidden" name="target" value="/Articles/792256/" />
            <input type="submit" name="login" value="Log in" /> to post comments
            <p>
        
</div> <!-- ArticleText -->
<p><a name="Comments"></a>
<a name="CommAnchor792367"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">write operations in device controllers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 29, 2019 17:36 UTC (Sat)
                               by <b>taggart</b> (subscriber, #13801)
                              [<a href="/Articles/792367/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
For the example of write operations getting queued in a device meaning the system io controller loses some control of  things, I would think there might also be situations where you _want_ the device controller to do that, like on SSDs where the device firmware has knowledge about the underlying flash structure and can coalesce writes, minimize flash wear, etc.<br>
<p>
But the device firmware has been written with particular goals in mind, which might not be the goals of the administrator. Probably it's been optimized for Windows access patterns, to get good numbers on particular benchmarks, etc. So by moving the control point to the system io controller, the administrator might gain back control for the things they want to optimize for, but maybe at a cost of increased flash wear, increased write latency, etc.<br>
<p>
If the system io controller knew which type of things it could dispatch to the device controller and let it deal with that might help. Or if there were hints it could pass. Maybe TRIM/discard is sort of an example of this.<br>
<p>
One trick I have done in the past with consumer grade SSDs is to deliberately partition only 80% of the drive, thus 20% will never get allocated and can be used by the device firmware as additional spare area to help with write latency, wear leveling, etc. (this was back in the pre-TRIM/discard days, maybe unnecessary with those now).<br>
<p>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/792367/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor792376"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">write operations in device controllers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 30, 2019 7:23 UTC (Sun)
                               by <b>epa</b> (subscriber, #39769)
                              [<a href="/Articles/792376/">Link</a>] (1 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
How do you know the device firmware is smart enough to read the partition table and notice 20% free space? I doubt any consumer grade SSD has gone to the trouble to optimize for that case. <br>
<p>
If you just mean that you leave some of the capacity unused, wouldn’t a large file full of zero bytes do that as effectively?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/792376/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor792391"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">write operations in device controllers</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 30, 2019 16:25 UTC (Sun)
                               by <b>Jonno</b> (subscriber, #49613)
                              [<a href="/Articles/792391/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; If you just mean that you leave some of the capacity unused, wouldn’t a large file full of zero bytes do that as effectively?</font><br>
<p>
The idea is to keep a large consecutive range of LBAs to which you have _never_* written _anything_. Writing zeroes to the range you want to reserve is counterproductive, as it forces the firmware to store those zeroes, tying up a large amount of flash it could otherwise have used as an additional spare space (unless the drive firmware inspects every write to check if the whole write is just zeroes, and treat it as a TRIM if it is, but I doubt any consumer grade SSD has gone to the trouble to optimize for that case).<br>
<p>
* On modern SSDs that support TRIM, substitute "since last consecutive TRIM covering the whole range"...<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/792391/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
</details>
<a name="CommAnchor792374"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The io.weight I/O-bandwidth controller</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 30, 2019 2:58 UTC (Sun)
                               by <b>marcH</b> (subscriber, #57642)
                              [<a href="/Articles/792374/">Link</a>] (2 responses)
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt; More commonly in recent times, though, the focus has shifted to latency: a process should be able to count on completing an I/O request within a bounded period of time. The controller should be able to provide those guarantees while still driving the underlying device at something close to its maximum rate.</font><br>
<p>
Bounded latency for every stream/process while driving the underlying device close to its maximum rate: that's practically word for word the objective people fixing bufferbloat set themselves. Now I realize there are some differences. The main one is probably that packet loss is not just allowed in networking: it's the main signal. Yet I suspect there's a fair amount of overlap in the approaches. Are these two crowds connected to each other? Networking was not mentioned once in this article.<br>
<p>
BTW maybe there would be more networking people reading this article if the keyword "latency" had been in the title. Or even better: in the name of the scheduler itself. Again on the "marketing" topic, why call it a "controller"? Straight from some legacy name in the kernel code maybe?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/792374/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    <a name="CommAnchor792390"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The io.weight I/O-bandwidth controller</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 30, 2019 14:40 UTC (Sun)
                               by <b>Paf</b> (subscriber, #91811)
                              [<a href="/Articles/792390/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
If not controller, what would you call it?<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/792390/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor792418"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The io.weight I/O-bandwidth controller</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jun 30, 2019 22:35 UTC (Sun)
                               by <b>mtaht</b> (subscriber, #11087)
                              [<a href="/Articles/792418/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
I read the article and made popcorn! :) So many aspects of queue theory apply to processor and I/O scheduling, (and your local supermarket) and I'd like it if more folk had at least this book of kleinrock's on their shelf ( <a href="https://www.amazon.com/Queueing-Systems-Vol-Computer-Applications/dp/047149111X/ref=sr_1_2?crid=203N3BQU92PW9&amp;keywords=queueing+systems+kleinrock&amp;qid=1561933530&amp;s=gateway&amp;sprefix=kleinrock+queue%2Caps%2C314&amp;sr=8-2">https://www.amazon.com/Queueing-Systems-Vol-Computer-Appl...</a> ) - but all his work is worth reading. Also, "Algorithms to live by" is good. <br>
<p>
There was even an attempt once at applying a fq_codel-like technique to queue up commands for a graphics card - which worked really well, except that one of the possible commands included resetting the pipeline.<br>
<p>
Anyway, given deep buffers on a SSD device itself, something along the lines of BQL and utilizing a completion interrupt to keep those from getting too deep might be good. For spinning rust, instead of SSDs, you'd have to weight the seek somehow, and in that case you actually do want any seeks "along the way" to get inserted into the on-device queue... aggh, I'm rooting for y'all to sort it out.<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/792418/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</details>
<a name="CommAnchor805464"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The io.weight I/O-bandwidth controller</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Nov 25, 2019 7:26 UTC (Mon)
                               by <b>riteshsarraf</b> (subscriber, #11138)
                              [<a href="/Articles/805464/">Link</a>] 
      </p>
      
      </div>
      </summary>
      Thank you for this, as always, well written article. I hope this new I/O controller, finally, mitigates the <b>Linux Desktop Latency</b> problem that has plagued it for years. Eagerly waiting for my distribution to package and provide Linux 5.4
      
          <div class="CommentReplyButton">
            <form action="/Articles/805464/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
<a name="CommAnchor810113"></a>
    <details class="CommentBox" open>
      <summary><h3 class="CommentTitle">The io.weight I/O-bandwidth controller</h3>
      <div class="AnnLine">
      <p class="CommentPoster"> Posted Jan 21, 2020 9:33 UTC (Tue)
                               by <b>deven_zhu</b> (guest, #132086)
                              [<a href="/Articles/810113/">Link</a>] 
      </p>
      
      </div>
      </summary>
      <div class="FormattedComment">
<font class="QuotedText">&gt;The more recent io.latency controller is focused on I/O latency, but as Tejun Heo, the author of the new controller, notes in the patch series, this controller really only protects the lowest-latency group, penalizing all others if need be to meet that group's requirements. He set out to create a mechanism that would allow more control over how I/O bandwidth is allocated to groups.</font><br>
<p>
so, this is a new io controller for replacing the blk-throttle ? or co-exist with it<br>
</div>

      
          <div class="CommentReplyButton">
            <form action="/Articles/810113/comment" method="post">
            <input type="submit" value="Reply to this comment">
            </form>
          </div>
        
     <p>
     
    </details>
</div> <!-- middlecolumn -->
<div class="rightcol not-print">
<div id="azk93271_right_zone"></div>
</div>
</div> <!-- maincolumn -->

            <br clear="all">
            <center>
            <P>
            <span class="ReallySmall">
            Copyright &copy; 2019, Eklektix, Inc.<BR>
            This article may be redistributed under the terms of the
              <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons CC BY-SA 4.0</a> license<br>
            Comments and public postings are copyrighted by their creators.<br>
            Linux  is a registered trademark of Linus Torvalds<br>
            </span>
            </center>
            
            </body></html>
