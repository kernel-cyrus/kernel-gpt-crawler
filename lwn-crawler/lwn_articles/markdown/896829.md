# What constitutes disclosure of a kernel vulnerability? [LWN.net]

By
Jonathan Corbet
June 3, 2022
Opinions differ on the best way to disclose security vulnerabilities, but
there is a general consensus in our community  that vulnerabilities
should, indeed, be 
made public at some point.  What happens between the discovery of a
vulnerability and its disclosure can be more controversial.  A recent
discussion on the handling of kernel vulnerabilities has led to change in
the policies of the linux-distros mailing list — all based on the question
of what constitutes "disclosure".
There are two mailing lists that are commonly used for the discussion of
vulnerabilities in the Linux community; they are not limited to kernel
problems.  The first of these,
linux-distros
,
is a closed list that is used to coordinate the response to non-public
security bugs.  The second,
oss-security
,
is a public list which is used for, among other things, the public
disclosure of vulnerabilities.  Both are administered by Alexander "Solar
Designer" Peslyak.
There is a long list of policies that apply to postings on linux-distros,
including one that requires the public disclosure of all vulnerabilities
reported there within a relatively short period of time.  That rule is there to
ensure that companies don't sit on vulnerability reports indefinitely, no
matter how embarrassing they are.  Another list policy, though, says that
vulnerabilities that are
already
public have no place on
linux-distros; all discussion 
of public vulnerabilities belongs on oss-security instead.  The
implementation of these policies has often proved to be tricky, especially
when dealing with kernel vulnerabilities; see
this 2021 article
for a recent example.
In mid-May, Peslyak
wrote to
oss-security
in search of a solution for the ongoing mismatch between
the list policies and how the kernel project does business.  The core
problem is how security problems are often handled in the kernel community:
For Linux kernel maintainers, it is customary to post a fix
	technically publicly but without indication of its security
	relevance, then work on getting it merged into the various trees,
	and expect that its security relevance wouldn't be clearly
	indicated publicly for a while.
Such patches
tend to
look like this
(though the exploitability of that particular bug has
not been verified here).
According to the linux-distros list policy, this public posting of a fix
makes a particular vulnerability ineligible for discussion there — the
vulnerability has already been disclosed.  But
distributors of the Linux kernel still often want a way to discuss the real
problem, which has not been disclosed yet, under embargo and coordinate the
shipping of the fix to their 
users.  That cannot be done on oss-security, which is public, and it cannot
be done on linux-distros because posting a patch is seen as having
disclosed the vulnerability.
Increasingly, Peslyak said, the linux-distros policy is simply being
ignored when it comes to kernel vulnerabilities; he asked what should be
done about that problem.  One option, he said, would be to continue to look
the other way when a vulnerability for which a public patch is available
shows up on linux-distros.  Alternatives would include strictly enforcing
the policy (and thus forcing kernel vulnerabilities off the list entirely),
changing the list policy, or even just shutting down the list entirely.
As one might expect, a variety of opinions was expressed — though nobody
seemed to be in favor of just killing the list.  Jason Donenfeld
suggested
enforcing
the policy, since kernel developers have little interest in anything but
fixing the bug anyway.  The dominant view, though, seemed to be in favor of
adjusting the list's policies to better fit how the kernel project
operates.  As Donenfeld put it, kernel developers have little interest in
the "security game" and are unlikely to start playing it, but Greg
Kroah-Hartman
described another
reason
for why the kernel project handles security fixes the way it
does:
As you know, there are different "grades" of attackers.  There's a
	huge range from "run metasploit that I just downloaded" to "look at
	this kernel change and figure out how to abuse the system that does
	not have it".  By delaying a small bit of time from publicly
	posting a patch to telling the world that "hey, that was a security
	fix over there" that allows the community that works in the public
	added time for review and testing as our testing infrastructure
	that is NOT public is quite limited and reviews are limited given
	the huge range of needed developers to do that review.
That delay can allow users to have the fix on their system first
	before the "metasploit" package is updated to attack it, which
	reduces the amount of vulnerable systems out there.  Yes, it does
	not solve the "prevent readers of all commits" issue, but I don't
	know what we can really do about that except switch to a closed
	source development model, which isn't a good thing overall anyway.
The review issue is not a small one.  Security fixes are not immune from
the ills that plague software development in general; they can easily
introduce bugs (including security-related bugs) of their own, cause
user-space regressions, and more.  Like all other changes, they benefit
from more review (and extensive testing) before being applied.  There are
limits to how much of 
that review and testing can happen without posting the patch in public.
The benefits of obscuring the security problem motivating a specific patch
may not be quite so clear.  It may well reduce the number of casual attacks
from the people often known as "script kiddies" but, as Kroah-Hartman
pointed out, it does little to defend against capable attackers who are
reading the commit stream for the purpose of finding vulnerabilities.  Even
so, 
it seems clear that there are developers and companies that see good
reasons to keep security problems under wraps, at least for a short period.
Given the perceived value of posting patches without explicitly disclosing
the underlying security issue, Kroah-Hartman
said
, the best
thing to do would be to amend the list policy to allow such posts.  He
suggested that other large projects might also benefit from such a policy.
Peslyak
wasn't
convinced
that those projects, most of which do not use linux-distros
at all, would be interested, but he did, in the end,
decide to
amend the linux-distros policy
to accommodate the kernel's way of doing
things.  Issues with a public fix are themselves considered public, the
policy reads, except when they aren't:
There can be occasional exceptions to this, such as if the
	 publicly accessible fix doesn't look like it's for a security
	 issue and not revealing this publicly right away is somehow deemed
	 desirable.  In particular, we grant such exceptions to Linux
	 kernel issues concurrently or very recently handled by the Linux
	 kernel security team.
Given the lack of subsequent discussion, it seems likely that this change
is acceptable to the list members as a whole.  Meanwhile, Vegard Nossum is
working on
some
changes to the kernel's documentation
to make the policies for the
reporting of security bugs more clear.  None of this will definitively end
the discussions around vulnerability reporting, disclosure, and
mailing-list policies but, with luck, it will make things work a bit more
smoothly than they do now.
Index entries for this article
Kernel
Development model/Security issues
Kernel
Security/Vulnerabilities
to post comments